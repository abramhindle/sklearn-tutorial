@relation large.json
@attribute id integer
@attribute owner string
@attribute content string
@data
3286,'',"knife_hp fog version error\nI'm using ubuntu14.04 LTS, ruby 2.1.5p273, gem-2.2.2, knife-hp-0.4.2 and fog-1.25.0. When i try to list my hp servers, it shows the following error\r\n\r\nroot@megamd:~# knife hp server list -VV\r\nDL is deprecated, please use Fiddle\r\nWARNING: No knife configuration file found\r\nDEBUG: hp_auth_uri: https://region-a.geo-1.identity.hpcloudsvc.com:35357/v2.0/\r\nDEBUG: hp_access_key: ACCESS_KEY\r\nDEBUG: hp_secret_key: SECRET_KEY\r\nDEBUG: hp_tenant_id: TENANT_ID\r\nDEBUG: hp_avl_zone: us-west->'region-a.geo-1'\r\nDEBUG: hp_avl_zone: region-a.geo-1\r\nDEBUG: hp_avl_zone: us-west->'region-a.geo-1'\r\n/usr/local/lib/ruby/gems/2.1.0/gems/fog-1.25.0/lib/fog/hp/core.rb:159:in `authenticate_v2': uninitialized constant Fog::VERSION (NameError)\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/fog-1.25.0/lib/fog/hp/compute_v2.rb:253:in `initialize'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/fog-core-1.25.0/lib/fog/core/service.rb:115:in `new'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/fog-core-1.25.0/lib/fog/core/service.rb:115:in `new'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/fog-core-1.25.0/lib/fog/compute.rb:20:in `new'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/knife-hp-0.4.2/lib/chef/knife/hp_base.rb:79:in `connection'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/knife-hp-0.4.2/lib/chef/knife/hp_server_list.rb:43:in `run'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/chef-11.16.4/lib/chef/knife.rb:493:in `run_with_pretty_exceptions'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/chef-11.16.4/lib/chef/knife.rb:174:in `run'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/chef-11.16.4/lib/chef/application/knife.rb:139:in `run'\r\n\tfrom /usr/local/lib/ruby/gems/2.1.0/gems/chef-11.16.4/bin/knife:25:in `<top (required)>'\r\n\tfrom /usr/local/bin/knife:23:in `load'\r\n\tfrom /usr/local/bin/knife:23:in `<main>'\r\n\r\nwhen i remove  Fog::VERSION from /usr/local/lib/ruby/gems/2.1.0/gems/fog-1.25.0/lib/fog/hp/core.rb:159, it works fine."
3284,'','Remove dependencies on external fog modules\nThis reduces the number of gems that fog installs for most users.\r\nUsers can choose to install modular providers on an as-needed basis.\r\n\r\nI really like that fog is going modular, but I only use AWS so all of these modules are unneeded for me. As a general policy going forward, would you consider not adding new modular providers to the gemspec?'
3283,'',"Can't find owner of S3 Object\nSorry if this is a faq. I'm trying to find the owner of an S3 Object. The following gets owner = nil,\r\nother variations give owner = { 'user_id' => nil, 'display_name' => nil }. I've verified that the ListBucketResult in the html response does include owner.\r\n\r\nAm I doing it wrong?\r\n\r\nRegards\r\nJon\r\n\r\nJon KÃ¥re Hellan, UNINETT AS, Trondheim, Norway\r\n\r\n```\r\n#!/usr/bin/env ruby\r\nrequire 'fog'\r\n\r\nawshost     = 's3.amazonaws.com'\r\nawskey      = '99999999999999999999'\r\nawssecret   = 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz'\r\nbucketname  = 'jk-xyzzy'\r\nfilename    = 'bootstrap.sh'\r\n\r\nconnection = Fog::Storage.new({\r\n  :provider                 => 'AWS',\r\n  :aws_access_key_id        => awskey,\r\n  :aws_secret_access_key    => awssecret,\r\n  :host                     => awshost,\r\n  :scheme                   => 'http',\r\n})\r\nbucket = connection.directories.get(bucketname)\r\nobject = bucket.files.get(filename)\r\nputs object.key\r\np object.owner\r\n```"
3282,'','Rescue "Illegal Seek" exception in case body is a pipe or socket\nAs for Glacier, this is needed for when an unseekable IO is passed in for the body (e.g. end of a Pipe or socket).'
3281,'',"fog --version fails\nError as follows:\r\n\r\n```\r\n$ fog --version\r\n/usr/local/Homebrew/lib/ruby/gems/2.1.0/gems/fog-1.25.0/bin/fog:16:in `block (2 levels) in <top (required)>': uninitialized constant Fog::VERSION (NameError)\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1359:in `call'\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1359:in `block in parse_in_order'\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1346:in `catch'\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1346:in `parse_in_order'\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1340:in `order!'\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1432:in `permute!'\r\nfrom /usr/local/Homebrew/Cellar/ruby/2.1.4/lib/ruby/2.1.0/optparse.rb:1454:in `parse!'\r\nfrom /usr/local/Homebrew/lib/ruby/gems/2.1.0/gems/fog-1.25.0/bin/fog:25:in `<top (required)>'\r\nfrom /usr/local/Homebrew/bin/fog:23:in `load'\r\nfrom /usr/local/Homebrew/bin/fog:23:in `<main>' \r\n```\r\n\r\nThis is the same error that prevents the `rumm` Rackspace utility from functioning, it would seem (see https://github.com/rackspace/rumm/issues/93)."
3279,'',"Don't add all cloud modules as gem dependencies\nThe fog gem currently forces you to load a bunch of extra cloud gems as dependencies when they likely won't be used. These should not be required dependencies so users have the choice to only load the ones they use into their application."
3277,'',"Breaking change to AWS-S3 expiry dates in 1.25.0\nhttps://github.com/fog/fog/commit/b90b6040bcc6ea08c0d8a5cd242634994b593fa9 changes how expiry works to use X-Amz-Expires. It's a good change, but means that URLs need to be 7 days or fewer in the future (previously 1 year+ was fine).\r\n\r\nWorth documenting in the changelog?\r\n"
3276,'','Latest version 1.25.0 is giving errors\n...when writing to S3.\r\n\r\n```\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\nexcon.error.response\r\n  :body          => "<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>InvalidBucketName</Code><Message>The specified bucket is not valid.</Message><BucketName>my-images-production.s3-us-west-2.amazonaws.com/my-images-production</BucketName><RequestId>05B1B32ED41A5F48</RequestId><HostId>/niQQgVnvZtyzw5gU5vFzZPmuaJHqrWn8SA46fxfHDAL4G5uMxDZ81HRRk9aC3x/</HostId></Error>"\r\n  :headers       => {\r\n    "Connection"       => "close"\r\n    "Content-Type"     => "application/xml"\r\n    "Date"             => "Wed, 19 Nov 2014 03:19:05 GMT"\r\n    "Server"           => "AmazonS3"\r\n    "x-amz-id-2"       => "/niQQgVnvZtyzw5gU5vFzZPmuaJHqrWn8SA46fxfHDAL4G5uMxDZ81HRRk9aC3x/"\r\n    "x-amz-request-id" => "05B1B32ED41A5F48"\r\n  }\r\n  :local_address => "172.18.100.42"\r\n  :local_port    => 44768\r\n  :reason_phrase => "Bad Request"\r\n  :remote_ip     => "54.231.165.9"\r\n  :status        => 400\r\n```'
3275,'','Fog broken for Amazon S3 in ap-northeast-1 region after 1.25.0 release.\nFog is broken for me after upgrading to the 1.25.0 release when uploading to Amazon S3 in ap-northeast-1 region. Rolling back to 1.23.0 fixes the issue. Here\'s the error:\r\n\r\n```\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\nexcon.error.response\r\n  :body          => "<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AuthorizationHeaderMalformed</Code><Message>The authorization header is malformed; the region \'us-east-1\' is wrong; expecting \'ap-northeast-1\'</Message><Region>ap-northeast-1</Region><RequestId>XXX</RequestId><HostId>XXXX</HostId></Error>"\r\n  :headers       => {\r\n    "Connection"       => "close"\r\n    "Content-Type"     => "application/xml"\r\n    "Date"             => "Tue, 18 Nov 2014 19:43:20 GMT"\r\n    "Server"           => "AmazonS3"\r\n    "x-amz-id-2"       => "XXXX"\r\n    "x-amz-request-id" => "XXXX"\r\n  }\r\n  :local_address => "X.X.X.X"\r\n  :local_port    => XXXXX\r\n  :reason_phrase => "Bad Request"\r\n  :remote_ip     => "X.X.X.X"\r\n  :status        => 400\r\n.../shared/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/middlewares/expects.rb:6:in `response_call\'\r\n.../shared/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n.../shared/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/connection.rb:365:in `response\'\r\n.../shared/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/connection.rb:235:in `request\'\r\n.../shared/bundle/ruby/2.1.0/gems/fog-xml-0.1.1/lib/fog/xml/sax_parser_connection.rb:37:in `request\'\r\n.../shared/bundle/ruby/2.1.0/gems/fog-xml-0.1.1/lib/fog/xml/connection.rb:7:in `request\'\r\n.../shared/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/storage.rb:521:in `_request\'\r\n.../shared/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/storage.rb:516:in `request\'\r\n.../shared/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/requests/storage/get_bucket.rb:43:in `get_bucket\'\r\n.../shared/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/models/storage/directories.rb:22:in `get\'\r\n```'
3274,'','[aws] - refactor validate_aws_region\nref: http://projects.theforeman.org/issues/8429\r\nthe second condition is not correctly evaluated.'
3273,'','[google|storage] Reintroduce workaround for excon headers issue while ke...\n...eping fix where file_data was not being saved.\r\n\r\nThe last commit undid the excon headers issue workaround and but fixed another issue. This merges them.'
3272,'','[Docker] Parse properly ports and links attributes\nHash based attributes were not parsed properly by container_get. This\r\npatch fixes that and adds support for tty, attach_stdin, attach_stdout,\r\nattach_stderr, links, port bindings and exposed ports.'
3271,'','[AWS] Security Group reload is returning wrong group if same group name exists in EC2-Classic and VPC\nIf you get a Security Group from a VPC by group_id and then call "reload", the reloaded group is the group from EC2-Classic if one exists with the same name.  \r\n\r\n```\r\ng = compute.security_groups.get_by_id "sg-50d54a35"\r\np "#{g.name}  :  #{g.group_id}"\r\n"default  :  sg-50d54a35"\r\n\r\ng.reload\r\np "#{g.name}  :  #{g.group_id}"\r\n"default  :  sg-c6e66af6"\r\n```'
3270,'',"[Docker] Environment variables support\nThis allows the Docker provider to fetch env variables from docker and set them as an array, i.e:\r\n```\r\ncontainer.environment_variables = ['foo=bar', 'baz=qux']\r\n```"
3269,'','Move Terremark to its own gem\n'
3268,'','Handle Docker authentication errors\nFog was not handling at all the error returned by docker-api. This\r\ncommit fixes that and raises an AuthenticationError that can be caught\r\nby Fog clients.\r\n\r\nThere was a bug in the errors code for container_action that this PR\r\nfixes too.'
3267,'','        Fix Dynect job poll bug.\n        Dynect sometimes gives back HTTP 200 instead of 307.\r\n        https://github.com/Netflix/denominator/issues/261\r\n\r\n        We need a workaround for this until it is fixed.'
3266,'','Updating authentication functions to prevent sending expired token.\nWhen the Keystone token expires the existing OpenStack code sends in the expired token along with the re-authentication request.  Unfortunately, newer versions of Keystone error out with a "token not found" error when sending an expired token as a parameter, and logically it makes no sense to do so.\r\n\r\nThis code change will send nil instead of the expired token only in the case where we are re-authenticating and a new token will be retrieved and all calls will carry on as before.  The option to initially authenticate with a valid token still works with no changes.'
3265,'',"Fix 1322\nI'm not sure if the iam user destroy method should be updated to include deleting any policies and access keys first as described [here](http://docs.aws.amazon.com/IAM/latest/UserGuide/Using_DeletingUserFromAccount.html#Using_DeleteUser_APIandCLI), but I didn't want to change the behavior of things just to fix the tests if possible.\r\n\r\nI did end up passing path when creating a role, but seems to work fine with the defaults."
3264,'','Moved Vmfusion to its own gem\n@geemus More work on modularization. =)'
3263,'','[AWS] S3 and public non signed urls \nThis issue comes from this [post](https://groups.google.com/forum/#!topic/ruby-fog/mzVaOoQ3zCQ) on the mailing list.\r\n\r\nIn a nutshell: how to get the public (non signed) url of a public s3 object? (By public object, I mean created with the option `:public => true`).\r\n\r\nRight now, there isn\'t a straightforward way to do that. You can either build the url using something like `"https://#{bucket_name}.s3.amazonaws.com/#{object_name}"` or use the underlying service object with something like `service.request_url(:bucket_name => "foo", :object_name => "bar")`.\r\n\r\nThe idea is to have a more convenient way to do this.\r\n\r\nFrom the linked post, we have two suggestions:\r\n* the "direct" way: a method `get_public_http_url` on `Fog::Storage::AWS::Files` (see the existing methods `get_http_url` and `get_https_url`)\r\n* Enhance the existing `get_http_url` and `get_https_url` methods to support a `:public => true` option.\r\n\r\nThoughts?'
3262,'','[vSphere] Support clusters that are located below folders\nvSphere supports creating folders under datacenters (and clusters within the folders).\r\nThis fix searches for clusters within folders in the datacenter.\r\nref: http://projects.theforeman.org/issues/5855'
3261,'','Bump the API version for DynamoDB put\nIncrement the DynamoDB put item API version to allow for more data types to be used. (L, M, etc.). All the data types are listed here: http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_AttributeValue.html'
3259,'','#3258 - allow modification of ConnectionSettings.IdleTimeout parameter in AWS ELBs\nThis PR adds functionality to AWS::ELB module for adjusting ConnectionSettings.IdleTimeout via AWS::ELB.ModifyLoadBalanceAttributes\r\n'
3258,'','AWS::ELB should allow modifying idle connection timeout attribute\nGiven that AWS provides a mechanism to modify ELB attributes (http://docs.aws.amazon.com/ElasticLoadBalancing/latest/APIReference/API_ModifyLoadBalancerAttributes.html)\r\n\r\nWhen I want to configure idle connection timeouts\r\n\r\nThen Fog::AWS::ELB provides a mechanism for modifying an ELB after it has been created.\r\n\r\nNote: connection draining and cross zone load balancing was implemented in pull #2885 . This issue could also cover adding in `AccessLog` to control ELB logging to S3.\r\n\r\n\r\n'
3257,'','Consider using bundler caching\nShould we be using http://docs.travis-ci.com/user/caching/ ?\r\n\r\nWell over half the time for a travis build is currently spent running bundler'
3256,'','[cloudstack] Extend server interface\n'
3255,'',"Improved OpenNebula support\nThis patch improves Fog's OpenNebula support in a number of ways:\r\nBetter NIC support in VM templates\r\nBetter ability to tune number of CPUs and memory\r\nAbility to add/remove entries from a VM template's context section\r\nAbility to add/remove entries from a VM template's user variables\r\nImproved filtering for templates and NICs"
3254,'',"LoadError: cannot load such file -- nokogiri/nokogiri\nHi. I'm new in Ruby. Pls help me find out the solution for my problem. I've try setup the project, which use For gem, but got he error.\r\n\r\nWhen I try run this command\r\n$ rake tire:import:all:force\r\n\r\nAnd got this error:\r\nrake aborted!\r\nLoadError: cannot load such file -- nokogiri/nokogiri\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.3.1/lib/fog/core/parser.rb:1:in `require'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.3.1/lib/fog/core/parser.rb:1:in `<top (required)>'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.3.1/lib/fog/core.rb:29:in `require'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.3.1/lib/fog/core.rb:29:in `<top (required)>'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.3.1/lib/fog.rb:1:in `require'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.3.1/lib/fog.rb:1:in `<top (required)>'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler/runtime.rb:76:in `require'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler/runtime.rb:76:in `block (2 levels) in require'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler/runtime.rb:72:in `each'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler/runtime.rb:72:in `block in require'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler/runtime.rb:61:in `each'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler/runtime.rb:61:in `require'\r\n/Library/Ruby/Gems/2.0.0/gems/bundler-1.7.4/lib/bundler.rb:133:in `require'\r\n/Users/maxim/Sites/ror/archer/Vision-Institute-development/config/application.rb:13:in `<top (required)>'\r\n/Users/maxim/Sites/ror/archer/Vision-Institute-development/Rakefile:5:in `<top (required)>'\r\n\r\nCan you help me find the solution. THanks. Os X Maverics. \r\n"
3253,'','Modularized Voxel Provider\nMoved Voxel to its own [gem](https://github.com/fog/fog-voxel).'
3252,'',"Improved OpenNebula support\nThis patch improves Fog's OpenNebula support in a number of ways:\r\nBetter NIC support in VM templates\r\nBetter ability to tune number of CPUs and memory\r\nAbility to add/remove entries from a VM template's context section\r\nAbility to add/remove entries from a VM template's user variables\r\nImproved filtering for templates and NICs"
3251,'',"[Openstack|Compute] fix randomly failing spec\nThe security group failure tests have been failing randomly. This happens\r\nbecause the random id assigned by the create security group mock can collide\r\nwith the id (0) of the default security group. The mock data stores the keys\r\nas strings (except) for the default one, meaning that you end up with 2\r\nsecurity groups with id 0, one stored under the key 0 and the other\r\nunder the key '0'\r\n\r\nI've addressed this by storing the default group as '0' (so that it can \r\nbe retrieved properly) and also by changing the create security group mock\r\nso that it will never assign the id 0\r\n\r\nI'm not an openstack user, so review appreciated - just want to stop random\r\nbuild failures. It also occurs to me that perhaps the mock should take\r\nsteps to make duplicate ids impossible - could lead to some hard to reproduce problems if you were using the mocks.\r\n\r\n"
3249,'',"make zones.get(domain_or_id) work, same as dnsimple\nzones.find() returns nil if not found\r\nWhile it does result in two calls, it now functions similarly to dnsimple.\r\nDo we have a definition for how the top levels should work across providers?\r\n\r\ndns.zones.get('domainname.com') makes the most sense to me\r\n\r\n"
3248,'','[Google] Add ubuntu-os-cloud to list of global projects\nhttps://cloud.google.com/compute/docs/operating-systems#ubuntu'
3246,'',"Don't attempt to rewind IO if it's not offset\nThis will permit the passing in of pipes, sockets, or other IO objects that\r\ndon't support the #rewind method."
3245,'','[Fog|Core] Move fog/core/parser to fog-xml gem\n'
3244,'',"[AWS|Storage] update post_object_hidden_fields to use signature v4\nI missed this during my first pass to update everything to v4. I've tested this with some sample code I threw together and it does let you upload files to S3 but this isn't something I use day to day - can anyone who does use it verify I haven't changed behaviour?"
3243,'','[rackspace] add :type to LoadBalancers nodes\nhttp://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/Nodes-d1e2173.html\r\nType of node:\r\n\r\nPRIMARY â Nodes defined as PRIMARY are in the normal rotation to receive traffic from the load balancer.\r\n\r\nSECONDARY â Nodes defined as SECONDARY are only in the rotation to receive traffic from the load balancer when all the primary nodes fail. This provides a failover feature that automatically routes traffic to the secondary node in the event that the primary node is disabled or in a failing state. Note that active health monitoring must be enabled on the load balancer to enable the failover feature to the secondary node.\r\n\r\nThis is cleaned up and \'works for me\'\r\n\r\nI used  Charles Proxy to debug traffic generate the gists\r\n\r\nhttps://gist.github.com/hh/d9cbd23097d42db7e531\r\n\r\n```ruby\r\nc=Fog::Rackspace::LoadBalancers.new(rackspace_region: :dfw,\r\n  connection_options: {ssl_verify_peer: false, proxy: \'http://localhost:8888\'})\r\n[1] pry(main)> lb=s.load_balancers.find {|lb| lb.name == \'testhttp\'} \r\n[2] pry(main)> lb.nodes\r\n=> [  <Fog::Rackspace::LoadBalancers::Node\r\n    id=592343,\r\n    address="72.32.12.183",\r\n    status="OFFLINE",\r\n    weight=1,\r\n    port=80,\r\n    type="PRIMARY",\r\n    condition="ENABLED"\r\n  >,\r\n   <Fog::Rackspace::LoadBalancers::Node\r\n    id=592345,\r\n    address="98.129.97.72",\r\n    status="ONLINE",\r\n    weight=1,\r\n    port=80,\r\n    type="SECONDARY",\r\n    condition="ENABLED"\r\n  >,\r\n   <Fog::Rackspace::LoadBalancers::Node\r\n    id=712997,\r\n    address="10.179.69.183",\r\n    status="OFFLINE",\r\n    weight=1,\r\n    port=80,\r\n    type="PRIMARY",\r\n    condition="ENABLED"\r\n  >]\r\n[3] pry(main)> lb.nodes.last.type="SECONDARY"\r\n=> "SECONDARY"\r\n[4] pry(main)> lb.nodes.last.save\r\n=> true\r\n[5] pry(main)> s.load_balancers.find {|lb| lb.name == \'testhttp\'}.nodes\r\n=> [  <Fog::Rackspace::LoadBalancers::Node\r\n    id=592343,\r\n    address="72.32.12.183",\r\n    status="OFFLINE",\r\n    weight=1,\r\n    port=80,\r\n    type="PRIMARY",\r\n    condition="ENABLED"\r\n  >,\r\n   <Fog::Rackspace::LoadBalancers::Node\r\n    id=592345,\r\n    address="98.129.97.72",\r\n    status="ONLINE",\r\n    weight=1,\r\n    port=80,\r\n    type="SECONDARY",\r\n    condition="ENABLED"\r\n  >,\r\n   <Fog::Rackspace::LoadBalancers::Node\r\n    id=712997,\r\n    address="10.179.69.183",\r\n    status="OFFLINE",\r\n    weight=1,\r\n    port=80,\r\n    type="SECONDARY",\r\n    condition="ENABLED"\r\n  >]\r\n\r\n```'
3242,'','Remove extra space in HP Storage service type\nThis was causing the following to fail with `Unable to retrieve endpoint service url for availability zone \'<AVAILABILITY_ZONE>\' from service catalog.`:\r\n\r\n```ruby\r\nservice = Fog::Storage.new({\r\n  provider: "HP",\r\n  ... additional credentials ...\r\n})\r\n```\r\n'
3241,'',"Wrong attribute :description in Xenserver server.rb\nHi! Foreman 1.6 software is trying to retrieve ':vm_description' attribute from /lib/fog/xenserver/models/compute/server.rb, but there is no such attribute so the error appears. Just change ':description' to 'vm_description' to fix it."
3240,'','Vsphere: Specify datacenter by name\nHi,\r\nis it possible not lo load a datacenter form esx/vsphere but specify a specific datacenter by name?\r\n\r\nRegards'
3239,'','Undefined namespace prefix: //soapenv:Body/* (Nokogiri::XML::XPath::SyntaxError)\nI try to connect to vsphere 5.5 with fog:\r\n\r\n```\r\nrequire \'fog\'\r\n\r\nf = Fog::Compute.new(\r\n  provider: \'vsphere\',\r\n  vsphere_username: \'xxx\',\r\n  vsphere_password: \'xxx\',\r\n  vsphere_server: \'xxx.xxx.xxx.xxx\',\r\n  vsphere_port: \'xxx\',\r\n  vsphere_ssl: true,\r\n  vsphere_expected_pubkey_hash: \'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\',\r\n  vsphere_rev: \'5.5\'\r\n)\r\n\r\nputs f\r\n```\r\n\r\nI got the following stack trace at line "Fog::Compute.new..."\r\n\r\n```\r\n/home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/nokogiri-1.6.4/lib/nokogiri/xml/node.rb:159:in `evaluate\': Undefined namespace prefix: //soapenv:Body/* (Nokogiri::XML::XPath::SyntaxError)\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/nokogiri-1.6.4/lib/nokogiri/xml/node.rb:159:in `block in xpath\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/nokogiri-1.6.4/lib/nokogiri/xml/node.rb:150:in `map\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/nokogiri-1.6.4/lib/nokogiri/xml/node.rb:150:in `xpath\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/rbvmomi-1.8.2/lib/rbvmomi/trivial_soap.rb:112:in `request\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/rbvmomi-1.8.2/lib/rbvmomi/connection.rb:87:in `call\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/rbvmomi-1.8.2/lib/rbvmomi/basic_types.rb:205:in `_call\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/rbvmomi-1.8.2/lib/rbvmomi/basic_types.rb:74:in `block (2 levels) in init\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/rbvmomi-1.8.2/lib/rbvmomi/vim.rb:68:in `serviceContent\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/fog-1.24.0/lib/fog/vsphere/compute.rb:370:in `negotiate_revision\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/fog-1.24.0/lib/fog/vsphere/compute.rb:349:in `initialize\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/fog-core-1.24.0/lib/fog/core/service.rb:115:in `new\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/fog-core-1.24.0/lib/fog/core/service.rb:115:in `new\'\r\n\tfrom /home/obazoud/.rvm/gems/ruby-1.9.3-p550/gems/fog-core-1.24.0/lib/fog/compute.rb:58:in `new\'\r\n\tfrom test.rb:5:in `<main>\'\r\n\r\n```\r\n\r\nAny idea ?\r\nThanks'
3237,'','nodes need  an optional :type\n\x01http://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/Nodes-d1e2173.html\r\nType of node:\r\n\r\nPRIMARY â Nodes defined as PRIMARY are in the normal rotation to receive traffic from the load balancer.\r\n\r\nSECONDARY â Nodes defined as SECONDARY are only in the rotation to receive traffic from the load balancer when all the primary nodes fail. This provides a failover feature that automatically routes traffic to the secondary node in the event that the primary node is disabled or in a failing state. Note that active health monitoring must be enabled on the load balancer to enable the failover feature to the secondary node.'
3236,'',"Fix spelling mistake in docs for AWS File#public_url\nI ran across this spelling mistake trying to figure out why `public_url` was making api calls, and figured it wouldn't hurt to submit a PR to fix the issue, as amusing as the misspelling is."
3235,'','Add :job_poll_timeout to the list of recognized options.\n'
3234,'',"[AWS|S3] Vhost buckets don't work if bucket name has a . in it\nWe shouldn't convert to dns addresseing in this case since the S3 wildcard cert is only valid for \\*.s3.amazonaws.com, not foo.\\*.amazonaws.com. "
3233,'',"Ec2 eu central\nThis adds support to for the eu-central-1 region (ec2 only). This requires the following changes:\r\n\r\n- adding eu-central-1 to the whitelist of regions (I noticed some services had their own whitelist - I assume this is an artifact of times when certain services only existed in some regions)\r\n- switching over to user aws signature v4\r\n\r\nAll AWS regions support AWS signature v4 (new regions, such as eu-central-1 only support v4), so this won't break anything for existing AWS users. I'm less sure about the impact on people using services with an AWS compatible API (eg eucalyptus) - while I assume current versions support v4, presumably some people out there still use older versions.\r\n\r\nIf we can agree the approach (eg should we allow people to request signature v2?) then it should be straightforward to make this change to the other aws services"
3232,'',"[AWS|Core] aws needs fog/core/parser to be loaded\nI've not really been following the efforts to split fog up but as of current master requiring just 'fog/aws' doesn't work because Fog::Parsers::Base hasn't been loaded. This fixes it, although I don't know whether this is the best place for this (eg should this be pulled in by fog/xml ?)"
3231,'',"Added docs/tests for Storage's public_url\nAdding tests/docs for https://github.com/fog/fog/pull/3228"
3230,'',"[rackspace] Queues: makes block optional when dequeuing\nCurrently when you want to dequeue a message you always have to pass a block, even if you have no reasons for one. I've found my self passing empty blocks all the time, when I just want to dequeue a message.\r\n\r\nThis PR makes a simple modification to make the block optional. This way you don't need  to pass an empty block when you don't need one. No side effects and backward compatible."
3229,'',"Preserve @ symbols in vcloud_director usernames\nIt's valid to have an email address as a vCloud Director username which\r\nwould result in a `vcloud_director_username` string that looks like:\r\n\r\n    user@example.com@organisation\r\n\r\nThe previous code incorrectly stripped any @ symbols from the username which\r\nwould turn the previous example into:\r\n\r\n    fog_credential_user = 'userexample.com'\r\n    fog_credential_org = 'organisation'\r\n\r\nThis meant that check_session_matches_credentials() would always raise an\r\nerror for such usernames. Prevent this from happening by restoring the @\r\nseparators when we join the array back together (minus the org).\r\n\r\nFixes an error reported in gds-operations/vcloud-core#139"
3228,'',"implements the public_url feature for openstack storage\nThis PR introduces public_url generation for the OpenStack provider's storage module.\r\n\r\nI did not know how to test the feature in the correct way, so please feel free to give me an introduction to do so, or help me implementing the test suite.\r\n\r\nI already tested it manually using our Swift installation and it worked as expected.\r\n\r\nCheers,\r\nJulian Weber"
3227,'',"Openstack storage public urls\nThis PR introduces public_url generation for the OpenStack provider's storage module.\r\n\r\nI did not know how to test the feature in the correct way, so please feel free to give me an introduction to do so, or help me implementing the test suite.\r\n\r\nI already tested it manually using our Swift installation and it worked as expected.\r\n\r\nCheers,\r\nJulian Weber"
3226,'tokengeek','[Brightbox] Update Brightbox gem to add storage\nThis adds support for our Orbit storage service to the `Fog` binary.\r\n\r\nDue to the whitelisting of supported services, without these changes\r\nversions of `fog-brightbox >= 0.4.0` would error when the `shindo` tests\r\nwere starting so all Brightbox tests would be skipped.'
3225,'',"Added new provider: exoscale\nHello,\r\n\r\nI've added a new provider: [exoscale](https://www.exoscale.ch).\r\n\r\nLet me know if there's anything I should add or change!"
3223,'',"Added tags attr to AWS security_groups and made sg.save() create tags\nAmazon API already returns tags w/ SG: it just wasn't being parsed.  I added the tag to the parser and also made sg.save call out to create_tags to save a few lines of code elsewhere.  Looking around the rest of the compute resources in fog I don't see any tag-related tests so will refrain from creating any unless necessary.\r\n\r\n"
3222,'','Remove duplicated hash key in rackspace/mock_data.rb\n'
3220,'','Rackspace neutron (networking) support\nThis patch adds `Fog::Rackspace::Networking`, which provides access to `Network` and `Virtual Interfaces`. Tests and docs added.'
3219,'','reload libvirt actions to get current state\nCurrently on libvirt, there is no reload of state after each action, besides start.\r\nWhen trying to run \r\n```ruby\r\npoweroff\r\nstart\r\n```\r\nthe vm will not start, because its state did not change from "running" to "shutoff"'
3218,'','Added ELB tags methods, mocks, and tests\nThanks to 20goto10 Ben Chadwick <bchadwick@mdsol.com> for the initial groundwork'
3215,'',"Adding fog-profitbricks as a runtime_dependency\nThe fog-profitbricks gem is passing all tests. Let me know if I'm missing anything."
3213,'','AWS Frankfurt region announced\nhttp://aws.amazon.com/blogs/aws/aws-region-germany/\r\n\r\n"The new Frankfurt Region supports Amazon Elastic Compute Cloud (EC2) and related services including Amazon Elastic Block Store (EBS), Amazon Virtual Private Cloud, Auto Scaling, and Elastic Load Balancing."\r\n\r\n"It also supports AWS Elastic Beanstalk, AWS CloudFormation, Amazon CloudFront, Amazon CloudSearch, AWS CloudTrail, Amazon CloudWatch, AWS Direct Connect, Amazon DynamoDB, Amazon Elastic MapReduce, AWS Storage Gateway, Amazon Glacier, AWS CloudHSM, AWS Identity and Access Management (IAM), Amazon Kinesis, AWS OpsWorks, Amazon Route 53, Amazon Relational Database Service (RDS), Amazon Redshift, Amazon Simple Storage Service (S3), Amazon Simple Notification Service (SNS), Amazon Simple Queue Service (SQS), and Amazon Simple Workflow Service (SWF)."\r\n\r\nWould be more helpful to know what it didn\'t support.'
3212,'','[bluebox] Add vsh_id attribute to Bluebox::Server\nThis attribute was added about 3 months ago.'
3211,'','Fix floating_ip detection for OpenStack Folsom Release\nOS-EXT-IPS:type was introduced only in Grizzly, thus Folsom\r\ncannot rely on this api extension.\r\nSee https://bugs.launchpad.net/openstack-api-site/+bug/1128562\r\nMeanwhile we can designate floating ip from fixed_ip by provided\r\nfallback'
3210,'','AWS SES not working because the request method was renamed\n'
3209,'','[google|dns] Improve Resource Record Sets changes\n- Add the ability to wait for a RRSet change completion (fixes https://github.com/fog/fog/pull/3195#issuecomment-59125319)\r\n- Add "get" method and tests to Resource Record Sets'
3208,'',"[google|storage] Fix bug in files.get\nKey was being ignored because array wasn't being saved after being modified. Fixes #3204."
3207,'','Using fog/xml gem\nMigrating xml code to its own gem. fixes fog/fog-xml#1'
3206,'','Requiring fog/version\nfix #3203 \r\n\r\n@geemus The problem was that fog was not requiring its own `version` file.\r\nBefore the [changes](https://github.com/fog/fog-core/pull/86) in `fog-core` it was using the file from `fog-core`.\r\nAfter we made the change in `fog-core` the edge build in `fog` begin to break because of that miss.'
3205,'','Flavours in OpenNebula not applied \nWe\'re currently investigating how we can implement fog to deploy VMs into our OpenNebula-Cloud. After some test I found a problem with I\'cant fix or find a solution for it. \r\n  \r\nWhen I create a VM threw the OpenNebula provider, the vm still is deployed with 1 VCPU and 128MB of memory. I have tested this with the flavours of the template and also override the flavours of the template. In the code snippets below there is a example how I did these tests. \r\n\r\nirb(main):001:0> require \'./fog.rb\'\r\n=> true\r\nirb(main):002:0> \r\nirb(main):003:0* \r\nirb(main):004:0* \r\nirb(main):005:0* con = Fog::Compute.new(\r\nirb(main):006:1*     {\r\nirb(main):007:2*       :provider => \'OpenNebula\',\r\nirb(main):008:2*       :opennebula_username => \'user\',\r\nirb(main):009:2*       :opennebula_password => \'xxxxxxx\',\r\nirb(main):010:2*       :opennebula_endpoint => \'http://ip.ip.ip.ip:2633/RPC2\'\r\nirb(main):011:2>     }\r\nirb(main):012:1> )\r\n=> #<Fog::Compute::OpenNebula::Real:8497580 @client=#<OpenNebula::Client:0x00000000a63768 @one_auth="oneadmin:ibda", @one_endpoint="http://ip.ip.ip.ip:2633/RPC2", @server=#<XMLRPC::Client:0x00000000a61008 @http_header_extra={"accept-encoding"=>"identity"}, @http_last_response=nil, @cookie=nil, @host="ip.ip.ip.ip", @path="/RPC2", @proxy_host=nil, @proxy_port=nil, @use_ssl=false, @timeout=30, @port=2633, @password=nil, @user=nil, @auth=nil, @http=#<Net::HTTP ip.ip.ip.ip:2633 open=false>, @parser=#<OpenNebula::NokogiriStreamParser:0x000000012ad8b0 @parser_class=OpenNebula::NokogiriStreamParser::NokogiriParser>, @create=nil>>>\r\nirb(main):013:0> newvm = con.servers.new\r\n=>   <Fog::Compute::OpenNebula::Server\r\n    id=nil,\r\n    template_str=nil,\r\n    name=nil,\r\n    uuid=nil,\r\n    state=nil,\r\n    status=nil,\r\n    ip=nil,\r\n    mac=nil,\r\n    vcpu=nil,\r\n    cpu=nil,\r\n    memory=nil,\r\n    user=nil,\r\n    gid=nil,\r\n    group=nil,\r\n    onevm_object=nil,\r\n    flavor=nil\r\n  >\r\nirb(main):014:0> newvm.flavor = con.flavors.get 19\r\n=>   <Fog::Compute::OpenNebula::Flavor\r\n    id="19",\r\n    name="one-hook",\r\n    content="CPU=\\"1\\"\\nDISK=[\\n  CACHE=\\"none\\",\\n  DEV_PREFIX=\\"vd\\",\\n  DRIVER=\\"qcow2\\",\\n  IMAGE=\\"one-hook-test-1\\",\\n  IMAGE_UNAME=\\"oneadmin\\" ]\\nGRAPHICS=[\\n  KEYMAP=\\"de\\",\\n  LISTEN=\\"0.0.0.0\\",\\n  TYPE=\\"VNC\\" ]\\nMEMORY=\\"1024\\"\\nOS=[\\n  ARCH=\\"x86_64\\",\\n  BOOT=\\"network\\" ]\\nVCPU=\\"2\\"",\r\n    cpu="1",\r\n    vcpu="2",\r\n    memory="1024",\r\n    sched_requirements=nil,\r\n    sched_rank=nil,\r\n    sched_ds_requirements=nil,\r\n    sched_ds_rank=nil,\r\n    disk={"CACHE"=>"none", "DEV_PREFIX"=>"vd", "DRIVER"=>"qcow2", "IMAGE"=>"one-hook-test-1", "IMAGE_UNAME"=>"oneadmin"},\r\n    nic=[],\r\n    os={"ARCH"=>"x86_64", "BOOT"=>"network"},\r\n    graphics={"KEYMAP"=>"de", "LISTEN"=>"0.0.0.0", "TYPE"=>"VNC"},\r\n    raw=nil\r\n  >\r\nirb(main):015:0> newvm.flavor.vcpu = 2\r\n=> 2\r\nirb(main):016:0> newvm.flavor.memory = 2048\r\n=> 2048\r\nirb(main):017:0> network = client.networks.get 1\r\nNameError: undefined local variable or method `client\' for main:Object\r\n\tfrom (irb):17\r\n\tfrom /usr/bin/irb:12:in `<main>\'\r\nirb(main):018:0> network = con.networks.get 1\r\n=>   <Fog::Compute::OpenNebula::Network\r\n    id="1",\r\n    name="LAB LAN",\r\n    uid="0",\r\n    gid="0",\r\n    description="",\r\n    vlan=""\r\n  >\r\nirb(main):019:0> nic = con.interfaces.new({ :vnet => network, :model => "virtio"})\r\n=>   <Fog::Compute::OpenNebula::Interface\r\n    id=nil,\r\n    vnet=    <Fog::Compute::OpenNebula::Network\r\n      id="1",\r\n      name="LAB LAN",\r\n      uid="0",\r\n      gid="0",\r\n      description="",\r\n      vlan=""\r\n    >,\r\n    model="virtio",\r\n    name=nil,\r\n    mac=nil\r\n  >\r\nirb(main):020:0> newvm.flavor.nic = [ nic ]\r\n=> [  <Fog::Compute::OpenNebula::Interface\r\n    id=nil,\r\n    vnet=    <Fog::Compute::OpenNebula::Network\r\n      id="1",\r\n      name="LAB LAN",\r\n      uid="0",\r\n      gid="0",\r\n      description="",\r\n      vlan=""\r\n    >,\r\n    model="virtio",\r\n    name=nil,\r\n    mac=nil\r\n  >]\r\nirb(main):021:0> newvm.name = "FooBarVM"\r\n=> "FooBarVM"\r\nirb(main):022:0> newvm.save\r\n=>   <Fog::Compute::OpenNebula::Server\r\n    id=141,\r\n    template_str=nil,\r\n    name="FooBarVM",\r\n    uuid=141,\r\n    state="LCM_INIT",\r\n    status=1,\r\n    ip="192.168.30.3",\r\n    mac="02:00:c0:a8:1e:03",\r\n    vcpu=nil,\r\n    cpu="1",\r\n    memory="128",\r\n    user="oneadmin",\r\n    gid=0,\r\n    group="oneadmin",\r\n    onevm_object=#<OpenNebula::VirtualMachine:0x00000002071708 @xml=[#<Nokogiri::XML::Element:0xf75c60 name="VM" children=[#<Nokogiri::XML::Element:0xf756e8 name="ID" children=[#<Nokogiri::XML::Text:0xf78578 "141">]>, #<Nokogiri::XML::Element:0xf78488 name="UID" children=[#<Nokogiri::XML::Text:0xf78460 "0">]>, #<Nokogiri::XML::Element:0xf78370 name="GID" children=[#<Nokogiri::XML::Text:0xf782d0 "0">]>, #<Nokogiri::XML::Element:0xf78244 name="UNAME" children=[#<Nokogiri::XML::Text:0xf7821c "oneadmin">]>, #<Nokogiri::XML::Element:0xf780c8 name="GNAME" children=[#<Nokogiri::XML::Text:0xf78050 "oneadmin">]>, #<Nokogiri::XML::Element:0xf74e64 name="NAME" children=[#<Nokogiri::XML::Text:0xf77fc4 "FooBarVM">]>, #<Nokogiri::XML::Element:0xf77e48 name="PERMISSIONS" children=[#<Nokogiri::XML::Element:0xf77de4 name="OWNER_U" children=[#<Nokogiri::XML::Text:0xf77dbc "1">]>, #<Nokogiri::XML::Element:0xf77bf0 name="OWNER_M" children=[#<Nokogiri::XML::Text:0xf77b78 "1">]>, #<Nokogiri::XML::Element:0xf77ab0 name="OWNER_A" children=[#<Nokogiri::XML::Text:0xf77970 "0">]>, #<Nokogiri::XML::Element:0xf7781c name="GROUP_U" children=[#<Nokogiri::XML::Text:0xf77704 "0">]>, #<Nokogiri::XML::Element:0xf7754c name="GROUP_M" children=[#<Nokogiri::XML::Text:0xf77524 "0">]>, #<Nokogiri::XML::Element:0xf773e4 name="GROUP_A" children=[#<Nokogiri::XML::Text:0xf77330 "0">]>, #<Nokogiri::XML::Element:0xf772b8 name="OTHER_U" children=[#<Nokogiri::XML::Text:0xf77290 "0">]>, #<Nokogiri::XML::Element:0xf771f0 name="OTHER_M" children=[#<Nokogiri::XML::Text:0xf77150 "0">]>, #<Nokogiri::XML::Element:0xf77100 name="OTHER_A" children=[#<Nokogiri::XML::Text:0xf770c4 "0">]>]>, #<Nokogiri::XML::Element:0xf77038 name="LAST_POLL" children=[#<Nokogiri::XML::Text:0xf76ffc "0">]>, #<Nokogiri::XML::Element:0xf76f70 name="STATE" children=[#<Nokogiri::XML::Text:0xf76f20 "1">]>, #<Nokogiri::XML::Element:0xf76e6c name="LCM_STATE" children=[#<Nokogiri::XML::Text:0xf76e44 "0">]>, #<Nokogiri::XML::Element:0xf76cf0 name="RESCHED" children=[#<Nokogiri::XML::Text:0xf76c50 "0">]>, #<Nokogiri::XML::Element:0xf76bec name="STIME" children=[#<Nokogiri::XML::Text:0xf76bb0 "1413542116">]>, #<Nokogiri::XML::Element:0xf76b10 name="ETIME" children=[#<Nokogiri::XML::Text:0xf76ae8 "0">]>, #<Nokogiri::XML::Element:0xf76a98 name="DEPLOY_ID">, #<Nokogiri::XML::Element:0x10bc86c name="MEMORY" children=[#<Nokogiri::XML::Text:0x10bc844 "0">]>, #<Nokogiri::XML::Element:0x10bc7f4 name="CPU" children=[#<Nokogiri::XML::Text:0x10bc7b8 "0">]>, #<Nokogiri::XML::Element:0x10bc754 name="NET_TX" children=[#<Nokogiri::XML::Text:0x10bc72c "0">]>, #<Nokogiri::XML::Element:0x10bc6c8 name="NET_RX" children=[#<Nokogiri::XML::Text:0x10bc6a0 "0">]>, #<Nokogiri::XML::Element:0x10bc63c name="TEMPLATE" children=[#<Nokogiri::XML::Element:0x10bc5d8 name="AUTOMATIC_REQUIREMENTS" children=[#<Nokogiri::XML::CDATA:0x10bc5b0 "CLUSTER_ID = 100 & !(PUBLIC_CLOUD = YES)">]>, #<Nokogiri::XML::Element:0x10bc560 name="CPU" children=[#<Nokogiri::XML::CDATA:0x10bc524 "0.2">]>, #<Nokogiri::XML::Element:0x10bc498 name="DISK" children=[#<Nokogiri::XML::Element:0x10bc3d0 name="CACHE" children=[#<Nokogiri::XML::CDATA:0x10bc3a8 "none">]>, #<Nokogiri::XML::Element:0x10bc330 name="CLONE" children=[#<Nokogiri::XML::CDATA:0x10bc2e0 "YES">]>, #<Nokogiri::XML::Element:0x10bc290 name="CLONE_TARGET" children=[#<Nokogiri::XML::CDATA:0x10bc254 "SYSTEM">]>, #<Nokogiri::XML::Element:0x10bc1f0 name="DATASTORE" children=[#<Nokogiri::XML::CDATA:0x10bc128 "SYNO-IMAGE">]>, #<Nokogiri::XML::Element:0x10bc060 name="DATASTORE_ID" children=[#<Nokogiri::XML::0x10bc038 "106">]>, #<Nokogiri::XML::Element:0x10bbfe8 name="DEV_PREFIX" children=[#<Nokogiri::XML::CDATA:0x10bbfc0 "vd">]>, #<Nokogiri::XML::Element:0x10bbf70 name="DISK_ID" children=[#<Nokogiri::XML::CDATA:0x10bbf48 "0">]>, #<Nokogiri::XML::Element:0x10bbea8 name="DRIVER" children=[#<Nokogiri::XML::CDATA:0x10bbe30 "qcow2">]>, #<Nokogiri::XML::Element:0x10bbdcc name="IMAGE" children=[#<Nokogiri::XML::CDATA:0x10bbda4 "one-hook-test-1">]>, #<Nokogiri::XML::Element:0x10bbd18 name="IMAGE_ID" children=[#<Nokogiri::XML::CDATA:0x10bbcf0 "16">]>, #<Nokogiri::XML::Element:0x10bbc8c name="IMAGE_UNAME" children=[#<Nokogiri::XML::CDATA:0x10bbc64 "oneadmin">]>, #<Nokogiri::XML::Element:0x10bbc14 name="LN_TARGET" children=[#<Nokogiri::XML::CDATA:0x10bbbec "NONE">]>, #<Nokogiri::XML::Element:0x10bbb9c name="READONLY" children=[#<Nokogiri::XML::CDATA:0x10bbb74 "NO">]>, #<Nokogiri::XML::Element:0x10bbb24 name="SAVE" children=[#<Nokogiri::XML::CDATA:0x10bbafc "NO">]>, #<Nokogiri::XML::Element:0x10bbaac name="SIZE" children=[#<Nokogiri::XML::CDATA:0x10bba84 "30720">]>, #<Nokogiri::XML::Element:0x10bb980 name="SOURCE" children=[#<Nokogiri::XML::CDATA:0x10bb908 "/var/lib/one//datastores/106/1e3d99c3f01fd22e12f453339abf0389">]>, #<Nokogiri::XML::Element:0x10bb82c name="TARGET" children=[#<Nokogiri::XML::CDATA:0x10bb73c "vda">]>, #<Nokogiri::XML::Element:0x10bb6b0 name="TM_MAD" children=[#<Nokogiri::XML::CDATA:0x10bb624 "shared">]>, #<Nokogiri::XML::Element:0x10bb584 name="TYPE" children=[#<Nokogiri::XML::CDATA:0x10bb55c "FILE">]>]>, #<Nokogiri::XML::Element:0x10bb4bc name="GRAPHICS" children=[#<Nokogiri::XML::Element:0x10bb444 name="KEYMAP" children=[#<Nokogiri::XML::CDATA:0x10bb41c "de">]>, #<Nokogiri::XML::Element:0x10bb3cc name="LISTEN" children=[#<Nokogiri::XML::CDATA:0x10bb3a4 "0.0.0.0">]>, #<Nokogiri::XML::Element:0x10bb354 name="PORT" children=[#<Nokogiri::XML::CDATA:0x10bb32c "6041">]>, #<Nokogiri::XML::Element:0x10bb2c8 name="TYPE" children=[#<Nokogiri::XML::CDATA:0x10bb2a0 "VNC">]>]>, #<Nokogiri::XML::Element:0x10bb200 name="MEMORY" children=[#<Nokogiri::XML::CDATA:0x10bb1d8 "128">]>, #<Nokogiri::XML::Element:0x10bb188 name="NIC" children=[#<Nokogiri::XML::Element:0x10bb0d4 name="BRIDGE" children=[#<Nokogiri::XML::CDATA:0x10bb0ac "vmnet0">]>, #<Nokogiri::XML::Element:0x10baeb8 name="CLUSTER_ID" children=[#<Nokogiri::XML::CDATA:0x10bae90 "100">]>, #<Nokogiri::XML::Element:0x10baddc name="IP" children=[#<Nokogiri::XML::CDATA:0x10badb4 "192.168.30.3">]>, #<Nokogiri::XML::Element:0x10bad64 name="IP6_LINK" children=[#<Nokogiri::XML::CDATA:0x10bad28 "fe80::400:c0ff:fea8:1e03">]>, #<Nokogiri::XML::Element:0x10bac9c name="MAC" children=[#<Nokogiri::XML::CDATA:0x10bac74 "02:00:c0:a8:1e:03">]>, #<Nokogiri::XML::Element:0x10bac24 name="MODEL" children=[#<Nokogiri::XML::CDATA:0x10babe8 "virtio">]>, #<Nokogiri::XML::Element:0x10bab98 name="NETWORK" children=[#<Nokogiri::XML::CDATA:0x10bab70 "LAB LAN">]>, #<Nokogiri::XML::Element:0x10bab0c name="NETWORK_ID" children=[#<Nokogiri::XML::CDATA:0x10baae4 "1">]>, #<Nokogiri::XML::Element:0x10baa44 name="NIC_ID" children=[#<Nokogiri::XML::CDATA:0x10ba9e0 "0">]>, #<Nokogiri::XML::Element:0x10ba968 name="VLAN" children=[#<Nokogiri::XML::CDATA:0x10ba918 "NO">]>]>, #<Nokogiri::XML::Element:0xf40830 name="OS" children=[#<Nokogiri::XML::Element:0xf4077c name="ARCH" children=[#<Nokogiri::XML::CDATA:0xf40704 "x86_64">]>, #<Nokogiri::XML::Element:0xf406a0 name="BOOT" children=[#<Nokogiri::XML::CDATA:0xf40664 "network">]>]>, #<Nokogiri::XML::Element:0xf4054c name="VCPU" children=[#<Nokogiri::XML::CDATA:0xf40510 "1">]>, #<Nokogiri::XML::Element:0xf40484 name="VMID" children=[#<Nokogiri::XML::CDATA:0xf4045c "141">]>]>, #<Nokogiri::XML::Element:0xf40240 name="USER_TEMPLATE">, #<Nokogiri::XML::Element:0xf40074 name="HISTORY_RECORDS">]>], @client=#<OpenNebula::Client:0x00000000a63768 @one_auth="oneadmin:ibda", @one_endpoint="http://192.168.30.22:2633/RPC2", @server=#<XMLRPC::Client:0x00000000a61008 @http_header_extra={"accept-encoding"=>"identity"}, @http_last_response=#<Net::HTTPOK 200 OK readbody=true>, @cookie=nil, @host="192.168.30.22", @path="/RPC2", @proxy_host=nil, @proxy_port=nil, @use_ssl=false, @timeout=30, @port=2633, @password=nil, @user=nil, @auth=nil, @http=#<Net::HTTP ip.ip.ip.ip:2633 open=false>, @parser=#<OpenNebula::NokogiriStreamParser:0x000000012ad8b0 @parser_class=OpenNebula::NokogiriStreamParser::NokogiriParser>, @create=#<XMLRPC::Create:0x000000012ce470 @writer=#<XMLRPC::XMLWriter::Simple:0x000000012ce510>>>>, @pe_id=141, @name="FooBarVM">,\r\n    flavor=    <Fog::Compute::OpenNebula::Flavor\r\n      id="19",\r\n      name="one-hook",\r\n      content="CPU=\\"1\\"\\nDISK=[\\n  CACHE=\\"none\\",\\n  DEV_PREFIX=\\"vd\\",\\n  DRIVER=\\"qcow2\\",\\n  IMAGE=\\"one-hook-test-1\\",\\n  IMAGE_UNAME=\\"oneadmin\\" ]\\nGRAPHICS=[\\n  KEYMAP=\\"de\\",\\n  LISTEN=\\"0.0.0.0\\",\\n  TYPE=\\"VNC\\" ]\\nMEMORY=\\"1024\\"\\nOS=[\\n  ARCH=\\"x86_64\\",\\n  BOOT=\\"network\\" ]\\nVCPU=\\"2\\"",\r\n      cpu="1",\r\n      vcpu=2,\r\n      memory=2048,\r\n      sched_requirements=nil,\r\n      sched_rank=nil,\r\n      sched_ds_requirements=nil,\r\n      sched_ds_rank=nil,\r\n      disk={"CACHE"=>"none", "DEV_PREFIX"=>"vd", "DRIVER"=>"qcow2", "IMAGE"=>"one-hook-test-1", "IMAGE_UNAME"=>"oneadmin"},\r\n      nic=[      <Fog::Compute::OpenNebula::Interface\r\n        id=nil,\r\n        vnet=        <Fog::Compute::OpenNebula::Network\r\n          id="1",\r\n          name="LAB LAN",\r\n          uid="0",\r\n          gid="0",\r\n          description="",\r\n          vlan=""\r\n        >,\r\n        model="virtio",\r\n        name=nil,\r\n        mac=nil\r\n      >],\r\n      os={"ARCH"=>"x86_64", "BOOT"=>"network"},\r\n      graphics={"KEYMAP"=>"de", "LISTEN"=>"0.0.0.0", "TYPE"=>"VNC"},\r\n      raw=nil\r\n    >\r\n  >\r\n\r\nPlease let me know if I\'m doing something wrong or if this is a current bug.\r\n\r\nThanks a lot in advance and for all the work of this great project. '
3204,'icco','Regression in Fock.mock causing CarrierWave specs to fail\nIt seems that fog 1.24.0 introduced a regression not present in 1.23.0 which is causing CarrierWave\'s test suite to fail. Here\'s a reproduction:\r\n\r\n``` ruby\r\nrequire \'fog\'\r\n\r\nFog.mock!\r\n\r\n[\'AWS\', \'Google\'].each do |provider|\r\n  connection = ::Fog::Storage.new({ provider: provider, google_storage_access_key_id: \'xtz\', google_storage_secret_access_key: \'yyy\', aws_access_key_id: \'blah\', aws_secret_access_key: \'moo\' })\r\n\r\n  directory = connection.directories.create(key: "xyz")\r\n  directory.files.create(body: "this is stuff", key: "moo.txt")\r\n\r\n  p directory.files.get("moo.txt").body\r\nend\r\n```\r\n\r\nOn 1.23.0 this prints:\r\n\r\n```\r\n"this is stuff"\r\n"this is stuff"\r\n```\r\n\r\nBut on 1.24.0 this fails like this:\r\n\r\n```\r\n"this is stuff"\r\n/Users/dev/.rvm/gems/ruby-2.1.2/gems/fog-1.24.0/lib/fog/google/requests/storage/get_object.rb:67:in `get_object\': object_name is required (ArgumentError)\r\n\tfrom /Users/dev/.rvm/gems/ruby-2.1.2/gems/fog-1.24.0/lib/fog/google/models/storage/files.rb:62:in `get\'\r\n\tfrom /Users/dev/.rvm/gems/ruby-2.1.2/gems/fog-1.24.0/lib/fog/google/models/storage/file.rb:31:in `body\'\r\n\tfrom test.rb:11:in `block in <main>\'\r\n\tfrom test.rb:5:in `each\'\r\n\tfrom test.rb:5:in `<main>\'\r\n```\r\n\r\nEverything works fine, but it seems that the `File` object for Google has not received a `key`. Printing out the file object looks like this:\r\n\r\n```\r\n  <Fog::Storage::Google::File\r\n    key=nil,\r\n    cache_control=nil,\r\n    content_disposition=nil,\r\n    content_encoding=nil,\r\n    content_length=13,\r\n    content_md5=nil,\r\n    content_type=nil,\r\n    etag="938e47592dc66e9082e241733ac79328",\r\n    expires=nil,\r\n    last_modified="Fri, 17 Oct 2014 07:54:03 +0000",\r\n    metadata={},\r\n    owner=nil,\r\n    storage_class=nil\r\n  >\r\n```\r\n\r\nNote that `key` is nil. This is not the case when running with AWS, and I don\'t think it\'s supposed to be, this is causing the subsequent failure when trying to read the body.'
3203,'','undefined Fog::Version in travis edge tests\nSomehow this ONLY comes up in edge and only since we changed the fog vs fog core version stuff. See: https://travis-ci.org/fog/fog/jobs/38187824\r\n\r\n@plribeiro3000 could you take a look and see if you can maybe figure it out?'
3202,'','Docker: Support for logs/top operations\nIn order to test this properly, responses from the mock return values\r\ncloser to what the API actually returns. Examples are from Remote API\r\n1.18.\r\n\r\ndowncasing hash keys cannot be performed on all Docker API operations so\r\nnow it will only be done where the top element is a hash. Logs, top, and\r\nmany others will not return a hash.'
3201,'','PreDefined Policies in ELBs \nhow do i assign a pregenerated policy to an elb listener using fog?\r\n\r\nif anyone has a script to deal with POODLE that would be much apreciated as well'
3199,'','[openstack] add remove header if setting directory back to private\nThis is needed if you want to put you container back to private. Since sending empty header wont do it. \r\n'
3198,'','[ovirt] Add interface for updating volumes\n'
3197,'',"Added GovCloud region to acceptable AWS list\nI'm working with fog in the Amazon's GovCloud region, us-gov-west-1. Please include it as a valid region."
3196,'','added support for searching of images in fogdocker\n'
3195,'icco','[google|dns] Add missing models, requests and tests\n- Add Zone model and tests\r\n- Add Record models, requests and tests\r\n- Add Change models, requests and tests\r\n- Add Project models, requests and tests\r\n- Add examples'
3193,'',"Raise docker-api errors up\nThis allows Docker API errors to be caught by Fog's clients and also raises specific errors depending on the problem."
3192,'','Found a typo in the Changelog\ntypo!'
3189,'','[rackspace] Boot from volume\nThis adds the ability to boot Rackspace servers from a volume, including:\r\n\r\n * Creating a bootable volume from an image explicitly, then creating a server referencing that volume id;\r\n * Creating a server and a bootable volume at once from an image id; and\r\n * Specifying arbitrary custom volume mounts explicitly in a `create_server` request.\r\n\r\nHere\'s some example code:\r\n\r\n```ruby\r\nblock = Fog::Rackspace::BlockStorage.new(rackspace_username: \'\' ... )\r\ncompute = Fog::Compute.new(provider: :rackspace\r\n\r\nimage_id = compute.images.find { |i| i.name =~ /Ubuntu/ }.id\r\nflavor_id = compute.flavors.find { |f| f.name =~ /Performance/ }.id\r\n\r\n# Two-step with explicit volume creation\r\nvolume = block.volumes.create size: 100, image_id: image_id\r\nvolume.wait_for { ready? }\r\nserver = compute.servers.create name: \'two-step\', image_id: \'\', flavor_id: flavor_id, boot_volume_id: volume.id\r\n\r\n# One-step with implicit volume creation\r\nserver = compute.servers.create name: \'one-step\', image_id: \'\', flavor_id: flavor_id, boot_image_id: image_id\r\n\r\n# Direct server request with explicit volume initialization\r\ncompute.create_server \'explicit\', \'\', flavor_id, 1, 1, block_device_mapping: [\r\n  {\r\n    "device_name" => "/dev/sdb1",\r\n    "source_type" => "blank",\r\n    "destination_type" => "local",\r\n    "delete_on_termination" => "True",\r\n    "guest_format" => "swap",\r\n    "boot_index" => "-1"\r\n  },\r\n  {\r\n    "device_name" => "/dev/sda1",\r\n    "source_type" => "volume",\r\n    "destination_type" => "volume",\r\n    "uuid" => "fake-volume-id-1",\r\n    "boot_index" => "0"\r\n  }\r\n]\r\n```\r\n\r\nHere\'s the Openstack reference for it: http://developer.openstack.org/api-ref-compute-v2-ext.html#ext-os-block-device-mapping-v2-boot\r\n\r\n/cc @mdarby'
3188,'',"Require docker-api in Gemfile\nIn lib/fog/fogdocker/compute.rb, require 'docker' is used.\r\nThe gem is used throughout this part of the code but is not required in the Gemfile,\r\nI've added it, it's https://github.com/swipely/docker-api , 'docker-api."
3187,'','Initial release of ProfitBricks provider\nThis is a preliminary release of a [ProfitBricks](http://www.profitbricks.com/) provider for Fog.\r\n\r\nIt includes requests that map closely to the ProfitBricks SOAP API for most basic methods such as managing virtual datacenters, storage volumes, NICs, and servers. There are also helper requests for viewing/managing flavors and regions despite these not being available through the API.\r\n\r\nThis release also includes models for the previously mentioned components as well as a pb_demo.py example that demonstrates basic usage. Mock data is provided for all available requests/models. Unit tests are available for only the requests at this time and pass successfully with both mock and real classes.\r\n\r\nThe next release should include further documentation and additional requests/models.\r\n\r\nPlease let me know if there any questions or concerns.'
3185,'','add missing HEAD Bucket request, with a basic test in there\nReplaces https://github.com/fog/fog/pull/3105'
3182,'','[AWS] Setup a fog keypair only if not supplied.\nWhen calling bootstrap, the :key_name argument is currently ignored\r\nand not passed to the internal _setup_bootstrap() method. This results\r\nin fog creating a keypair and using it for the instance.\r\n\r\nThe additional parameter -- new_attributes -- is also never actually\r\nused when calling _setup_bootstrap().\r\n\r\nThe patch removes the new_attributes parameter and uses the key_name\r\nattribute of the passed server object to ascertain whether a default\r\nfog keypair should be created.'
3181,'nirvdrum','Fixed attribute passing for add_interface\nServer model has an `add_interface` method. This method allows attributes to be passed so you can configure options on the interface. \r\n\r\nUnfortunately it doesn\'t pass these options to the create_interface call. This in turn leaves `attributes` empty for `create_vm.rb#create_interface` and subsequently `create_vm.rb#create_nic_backing`.\r\n\r\n When you define a `DistributedVirtualPortgroup` as the network attribute, and `create_nic_backing` doesn\'t have `attributes[:datacenter]`, you will end up with a newly created StandardPortgroup instead of the correct `DistributedVirtualPortgroup` in your Backing info for the interface. \r\n\r\nTo solve this you will need to pass along the `datacenter: \'name-your-dc-here\'` param when you call server.add_interface, along with `type`, and `network`. \r\n\r\nTested in ESX 5.5. See debug code below to replicate issue.\r\n\r\n```ruby\r\nv = Fog::Compute[:vsphere]\r\n\r\nc = v.datacenters.get(\'data-center-name-here\').virtual_machines.get(\'path/to/my/virtual/machine\')\r\n\r\n>> c.add_interface type: RbVmomi::VIM::VirtualE1000, network: \'network-name-here\', datacenter: \'data-center-name-here\'\r\n/home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/modify_vm_interface.rb:10\r\ninterface=get_interface_from_options(vmid, options)\r\n\r\n[5, 14] in /home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/modify_vm_interface.rb\r\n   5\r\n   6          def add_vm_interface(vmid, options = {})\r\n   7            raise ArgumentError, "instance id is a required parameter" unless vmid\r\n   8            debugger\r\n   9\r\n=> 10            interface=get_interface_from_options(vmid, options)\r\n   11            vm_reconfig_hardware(\'instance_uuid\' => vmid, \'hardware_spec\' => {\'deviceChange\'=>[create_interface(interface)]})\r\n   12          end\r\n   13\r\n   14          def destroy_vm_interface(vmid, options = {})\r\n(rdb:1) options\r\n{:type=>VirtualE1000, :network=>"network-name-here", :datacenter=>"data-center-name-here"}\r\n(rdb:1) n\r\n/home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/modify_vm_interface.rb:11\r\nvm_reconfig_hardware(\'instance_uuid\' => vmid, \'hardware_spec\' => {\'deviceChange\'=>[create_interface(interface)]})\r\n\r\n[6, 15] in /home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/modify_vm_interface.rb\r\n   6          def add_vm_interface(vmid, options = {})\r\n   7            raise ArgumentError, "instance id is a required parameter" unless vmid\r\n   8            debugger\r\n   9\r\n   10            interface=get_interface_from_options(vmid, options)\r\n=> 11            vm_reconfig_hardware(\'instance_uuid\' => vmid, \'hardware_spec\' => {\'deviceChange\'=>[create_interface(interface)]})\r\n   12          end\r\n   13\r\n   14          def destroy_vm_interface(vmid, options = {})\r\n   15            raise ArgumentError, "instance id is a required parameter" unless vmid\r\n(rdb:1) s\r\n/home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:79\r\n}\r\n\r\n[74, 83] in /home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb\r\n   74                    :label   => nic.name,\r\n   75                    :summary => nic.summary,\r\n   76                  },\r\n   77                :backing     => create_nic_backing(nic, attributes),\r\n   78                :addressType => \'generated\')\r\n=> 79            }\r\n   80          end\r\n   81\r\n   82          def create_controller operation = :add, controller_key = 1000, bus_id = 0\r\n   83            {\r\n(rdb:1) attributes\r\n{}\r\n(rdb:1) s\r\n\r\n# <snip> I hit next three times </snip>\r\n\r\n/home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:53\r\nraw_network = get_raw_network(nic.network, attributes[:datacenter], if nic.virtualswitch then nic.virtualswitch end)\r\n\r\n[48, 57] in /home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb\r\n   48            end\r\n   49            devices.flatten\r\n   50          end\r\n   51\r\n   52          def create_nic_backing nic, attributes\r\n=> 53            raw_network = get_raw_network(nic.network, attributes[:datacenter], if nic.virtualswitch then nic.virtualswitch end)\r\n   54\r\n   55            if raw_network.kind_of? RbVmomi::VIM::DistributedVirtualPortgroup\r\n   56              RbVmomi::VIM.VirtualEthernetCardDistributedVirtualPortBackingInfo(\r\n   57                :port => RbVmomi::VIM.DistributedVirtualSwitchPortConnection(\r\n(rdb:1) attributes\r\n{}\r\n(rdb:1) n\r\n/home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:55\r\nif raw_network.kind_of? RbVmomi::VIM::DistributedVirtualPortgroup\r\n\r\n[50, 59] in /home/vagrant/.rvm/gems/ruby-1.9.3-p547/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb\r\n   50          end\r\n   51\r\n   52          def create_nic_backing nic, attributes\r\n   53            raw_network = get_raw_network(nic.network, attributes[:datacenter], if nic.virtualswitch then nic.virtualswitch end)\r\n   54\r\n=> 55            if raw_network.kind_of? RbVmomi::VIM::DistributedVirtualPortgroup\r\n   56              RbVmomi::VIM.VirtualEthernetCardDistributedVirtualPortBackingInfo(\r\n   57                :port => RbVmomi::VIM.DistributedVirtualSwitchPortConnection(\r\n   58                  :portgroupKey => raw_network.key,\r\n   59                  :switchUuid   => raw_network.config.distributedVirtualSwitch.uuid\r\n(rdb:1) raw_network\r\nnil\r\n(rdb:1) raw_network = get_raw_network(nic.network, \'data-center-name-here\', if nic.virtualswitch then nic.virtualswitch end)\r\nDistributedVirtualPortgroup("dvportgroup-100")\r\n(rdb:1) raw_network.kind_of? RbVmomi::VIM::DistributedVirtualPortgroup\r\ntrue\r\n(rdb:1) get_raw_network(nic.network, attributes[:datacenter], if nic.virtualswitch then nic.virtualswitch end).kind_of? RbVmomi::VIM::DistributedVirtualPortgroup\r\nfalse\r\n(rdb:1)\r\n```'
3180,'','AWS: Add Tagging for ELBs\nThis PR adds the features necessary to add, describe, and remove tags from an Elastic Load Balancer.\r\n'
3178,'',"Updating the HP connect docs\nI found a few typos and it seems that there isn't a dashboard\r\nlink anymore. HP has updated to Horizon as their URLs."
3177,'','Compute.Servers Failing : CExcon::Errors::SocketError: SSL_connect SYSCALL returned=5 errno=0 state=SSLv2/v3 read server hello A (OpenSSL::SSL::SSLError)\nHello, \r\nI am repeatedly getting error after trying to do connection.servers. Compute.new wont fail. But connection.servers is failed\r\n>> connection = Fog::Compute.new({:provider => \'openstack\', :openstack_tenant => \'test\' , :openstack_api_key => \'test\' , :openstack_username => "hr@hr.com", :openstack_auth_url => \'https://identity.localopenstack.com:5000/v2.0/tokens\'})\r\n>>  connection.servers\r\nExcon::Errors::SocketError: SSL_connect SYSCALL returned=5 errno=0 state=SSLv2/v3 read server hello A (OpenSSL::SSL::SSLError)\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/ssl_socket.rb:76:in `connect\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/ssl_socket.rb:76:in `initialize\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/connection.rb:373:in `new\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/connection.rb:373:in `socket\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/connection.rb:122:in `request_call\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/middlewares/mock.rb:42:in `request_call\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/middlewares/instrumentor.rb:22:in `request_call\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.28.0/lib/excon/connection.rb:251:in `request\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/core/connection.rb:57:in `request\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/openstack/compute.rb:339:in `request\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/openstack/requests/compute/list_servers_detail.rb:11:in `list_servers_detail\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/openstack/models/compute/servers.rb:21:in `all\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/core/collection.rb:141:in `lazy_load\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/core/collection.rb:15:in `empty?\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/core/collection.rb:86:in `block in inspect\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/formatador-0.2.5/lib/formatador.rb:92:in `indent\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/lib/fog/core/collection.rb:79:in `inspect\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/bin/fog:76:in `block in <top (required)>\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/bin/fog:76:in `catch\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/lib/ruby/gems/2.1.0/gems/fog-1.18.0/bin/fog:76:in `<top (required)>\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/bin/fog:23:in `load\'\r\n\tfrom /home/hr/.rvm/rubies/ruby-2.1.1/bin/fog:23:in `<main>\'\r\n\tfrom /home/hr/.rvm/gems/ruby-2.1.1/bin/ruby_executable_hooks:15:in `eval\'\r\n\tfrom /home/hr/.rvm/gems/ruby-2.1.1/bin/ruby_executable_hooks:15:in `<main>\''
3176,'',"[vcloud_director] Add Query API support to Model\nThis adds support for the vCloud Director Query API into the Model, via a mixin.\r\n\r\nIt adds a 'find_by_query' call which returns a Collection of objects matching that query. The full query syntax is available via this call, so it's pretty powerful.\r\n\r\nI've added Mock code and tried to increase the coverage of our tests under Travis.\r\n\r\nCurrently this support has been added to:\r\n\r\nvms\r\nvapps\r\nvdcs\r\nnetworks\r\ntasks\r\n... though it is trivial to add it to the other entities."
3175,'','Local storage: Always try to create directories, handle already existing\nThis reduces the chances of races where two client try to upload the same file / two files with the same directory.\r\n\r\nNot sure if this is the right way (or if the `.directory?` check should be left in); please advise.'
3174,'',"EXCON_DEBUG and DEBUG env variables have no effect?\nThe getting started document suggests using them\r\n\r\n    http://fog.io/about/getting_started.html\r\n\r\nGrepping the source didn't find any mention of them.\r\n\r\nIf this document is out of date, any suggestions how to get fog to print to stderr the locations it's accessing please?"
3173,'','added public? and acl method to s3 file and minor refactoring\nAdded ```public?``` and ```acl``` method to aws s3 file. Did some minor refactoring and corrected a typo.'
3172,'','Is there a reason not to set up one global S3 storage object in an initializer?\nHere\'s what I\'d like to do:\r\n\r\n```ruby\r\n# config/initializers/fog.rb\r\nS3 = Fog::Storage.new({\r\n  :provider => "AWS",\r\n  :aws_access_key_id => ENV[\'AWS_ACCESS_KEY_ID\'],\r\n  :aws_secret_access_key => ENV[\'AWS_SECRET_ACCESS_KEY\']\r\n})\r\n\r\nBUCKET = S3.directories.new(key: ENV["AWS_S3_BUCKET"])\r\n```\r\n\r\nThen, all over my application (including in sidekiq threads), do things like:\r\n\r\n```ruby\r\nBUCKET.files.get(s3_key)\r\n```\r\n\r\nand:\r\n\r\n```ruby\r\nS3.head_object(ENV["AWS_S3_BUCKET"], s3_key)\r\n```\r\n\r\nCurrently I have things set up so I dynamically create a separate `Fog::Storage` object whenever I need one, but having one global `S3` to work with would make my code a lot cleaner.\r\n\r\nSo yeah, is there a reason I shouldn\'t do this?'
3171,'','Depend on fog-radosgw.\nDepend on fog-radosgw. See https://github.com/fog/fog/pull/3143#issuecomment-55897284.'
3170,'','Fix broken build\nFixes #3161. Sorry about that.\r\n\r\nMy shame is great...\r\n\r\n![selfie-0](http://i.imgur.com/Txu6TSd.gif)\r\n'
3169,'',"Error if FOG_CREDENTIAL doesn't match session\nCurrently, Fog will ignore the vCloud organisation specified by a\r\n`FOG_CREDENTIAL` environment variable if a vCloud authorization token\r\nis used to log in by specifying the `FOG_VCLOUD_TOKEN` environment\r\nvariable.\r\n\r\nThis happens because the organisation name is pulled from the response\r\nbody of the login request call. If a `FOG_VCLOUD_TOKEN` environment\r\nvariable is specified, the `get_current_session` API call is used and\r\nthe organisation returned in the response body will correspond to the\r\norganisation specified when the vCloud token was first obtained using\r\nthe `post_login_session` API call.\r\n\r\nIt is therefore possible to specify a second `FOG_CREDENTIAL`, which\r\npoints to the same vCloud Director instance and specifies a different\r\norganisation, but connect to the organisation used when creating the\r\nvCloud session token. The end-user may believe that Fog is connecting to\r\nthe organisation specified by `FOG_CREDENTIAL`, but the effective\r\norganisation is the one that was specified when first obtaining the\r\nvCloud session token.\r\n\r\nThis could be potentially very serious if your production and test\r\norganisations use the same vCloud Director instance (with the same\r\nusername for both organisations).\r\n\r\nRaise an exception if the organisation implied by `FOG_CREDENTIAL`\r\ndiffers to the one returned in the response body of the\r\n`post_login_session` API call.\r\n\r\nThis behaves correctly if the session has expired; this code won't be\r\nexecuted in that case.\r\n\r\n* * *\r\n\r\nI wasn't sure about the correct exception type to use, so went with `Fog::Errors::Error`; suggestions welcome if there's a better exception type to use."
3168,'',"AWS S3 Server Side Encryption using Customer Key(SSE-C)\nI was trying to use AWS S3's Server Side Encryption using Customer Key(SSE-C) - http://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html . I was successful in getting the encryption working by setting the 'fog_attributes'.\r\n\r\nBut I need to send the same headers while making a GET request for the file as well (for decrypting). Unfortunately I could not make a GET request since AWS requires a computed signature of the request. I could not get it working with Fog since it does not allow me to set custom headers and make a GET request. It would be a great if you could give me pointers to get this working."
3167,'','Revert "S3 invalid signature generation"\nReverts fog/fog#3144'
3166,'','Allow get_object_https_url to accept a method\nget_object_https_url is used to generate GET URLs to cloud files. However, we can support PUT requests (uploads) by allowing people to specify PUT as the method rather than having it hard coded to GET.'
3164,'','Instrument aws\nExtend instrumentation support to all AWS APIs.'
3163,'','Fix AWS::AutoScaling::Instance#healthy?\nFixes #3151'
3162,'','[oVirt] expose ips attribute\nThis attribute contains a list of IP addresses as used by the guest virtual machine'
3161,'icco','Google compute tests are failing due to Not Found error\nTravis has been failing for a while, mostly from `tests/google/models/compute/target_pools_tests.rb` failing.\r\n\r\nE.g. https://travis-ci.org/fog/fog/jobs/35336198 (and many others)\r\n\r\n@icco Can you have a look, assign a minion or something please?'
3160,'','[GH-3156] Fix fog binary dependencies\nThe Sakuracloud `bin` file was removed to `v0.0.4` but the dependency\r\nwas not declared.\r\n\r\nUsing `$ fog` without manually updating the dependency would trigger a\r\nrequire error due to this missing file.\r\n\r\nThis adds the minimal dependency required.'
3159,'',"Vcloud director static routes for edge gateway\nThis commit adds support for Edge Gateway's StaticRoutingService"
3158,'','[GH-3157] Replace 1.9 hashes with Hash rockets\nTests failing on 1.8 for this (among other reasons)'
3157,'tokengeek','Number of 1.9 style hashes introduced in testing\nTravis is showing failures due to 1.9 hashes being introduced into the tests.\r\n\r\nThese should be fixed to be hash rocket versions.\r\n\r\ne.g. https://travis-ci.org/fog/fog/jobs/34821735'
3155,'','New release \nPlease release a new version, I especially need the compatibility fixes for cloudstack. '
3154,'','Move chunk_size parameter to the connection_options table\n`chunk_size` is an Excon parameter, not a `Fog::Storage::Rackspace` one.'
3153,'',"fix CGI escaping\nThe prior PR (https://github.com/fog/fog/pull/3144) ended up causing some travis failures that we were unaware of. We're still testing the effect of this PR's change on our system, but it at least moves the escaping to a more appropriate place and allows the failing signaturev4 tests to pass."
3152,'','Error 404 "CLASSIFICATION_FAILURE" when accessing Neutron endpoint in HP Cloud\nSince 9th September, I get the following error when accessing the Neutron endpoint in HP Cloud (EXCON_DEBUG is set to true for showing response in detail):\r\n\r\n```\r\n...\r\n...\r\nexcon.error.response\r\n  :body          => "{\\"fault\\":{\\"faultstring\\":\\"Not Found\\",\\"detail\\":{\\"errorcode\\":\\"CLASSIFICATION_FAILURE\\"}}}"\r\n  :headers       => {\r\n    "Content-Length" => "85"\r\n    "Content-Type"   => "application/json"\r\n    "nnCoection"     => "close"\r\n  }\r\n  :local_address => "192.168.1.11"\r\n  :local_port    => 48482\r\n  :remote_ip     => "206.164.176.32"\r\n  :status        => 404\r\n        from /var/lib/gems/1.9.1/gems/excon-0.39.5/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n        from /var/lib/gems/1.9.1/gems/excon-0.39.5/lib/excon/connection.rb:363:in `response\'\r\n        from /var/lib/gems/1.9.1/gems/excon-0.39.5/lib/excon/connection.rb:233:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-core-1.24.0/lib/fog/core/connection.rb:64:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.23.0/lib/fog/xml/connection.rb:19:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.23.0/lib/fog/hp/network.rb:164:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.23.0/lib/fog/hp/requests/network/list_networks.rb:28:in `list_networks\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.23.0/lib/fog/hp/models/network/networks.rb:20:in `all\'\r\n        from /var/lib/gems/1.9.1/gems/fog-core-1.24.0/lib/fog/core/collection.rb:139:in `lazy_load\'\r\n        from /var/lib/gems/1.9.1/gems/fog-core-1.24.0/lib/fog/core/collection.rb:22:in `to_s\'\r\n\r\n```\r\n\r\nThe script to reproduce is this:\r\n\r\n```\r\nrequire \'fog\'\r\n\r\nconn = Fog::HP::Network.new(\r\n       :hp_access_key  => ENV[\'OS_ACCESS_KEY\'],\r\n       :hp_secret_key => ENV[\'OS_SECRET_KEY\'],\r\n       :hp_auth_uri   => ENV[\'OS_AUTH_URL\'],\r\n       :hp_tenant_id => ENV[\'OS_TENANT_ID\'],\r\n       :hp_avl_zone => ENV[\'OS_REGION_NAME\'],\r\n)\r\n\r\nconn.networks.to_s\r\n```\r\n\r\nThis happens in both HP US East and West, so it doesn\'t appear a HP Cloud problem.\r\n\r\nRegards'
3151,'','AWS::AutoScaling::Instance#healthy? return incorrect ("Healthy" vs. "HEALTHY")\nUsing Fog 1.22.1, `AWS::AutoScaling::Instance#healthy?` returns `false` when it should return `true` because the method compares the value `"Healthy"` to the string `"HEALTHY"`:\r\n\r\n```ruby\r\npry> p instance\r\n<Fog::AWS::AutoScaling::Instance\r\n  id="i-9d15XXXX",\r\n  auto_scaling_group_name=nil,\r\n  availability_zone="us-west-2c",\r\n  health_status="Healthy",\r\n  launch_configuration_name="XXXX",\r\n  life_cycle_state="InService"\r\n>\r\npry> instance.health_status\r\n"Healthy"\r\npry> instance.healthy?\r\nfalse\r\n```\r\n\r\n`AWS::AutoScaling::Instance#healthy?` is [defined thusly](https://github.com/fog/fog/blob/v1.22.1/lib/fog/aws/models/auto_scaling/instance.rb#L39-L41):\r\n\r\n```ruby\r\ndef healthy?\r\n  health_status == \'HEALTHY\'\r\nend\r\n```\r\n\r\n[According to the Auto Scaling docs](http://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_SetInstanceHealth.html) this value is expected to be `Healthy` or `Unhealthy`. I\'m not sure if the best solution would be to check for those strings (`health_status == \'Healthy\'`), or to do a case-insensitive comparison (`health_status.casecmp(\'healthy\') == 0`).'
3149,'','AWS: Add EBSOptimized flag to Autoscaling Launch Configuration\nAdds the EbsOptimized flag to launch configurations. See here for reference.\r\nhttp://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_CreateLaunchConfiguration.html \r\n'
3148,'',"How to update an aws s3 file caching header?\nHi, this is not an issue, but a question:\r\n\r\nHow to update an s3 object's cache control header?\r\n\r\nI tried: \r\n\r\n    fog_file.cache_control = 'max-age=3333333'\r\n    fog_file.save\r\n\r\nThat worked fine, but removed the file's acl. How can I simply update the cache_control header without changing anything else?\r\n\r\nIs there a comprehensive guide somewhere how to do common things with fog? I found http://fog.io/, but there is only very basic info."
3147,'','digitalocean server_create add options for backup, ipv6, and user_data\nWhen creating a droplet, support the server create options for backup, ipv6 networking, and a custom user_data string (helps with CoreOS images)'
3146,'','Add support for httpsRedirect flag on Rackspace LB\nThis PR adds support to the "hidden" `httpsRedirect` flag on Rackspace Cloud Load Balancers. The flag is documented here: http://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/GET_showLoadBalancer_v1.0__account__loadbalancers__loadBalancerId__load-balancers.html\r\n\r\nI\'m not sure this patch is ready to merge yet because the `https_redirect` flag is not being correctly set on LoadBalancer instances that come from `list_load_balancers`. This is because the `httpsRedirect` field is not included in the JSON response in that case; only requests to `get_load_balancer` will contain the field. I didn\'t see a good example of how to handle this in the code. I could imagine the `https_redirect` accessor being augmented to force a call to `get_load_balancer` if the field is used and it hasn\'t been populated in the initialize call.'
3145,'',"[openstack] should allow endpoint_type on storage for authentication\nHi,\r\nwe had some problems with the storage authentication on fog/openstack.\r\nOur openstack storage-object doesn't authenticate on the 'publicURL' it should use the 'adminURL'.\r\nSo to avoid breaking other people code, you can just pass the :openstack_endpoint_type as an option.\r\nThanks."
3144,'','S3 invalid signature generation\nsignatureV4.rb can generate signatures with + signs\r\nex) "x-amz-id-2"\u2002\u2002\u2002\u2002\u2002\u2002 => "5t1UgVprgnyMWwzu2C43kMLkKmdzmeFGDPzpFrLRM68TA1dMGNJp+7unLo6iKLko"\r\namazon however generates the hash with the + symbol escaped e.g) "5t1UgVprgnyMWwzu2C43kMLkKmdzmeFGDPzpFrLRM68TA1dMGNJp%2B7unLo6iKLko"\r\nresulting in the request being rejected every time. Other symbols seem to have the same effect.\r\n\r\nOther examples of people with this problem when interacting with S3:\r\nhttp://stackoverflow.com/questions/17397924/amazon-s3-strange-error-sometimes-signaturedoesnotmatch-sometimes-it-does\r\nhttps://coderwall.com/p/56a9ja\r\n\r\nI believe the underlying cause is due to the fact S3 accepts the signature in both the header and as a query param and they are using the same code for both (i.e. + signs and / are invalid in the query param for obvious reasons) As a result any signature that gets generated with a special character in a url query param would be invalid in the header.\r\n\r\nsupporting documentation:\r\nhttp://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html'
3143,'',"Radosgw\nHere is a Fog backend for provisioning Ceph Radosgw - the Swift and S3 comaptible REST API for Ceph. It is based on the backend for Riak-CS. We only care about S3 compatible storage, so we haven't done anything about provisioning Swift subusers.\r\n\r\nJon KÃ¥re Hellan\r\nUNINETT AS\r\nTrondheim, Norway"
3142,'','remove fog/bin/sakuracloud and copy it to fog_sakuracloud\nIt depends on fog/fog-sakuracloud issues below.\r\n\r\nhttps://github.com/fog/fog-sakuracloud/pull/1\r\nhttps://github.com/fog/fog-sakuracloud/pull/2\r\n\r\nWe have to release fog-sakuracloud v0.0.4 before merge this PR.'
3141,'','Linode plans filter by planid, remove hack\nThe API call avail.linodeplans correctly filters by planid now.  The PR removes the hack that filtered in local code.\r\n\r\nWhile testing this, I found that `Fog::Compute::Linode` was incorrectly referenced in a couple places.\r\n\r\nI was able to test as in: \r\n```\r\n>> Fog::Compute.new(:provider=>\'Linode\').flavors.get 1\r\n  <Fog::Compute::Linode::Flavor\r\n    id=1,\r\n    disk=24,\r\n    name="Linode 1024",\r\n    ram=1024,\r\n    price=10.0\r\n  >\r\n```\r\n\r\nBut (even on fog/master) I get the full list when I try:\r\n```\r\n>> Fog::Compute.new(:provider=>\'Linode\').flavors :id=>1\r\n```\r\nIs this intended to return the specific flavor?'
3138,'',"select vlan or portgroup for first network interface with vsphere?\nHello,\r\n\r\ncan you tell me, if there is a solution for selecting the vlan on vSwitch and if I'm on a distributed virtual switch, the portgroup the vm should be connected to, during vm_clone with the vsphere provider? I've been looking in the docs, and on google but didn't find out the right way.\r\n\r\nKind regards,\r\nLothar"
3135,'','Ruby Warnings\nHere are fixes for some trivial Ruby :warning:s.'
3134,'',"[vsphere] vm_clone method uses wrong path to find vm\nIf you pass 'template_path' but not a 'dest_folder' in the options to the vm_clone method, the vm will be created in the template folder but the get_virtual_machine method at the end of the vm_clone method uses the option['dest_folder'] which is nil so the path is wrong. "
3133,'','remove sakuracloud libs and add fog sakura-cloud to depends.\nI had divided sakura cloud provider as rubygem for maintainability.\r\nThe gem fog-sakuracloud had been released.'
3132,'',"[linode|compute] Get number of CPU cores from the API\nLinode's `avail.linodeplans` API call (https://www.linode.com/api/utility/avail.linodeplans) now returns the number of CPU cores for a given plan; these changes take advantage of that."
3130,'',"[RACKSPACE] allow userdata to be passed to Rackspace AutoScale\nHi,\r\nthis passes through the options to create a config-drive and upload user-data to it. It makes me rather sad that we might end up copying all of the attributes of the v2 node creation into the auto scale launch config, but I can't see a more appropriate approach right now."
3129,'',"Failures to bootstrap ubuntu 12.04 in the Rackspace cloud\nHello! I'm using test-kitchen with the Rackspace driver, which wraps fog. And whenever the bootstrap (rackspace/models/compute_v2/servers.rb) and setup (rackspace/models/compute_v2/server.rb) methods are called on an Ubuntu 12.04 server, net-ssh dies:\r\n\r\n```\r\n$ kitchen converge default-ubuntu-1204 -l debug\r\n-----> Starting Kitchen (v1.2.1)\r\nD      Berksfile found at /home/mart6985/src/sanitized/Berksfile, loading Berkshelf\r\nD      Berkshelf 3.1.5 library loaded\r\nD      Berksfile found at /home/mart6985/src/sanitized/Berksfile, loading Berkshelf\r\nD      Berkshelf 3.1.5 previously loaded\r\nD      Berksfile found at /home/mart6985/src/sanitized/Berksfile, loading Berkshelf\r\nD      Berkshelf 3.1.5 previously loaded\r\nD      Berksfile found at /home/mart6985/src/sanitized/Berksfile, loading Berkshelf\r\nD      Berkshelf 3.1.5 previously loaded\r\nD      Berksfile found at /home/mart6985/src/sanitized/Berksfile, loading Berkshelf\r\nD      Berkshelf 3.1.5 previously loaded\r\nD      Berksfile found at /home/mart6985/src/sanitized/Berksfile, loading Berkshelf\r\nD      Berkshelf 3.1.5 previously loaded\r\n-----> Creating <default-ubuntu-1204>...\r\n>>>>>> ------Exception-------\r\n>>>>>> Class: Kitchen::ActionFailed\r\n>>>>>> Message: Failed to complete #create action: [end of file reached]\r\n>>>>>> ----------------------\r\n>>>>>> Please see .kitchen/logs/kitchen.log for more details\r\n>>>>>> Also try running `kitchen diagnose --all` for configuration\r\n\r\nD      ------Exception-------\r\nD      Class: Kitchen::ActionFailed\r\nD      Message: Failed to complete #create action: [end of file reached]\r\nD      ---Nested Exception---\r\nD      Class: EOFError\r\nD      Message: end of file reached\r\nD      ------Backtrace-------\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/proxy/command.rb:75:in `read_nonblock'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/proxy/command.rb:75:in `recv'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/buffered_io.rb:65:in `fill'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/packet_stream.rb:86:in `next_packet'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:178:in `block in poll_message'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:173:in `loop'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:173:in `poll_message'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:210:in `block in wait'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:208:in `loop'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:208:in `wait'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/transport/session.rb:87:in `initialize'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh.rb:202:in `new'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh.rb:202:in `start'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/fog-core-1.23.0/lib/fog/core/ssh.rb:67:in `run'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/fog-1.23.0/lib/fog/rackspace/models/compute_v2/server.rb:583:in `setup'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/fog-1.23.0/lib/fog/rackspace/models/compute_v2/servers.rb:43:in `bootstrap'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/kitchen-rackspace-0.9.0/lib/kitchen/driver/rackspace.rb:123:in `create_server'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/kitchen-rackspace-0.9.0/lib/kitchen/driver/rackspace.rb:72:in `create'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:273:in `public_send'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:273:in `block in perform_action'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:308:in `call'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:308:in `synchronize_or_call'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:283:in `block in action'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/1.9.1/benchmark.rb:280:in `measure'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:282:in `action'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:273:in `perform_action'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:252:in `create_action'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:246:in `block in transition_to'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:245:in `each'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:245:in `transition_to'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/instance.rb:119:in `converge'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/command.rb:109:in `public_send'\r\nD      /home/mart6985/.rbenv/versions/1.9.3-p484/lib/ruby/gems/1.9.1/gems/test-kitchen-1.2.1/lib/kitchen/command.rb:109:in `block (2 levels) in run_action'\r\nD      ----------------------\r\n```\r\n\r\nI noticed someone else had also seen failures, and added a retry in https://github.com/fog/fog/pull/2918. And in the comments of the code itself under ` fog/lib/fog/rackspace/models/compute_v2 / server.rb`, there's a bit that says:\r\n```\r\n# Ubuntu 12.04 images seem to be disconnecting during the ssh setup process.\r\n# This rescue block is an effort to address that issue.\r\n```\r\n\r\nSomehow, I've started experiencing this as well. I have not updated any gems recently, so I'm baffled as to where this came from. Any advice to help troubleshoot or seek out solutions from net-ssh would be much appreciated."
3128,'','Redux of update to CloudStack 4.4 API and supporting "overloaded" method...\n...s to support old and new styles of calling\r\n\r\nCloudStack API functions.\r\nThis should allow all options to be passed as a single hash or as an ordered list of parameters.'
3127,'','Revert "Updated to CloudStack 4.4 API and re-added historical function b...\n...ehavior."\r\n\r\nThis didn\'t work as expected for some of the functions, so revert and I\'ll continue hacking on this to get it to behave correctly.'
3126,'',"Updated to CloudStack 4.4 API and re-added historical function behavior.\nI'm hoping to start adding more mocks and tests as soon as I've wrapped my head around Shindo."
3125,'icco','[google|dns] Improve non-mocked tests, add support for get_managed_zone, with tests.\n@icco please ignore the previous pull requests, this one has both commits.\r\nThis is for #2865'
3124,'','[google|dns] Let non-mocked tests run by setting an env variable.\nIf $FOG_TEST_GOOGLE_DNS_ZONE is set in the environment, the tests run in\r\nnon-mocked mode too. Also perform some basic validation for the convenience of\r\nthe user - Google API just says "Invalid value for\r\n\'entity.managedZone.dnsName\'" without hinting on what is wrong.\r\n\r\n@icco please review\r\nThis is for #2865'
3120,'','[Rackspace | LoadBalancer] Adding nodes to load balancer\nI cannot figure out how to add nodes to an existing load balancer.  I\'m trying various things like:\r\n\r\n```\r\nload_balancers.first.nodes.append(Fog::Rackspace::LoadBalancers::Node.new("address" => "10.176.71.1", "port" => 443, "condition" => "ENABLED", "status" => "ONLINE"))\r\n```\r\n\r\nand\r\n\r\n```\r\nload_balancers.first.nodes << {"address" => "10.176.71.1", "port" => 80, "condition" => "ENABLED"}\r\n```\r\n\r\nI don\'t get any error, but the node doesn\'t actually get added to the load balancer.\r\n\r\nCan you direct me as to the appropriate way to use this API?\r\n\r\nThanks,\r\nPatrick'
3119,'',"[aws] catch invalid uri\nif URI.parse does not result in a host we don't continue and raise\r\nan error.\r\nthis fixes the failing build"
3118,'','normalize openstack config parameter names.\nThis normalizes all of the class options for the openstack provider by removing the prepended  "openstack_" string to all config parameters.\r\n\r\nWhen developing tooling for a multi-cloud environment (e.g. openstack and aws), the goal should be to abstract away differences between cloud providers. This is not possible when each fog provider has chosen to add provider-specific nomenclature to their configuration parameters. \r\n\r\nWhen I specify "region", it should be implied that it means "region" in whatever provider I\'ve instantiated. I shouldn\'t have to add complexity to my code to say "In the AWS case, the variable is called "region", but in the OpenStack case, it\'s called "openstack_region".\r\n\r\nThis pull request is aimed at fixing this issue.'
3116,'',"Azure support\nHello, \r\nI'm about to start implementation of Microsoft Azure support in Fog. I'm corious about your opinions about using azure client for that matter:\r\nhttps://github.com/Azure/azure-sdk-for-ruby\r\nWould you prefer to have independent implementation creating requests to API directly or rather make use of the client gem. \r\nThanks for any help. \r\nBW"
3113,'','Fix Openstack Storage service_type\nChange the Openstack Storage service (Swift) openstack_service_type default value from "object-store" to ["object-store"].\r\n    \r\nThe problem with "object-store" as an openstack_service_type is that if the Swift service is unavailable, the authenticate_v2 method will attempt to call:\r\n    \r\n   service_type.join ", "\r\n    \r\nThis will fail for anything that isn\'t an array.\r\n    \r\nChanging the openstack_service_type to an array solves this problem.  Additionally, it keeps the openstack_service_type consistent with all of the other Openstack services\' openstack_service_type default values.\r\n\r\nFixes issue #3112'
3112,'','The Openstack Service Type for Storage should be an array\nIf an Openstack installation doesn\'t have Swift running, trying to connect to Swift via Fog should throw an error indicating that the service is not available.  This is how all of the other services behave.\r\n\r\nHowever, with Swift (the "Storage" service) the `openstack_service_type` is "object-store".  For all other Openstack services, the `openstack_service_type` is an array.  This is important because when the Openstack connection is attempted and fails, it attempts to assemble an error message by calling:\r\n\r\n```ruby\r\nservice_type.join \', \'\r\n```\r\n\r\nHowever, `String` doesn\'t have a `join` method.  So, this fails.\r\n\r\nThe fix is to simply wrap the `Openstack::Storage openstack_service_type` with an array: `["object-store"]`.\r\n\r\nWe\'re currently using Fog 1.19, but I believe I still see the same code in master.  So, this *should* still be a problem in master.  However, if someone has validated that this is actually not a problem in master anymore, please note it in the comments.  Thanks! '
3111,'','Aws account policy\ni have added the account password policy methods to the iam model for AWS'
3110,'','[rackspace] More optional parameters for Cloud Load Balancers\nThis makes the `:nodes` and `:port` parameters optional for `create_load_balancer()` and `load_balancers.create()`. The docs (and testing against the API) indicate that `:virtual_ips` *is* required.\r\n\r\n/cc @elight, @maxlinc\r\n\r\nfixes #2902'
3109,'','Check region against static list, only if host is a subdomain of amazonaws\nFollowing the proposal in #3106, here is the simple approach of simply disabling the check for non-aws subdomains.\r\n'
3108,'','[openstack] fix network.rb\nI found a bug.\r\nThis code only, was different to the other code.(compute.rb,identity,....etc)'
3107,'',"Remove default region from Rackspace services\nI've pulled the trigger and removed the default region from all (regioned) Rackspace services. Attempting to instantiate a service without a `:rackspace_region` or appropriate endpoint parameter now results in a message like:\r\n\r\n```\r\nThere are multiple endpoints available for cloudFiles. Please specify one of the following regions: :ord, :syd, :dfw, :iad. (RuntimeError)\r\n```\r\n\r\nNote that `:rackspace_region` is still a `recognizes` rather than a `requires` so that you can still specify the service endpoint manually and bypass the service catalog interrogation.\r\n\r\nAlso, while I was going through, I noticed that `Queues` and `Storage` didn't have deprecation messages! What should we do about those?\r\n\r\n/cc @elight\r\n\r\nFixes #3091."
3106,'',"AWS: Hard-coded regions break provider for compatible services\nHi,\r\n\r\nIn [validate_regions](https://github.com/fog/fog/blob/master/lib/fog/aws/region_methods.rb) there is a list of hard-coded regions. If I run a AWS compatible cloud provider, I cannot use the AWS provider with my defined regions, and neither can I use any future introduced region from Amazon without changing the code.\r\n\r\nI'd propose to either scrap the validation and catch the resulting error where they occur, or\r\nuse the API call  [describe_regions](https://github.com/fog/fog/blob/master/lib/fog/aws/requests/compute/describe_regions.rb) instead.\r\n\r\nIf I find some time, and you don't object my proposal or fix it faster yourself, I'd offer a merge request at some later time\r\n\r\nThanks,\r\n  Fabian\r\n\r\n"
3105,'','add missing HEAD Bucket request\nas per http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketHEAD.html\r\n\r\nbasically just copied and stripped down head_object.rb to suit'
3104,'','updating the key_pair method call from the aws server model\ngetting rid of the depreciation warning when calling key_pair from the aws server model.'
3103,'',"added ready? for sshable\nFix for linode servers wait_for { sshable? }.\r\nAnd also swap is fixed to 256m, since it's useless to have a big swap in virtual env/...\r\n\r\n- Dennis"
3102,'','Route 53 health check support\nThis PR adds request support for creating, deleting and listing Amazon Route 53 Health checks.  It also modifies the existing Route 53 DNS requests so that the missing fields from the API are included such as Failover, GeoLocation and HealthCheckID.  Finally, the DNS record model is updated to show these missing fields.\r\n\r\nNote: All of the new requests do not have Mocks as it seemed like a lot of work, and at present, I am not sure where they would be used.  If there is demand for this I would consider adding this later, however I have added tests to all the requests ensuring the code provided does work against the Amazon Route 53 API.'
3101,'','Db grant access\nAdds support for granting and revoking DB privileges on a per user basis.'
3100,'','fog: `lookup_volume_by_name\': Expected Connection object (ArgumentError)\nHi, i\'m following the quick start guide using the centos64 box.\r\ni\'m getting this eror, and don\'t know if i should address this here or at the vagrant-libvirt project:\r\n\r\n```\r\n$ cat Vagrantfile\r\nVagrant.configure("2") do |config|\r\n  config.vm.define :test_vm do |test_vm|\r\n    test_vm.vm.box = "centos64"\r\n  end\r\nend\r\n\r\n$ vagrant up --provider=libvirt\r\nVagrant.require_plugin is deprecated and has no effect any longer.\r\nUse `vagrant plugin` commands to manage plugins. This warning will\r\nbe removed in the next version of Vagrant.\r\nBringing machine \'test_vm\' up with \'libvirt\' provider...\r\n/home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:10:in `lookup_volume_by_name\': Expected Connection object (ArgumentError)\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:10:in `block (2 levels) in list_volumes\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:9:in `each\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:9:in `block in list_volumes\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:44:in `block in raw_volumes\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:42:in `each\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:42:in `raw_volumes\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/requests/compute/list_volumes.rb:8:in `list_volumes\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/fog-1.23.0/lib/fog/libvirt/models/compute/volumes.rb:11:in `all\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/vagrant-libvirt-0.0.19/lib/vagrant-libvirt/action/handle_box_image.rb:39:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/builtin/handle_box.rb:56:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/vagrant-libvirt-0.0.19/lib/vagrant-libvirt/action/handle_storage_pool.rb:21:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/vagrant-libvirt-0.0.19/lib/vagrant-libvirt/action/set_name_of_domain.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:95:in `block in finalize_action\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/builder.rb:116:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/runner.rb:66:in `block in run\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/util/busy.rb:19:in `busy\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/runner.rb:66:in `run\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/builtin/call.rb:53:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /home/varac/.vagrant.d/gems/gems/vagrant-libvirt-0.0.19/lib/vagrant-libvirt/action/connect_libvirt.rb:45:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/builtin/config_validate.rb:25:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/warden.rb:34:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/builder.rb:116:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/runner.rb:66:in `block in run\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/util/busy.rb:19:in `busy\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/action/runner.rb:66:in `run\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/machine.rb:196:in `action_raw\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/machine.rb:173:in `block in action\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/environment.rb:434:in `lock\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/machine.rb:161:in `call\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/machine.rb:161:in `action\'\r\n\tfrom /opt/vagrant/embedded/gems/gems/vagrant-1.6.3/lib/vagrant/batch_action.rb:82:in `block (2 levels) in run\'\r\n\r\nvirsh pool-info default          \r\nName:           default\r\nUUID:           92183d39-f917-4ec1-87a2-837f852fab93\r\nState:          running\r\nPersistent:     yes\r\nAutostart:      no\r\nCapacity:       12.67 GiB\r\nAllocation:     5.42 GiB\r\nAvailable:      7.25 GiB\r\n\r\n```'
3097,'','[Openstack | Storage] add possibility to create public containers.\nI need to create public containers in OpenStack. \r\n\r\nThis PR adds this possibility.'
3096,'','[tutum] Adding tutum support\nThis is a WIP PR for adding tutum support to fog.\r\n\r\nTutum is a docker container PAAS providing three main models, containers, images and applications. An application consists of N containers based off of the same image. \r\n\r\nStill todo\r\n\r\n* Add requests and tests\r\n* Get all tests working'
3095,'','AutoScaling Tagging Docs Incorrect (also tests)\nDocumentation and tests are incorrect for the create_auto_scaling_group tags options. \r\n\r\nhttps://github.com/fog/fog/blob/v1.23.0/tests/aws/requests/auto_scaling/tag_tests.rb#L18-L24\r\n\r\nThis example yields \r\n\r\n```\r\nException Fog::AWS::AutoScaling::ValidationError -> 1 validation error detected: Value \'{&quot;Key&quot;=&gt;&quot;Name&quot;, &quot;PropigateAtLaunch&quot;=&gt;true, &quot;ResourceId&quot;=&gt;&quot;name-is-here-dude&quot;, &quot;ResourceType&quot;=&gt;&quot;auto-scaling-group&quot;, &quot;Value&quot;=&gt;&quot;name-is-here-dude&quot;}\' at \'tags.1.member.key\' failed to satisfy constraint: Member must have length less than or equal to 128\r\n```\r\n\r\nThe array each_with_index is broken (i\'m running ruby 1.9.3). See link below.\r\nhttps://github.com/fog/fog/blob/v1.23.0/lib/fog/aws/requests/auto_scaling/create_auto_scaling_group.rb#L74-L79\r\n\r\nIF you try and provide a hash (not an array) to "Tags" it will make each item a tag. \r\n![screen shot 2014-08-08 at 7 56 42 pm](https://cloud.githubusercontent.com/assets/1903525/3860686/e087a7d8-1f26-11e4-9d87-a929959b50ec.png)\r\n\r\n\r\nEither the docs need to be updated to provide a hash OR the code needs another iteration around the tags option. \r\n\r\nLink to the inline docs https://github.com/fog/fog/blob/v1.23.0/lib/fog/aws/requests/auto_scaling/create_auto_scaling_group.rb#L35-L47\r\n\r\n\r\nUsing Fog 1.23.0 - ruby 1.9.3'
3094,'','[google|dns] Add initial support for Google Cloud DNS.\n- some common plumbing\r\n- requests for creating, deleting and listing managed zones, with tests\r\n\r\nOne thing we should discuss is the test domain in tests/google/requests/dns/managed_zone_tests.rb\r\nFor the test to pass in non-mocked mode, the developer who runs the tests needs to confirm its ownership with Google. This implies that it needs to be configured for every developer individually.\r\nAlternatively (and this is what probably should be the default) is to disable most (if not all) the Google DNS tests in non-mocked mode.'
3093,'','[google|compute] fix for issue #3083, image create\n'
3092,'','Fix parsing of SpotInstanceRequests responce when we also specify NetworkInterface\nWhen you specify LaunchSpecification.NetworkInterface.* for [RequestSpotInstances](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-RequestSpotInstances.html)\r\nresponse of [DescribeSpotInstanceRequests](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeSpotInstanceRequests.html) have additional elements \r\n```xml\r\n<networkInterfaceSet>\r\n   <item>\r\n     <deviceIndex>0</deviceIndex>\r\n     <subnetId>subnet-aa707382</subnetId>\r\n     <description>test</description>\r\n     <privateIpAddress>10.0.0.12</privateIpAddress>\r\n     <groupSet>\r\n       <item>\r\n         <groupId>sg-f1612594</groupId>\r\n       </item>\r\n     </groupSet>\r\n     <deleteOnTermination>true</deleteOnTermination>\r\n   </item>\r\n</networkInterfaceSet>\r\n```\r\n[Default xml response](http://pastebin.com/3FVeqmUB)\r\n[With networking xml response](http://pastebin.com/c6BTeVtM)\r\n\r\nWith networking we does not parce instanceId well.\r\nThis pull request fix bug with parsing such cases.'
3091,'',"Remove default region support\n@krames and I deprecated this over 6 months ago.  We'd agreed to let this sit for that duration. Now that the period has lapsed, it should be removed entirely.\r\n\r\n/cc @smashwilson"
3090,'',"Accept Block For Get Requests\nMost storage providers accept a block for chunked downloads. Fog's Atmos implementation does not support this functionality hence the download_from_blobstore method (https://github.com/cloudfoundry/cloud_controller_ng/blob/master/lib/cloud_controller/blobstore/client.rb) fails. The method always results in a zero byte file downloaded.\r\n\r\nThis PR allows a block to be accepted and downloads to continue. \r\nI have not been able to add tests for this as there is no mocking structure in the Atmos implementation."
3089,'',"compute search filter for availability-zone broken on aws when mocking\nHi,\r\n\r\nIt seems that the filter for availability_zone doesn't work as intended, at least when mocking.  It looks like that's because when fog is iterating the list of servers returned, it is looking for a top level key of availabilityZone, when it is nested under the placement hash."
3088,'','[feature] Add support for GCE SSD\nSSD disks are now GA: https://developers.google.com/compute/docs/release-notes#june252014\r\n\r\nhttps://developers.google.com/compute/docs/disks#ssdperformance\r\nhttps://developers.google.com/compute/docs/disks#create_disk'
3085,'','[google|sql] Use the correct directory for Google Cloud SQL examples\nUpss, the examples were under `lib/fog/google/examples/examples` when they must go to `lib/fog/google/examples/sql`.'
3081,'',"[dynect|dns] Let job_poll_timeout be specified.\nThis lets the dynect job poll timeout be specified.\r\n\r\nWe've observed that as the number of records in a zone grows jobs can take longer than the previously hard-coded 10s."
3080,'','[google|compute] Refactor Compute to use the new Shared module\nCommit d801b27 introduced a new Shared module with logic to initialize a google_client_api, and to make requests.\r\n\r\nThis commit refactors Compute to use the new Shared module.'
3079,'','"Excon unable to add file to cert store" when accessing S3, reinstalling excon gem fixes problem\nI\'m using fog 1.23 (also have this problem in fog 1.15 though). I have the following Ruby code for listing files in an S3 bucket:\r\n\r\n    def s3_connect\r\n      aws = Fog::Storage.new({\r\n                                 :provider                 => \'AWS\',\r\n                                 :aws_access_key_id        => @aws_access_key_id,\r\n                                 :aws_secret_access_key    => @aws_secret_access_key\r\n                               })\r\n      aws.directories.new({:key => @aws_package_dir})\r\n    end\r\n\r\n    def s3_list(packagename)\r\n      s3_dir = s3_connect\r\n      begin\r\n        packages = s3_dir.files.all(:prefix => packagename).map { |f| f.key }\r\n      rescue\r\n        puts "Failure trying to list packages in S3!"\r\n        return []\r\n      end\r\n      packages ? packages : []\r\n    end\r\n\r\nWhen I call my s3_list method, it fails like this:\r\n\r\n[excon][WARNING] Excon unable to add file to cert store, ignoring: /var/lib/gems/1.8/gems/excon-0.38.0/data/cacert.pem\r\n[OpenSSL::X509::StoreError] system lib\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/ssl_socket.rb:47:in `initialize\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:414:in `new\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:414:in `socket\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:126:in `request_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/mock.rb:44:in `request_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/instrumentor.rb:22:in `request_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:269:in `request\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:292:in `request\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:292:in `request\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n/var/lib/gems/1.8/gems/excon-0.38.0/lib/excon/connection.rb:292:in `request\'\r\n/var/lib/gems/1.8/gems/fog-1.23.0/lib/fog/xml/sax_parser_connection.rb:35:in `request\'\r\n/var/lib/gems/1.8/gems/fog-1.23.0/lib/fog/xml/connection.rb:17:in `request\'\r\n/var/lib/gems/1.8/gems/fog-1.23.0/lib/fog/aws/storage.rb:535:in `request\'\r\n/var/lib/gems/1.8/gems/fog-1.23.0/lib/fog/aws/requests/storage/get_bucket.rb:51:in `get_bucket\'\r\n/var/lib/gems/1.8/gems/fog-1.23.0/lib/fog/aws/models/storage/directories.rb:22:in `get\'\r\n/var/lib/gems/1.8/gems/fog-1.23.0/lib/fog/aws/models/storage/files.rb:31:in `all\'\r\n/var/lib/gems/1.8/gems/brpkg-3.1.5/lib/package/storage.rb:39:in `s3_list\'\r\n/var/lib/gems/1.8/gems/brpkg-3.1.5/lib/package/finder.rb:90:in `remote_versions\'\r\n/var/lib/gems/1.8/gems/brpkg-3.1.5/lib/package/finder.rb:69:in `versions\'\r\n/var/lib/gems/1.8/gems/brpkg-3.1.5/lib/package/finder.rb:13:in `all\'\r\n/var/lib/gems/1.8/gems/brpkg-3.1.5/bin/brpkg:285\r\n/usr/local/bin/brpkg:19:in `load\'\r\n/usr/local/bin/brpkg:19\r\n\r\nIf I simply uninstall and reinstall the excon gem, the same code works fine. \r\n\r\nMy code is a gem, which simply lists fog as a requirement in its gemspec. I install my gem, and rubygems handles installing fog and all its dependencies. So I can\'t understand what could be failing there, or why simply reinstalling excon clears up the issue. This is Ruby 1.8.7 and and rubygems 1.8.15, the defaults on Ubuntu Precise. '
3078,'icco',"[google|compute] added more HTTP load balancing resources\n'add backend services backend', global forwarding rules, target http proxies, and url maps"
3077,'icco','[google|sql] Complete support for Google Cloud SQL\n- Add models, requests and tests for Flags\r\n- Add models, requests and tests for Operations\r\n- Add models, requests and tests for Instances\r\n- Add models, requests and tests for SslCerts\r\n- Add models and requests for BackupRuns\r\n- Add examples\r\n\r\nSolves https://github.com/fog/fog/issues/2976'
3076,'',"added more HTTP load balancing resources\n'add backend services backend', global forwarding rules, target http proxies, and url maps"
3074,'','remove leading slash from Rackspace compute_v2 request paths\nThis is a minor issue; the leading slash would create a double slash in the resulting path.\r\n![capture](https://cloud.githubusercontent.com/assets/1262042/3741365/1ae13ac2-175f-11e4-8a73-a172d879fda2.png)\r\n'
3072,'','Clean up Excon::Errors::SocketError::EOFError warning in vcloud_director\nEvery time I make a connection with the vcloud_director provider I get this warning:\r\n\r\n/Users/mray/.chgems/vchs/.gem/ruby/2.1.2/gems/fog-1.23.0/lib/fog/vcloud_director/compute.rb:372: warning: toplevel constant EOFError referenced by Excon::Errors::SocketError::EOFError'
3070,'',"[vsphere] Adding dnsSuffixList support\n**Problem**\r\nvm_clone uses domain as the DNS search suffix, without allowing the user override it. This prevents the user from being able to define multiple DNS suffixes.\r\n\r\n**Solution**\r\nAdded 'dnsSuffixList' as an option.. if not provided, default to using domain."
3069,'',"[google|compute] Add backend services resource for L7 load balancing\nThese changes allow management of GCE's backend services resource including create, destroy, and check health."
3067,'','log writing failed. "\\xFF" from ASCII-8BIT to UTF-8\n### log writing failed. "\\xFF" from ASCII-8BIT to UTF-8\r\nAfter i upgrade my application to ruby 2.1.2, and I using fog with version 1.23.0 (laster version), but when i run rspec with task upload image to S3 then error happend: "log writing failed. "\\xFF" from ASCII-8BIT to UTF-8".\r\n\r\nI try install gem activesupport-json-encode, but failure.\r\n\r\nSo, can everyone help me resolve this problem?\r\n\r\nThanks'
3066,'','[google|monitoring] Add support for Google Cloud Monitoring\nThis commit adds the initial support for [Google Cloud Monitoring](https://developers.google.com/cloud-monitoring/)\r\n\r\n- Add models, requests, tests & examples for Timeseries\r\n- Add models, requests, tests & examples for TimeseriesDescriptors\r\n- Add models, requests, tests & examples for MetricDescriptors'
3065,'','[google|compute] added centos, opensuse images\n@icco - added new projects to the list for CoreOS and Open Suse.  These are publicly available images now, https://developers.google.com/compute/docs/operating-systems.'
3064,'',"Looking for Suggestions.\nWhen i was trying to refactor some stuff at [fog-xenserver](https://github.com/fog/fog-xenserver) i found an interesting [method](https://github.com/fog/fog/blob/master/lib/fog/xenserver/models/compute/vlan.rb#L48).\r\nIt is an instance method and require `attributes[:pif]` and `attributes[:network]`, but the [model](https://github.com/fog/fog/blob/master/lib/fog/xenserver/models/compute/vlan.rb) doesn't have this attributes.\r\nThe [documentation](https://github.com/fog/fog/blob/master/lib/fog/xenserver/models/compute/vlan.rb#L45) is about the request, not this method. I really don't know how to proceed here. Should i go ahead and add this attributes to the model? Or just rewrite the method, since its not correctly working?\r\n\r\nI know it works if you set the attributes on the instance like:\r\n\r\n```ruby\r\n@vlan.attributes[:pif] = 'crazy-reference'\r\n@vlan.attributes[:network] = 'crazy-reference' \r\n```\r\n\r\nbut i don't think this is the way it is supposed to work. =s\r\n\r\ncc/ @geemus @tokengeek \r\n\r\nI'm looking for points/suggestions here. =)\r\nSorry if this is not the best place to ask this, but i wanted it to be asynchronous. (IRC #ruby-fog is kind of a lot of messages of commits and pull requests, so it would get lost) "
3063,'','Update create_server.rb\nRepair bug for platform attribute of a vm.'
3062,'','"Fog::Compute[:google] | server model (google)" ++ hangs\nruby 1.9.3p194 (2012-04-20 revision 35410) [x86_64-linux]\r\n\r\n    porridge@beczulka:~/fog$ FOG_CREDENTIAL=fake FOG_MOCK=true bundle exec shindont +google \r\n    [...]\r\n    Fog::Schema::DataValidator (meta)   \r\n    Fog::Compute[:google] | region model (google) +  \r\n    Fog::Compute[:google] | regions model (google) +++  \r\n    Fog::Compute[:google] | disk model (google) ++  \r\n    Fog::Compute[:google] | servers (google) +++++++++++++++++++  \r\n    Fog::Compute[:google] | server model (google) ++^C/var/lib/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:4:in `block in <top (required)>\': wrong number of arguments (1 for 0) (ArgumentError)\r\n\tfrom /var/lib/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:65:in `call\'\r\n\tfrom /var/lib/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:65:in `join\'\r\n\tfrom /var/lib/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:65:in `run_in_thread\'\r\n\tfrom /var/lib/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:72:in `<top (required)>\'\r\n\tfrom /var/lib/gems/1.9.1/gems/shindo-0.3.8/bin/shindont:5:in `require_relative\'\r\n\tfrom /var/lib/gems/1.9.1/gems/shindo-0.3.8/bin/shindont:5:in `<top (required)>\'\r\n\tfrom /usr/local/bin/shindont:23:in `load\'\r\n\tfrom /usr/local/bin/shindont:23:in `<main>\'\r\n    porridge@beczulka:~/fog$ \r\n\r\nThe stack trace is not terribly useful, I\'m afraid.'
3060,'','[aws] support `xvd` based devices (HVM)\nEY needs this for images that have `/dev/xvd[a-p]` devices.'
3059,'','Add fog-softlayer module .\n@geemus : as requested, a PR from this branch.'
3058,'','Remove providers directory\nModular code is gem based and we have been using fog-brightbox as a\r\nprototype for a while now as a proof of concept.\r\n\r\nManagement of numerous gems within the code base did not look like it\r\ncould scale particularly well for fog.'
3057,'','Vm.platform bug\nHello,\r\n\r\nThere is a problem in /lib/fog/xenserver/requests/compute/create_server.rb line 59\r\n"platform" attribute is specified 2 times(once in bad format and secound empty).\r\nCurrent code:\r\n            :actions_after_reboot =>    \'Restart\',\r\n            :actions_after_crash =>     \'Restart\',\r\n            :platform =>                { \'nx\' => false, \'acpi\' => true, \'apic\' => \'true\', \'pae\' => true, \'viridian\' => true},\r\n            :platform =>                {},\r\n            :other_config =>            {},\r\n            :pool_name =>               \'\',\r\n\r\nCorrect/working code:\r\n\r\n            :actions_after_reboot =>    \'Restart\',\r\n            :actions_after_crash =>     \'Restart\',\r\n            :platform =>                { :\'nx\' => \'true\', :\'acpi\' => \'true\', :\'apic\' => \'true\', :\'pae\' => \'true\', :\'viridian\' => \'true\'},\r\n            :other_config =>            {},\r\n            :pool_name =>               \'\',\r\n\r\nThis prevents the X64 vm\'s from booting from pxe.\r\n\r\nI hope this was the corrent way to report this\r\n\r\nThank you\r\n'
3056,'','[AWS] Add support for EBS Volume Type gp2\nA new general purpose (SSD) EBS volume is out: http://aws.amazon.com/ebs/details/'
3055,'','Typo in fog.io link\nfixed a type in the link to fog.io'
3053,'','[linode] add api requests to update and delete configuration profiles\n'
3052,'','[google|compute] Add support for Disk Types\nAdd support for [GCE DiskTypes resources](https://developers.google.com/compute/docs/reference/latest/diskTypes).'
3051,'','[vcloud_director] Add more mocks\nThis PR adds a couple more Mocks to the get_execute_query method.'
3050,'','Add options for Zerigo List Hosts\nAdd options to List Hosts for fqdn, page, per_page. \r\n\r\nThere is a little overlap find_hosts, but this adds pagination as well.\r\n\r\nI always have a little problem with the Shindo tests, so let me know if those need updating. '
3049,'','[#3048] Lock down rest-client version\nNew versions have dropped 1.8.7 support and they are getting picked up\r\nby Travis.'
3048,'',"Drop 1.8.7 support?\nUg, 1.8.7 builds are broken. I'm not sure how long we can really maintain this and I'm not keen on chasing it. I think I'll move the 1.8.7 related builds to still happen but be allowed to fail (for now). For now we'll try not to worsen the situation, but unless there is a champion that really wants to help us out here, I suspect it may be on it's way out."
3047,'','[glesys] API change, new attribute :bandwidth added\nGlesys has added a new attribute to be able to set bandwidth on servers. The default is set to 10 Mbit/s. (The range is 10 - 500 Mbit/s).'
3046,'','remove :host from request parameters, stopping excon errors with Elastic Beanstalk\n`beanstalk.rb` still contains a host parameter in this `#request` method, which throws an excon error when using the Elastic Beanstalk classes in Compute.. Removing it - as has been done in other points of the fog codebase - fixes that error.'
3045,'','Fix describe_internet_gateways calls for >1 igw\n@internet_gateway was incorrectly reset after the first\r\nInternetGatewaySet item.  On encountering a second, we end up\r\nattempting to dereference nil as a hash, causing the parser to\r\nblow up with an unintuitive error.\r\n\r\nFixes #2920'
3044,'','[vcloud_director] Mocks for a number of vApp operations\nThis PR adds Mocks for several requests. Some of the Mocks do not cover all possible cases, only the ones we need for running [our tests](https://github.com/gds-operations/vcloud-core/tree/master/spec/integration), but can easily be extended for other uses.'
3043,'','RAX API is returning virtual_ips, not virtualIps\nFixing mock for get_load_balancer'
3042,'','[vsphere] Remove the relative_path attribute.\nThe <Vsphere::Server>.relative_path attribute depends on having\r\ninitialized the <server>.datacenter field (which is lazy loaded).\r\nWhen the relative_path is computed from the attributes returned by\r\nthe underlying rbvmomi call, it is actually an absolute path to the\r\ninstance (that is, it includes the Datacenter). However, the path is\r\nmeant to be relative to the Datacenter.\r\n\r\nThe patch proposes the following solution:\r\n* remove the relative_path attribute\r\n* add a <Vsphere::Server>.relative_path method\r\n\r\nThis works well with the lazy initialization and restores\r\nfunctionality to methods that rely on the path actually being relative\r\nto the Datacenter.\r\n\r\nFixes: #3041'
3041,'','Vsphere::Server.clone method expects path relative to the Datacenter, but the actual path is absolute\nWhen one attempts to use the Vsphere::Server.clone method, the following error is produced:\r\n<pre>\r\nvm.clone(\'name\'        => name,\r\n         \'dest_folder\' => folder,\r\n        )\r\nlib/fog/vsphere/requests/compute/get_virtual_machine.rb:27:in `get_vm_ref\':\r\n_datacenter_/_folder_/_vm_ was not found (Fog::Compute::Vsphere::NotFound)\r\n</pre>\r\n\r\nQuerying for the instance using <code>servers.all()</code> does succeed and one can print out the ID, name, or any other property. The issue is in the implementation of the <code>clone()</code> request and the _relative_path_ attribute for the _server_. Specifically, the following assumption in _vsphere/requests/compute/vm_clone.rb_:\r\n```ruby\r\n36     #   * \'template_path\'<~String> - *REQUIRED* The path to the machine you\r\n37     #     want to clone FROM. Relative to Datacenter (Example:\r\n38     #     "FolderNameHere/VMNameHere")\r\n```\r\nCompare this requirement with the invocation in <code><Vsphere::Server>.clone()</code>:\r\n```ruby\r\n124     def clone(options = {})\r\n125       requires :name, :datacenter, :relative_path\r\n126 \r\n127       # Convert symbols to strings\r\n128       req_options = options.reduce({}) { |hsh, (k,v)| hsh[k.to_s] = v; hsh }\r\n129 \r\n130       # Give our path to the request\r\n131       req_options[\'template_path\'] ="#{relative_path}/#{name}"\r\n132       req_options[\'datacenter\'] = "#{datacenter}"\r\n```\r\nwhich seems ok, but the _relative_path_ is not actually relative to the datacenter:\r\n```ruby\r\nputs vm.relative_path, vm.datacenter\r\n> Maginatics/troll-images\r\nMaginatics\r\n```\r\n\r\nI believe the solution should be to fix the _relative_path_ variable to *actually* be a _relative_path_. However, I\'m not sure what, if any, code may rely on the fact that it is currently an absolute path. Will submit a pull request for the proposed fix.'
3040,'','Use server_id for Vsphere::Interfaces and Vsphere::Volumes\nAttempt to resolve the infinite loop when calling <code><Vsphere::Server>.inspect</code>. The loop is introduced because each <code><Vsphere::Server></code> instance has a reference to the <code><Vsphere::Interfaces></code> and <code><Vsphere::Volumes></code> collections. Each of these collections, in turn, has an attribute <code>server</code>, which refers to the <code><Vsphere::Server></code> object. This circular dependency breaks the _Fog_ <inspect()> method, which attempts to print out each of the attributes of a given object.\r\n\r\nThe proposed resolution is to introduce a functional change, modifying the aforementioned models to expect the ID of the <code><Vsphere::Server></code>. The models then lookup the server object as necessary.\r\n\r\nFixes: #2938'
3039,'',"Support modify subnet attribute for AWS VPC\nThe only thing modify subnet attribute can modify is the MapPublicIpOnLaunch flag.\r\n\r\nI chose to have the option passed be  `MapPublicIpOnLaunch` rather than `MapPublicIpOnLaunch.Value` - although that's the parameter name the api actually required it felt a bit over the top so i thought it was ok to  handle that for callers of the request"
3037,'','Add t2.micro, t2.small, t2.medium flavors\n[aws|compute] Add t2.micro, t2.small, t2.medium flavors. If no flavor specificed default to 2.micro since there is no reason to default to t1.micro\r\n\r\nResolves #3036'
3036,'','Support new AWS t2 instance class\nAWS has added a new instance class (t2) which represents the next generation of the t1.micro'
3035,'','New fix for create load balancer mock\n'
3034,'','Fixing missing uniq_id for Fog::Rackspace::LoadBalancers::Mock\nI found this issue when trying to mock create_load_balancer method for Rackspace. uniq_id was missing, added just 6 digit generator, and now works fine. '
3033,'icco','[google|compute] Added read metadata from file functionality\nThe patch adds the ability to read metadata from files allowing users to specify startup scripts or arbitrary metadata for instances in separate files.'
3032,'','add ability to replace existing Dyn records\nAdd the ability to replace existing records, instead of just throwing Excon::Errors::BadRequest.'
3031,'','[openstack | server] start/stop/pause/suspend actions\n2 new requests for openstack compute added:\r\n\r\n```ruby\r\nrequest :start_server\r\nrequest :stop_server\r\n```\r\n\r\nwhat is more new methods added into openstack compute server model:\r\n\r\n```ruby\r\nmodule Fog\r\n  module Compute\r\n    class OpenStack\r\n      class Server < Fog::Compute::Server\r\n         ...\r\n        def stop ... end\r\n        def pause ... end\r\n        def suspend ... end\r\n        def start ... end\r\n    end\r\n  end\r\nend\r\n```'
3030,'','[google|compute] Fix operations scopes for compute engine\n@icco, @erjohnso\r\nFix for scoping issues for operations.get on forwarding rules and target pools.'
3028,'','[vsphere] Fixed bug in which clients are forced to wait for instance\nFixed bug in which Fog always waited for an ESX instance to be created irrespective of whether wait was set to true or false. Such a wait was undesirable for me when an instance takes a long period of time to provision.'
3027,'','AWS Ensure NetworkInterface model exposes private ip addresses\nAWS allows you to have multiple private IP addresses on a network interface which the Parser currently supports but the Model does not expose.\r\n\r\nThis PR attempts to resolve that.'
3026,'','Issue 3011: Create volume in specific availability zone.\nPreviously the value of the availability_zone attribute was ignored when creating OpenStack volumes.'
3025,'',"[google | compute] add support for google container-optimized images\n@icco - back from holiday yet? :-)\r\n\r\nAdding the 'google-containers' project to the list of projects that will be searched for matching images.\r\n\r\n"
3024,'',"[google | compute] add support for google container-optimized images\nAdd 'google-containers' to the list of projects to consult for images.\r\n\r\nhttps://developers.google.com/compute/docs/containers/container_vms"
3023,'',"[dynect|dns] dramatically improve speed ...\n... of 'get_all_records' request and 'records.all' method.\r\n\r\npreviously 4 minutes on a domain with many records (266), now around 5 seconds on same domain.\r\nthis is enabled by a parameter to the 'get_all_records' request, detail=y. Which returns full records, rather than resource URLs."
3022,'','Add fog-softlayer module.\n'
3020,'','Add Fog::Compute.create_many and bootstrap_many\nThey work just like create() and bootstrap() except they take two parameters, min_instances and max_instances, that allow you to specify how many instances AWS should create.'
3018,'',"rename Fog::Compute::OpenStack::Tenants#find_by_id to #get for consisten...\nMake Tenants more consistent with the rest of the Compute classes, which all have #get methods, not #find_by_id.  I've also created an alias to #find_by_id to preserve backward compatibility."
3017,'',"[dynect|dns] Fixes exception behavior for 307's\nThis PR fixes exception behavior when Dynect returns a 307 with a job number.  At some point, the behavior of wait_for.rb was changed to raise an exception if duration > timeout. The exception raised by core supersedes the one raised in Dynect/dns.rb that includes the job number, which is then lost.  The job number is now returned as part of the exception.\r\n\r\nOriginal Issue:\r\nhttps://github.com/fog/fog/issues/575\r\n\r\nCommit implementing original behavior:\r\nhttps://github.com/fog/fog/commit/7ba6df8f1494c98849dbdc25bdc34a1f4605ee47"
3013,'','[rackspace|compute_v2] Escape flavor_id and image_id\nUpdating `flavors.get` and `image.get` to escape ids.'
3012,'','[rackspace|load balancers] updating node handling\nUpdate load balancers to treat nodes similar to virtual ips in PR#3010. This should hopefully minimize the impact to required node attributes.'
3010,'','[rackspace|loadbalancers] Populate virtual ip and ipVersion\nhe id, and ipVersion were not being populated when making a create load balancer call. Fixes #3008'
3009,'','[aws] add mock tagging for acls and vpcs, refactor types\nfix for https://github.com/fog/fog/issues/2997\r\n\r\n@geemus'
3008,'','[Rackspace | LoadBalancer] Unable to create a load balancer using a shared VIP\nHopefully I\'m just misunderstanding/misusing the library, but I cannot figure out to create two load balancers using a shared VIP via the API (this works via the web interface).\r\n\r\nHere\'s what I\'m trying:\r\n\r\n```\r\nlb443 = _load_balancer_service.load_balancers.create(\r\n  :name => "#{name}-443",\r\n  :protocol => "HTTPS",\r\n  :port => 443,\r\n  :virtual_ips => [{:type => \'PUBLIC\'}],\r\n  :nodes => []\r\n)\r\nvip_data = lb443.virtual_ips.map {|lb| {:id => lb.id}}\r\nlb80 = _load_balancer_service.load_balancers.create(\r\n  :name => "#{name}-80",\r\n  :protocol => "HTTP",\r\n  :port => 80,\r\n  :virtual_ips => vip_data,\r\n  :nodes => []\r\n)\r\n```\r\n\r\nThis gives a validation error (400) on the second create. I also tried passing lb443.virtual_ips instead of vip_data, but this complains:\r\n\r\n```\r\nArgumentError - Initialization parameters must be an attributes hash, got Fog::Rackspace::LoadBalancers::VirtualIp   <Fog::Rackspace::LoadBalancers::VirtualIp\r\n    id=4287,\r\n    address="23.111.222.111",\r\n    type="PUBLIC",\r\n    ip_version="IPV4"\r\n  >:\r\n        /home/user/.rvm/gems/ruby-2.1.1@konzertmeister/gems/fog-core-1.22.0/lib/fog/core/collection.rb:112:in `new\'\r\n        /home/user/.rvm/gems/ruby-2.1.1@konzertmeister/gems/fog-core-1.22.0/lib/fog/core/collection.rb:101:in `block in load\'\r\n        /home/user/.rvm/gems/ruby-2.1.1@konzertmeister/gems/fog-core-1.22.0/lib/fog/core/collection.rb:17:in `each\'\r\n        /home/user/.rvm/gems/ruby-2.1.1@konzertmeister/gems/fog-core-1.22.0/lib/fog/core/collection.rb:17:in `each\'\r\n        /home/user/.rvm/gems/ruby-2.1.1@konzertmeister/gems/fog-core-1.22.0/lib/fog/core/collection.rb:100:in `load\'\r\n        /home/user/.rvm/gems/ruby-2.1.1@konzertmeister/gems/fog-1.22.1/lib/fog/rackspace/models/load_balancers/load_balancer.rb:96:in `virtual_ips=\'\r\n...\r\n```\r\n\r\n\r\nEDIT: I fixed the protocol and port being supplied to lb80. The error is the same, though. It looks like just passing the ID (which I\'m trying to do with vip_data) should work: http://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/Create_Load_Balancer-d1e1635.html'
3007,'','Update links to DigitalOcean SSH-key docs\nUpdate links from https://www.digitalocean.com/api#ssh_keys to https://developers.digitalocean.com/ssh-keys'
3006,'',"[vcloud_director] Query API mixin for Model.\nThis adds support for the vCloud Director Query API into the Model, via a mixin.\r\n\r\nIt adds a 'find_by_query' call which returns a Collection of objects matching that query. The full query syntax is available via this call, so it's pretty powerful.\r\n\r\nI've added Mock code and tried to increase the coverage of our tests under Travis.\r\n\r\nCurrently this support has been added to:\r\n\r\n* vms\r\n* vapps\r\n* vdcs\r\n* networks\r\n* tasks\r\n\r\n... though it is trivial to add it to the other entities.\r\n"
3005,'','Support for required EvaluateTargetHealth for ALIAS records\nNote an error was being raised when using the old API about EvaluateTargetHealth being missing.\r\n\r\n```\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\n  response => #<Excon::Response:0x007fde3baf66a0 @data={:body=>"<?xml version=\\"1.0\\"?>\\n<ErrorResponse xmlns=\\"https://route53.amazonaws.com/doc/2013-04-01/\\"><Error><Type>Sender</Type><Code>InvalidInput</Code><Message>Invalid XML ; cvc-complex-type.2.4.b: The content of element \'AliasTarget\' is not complete. One of \'{&quot;https://route53.amazonaws.com/doc/2013-04-01/&quot;:EvaluateTargetHealth}\' is expected.</Message></Error><RequestId>f141b55c-f726-11e3-b2ac-73337c63db62</RequestId></ErrorResponse>", :headers=>{"x-amzn-RequestId"=>"f141b55c-f726-11e3-b2ac-73337c63db62", "Content-Type"=>"text/xml", "Content-Length"=>"438", "Date"=>"Wed, 18 Jun 2014 20:27:17 GMT"}, :status=>400, :remote_ip=>"72.21.214.31", :local_port=>60240, :local_address=>"192.168.1.85"}, @body="<?xml version=\\"1.0\\"?>\\n<ErrorResponse xmlns=\\"https://route53.amazonaws.com/doc/2013-04-01/\\"><Error><Type>Sender</Type><Code>InvalidInput</Code><Message>Invalid XML ; cvc-complex-type.2.4.b: The content of element \'AliasTarget\' is not complete. One of \'{&quot;https://route53.amazonaws.com/doc/2013-04-01/&quot;:EvaluateTargetHealth}\' is expected.</Message></Error><RequestId>f141b55c-f726-11e3-b2ac-73337c63db62</RequestId></ErrorResponse>", @headers={"x-amzn-RequestId"=>"f141b55c-f726-11e3-b2ac-73337c63db62", "Content-Type"=>"text/xml", "Content-Length"=>"438", "Date"=>"Wed, 18 Jun 2014 20:27:17 GMT"}, @status=400, @remote_ip="72.21.214.31", @local_port=60240, @local_address="192.168.1.85">\r\n\tfrom /gems/ruby-2.0.0-p353/gems/excon-0.37.0/lib/excon/middlewares/expects.rb:6:in `response_call\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/excon-0.37.0/lib/excon/middlewares/response_parser.rb:26:in `response_call\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/excon-0.37.0/lib/excon/connection.rb:402:in `response\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/excon-0.37.0/lib/excon/connection.rb:272:in `request\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/fog-1.22.1/lib/fog/xml/sax_parser_connection.rb:35:in `request\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/fog-1.22.1/lib/fog/xml.rb:21:in `request\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/fog-1.22.1/lib/fog/aws/dns.rb:126:in `request\'\r\n\tfrom /gems/ruby-2.0.0-p353/gems/fog-1.22.1/lib/fog/aws/requests/dns/change_resource_record_sets.rb:120:in `change_resource_record_sets\'\r\n```'
3004,'','[opennebula] fix for #3003 - soft load the opennebula gem\n'
3003,'',"Cannot load opennebula\nSince the OpenNebula provider was added via #2919, all of rubber/rubber's tests have been failing.  E.g., [this Travis build](https://travis-ci.org/rubber/rubber/jobs/27766664) has the following trace:\r\n\r\n```\r\n/home/travis/.rvm/gems/ruby-2.0.0-p451/bundler/gems/fog-fd2ce6232640/lib/fog/opennebula/compute.rb:1:in `require': cannot load such file -- opennebula (LoadError)\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/bundler/gems/fog-fd2ce6232640/lib/fog/opennebula/compute.rb:1:in `<top (required)>'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/bundler/gems/fog-fd2ce6232640/lib/fog/opennebula.rb:1:in `require'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/bundler/gems/fog-fd2ce6232640/lib/fog/opennebula.rb:1:in `<top (required)>'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/bundler/gems/fog-fd2ce6232640/lib/fog.rb:64:in `require'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/bundler/gems/fog-fd2ce6232640/lib/fog.rb:64:in `<top (required)>'\r\n\tfrom /home/travis/build/rubber/rubber/test/test_helper.rb:12:in `require'\r\n\tfrom /home/travis/build/rubber/rubber/test/test_helper.rb:12:in `<top (required)>'\r\n\tfrom /home/travis/build/rubber/rubber/test/cloud/aws_table_store_test.rb:1:in `require'\r\n\tfrom /home/travis/build/rubber/rubber/test/cloud/aws_table_store_test.rb:1:in `<top (required)>'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/gems/rake-10.3.2/lib/rake/rake_test_loader.rb:10:in `require'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/gems/rake-10.3.2/lib/rake/rake_test_loader.rb:10:in `block (2 levels) in <main>'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/gems/rake-10.3.2/lib/rake/rake_test_loader.rb:9:in `each'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/gems/rake-10.3.2/lib/rake/rake_test_loader.rb:9:in `block in <main>'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/gems/rake-10.3.2/lib/rake/rake_test_loader.rb:4:in `select'\r\n\tfrom /home/travis/.rvm/gems/ruby-2.0.0-p451/gems/rake-10.3.2/lib/rake/rake_test_loader.rb:4:in `<main>'\r\nrake aborted!\r\n```\r\n\r\n@b0e or @krames, have any ideas?"
3002,'',"[Rakefile] fix test task to use FOG_MOCK\nmock wasn't being set with FOG_MOCK env variable."
3001,'','Unable to use fog to create s3 buckets with periods in bucket name\nFor example, if I wanted to create a bucket with name: "www.example.com"\r\n\r\n```\r\nruby/2.0.0/openssl/ssl.rb:139:in `post_connection_check\': hostname "www.example.com.s3.amazonaws.com" does not match the server certificate (OpenSSL::SSL::SSLError) (Excon::Errors::SocketError)\r\n```'
3000,'',"[Google | refactor] Remove backoff_if_unfound method from google compute service\nThe better way to wait until resource is created is to check if operation object that is return by API call is ready. Since we use this approach in other places, I've decided to remove usage `backoff_if_unfound`. Also `backoff_if_unfound` was complication and wasn't tested.\r\n\r\nIt could be a better way of getting `operation` object, but I've done it this way using other models as an example.\r\n\r\nI've run manually mock and live tests (live tests was take from #2995): all tests passed."
2999,'','updated cores for new flavor IDs\nLinode introduced a new $10/month plan and changed the flavor IDs on the rest of the plans.  More info here:\r\n\r\nhttps://blog.linode.com/2014/06/16/11th-linode-birthday-10-linode-plan/'
2997,'','[aws] Add support to mock tagging of other AWS resources\nI\'m trying to test the tagging of AWS vpcs and network acls, but it looks like the tag mocks are limited to those listed in this case statement: https://github.com/fog/fog/blob/master/lib/fog/aws/requests/compute/create_tags.rb#L44-L60\r\n\r\n```ruby\r\nirb(main):001:0> require \'fog\'\r\nFog.=> true\r\nirb(main):002:0> Fog.mock!\r\n=> true\r\nirb(main):003:0> aws = Fog::Compute.new :provider => \'AWS\'\r\n=> #<Fog::Compute::AWS::Mock:0x007fc3126ad560 @use_iam_profile=nil, @aws_credentials_expire_at=2014-06-15 15:58:57 -0700, @aws_access_key_id="ASDF", @region="us-east-1">\r\nirb(main):004:0> v = aws.vpcs.new :cidr_block => \'10.0.0.0/16\'\r\n=>   <Fog::Compute::AWS::VPC\r\n    id=nil,\r\n    state=nil,\r\n    cidr_block="10.0.0.0/16",\r\n    dhcp_options_id="default",\r\n    tags=nil,\r\n    tenancy="default"\r\n  >\r\nirb(main):005:0> v.save\r\n=> true\r\nirb(main):006:0> acl = aws.network_acls.first\r\n=>   <Fog::Compute::AWS::NetworkAcl\r\n    network_acl_id="acl-ecb6fcc0",\r\n    vpc_id="vpc-83f86c06",\r\n    default=true,\r\n    entries=[{"icmpTypeCode"=>{}, "portRange"=>{}, "ruleNumber"=>32767, "protocol"=>-1, "ruleAction"=>"deny", "egress"=>true, "cidrBlock"=>"0.0.0.0/0"}, {"icmpTypeCode"=>{}, "portRange"=>{}, "ruleNumber"=>32767, "protocol"=>-1, "ruleAction"=>"deny", "egress"=>false, "cidrBlock"=>"0.0.0.0/0"}],\r\n    associations=[],\r\n    tags={}\r\n  >\r\nirb(main):007:0> aws.tags.create :resource_id => acl.network_acl_id, :key => \'foo\', :value => \'bar\'\r\nFog::Service::NotFound: The  ID \'acl-ecb6fcc0\' does not exist\r\n```'
2996,'','[Rackspace | LoadBalancer] Unable to create a load balancer\nI don\'t see any example to of creating a load balancer for rackspace. I am expecting it to be something like:\r\n\r\n```\r\nlbs = Fog::Rackspace::LoadBalancers.new(\r\n:rackspace_username  => "user", \r\n:rackspace_api_key   => "apikey",\r\n:rackspace_region    => :ord)\r\n\r\nlbs.load_balancers.create(:name => "lb-443", :protocol => "HTTPS", :port => 443, :service_ips => [], :nodes => [])\r\n```\r\n\r\nBut this gives me an exception:\r\n```\r\n/home/user/repos/fog/lib/fog/rackspace/load_balancers.rb:125:in `rescue in request\': [HTTP 404 | ] resource not found in ord region (Fog::Rackspace::LoadBalancers::NotFound)\r\n        from /home/user/repos/fog/lib/fog/rackspace/load_balancers.rb:123:in `request\'\r\n        from /home/user/repos/fog/lib/fog/rackspace/requests/load_balancers/list_virtual_ips.rb:9:in `list_virtual_ips\'\r\n        from /home/user/repos/fog/lib/fog/rackspace/models/load_balancers/virtual_ips.rb:27:in `all_raw\'\r\n        from /home/user/repos/fog/lib/fog/rackspace/models/load_balancers/virtual_ips.rb:13:in `all\'\r\n        from /home/user/.rvm/gems/ruby-1.9.2-p320@coi_poc/gems/fog-core-1.22.0/lib/fog/core/collection.rb:139:in `lazy_load\'\r\n        from /home/user/.rvm/gems/ruby-1.9.2-p320@coi_poc/gems/fog-core-1.22.0/lib/fog/core/collection.rb:22:in `map\'\r\n        from /home/user/repos/fog/lib/fog/rackspace/models/load_balancers/load_balancer.rb:257:in `virtual_ips_hash\'\r\n        from /home/user/repos/fog/lib/fog/rackspace/models/load_balancers/load_balancer.rb:238:in `create\'\r\n        from /home/user/repos/fog/lib/fog/rackspace/models/load_balancers/load_balancer.rb:196:in `save\'\r\n        from /home/user/.rvm/gems/ruby-1.9.2-p320@coi_poc/gems/fog-core-1.22.0/lib/fog/core/collection.rb:51:in `create\'\r\n        from rackspace.rb:60:in `create_load_balancer\'\r\n        from rackspace.rb:180:in `<main>\'\r\n```\r\n\r\nDigging a little deeper, I see it trying to make this request:\r\n```\r\n{:expects=>200, :method=>"GET", :path=>"/v1.0/<some_number>/loadbalancers//virtualips.json", :headers=>{"Content-Type"=>"application/json", "Accept"=>"application/json", "X-Auth-Token"=>"<token>"}}\r\n```\r\n\r\nI\'m not very familiar with the fog library, but it looks like it\'s trying to load the VIPs for a load balancer that doesn\'t exist yet.\r\n\r\nIs there another way I should be creating a load balancer, or is there some fix for this?'
2995,'',"[google|tests] Fix disks and servers live tests\nI've noticed that `rake live[google]` gives a lot of errors, so I've decided to fix it. For now I have fixed issues with disks and servers tests. \r\n\r\nMainly the issues was connected with adding asynchronous requests in `destroy` methods, in this way resources from one test were not removed before execution of another test. I've solved it with generating randomized names for resources.\r\n\r\nIf someone needs, [here](https://gist.github.com/allomov/464642096193dada7cad) is my script to remove all test resources generated by this tests and not removed because of tests failure. \r\n\r\n@icco do you think it is needed to implement live tests ? as sometimes they are far away from development version.\r\n\r\n@geemus I needed to edit `model_helper.rb` (see the [link](https://github.com/allomov/fog/blob/google-live-tests/tests/helpers/model_helper.rb#L12)) to [wait resource](https://github.com/allomov/fog/blob/2f6dfc9ceb0aff528623c30601945ec3889c0854/tests/google/models/compute/disk_tests.rb#L8) is ready before remove it. "
2994,'',"[Google|Storage] remove :url param from get_service request for google storage\nThe format of `request` method was slightly changed by this [commit](https://github.com/fog/fog/commit/e3299982ee882c5789e54401dd56f2dd892185eb). Still in  [storage/get_service.rb](https://github.com/fog/fog/blob/master/lib/fog/google/requests/storage/get_service.rb) we [place](https://github.com/fog/fog/blob/master/lib/fog/google/requests/storage/get_service.rb#L26) `url` option. This cause Excon warning message every time you initialize Google Storage object. Here is an output from my console:\r\n```\r\n[excon][WARNING] Invalid Excon request keys: :url\r\n/Users/allomov/.rvm/gems/ruby-2.1.1/gems/excon-0.37.0/lib/excon/connection.rb:393:in `validate_params'\r\n/Users/allomov/.rvm/gems/ruby-2.1.1/gems/excon-0.37.0/lib/excon/connection.rb:229:in `request'\r\n/Users/allomov/work/github/fog/lib/fog/xml/sax_parser_connection.rb:35:in `request'\r\n/Users/allomov/work/github/fog/lib/fog/xml.rb:21:in `request'\r\n/Users/allomov/work/github/fog/lib/fog/google/storage.rb:296:in `request'\r\n/Users/allomov/work/github/fog/lib/fog/google/requests/storage/get_service.rb:19:in `get_service'\r\n/Users/allomov/work/github/fog/lib/fog/google/models/storage/directories.rb:11:in `all'\r\n/Users/allomov/.rvm/gems/ruby-2.1.1/gems/fog-core-1.22.0/lib/fog/core/collection.rb:139:in `lazy_load'\r\n/Users/allomov/.rvm/gems/ruby-2.1.1/gems/fog-core-1.22.0/lib/fog/core/collection.rb:15:in `first'\r\nfog_clean_gce.rb:30:in `<main>'\r\n```"
2990,'','[vcloud_director] Removing Static IP references\nRemoving a static IP that is referenced in XSI location of master.xsd on PUT CPU and Memory requests.'
2989,'','[OpenStack] Unable to list networks with OpenStack IceHouse\nI am having trouble listing networks for my local installation of OpenStack Icehouse. I seemed to have narrowed it down to fog as with knife-openstack and kitchen-openstack (both use fog as the cloud provider interface). Here is what I have gathered thus far:\r\n\r\n```ruby\r\n$ pry\r\n[1] pry(main)> require "fog"\r\n=> true\r\n[2] pry(main)> Fog::Compute.new({:provider=>"OpenStack", :openstack_username=>"admin", :openstack_api_key=>"XXXXXXXXXXX", :openstack_auth_url=>"http://192.168.100.34:5000/v2.0/tokens", :openstack_tenant=>"admin", :openstack_region=>nil, :openstack_service_name=>nil})\r\n=> #<Fog::Compute::OpenStack::Real:2170269320 @openstack_auth_token=nil @auth_token="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-Cp4Fk7NYaI+1T4iSqYsa+DYVL2V6BxPIk7xjUJ2z22bk8vfRs9BtL33+FbBmM2Xo2MRI4Y-dp3uPLLh65hi4k+3qZ9-zTIRD0SdkbCaWzxVOn94YGA51yVkNvFgPiVO5PECfhlu6hH3SKnJ1ZQOpQjDkVqOS3PYP4JZe8D26lhCUVUYa4lb3CwC6fcmVU9CLGhffwN14JU8Wx-wTQQl4-dNv5OYb4mhvfhsH27BEnseAXYDMNOS-+yg-cFzNAYkSN7vCpU2hB4Hq8QGbnymKzSUA-uMOerlEhvjqoYSoTog7FHpEK5-k0" @openstack_identity_public_endpoint="http://192.168.100.34:5000/v2.0" @openstack_api_key="7c7a5b891b5d4c36" @openstack_username="admin" @openstack_tenant="admin" @openstack_auth_uri=#<URI::HTTP:0x00000102b75180 URL:http://192.168.100.34:5000/v2.0/tokens> @openstack_management_url="http://192.168.100.34:8774/v2/6cbe264279664bd5a9e6a42b7b777bfb" @openstack_must_reauthenticate=false @openstack_service_type=["nova", "compute"] @openstack_service_name=nil @openstack_identity_service_type="identity" @openstack_endpoint_type="publicURL" @openstack_region=nil @connection_options={:debug_response=>true, :headers=>{"User-Agent"=>"fog/1.22.1"}, :persistent=>false} @current_user={"username"=>"admin", "roles_links"=>[], "id"=>"3fdb60fe581f487d9e422481239d13ad", "roles"=>[{"name"=>"admin"}], "name"=>"admin"} @current_tenant={"description"=>"admin tenant", "enabled"=>true, "id"=>"6cbe264279664bd5a9e6a42b7b777bfb", "name"=>"admin"} @auth_token_expiration="2014-06-10T22:08:26Z" @host="192.168.100.34" @path="/v2" @tenant_id="6cbe264279664bd5a9e6a42b7b777bfb" @port=8774 @scheme="http" @identity_connection=#<Fog::Core::Connection:0x00000102b262d8 @excon=#<Excon::Connection:102b25ea0 @data={:chunk_size=>1048576, :ciphers=>"HIGH:!SSLv2:!aNULL:!eNULL:!3DES", :connect_timeout=>60, :debug_request=>false, :debug_response=>true, :headers=>{"User-Agent"=>"fog/1.22.1"}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::ResponseParser, Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>false, :nonblock=>true, :omit_default_port=>false, :persistent=>false, :read_timeout=>60, :retry_limit=>4, :ssl_verify_peer=>true, :tcp_nodelay=>false, :uri_parser=>URI, :write_timeout=>60, :host=>"192.168.100.34", :path=>"/v2.0", :port=>5000, :query=>nil, :scheme=>"http", :user=>nil, :password=>nil} @socket_key="http://192.168.100.34:5000">> @persistent=false @connection=#<Fog::Core::Connection:0x00000102b258b0 @excon=#<Excon::Connection:102b25450 @data={:chunk_size=>1048576, :ciphers=>"HIGH:!SSLv2:!aNULL:!eNULL:!3DES", :connect_timeout=>60, :debug_request=>false, :debug_response=>true, :headers=>{"User-Agent"=>"fog/1.22.1"}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::ResponseParser, Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>false, :nonblock=>true, :omit_default_port=>false, :persistent=>false, :read_timeout=>60, :retry_limit=>4, :ssl_verify_peer=>true, :tcp_nodelay=>false, :uri_parser=>URI, :write_timeout=>60, :host=>"192.168.100.34", :path=>"", :port=>8774, :query=>nil, :scheme=>"http", :user=>nil, :password=>nil} @socket_key="http://192.168.100.34:8774">>>\r\n```\r\n\r\n```ruby\r\n[3] pry(main)> Fog::Network.new({:provider=>"OpenStack", :openstack_username=>"admin", :openstack_api_key=>"XXXXXXXXXXX", :openstack_auth_url=>"http://192.168.100.34:5000/v2.0/tokens", :openstack_tenant=>"admin", :openstack_region=>nil, :openstack_service_name=>nil})\r\nExcon::Errors::SocketError: Connection refused - connect(2) (Errno::ECONNREFUSED)\r\n```\r\n\r\nRelevant knife.rb for knife-openstack:\r\n```ruby\r\nknife[:openstack_auth_url] = "http://192.168.100.34:5000/v2.0/tokens"\r\nknife[:openstack_username] = "admin"\r\nknife[:openstack_password] = "XXXXXXXXXXX"\r\nknife[:openstack_tenant]   = "admin"\r\nknife[:flavor]             = "m1.small"\r\nknife[:image]              = "10114ab1-9894-442c-885a-3cc0d9699fcb"\r\n#knife[:network_id]        = "7e124ba0-d209-4bc8-906d-14828dc4eae3"\r\n```\r\n\r\n```\r\n$ knife openstack flavor list\r\nName       ID                                    Virtual CPUs  RAM       Disk\r\nm1.large   4                                     4             8192 MB   80 GB\r\nm1.little  09a9f07d-ad5b-414c-8f56-320fe1a28ef7  1             1024 MB   10 GB\r\nm1.medium  3                                     2             4096 MB   40 GB\r\nm1.small   2                                     1             2048 MB   20 GB\r\nm1.tiny    1                                     1             512 MB    1 GB\r\nm1.xlarge  5                                     8             16384 MB  160 GB\r\n```\r\n\r\n```\r\n$ knife openstack network list\r\nFATAL: Connection failure, please check your OpenStack authentication URL.\r\n```\r\n\r\nRelevant Gemfile.log for knife-openstack. Kitchen-openstack is using the same version of fog\r\n\r\n```\r\nGemfile.lock\r\nGEM\r\n  remote: https://rubygems.org/\r\n  specs:\r\n    activesupport (3.2.16)\r\n      i18n (~> 0.6, >= 0.6.4)\r\n      multi_json (~> 1.0)\r\n    addressable (2.3.5)\r\n    akami (1.2.1)\r\n      gyoku (>= 0.4.0)\r\n      nokogiri\r\n    app_conf (0.4.2)\r\n    berkshelf (2.0.13)\r\n      activesupport (~> 3.2.0)\r\n      addressable (~> 2.3.4)\r\n      buff-shell_out (~> 0.1)\r\n      chozo (>= 0.6.1)\r\n      faraday (~> 0.8.0)\r\n      faraday (~> 0.8.5)\r\n      hashie (>= 2.0.2)\r\n      minitar (~> 0.5.4)\r\n      rbzip2 (~> 0.2.0)\r\n      retryable (~> 1.3.3)\r\n      ridley (~> 1.5.0)\r\n      solve (>= 0.5.0)\r\n      thor (~> 0.18.0)\r\n    buff-config (0.4.0)\r\n      buff-extensions (~> 0.3)\r\n      varia_model (~> 0.1)\r\n    buff-extensions (0.5.0)\r\n    buff-ignore (1.1.1)\r\n    buff-ruby_engine (0.1.0)\r\n    buff-shell_out (0.1.1)\r\n      buff-ruby_engine (~> 0.1.0)\r\n    builder (3.2.2)\r\n    celluloid (0.14.1)\r\n      timers (>= 1.0.0)\r\n    celluloid-io (0.14.1)\r\n      celluloid (>= 0.14.1)\r\n      nio4r (>= 0.4.5)\r\n    chef (11.6.2)\r\n      erubis (~> 2.7)\r\n      highline (~> 1.6, >= 1.6.9)\r\n      json (>= 1.4.4, <= 1.7.7)\r\n      mixlib-authentication (~> 1.3)\r\n      mixlib-cli (~> 1.3)\r\n      mixlib-config (~> 1.1, >= 1.1.2)\r\n      mixlib-log (~> 1.3)\r\n      mixlib-shellout (~> 1.1)\r\n      net-ssh (~> 2.6)\r\n      net-ssh-multi (~> 1.1.0)\r\n      ohai (>= 0.6.0, < 7.0.0)\r\n      rest-client (>= 1.0.4, < 1.7.0)\r\n      yajl-ruby (~> 1.1)\r\n    chozo (0.6.1)\r\n      activesupport (>= 3.2.0)\r\n      hashie (>= 2.0.2)\r\n      multi_json (>= 1.3.0)\r\n    diffy (3.0.1)\r\n    em-winrm (0.5.4)\r\n      eventmachine (= 1.0.0.beta.3)\r\n      mixlib-log (>= 1.3.0)\r\n      uuidtools (~> 2.1.1)\r\n      winrm (~> 1.1.0)\r\n    erubis (2.7.0)\r\n    eventmachine (1.0.0.beta.3)\r\n    excon (0.37.0)\r\n    faraday (0.8.9)\r\n      multipart-post (~> 1.2.0)\r\n    ffi (1.9.3)\r\n    fog (1.22.1)\r\n      fog-brightbox\r\n      fog-core (~> 1.22)\r\n      fog-json\r\n      ipaddress (~> 0.5)\r\n      nokogiri (~> 1.5, >= 1.5.11)\r\n    fog-brightbox (0.0.2)\r\n      fog-core\r\n      fog-json\r\n    fog-core (1.22.0)\r\n      builder\r\n      excon (~> 0.33)\r\n      formatador (~> 0.2)\r\n      mime-types\r\n      net-scp (~> 1.1)\r\n      net-ssh (>= 2.1.3)\r\n    fog-json (1.0.0)\r\n      multi_json (~> 1.0)\r\n    formatador (0.2.5)\r\n    git (1.2.6)\r\n    gssapi (1.0.3)\r\n      ffi (>= 1.0.1)\r\n    gyoku (1.1.1)\r\n      builder (>= 2.1.2)\r\n    hashie (2.0.5)\r\n    highline (1.6.20)\r\n    hitimes (1.2.1)\r\n    httpclient (2.3.4.1)\r\n    httpi (0.9.7)\r\n      rack\r\n    i18n (0.6.9)\r\n    ipaddress (0.8.0)\r\n    json (1.7.7)\r\n    knife-backup (0.0.9)\r\n      chef (>= 0.10.10)\r\n    knife-openstack (0.10.0)\r\n      chef (>= 0.10.10)\r\n      fog (>= 1.10.0)\r\n      knife-windows\r\n    knife-rackspace (0.9.0)\r\n      chef (>= 0.10.10)\r\n      fog (~> 1.16)\r\n      knife-windows\r\n    knife-spork (1.3.2)\r\n      app_conf (>= 0.4.0)\r\n      chef (>= 11.0.0)\r\n      diffy (>= 3.0.1)\r\n      git (>= 1.2.5)\r\n    knife-windows (0.5.14)\r\n      em-winrm (= 0.5.4)\r\n    little-plugger (1.1.3)\r\n    logging (1.8.2)\r\n      little-plugger (>= 1.1.3)\r\n      multi_json (>= 1.8.4)\r\n    mime-types (2.3)\r\n    mini_portile (0.6.0)\r\n    minitar (0.5.4)\r\n    mixlib-authentication (1.3.0)\r\n      mixlib-log\r\n    mixlib-cli (1.4.0)\r\n    mixlib-config (1.1.2)\r\n    mixlib-log (1.6.0)\r\n    mixlib-shellout (1.3.0)\r\n    multi_json (1.10.1)\r\n    multipart-post (1.2.0)\r\n    net-http-persistent (2.9.1)\r\n    net-scp (1.2.1)\r\n      net-ssh (>= 2.6.5)\r\n    net-ssh (2.9.1)\r\n    net-ssh-gateway (1.2.0)\r\n      net-ssh (>= 2.6.5)\r\n    net-ssh-multi (1.1)\r\n      net-ssh (>= 2.1.4)\r\n      net-ssh-gateway (>= 0.99.0)\r\n    nio4r (1.0.0)\r\n    nokogiri (1.6.2.1)\r\n      mini_portile (= 0.6.0)\r\n    nori (1.1.5)\r\n    ohai (6.20.0)\r\n      ipaddress\r\n      mixlib-cli\r\n      mixlib-config\r\n      mixlib-log\r\n      mixlib-shellout\r\n      systemu (~> 2.5.2)\r\n      yajl-ruby\r\n    rack (1.5.2)\r\n    rbzip2 (0.2.0)\r\n    rest-client (1.6.7)\r\n      mime-types (>= 1.16)\r\n    retryable (1.3.5)\r\n    ridley (1.5.3)\r\n      addressable\r\n      buff-config (~> 0.2)\r\n      buff-extensions (~> 0.3)\r\n      buff-ignore (~> 1.1)\r\n      buff-shell_out (~> 0.1)\r\n      celluloid (~> 0.14.0)\r\n      celluloid-io (~> 0.14.0)\r\n      erubis\r\n      faraday (>= 0.8.4)\r\n      hashie (>= 2.0.2)\r\n      json (>= 1.7.7)\r\n      mixlib-authentication (>= 1.3.0)\r\n      net-http-persistent (>= 2.8)\r\n      net-ssh\r\n      nio4r (>= 0.5.0)\r\n      retryable\r\n      solve (>= 0.4.4)\r\n      varia_model (~> 0.1)\r\n      winrm (~> 1.1.0)\r\n    rubyntlm (0.1.1)\r\n    savon (0.9.5)\r\n      akami (~> 1.0)\r\n      builder (>= 2.1.2)\r\n      gyoku (>= 0.4.0)\r\n      httpi (~> 0.9)\r\n      nokogiri (>= 1.4.0)\r\n      nori (~> 1.0)\r\n      wasabi (~> 1.0)\r\n    solve (0.8.2)\r\n    systemu (2.5.2)\r\n    thor (0.18.1)\r\n    timers (2.0.0)\r\n      hitimes\r\n    uuidtools (2.1.4)\r\n    varia_model (0.3.2)\r\n      buff-extensions (~> 0.2)\r\n      hashie (>= 2.0.2)\r\n    wasabi (1.0.0)\r\n      nokogiri (>= 1.4.0)\r\n    winrm (1.1.3)\r\n      gssapi (~> 1.0.0)\r\n      httpclient (~> 2.2, >= 2.2.0.2)\r\n      logging (~> 1.6, >= 1.6.1)\r\n      nokogiri (~> 1.5)\r\n      rubyntlm (~> 0.1.1)\r\n      savon (= 0.9.5)\r\n      uuidtools (~> 2.1.2)\r\n    yajl-ruby (1.2.0)\r\n\r\nPLATFORMS\r\n  ruby\r\n\r\nDEPENDENCIES\r\n  berkshelf\r\n  chef\r\n  knife-backup\r\n  knife-openstack\r\n  knife-rackspace (~> 0.9.0)\r\n  knife-spork\r\n```'
2988,'',"Add tutum support\nThis is more of a statement of intent that feature request: http://www.tutum.co/\r\n\r\nThis should resemble fogdocker, in fact defining some kind of common docker-api style interface may be possible. If anyone has guidelines, guides, tips around adding provider support that would be sweet. I'll drop PR updates in here."
2987,'','[google|compute] remove hard-coded references to /projects/google/\nOnly significant change is to remove the hard-coded reference to /projects/google in get_machine_type request.\r\n\r\nGoogle is getting ready to deprecate that "project" and this will reduce potential 404 errors.\r\n'
2984,'',"Error when uploading to Atmos in Fog v1.22.0\nI'm getting this error when trying to upload files to an Atmos provider:\r\n\r\n    /home/jenkins/tmp/buildbundle/ruby/2.1.0/gems/nokogiri-1.6.2.1/lib/nokogiri/xml/sax/push_parser.rb:47:in `native_write': Opening and ending tag mismatch: ObjectD line 0 and ObjectID (Nokogiri::XML::SyntaxError)\r\n\tfrom /home/jenkins/tmp/buildbundle/ruby/2.1.0/gems/nokogiri-1.6.2.1/lib/nokogiri/xml/sax/push_parser.rb:47:in `write'\r\n\tfrom /home/jenkins/tmp/buildbundle/ruby/2.1.0/gems/fog-1.22.1/lib/fog/atmos/storage.rb:174:in `request'\r\n\tfrom /home/jenkins/tmp/buildbundle/ruby/2.1.0/gems/fog-1.22.1/lib/fog/atmos/requests/storage/get_namespace.rb:7:in `get_namespace'\r\n\tfrom /home/jenkins/tmp/buildbundle/ruby/2.1.0/gems/fog-1.22.1/lib/fog/atmos/models/storage/directories.rb:29:in `get'\r\n\tfrom build/archive_artifacts.rb:28:in `atmos_directory'\r\n\tfrom build/archive_artifacts.rb:65:in `block in upload_gems'\r\n\tfrom build/archive_artifacts.rb:63:in `open'\r\n\tfrom build/archive_artifacts.rb:63:in `upload_gems'\r\n\tfrom build/archive_artifacts.rb:95:in `run'\r\n\tfrom build/archive_artifacts.rb:104:in `<main>'\r\n\r\nMy code looks like this:\r\n\r\n    def atmos_storage\r\n      @atmos_storage ||= Fog::Storage.new(\r\n        :provider => 'Atmos',\r\n        :atmos_storage_endpoint => ATMOS_STORAGE_ENDPOINT,\r\n        :atmos_storage_token => ATMOS_STORAGE_TOKEN,\r\n        :atmos_storage_secret => ATMOS_STORAGE_SECRET\r\n      )\r\n    end\r\n\r\n    def atmos_directory\r\n      @atmos_directory ||= atmos_storage.directories.get(ATMOS_STORAGE_PATH) <<< ERROR OCCURS HERE\r\n    end\r\n\r\n\r\nIt started happening after we upgraded our bundle to Fog 1.22.0. It works OK in Fog 1.20.0 and earlier.\r\n"
2983,'',"[vcloud_director] Mocks for most vApp and VM GET operations.\n\r\nThis is a foundation for adding a more capable Mock system to the vcloud_director provider. \r\n\r\nSome work is needed to make it more dynamic, particularly wrt the network configuration. This will be added shortly.\r\n\r\nIt's a useful base though, and hopefully gives a clearer indication as to what's required for mocks.\r\n\r\n\r\n"
2982,'','AWS RDS - Fix EngineVersion for PendingModifiedValues (plus minor cleanup)\nChanges handling of \'EngineVersion\' in the RDS DB parser so that it will correctly appear in the PendingModifiedValues hash. (Note the differences in Fog\'s response versus the proper one from Amazon.) Previously, \'EngineVersion\' was appearing in two places in the response parser code; the second occurrence would never be processed.\r\n\r\nI also moved \'Iops\' and \'AllocatedStorage\' to be handled by the same code block, to reduce code duplication.\r\n\r\nCurrent response from Amazon via command line:\r\n"PendingModifiedValues": {\r\n                "DBInstanceClass": "db.t1.micro", \r\n                "EngineVersion": "5.6.17"\r\n            } \r\n\r\nFog\'s, before this change:\r\n"PendingModifiedValues": {\r\n                "DBInstanceClass": "db.t1.micro"\r\n            }\r\n'
2980,'','properly initialize compute object inside elb methods\nIn certain cases the compute object was not being instantiated properly inside the elb methods.  This corrects that'
2979,'','[aws/security_group] Support mock of group from another account\nIt is possible to have a security group rule refer to group that is a\r\ndifferent account, by UserId and GroupId or GroupName. If a GroupName is\r\nnot supplied, the security group mocking implementation searches for the\r\nsecurity group that matches the supplied GroupId. This commit allows for\r\na default GroupName of nil if it is not supplied.'
2978,'','[rackspace|autoscale] Updated to support creating groups without policies\n* Updated to call clear on policy collection to set the lazy_loaded flag to true if\n  group has not be persisted.\n\n* Fixed documentation bugs'
2977,'icco',"[google|sql] Initial support for Google Cloud SQL\nThis commit adds the initial support for Google Cloud SQL:\r\n- Adds a new service 'SQL' to the existing 'Google' provider\r\n- Creates new shared methods to be reused by different services\r\n- Add requests, models and tests for Tiers\r\n\r\nSee #2976 for more details"
2976,'','Add support for Google Cloud SQL\nAdd support for [Google Cloud SQL](https://developers.google.com/cloud-sql/):\r\n- [x] Use the [JSON API (v1beta3)](https://developers.google.com/cloud-sql/docs/admin-api/index) via the [Google::APIClient](https://github.com/google/google-api-ruby-client)\r\n- [x] Use the existing **Google** provider and add a **SQL** service\r\n- [x] Reuse methods (Google API client initialization, requests, ...) from the Compute service\r\n- [x] Add requests, models and tests for [Instances](https://developers.google.com/cloud-sql/docs/admin-api/v1beta3/instances)\r\n- [x] Add requests, models and tests for [Operations](https://developers.google.com/cloud-sql/docs/admin-api/v1beta3/operations)\r\n- [x] Add requests, models and tests for [SslCerts](https://developers.google.com/cloud-sql/docs/admin-api/v1beta3/sslCerts)\r\n- [x] Add requests, models and tests for [BackupRuns](https://developers.google.com/cloud-sql/docs/admin-api/v1beta3/backupRuns)\r\n- [x] Add requests, models and tests for [Tiers](https://developers.google.com/cloud-sql/docs/admin-api/v1beta3/tiers)\r\n- [x] Add requests, models and tests for [Flags](https://developers.google.com/cloud-sql/docs/admin-api/v1beta3/flags)'
2975,'','support r3 instances & expose virtualization type\n'
2973,'','Add support for tags for Data Pipeline\n@kbarette please review'
2972,'','[vcloud_director] Add :put_network request\nThe put_network request updates OrgVdcNetwork details:\r\n\r\n- name,\r\n- dns properties,\r\n- gateway\r\n\r\nThere appear to be some limitations with what the API will allow\r\nto be changes (such as IpRanges) but the input/output of the method\r\nis mapped as usual.\r\n\r\nThis also adds Mock support for the method.\r\n\r\nNetwork tests have been adjusted so that they work in Mock and Real\r\nmode (bar network_metadata, which is to be implemented in Mock).'
2970,'','[stormondemand|dns] fixing typo in require statement\nThis PR fixes a typo in a require statement.'
2968,'','VCloud Director - Edge gateway\n@mikepea,\r\nThis one is for DHCP and VPN configurations.'
2967,'','VCloud Director - Task to run vcloud-director tests only.\n@mikepea,\r\nThis is the second one for the test task.'
2966,'','VCloud Director - Bug fixes\n@mikepea - as agreed here are individual commits.\r\nThis one is for the bugs '
2965,'',"[google|compute] Add disk_size_gb to 'Image' model\nAdded new field to Image model, named diskSizeGb, which shows the\r\nsize of the image when it is restored to a persistent disk, in GB."
2964,'','Ruby 1.8.7 Sanity check\nOkay. Travis is showing errors on MRI 1.8.7 at the point we wanted to make a `fog-v1.22.1` release...\r\n\r\nhttps://travis-ci.org/fog/fog/builds/26281145\r\n\r\nHowever Bundler is not detecting `celluloid` as a dependency, it passes locally for myself on MRI 1.8.7 and also on JRuby 1.8.7 on Travis.\r\n\r\nThis branch merges in the tag of the commit released as the `fog-1.22.1` gem to master and lo! it works!'
2963,'','HTTPS: Google Cloud Storage\nHow can I enable through the fog config to have all assets served up over https?'
2962,'','[vsphere] expose VM virtual hardware version\nneeded for http://projects.theforeman.org/issues/5760'
2959,'','Full API coverage of the CloudStack 4.2.X API.\n'
2957,'',"wait_for { state? }\nOut of curiosity, is there a solid reason that Compute Server objects respond to `ready?` but not any other states? Take the following code for starting, stopping and pausing OpenStack instances:\r\n\r\n```ruby\r\ndef start\r\n  if state.downcase == 'paused'\r\n    service.unpause_server(id)\r\n  else\r\n    service.resume_server(id)\r\n  end\r\n  wait_for { ready? }\r\nend\r\n\r\ndef stop\r\n  service.suspend_server(id)\r\n  wait_for { state.downcase == 'suspended' }\r\nend\r\n\r\ndef pause\r\n  service.pause_server(id)\r\n  wait_for { state.downcase == 'paused' }\r\nend\r\n```\r\n\r\nIs there any good reason `wait_for` shouldn't also accept `suspended?` and `paused?` out of the box?"
2956,'',"VCloud Director Edge Gateway Configuration, Post Compose vApp and bug fixes\n- fixed expected content-type in post to create vApp templates\r\n- created task to run vcloud_director tests only\r\n- added VPN to edge gateway services and tests\r\n- added DHCP to edge gateway services and tests\r\n- fixed post deploy vapp - 'attr' is undeclared\r\n- created post compose vapp"
2955,'','Unrecognized arguments: rackspace_region\nWhy can\'t I use rackspace_region?\r\n\r\n```\r\n\r\nirb(main):006:0> Fog::Storage.new(:provider => \'Rackspace\', :rackspace_username => \'xxxxx\', :rackspace_api_key => \'xxxxx\')\r\n=> #<Fog::Storage::Rackspace::Real:0x007f8245811db0 @rackspace_api_key="xxxxx", @rackspace_username="xxxxx", @rackspace_cdn_ssl=nil, @rackspace_auth_url=nil, @connection_options={}, @auth_token="xxxxx", @host="storage101.ord1.clouddrive.com", @path="/v1/MossoCloudFS_xxxxx", @persistent=false, @port=443, @scheme="https", @connection=#<Fog::Connection:0x007f82458250e0 @excon=#<Excon::Connection:0x007f8245825068 @connection={:connect_timeout=>60, :headers=>{}, :instrumentor_name=>"excon", :mock=>false, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/xxx/.rbenv/versions/1.9.3-p545/lib/ruby/gems/1.9.1/gems/excon-0.13.4/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"storage101.ord1.clouddrive.com", :path=>"", :port=>"443", :query=>nil, :scheme=>"https"}, @proxy=nil, @socket_key="storage101.ord1.clouddrive.com:443">, @persistent=false>>\r\n```\r\nWhen I try to set the correct region...\r\n```\r\nirb(main):007:0> Fog::Storage.new(:provider => \'Rackspace\', :rackspace_username => \'xxxxx\', :rackspace_api_key => \'xxxxx\', :rackspace_region => :syd)\r\nArgumentError: Unrecognized arguments: rackspace_region\r\n\r\n```'
2953,'','Standardise method names based on style rules\nThis is a number of changes to bring synonymous methods in line to be the same across the code based.\r\n\r\nThis is based on the Rubocop rules and was done automatically using the `auto-correct` option.'
2952,'','[GH-2932] Disable brittle test\nThe AWS security group tests have been very unstable with 2 failures on\r\nTravis per build. The majority is the mocked version of\r\n`describe_security_groups` not working.\r\n\r\nWe have decided to disable it until someone makes time to figure out the\r\nbug since it is affecting every build.\r\n\r\nSee https://travis-ci.org/fog/fog/jobs/25614603#L1105'
2951,'',"Styling clean up of whitespace\nThis is a series of updates based on Rubocop's auto correction to remove empty lines and trailing whitespace."
2949,'',"OpenStack Identity Example throws Uninitialized Constant Error\nWhen running https://github.com/fog/fog/blob/master/lib/fog/openstack/examples/identity/basics.rb, I see the following exception:\r\n\r\n```\r\n/Users/sean/.rbenv/versions/2.1.0/lib/ruby/gems/2.1.0/gems/fog-core-1.22.0/lib/fog/identity.rb:20:in `const_get': uninitialized constant Fog::OpenStack::Identity (NameError)\r\n\tfrom /Users/sean/.rbenv/versions/2.1.0/lib/ruby/gems/2.1.0/gems/fog-core-1.22.0/lib/fog/identity.rb:20:in `rescue in new'\r\n\tfrom /Users/sean/.rbenv/versions/2.1.0/lib/ruby/gems/2.1.0/gems/fog-core-1.22.0/lib/fog/identity.rb:17:in `new'\r\n\tfrom openstack.rb:10:in `<main>'\r\n```"
2948,'',"Hound doesn't seem to respect Exclude filters\nIf I run Rubocop on the CL, things are evaluated as expected, but Hound continues to yell at many of my PR's.\r\n\r\nThe parts of my `.hound.yml` of interest:\r\n\r\n    AllCops:\r\n      RunRailsCops: true\r\n      Exclude:\r\n        - 'bin/**/*'\r\n        - 'config/environments/**/*'\r\n        - 'config/initializers/devise.rb'\r\n        - 'db/**/*'\r\n        - 'vendor/**/*'\r\n\r\n    IndentationConsistency:\r\n      Exclude:\r\n        - '**/factories/**/*'\r\n\r\n    IndentationWidth:\r\n      Exclude:\r\n        - '**/factories/**/*'\r\n\r\n    RedundantSelf:\r\n      Exclude:\r\n        - '**/models/**/*'\r\n"
2947,'','Correct AWS API version to one in the past\nThis was totally my bad. Revealed in testing. Sorry :( '
2946,'',"XenServer - attr_reader for Compute > connection > credentials\nThis would implements #2940\r\n\r\nTo open a console RFB stream you need the console URL and the session_id. The session_id it's the connection value stored in credentials."
2944,'',"Lock down `rainbow` gem to 1.8.7 compatible\nSeems `rainbow-v2.0` has dropped support for Ruby 1.8.7 so I've added a version constraint to the 1.8.7 Gemfile.\r\n\r\nLocally everything is passing again."
2943,'','AWS Encrypted EBS support\nThis patch adds support for encrypted AWS EBS volumes and snapshots http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html Also mocks are updated to correctly return the latest formats. '
2942,'','S3 SignatureDoesNotMatch with UTF8 in Headers\nUpload (put_object) to S3 fails on fog 1.22 with a SignatureDoesNotMatch exception if some of the headers contain utf8 characters.\r\n\r\nExample headers passed to `put_object` as generated by dragonfly-s3_data_store gem:\r\n```ruby\r\n{\r\n  "x-amz-acl"=>"public-read",\r\n  "x-amz-meta-json"=>"{\\"name\\":\\"utf8_filename_ÃÃ¤Ã¶Ã¼.pdf\\",\\"model_class\\":\\"Asset\\",\\"model_attachment\\":\\"attachment\\"}",\r\n  "Content-Type"=>"application/pdf"\r\n}\r\n```\r\n\r\nRequest fails with:\r\n```\r\nExcon::Errors::Forbidden: Expected(200) <=> Actual(403 Forbidden)\r\n  response => #<Excon::Response:0x007f862c3943b0 @data={:body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>SignatureDoesNotMatch</Code>\r\n...\r\n<StringToSign>PUT\\n\\napplication/pdf\\nThu, 22 May 2014 20:38:46 +0000\\nx-amz-acl:public-read\\nx-amz-meta-json:{\\"name\\":\\"utf8_filename_\\xC3\\x83\\xC2\\x9F\\xC3\\x83\\xC2\\xA4\\xC3\\x83\\xC2\\xB6\\xC3\\x83\\xC2\\xBC.pdf\\",\\"model_class\\":\\"Asset\\",\\"model_attachment\\":\\"attachment\\"}\\n/bucket_name_anonymized/d58/1e7/d581e775ee24442ee24d1bc53cf014d8.pdf</StringToSign>\r\n```\r\n\r\nThe request works fine if the x-amz-meta-json header does not contain unicode.\r\n'
2941,'','Initial commit of CloudStack code generated programatically.\nCloudStack code is being generated by https://github.com/fifthecho/fog-cloudstack-code-generator which leverages the CloudStack 4.X listApis call to iterate through all of the CloudStack APIs and generate all requests off of that information.'
2940,'','XenServer provider get credential/session_id\nI need to get the credentials value from a Fog::Compute::XenServer::Real to use it with the console URL.\r\n```\r\n@credentials="OpaqueRef:6415adcb-f099-1cb1-7d23-d3b4cf1fb78f"\r\n```\r\n\r\nWhat do you think about putting an accessor method in Connection and Real classes??'
2939,'','allow files in personality to have symbol keys\nAllow users to supply symbol keys for :contents and :path in the personality list.'
2936,'',"#to_json raise SystemStackError if receiver has Fog::Storage::AWS::Directory as instance variable\n`#to_json` raise `SystemStackError` if receiver has `Fog::Storage::AWS::Directory` as instance variable.\r\nThe following is the example code.\r\n\r\n```ruby\r\nrequire 'active_support/all'\r\nrequire 'fog'\r\n\r\nclass Foo\r\n  def initialize(bucket_name = 'foo')\r\n    storage = Fog::Storage.new(\r\n      provider: 'AWS',\r\n      aws_access_key_id:     'id',\r\n      aws_secret_access_key: 'key',\r\n      region:                'region'\r\n    )\r\n\r\n    storage.directories.create(key: bucket_name)\r\n    @bucket = storage.directories.get(bucket_name)\r\n  end\r\nend\r\n\r\ndescribe Foo do\r\n  before do\r\n    Fog.mock!\r\n  end\r\n\r\n  after do\r\n    Fog::Mock.reset\r\n  end\r\n\r\n  specify do\r\n    Foo.new.to_json # => raise SystemStackError\r\n  end\r\n\r\n  # #to_json call @bucket.as_json internally\r\n  # The causation of the problem is that @bucket.collection includes @bucket itself\r\n\r\n  specify do\r\n    storage = Fog::Storage.new(\r\n      provider: 'AWS',\r\n      aws_access_key_id:     'id',\r\n      aws_secret_access_key: 'key',\r\n      region:                'region'\r\n    )\r\n\r\n    storage.directories.create(key: 'foo')\r\n    bucket = storage.directories.get('foo')\r\n\r\n    bucket.as_json # => raise SystemStackError\r\n  end\r\nend\r\n```\r\n\r\nI can't say for sure that this is Fog's problem.\r\nPerhaps ActiveSupport should solve.\r\nBTAIM, I think that nobody wants this behavior."
2935,'',"Style cleanup based on WIP rules.\n@icco - this is the same Rubocop config but I've ran a number of `auto-correct` steps.\r\n\r\nSkimming through there may be some curious cases so we may not want to rely on anything just yet.\r\n\r\nPlus since we've not decided on the rules (where not covered by Github style guide) there may be some changes."
2934,'',"Add Rubocop and checklist\n@icco here's the stuff I had been working on. In the fog repo we can both work on it.\r\n\r\nNot ready for merging at the moment whilst everyone gets back places and can have a look at things."
2933,'','second attempt to fix issue# 2748, plus other places its broken\nfixes for 3 models, to avoid request limit exceeded due to exponential create tags API requests:\r\n\r\nservers\r\nvolumes\r\nspot requests'
2931,'','Basic initial rubocop config\n@geemus and @tokengeek, please take a look.\r\n\r\nCreated by running `rubocop --auto-gen-config`.'
2930,'','[vcloud_director] Add support for custom fields in vapp\nThis adds read/write custom properties support to vapp via ProductSections, as specified in http://pubs.vmware.com/vcloud-api-1-5/wwhelp/wwhimpl/js/html/wwhelp.htm#href=api_prog/GUID-E13A5613-8A41-46E3-889B-8E1EAF10ABBE.html'
2929,'','Remove coveralls\nDOWN WITH CLOTHES.'
2926,'','post_object_hidden_fields does not generate request policy\nHi,\r\n\r\n`aws-sdk` gem provide a [method](https://github.com/aws/aws-sdk-ruby/blob/master/lib/aws/s3/presigned_post.rb#L329) for generate policy request, [fog instead](https://github.com/fog/fog/blob/master/lib/fog/aws/requests/storage/post_object_hidden_fields.rb#L27) expect that policy is provided by coder, there a method to generate this policy?\r\n\r\nIs [not simple to generate](http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTConstructPolicy.html), would be a great thing to have.'
2925,'','Google requests insert_route does not parse for nextHopNetwork\nhttps://github.com/fog/fog/blob/master/lib/fog/google/requests/compute/insert_route.rb\r\n\r\nThe above file does not contain the logic to parse the nextHopNetwork from the options even though it is a field that exists in the Google route.rb model (https://github.com/fog/fog/blob/master/lib/fog/google/models/compute/route.rb) and in the v1 route object (https://developers.google.com/compute/docs/reference/latest/routes).'
2924,'','[rackspace|loadbalancers] Fix requiring nodes during load balancer creation\nFog currently requires you to specify a node when creating a load balancer balancers. However, according to the [documentation](http://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/Create_Load_Balancer-d1e1635.html), they should not be required. This PR addresses removes that requirement.'
2922,'','Added ip_address methods consistent with openstack\n'
2921,'','[rackspace|autoscale] fixing typo in docs\n'
2920,'',"AWS: Error listing internet gateways\nWe're using fog to create complete VPC configurations programatically.\r\n\r\nWe regularly get into a state where fog refuses to operate on internet gateway objects.\r\n\r\n```\r\n    def connection\r\n      @connection ||= Fog::Compute.new(parse_environment)\r\n    end\r\n\r\n\r\n  connection.internet_gateways.first\r\n\r\n  Excon::Errors::SocketError: EndTag: '</' not found (Nokogiri::XML::SyntaxError)\r\nfrom /home/jmasson/.rvm/gems/ruby-2.0.0-p353@fog/gems/nokogiri-1.6.1/lib/nokogiri/xml/sax/push_parser.rb:47:in `native_write'\r\n```\r\n\r\nThere are plenty of internet gateways visible in the Web UI, but fog can't do any operations on them. This state persists across runs of fog.\r\n\r\n\r\nThis error seems a bit transient - on some lists of IGs it's fine, but others not, but once the error appears it's constant through multiple runs of fog on different machines.\r\n\r\nAs a workaround, we're using...\r\n```\r\nconnection.internet_gateways.all(filter_goes_here)\r\n```\r\n... and this works fine"
2919,'','OpenNebula compute provider\nHi,\r\n\r\nwe added a compute provider for OpenNebula to fog. We implemented some basic features like creating, starting, stopping and deleting virtual machines.  More details are available in lib/fog/opennebula/README.md. \r\n\r\nAny feedback is welcome!'
2918,'',"[rackspace|compute] Updated setup method to retry once on disconnect \nWhen using the `servers.bootstrap` with Ubuntu 12.04 images I consistently get the following exception\r\n\r\n```\r\nNet::SSH::Disconnect: connection closed by remote host\r\nfrom /Users/krames/.gem/ruby/2.1.1/gems/net-ssh-2.9.0/lib/net/ssh/transport/packet_stream.rb:87:in `next_packet'\r\n```\r\nThis apparently is being caused by the failure to do a nonblocking read during the authentication setup for Net::SSH. This PR catches that exception and attempts to retry the connection one more time."
2917,'','S3 keys truncated for filenames containing ",", "(" or "\'"\nHi,\r\n\r\nUsing Fog to list and get signed urls for user-uploaded private files, I\'ve noticed some files didn\'t generate a proper signed url. For exemple:\r\n```Ruby\r\n# with a file named "Something (containing parenthesis).txt"\r\nfile.url 10.minutes.from_now\r\n```\r\nwould return an url that amazon answers with:\r\n```XML\r\n<Error>\r\n  <script/>\r\n  <Code>NoSuchKey</Code>\r\n  <Message>The specified key does not exist.</Message>\r\n  <Key>containing parenthesis).txt</Key>\r\n  <RequestId>...</RequestId>\r\n  <HostId>...</HostId>\r\n</Error>\r\n```\r\nNoticing the "<Key/>" tag contained a truncated version of the filename, I checked the keys obtained through fog:\r\n```Ruby\r\nfile.key\r\n```\r\nReturns "containing parenthesis).txt"\r\n\r\nSo far, I\'ve identified these 3 characters as troublemakers: ",", "(", "\'" ;  I guess the parser for amazon\'s responses mistakes these characters for JSON or something. I\'ll try to fix the problem and propose a pull request but I\'m not used to Fog that much so pointers would be usefull.\r\n\r\nAnyways, thanks for this awesome gem ^^d'
2916,'','[rackspace] updating authentication endpoints\nUpdating authentication endpoints.\r\n\r\nThis should address the following [stack overflow](http://stackoverflow.com/questions/23184560/when-saving-a-file-to-rackspace-cloudfiles-using-paperclip-fog-a-timeout-occurs/23222021?noredirect=1#comment35555691_23222021) issue.'
2915,'',"Issue2908\n- Resolves https://github.com/fog/fog/issues/2908\r\n- 'bundle exec rake' passes\r\n- Hand testing of pagination passes\r\n"
2913,'','Fix #2892: "rake travis" fails with can\'t modify frozen String\nMake an unfrozen copy of RUBY_VERSION so that rubygems version can\r\nstrip! it.'
2911,'','Racksapce: Add support for user-data for compute\nCurrently its possible to add user-data for aws instances, and custom user-data is critical for coreos clustering. It is possible to add user-data via supernova, can we add support via fog?\r\n'
2909,'','AWS: Move PrivateIpAddress to the NetworkInterface structure if it exists\nWhen trying to associate a specific private ip address and a (non-elastic) public ip address, AWS requires the PrivateIpAddress value to be under the NetworkInterface structure.\r\n\r\nSimilar to the fix for: https://github.com/aws/aws-cli/issues/520'
2908,'','Rackspace Monitoring: Add pagination marker for agent tokens, checks, and alarms\nIn issue 2469 and pull 2551 pagination marker was added to Rackspace monitoring entities for cases where the number of objects exceeds the pagination limit.  Please add this marker to the following objects to allow pagination as well:\r\n\r\n* https://github.com/fog/fog/blob/master/lib/fog/rackspace/models/monitoring/agent_tokens.rb\r\n* https://github.com/fog/fog/blob/master/lib/fog/rackspace/models/monitoring/alarms.rb\r\n* https://github.com/fog/fog/blob/master/lib/fog/rackspace/models/monitoring/checks.rb\r\n\r\nThanks!'
2907,'',"Improved digital ocean mocking\nA couple of minor tweaks to Digital Ocean mocking:\r\n\r\n- Updated the region list so it's a little more current\r\n- Have the create server request return a private ip if the private_networking parameter is supplied and the region supports private networking."
2905,'','Allow vApp Template Instantiation without network_id\nnetwork_id should not be required in order to instantiate a vApp from template.'
2904,'','Support for launching instance into specific Availability Zones\nI am leveraging the fog lib in conjunction with an Enterprise AWS based SaaS solution, and have run into a pretty significant challenge in that we must be able to launch instances into different availability zones.  Usually when leaving the availability zone null, AWS will deliver an instance on the "most available" AZ.  However, when deploying a fully fault tolerant solution, we have to be able to specify which AZ the instance is to be launched into so that we don\'t have all of the instances getting launched on the same AZ.  Would it be possible to include availability zone as a param in compute.rb, similar to the way region was added?  '
2903,'',"require 'fog' takes way too long to load unused providers\nI used Bumbler to profile my Rails startup time and fog is responsible for >600msec. While this doesn't sound like much, it's actually a big deal when other gems are between 10 and 200 msec and you're trying to improve `rails c` or `rake` startup time (it's currently taking about 12 seconds to start my Rails app, which is more than I want my whole test suite to take).\r\n\r\nI know I can just `require 'fog/aws'` but sadly, even when I do that, other gems (carrierwave and asset_sync) do `require 'fog'` which pulls in all the providers even though all I need is the AWS provider. Yes, this means that I should log an issue with them, but I'm not sure how you would recommend they change their code, since they have an annoying chicken-and-egg initialization problem -- they also don't know which fog providers I need, but they need to make sure they load after fog does, and Rails is not so good about guaranteeing order of execution during startup.\r\n\r\nIn the old days I'd suggest using `autoload` but it seems that's been deprecated: https://www.ruby-forum.com/topic/3036681 (or is it?)\r\n\r\nI hacked my fog gem to remove all other providers and, yep, it shaved 400 msec off the load time -- that's 66% off. (Note that this is on my new SSD setup; on my HDD it's more like 6 sec -> 1 sec.)\r\n"
2902,'',"Rackspace: optional params for load_balancers.create parameters\nI'm grouping two bugs into one issue because they are closely related: both are caused by `load_balancers.create` assuming a parameter is required that is supposed to be optional.\r\n\r\n## Port shouldn't (always) be required\r\n\r\nComment out port on [line 17 of tests/rackspace/helper.rb](https://github.com/fog/fog/blob/master/tests/rackspace/helper.rb#L17).  You should get this error when you run the test:\r\n>  port is required for this operation (ArgumentError)\r\n\r\nAccording to the [Create Load Balancer documentation](http://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/Create_Load_Balancer-d1e1635.html), port is not required for known protocols like HTTP.\r\n\r\n## Nodes should not be required, and error message is bad\r\n\r\nComment out port on [line 19 of tests/rackspace/helper.rb](https://github.com/fog/fog/blob/master/tests/rackspace/helper.rb#L19) (and the preceding comma).  That's this line:\r\n```ruby\r\n:nodes => [{ :address => '1.1.1.1', :port => 80, :condition => 'ENABLED'}]\r\n```\r\n\r\nWhen you run the test, you will get:\r\n> [HTTP 404 | ] resource not found in dfw region (Fog::Rackspace::LoadBalancers::NotFound)\r\n\r\nExcon debug reveals that it's trying to hit `/v1.0/831404/loadbalancers//nodes.json`.\r\n\r\nThis really shouldn't fail at all, because according to the [Create Load Balancer documentation](http://docs.rackspace.com/loadbalancers/api/v1.0/clb-devguide/content/Create_Load_Balancer-d1e1635.html) nodes are optional.  It should at least fail with a clearer error message."
2901,'','Add support for AWS describe_vpc_attribute\nFix issue #2900.\r\n\r\nAdded support for AWS describe_vpc_attribute requests: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeVpcAttribute.html and improved AWS modify_vpc_attribute mock tests.'
2900,'','Missing support for AWS describe_vpc_attribute\nMissing support for AWS describe_vpc_attribute requests: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeVpcAttribute.html'
2899,'','[zerigo] Fix Invalid Excon request warning\nThis was triggering the warning:\r\n`[excon][WARNING] Invalid Excon request keys: :host`\r\n\r\nFollowed by a stacktrace. Looking at [fog#2292][1] and the related\r\nissues this seems like the right fix and seems to work fine.\r\n\r\n[1]: https://github.com/fog/fog/pull/2292'
2898,'','[rackspace|storage] metadata now supports indifferent access\nAdded `[]` and `[]=` operators to support indifferent access in order to address  issue #2881.'
2895,'','[openstack|compute] Add descriptions to returns blocks in the\nsecurity_groups tests in hopes of trying to track down the cause of issue'
2894,'','Add the DisableApiTermination flag to the AWS Server model, so it can be...\n... sent on instance creation\r\n\r\nFrom RunInstances documentation (http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-RunInstances.html)\r\n\r\n"DisableApiTermination\r\nIf you set this parameter to true, you can\'t terminate the instance using the Amazon EC2 console, CLI, or API; otherwise, you can. If you set this parameter to true and then later want to be able to terminate the instance, you must first change the value of the disableApiTermination attribute to false using ModifyInstanceAttribute. Alternatively, if you set InstanceInitiatedShutdownBehavior to terminate, you can terminate the instance by running the shutdown command from the instance.\r\n\r\nType: Boolean\r\n\r\nDefault: false\r\n\r\nRequired: No"'
2893,'',"Fix elb tests\nThis fixes the ELB tests when run with FOG_MOCK=false: `FOG_MOCK=false bundle exec shindont tests/aws/models/elb`.\r\n\r\nI'd appreciate any feedback on:\r\n\r\n1. The way skipping of tests in incompatible environments is implemented\r\n2. The location of the new `ec2_compatibility_mode` method\r\n3. A more idiomatic way to teardown resources which may or may not actually exist"
2892,'','"rake travis" fails with can\'t modify frozen String\n```\r\n** Invoke coveralls_push_workaround (first_time)\r\n** Execute coveralls_push_workaround\r\nrake aborted!\r\ncan\'t modify frozen String\r\n/usr/lib/ruby/1.9.1/rubygems/version.rb:191:in `strip!\'\r\n/usr/lib/ruby/1.9.1/rubygems/version.rb:191:in `initialize\'\r\n/home/porridge/fog/Rakefile:217:in `new\'\r\n/home/porridge/fog/Rakefile:217:in `block in <top (required)>\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:205:in `call\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:205:in `block in execute\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:200:in `each\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:200:in `execute\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:158:in `block in invoke_with_call_chain\'\r\n/usr/lib/ruby/1.9.1/monitor.rb:211:in `mon_synchronize\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:151:in `invoke_with_call_chain\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:176:in `block in invoke_prerequisites\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:174:in `each\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:174:in `invoke_prerequisites\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:157:in `block in invoke_with_call_chain\'\r\n/usr/lib/ruby/1.9.1/monitor.rb:211:in `mon_synchronize\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:151:in `invoke_with_call_chain\'\r\n/usr/lib/ruby/vendor_ruby/rake/task.rb:144:in `invoke\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:116:in `invoke_task\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:94:in `block (2 levels) in top_level\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:94:in `each\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:94:in `block in top_level\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:133:in `standard_exception_handling\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:88:in `top_level\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:66:in `block in run\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:133:in `standard_exception_handling\'\r\n/usr/lib/ruby/vendor_ruby/rake/application.rb:63:in `run\'\r\n/usr/bin/rake:27:in `<main>\'\r\nTasks: TOP => travis => coveralls_push_workaround\r\n```'
2891,'','hardcoded linode flavor cores until they add it to their api\ntemporary solution as discussed here:\r\nhttps://github.com/fog/fog/issues/2886'
2890,'','fix(rackspace): Fix for global endpoint\nThis fix is needed for an identity modification for the Rackspace provider.\r\n\r\nUnit Test Provided'
2889,'','AWS security group configuration issue\nHi everyone,\r\n\r\nI need some help. I create a security_group inside a non-default VPC, but I can not give permissions doing the following:\r\n```\r\nconn = Fog::Compute.new({\r\n :provider => \'AWS\', :region => "XXX", :aws_access_key_id => XXX, :aws_secret_access_key => XXX\r\n})\r\n...\r\ncreateVPC & getVpcId\r\n...\r\nconn.create_security_group("Test", "test", vpcId)   --> OK\r\nconn.authorize_security_group_ingress("Test", options) --> FAILS\r\n\r\n/usr/local/Cellar/ruby/2.1.1/lib/ruby/gems/2.1.0/gems/excon-0.33.0/lib/excon/middlewares/expects.rb:6:in `response_call\': The security group \'Test\' does not exist in default VPC \'vpcId\' (Fog::Compute::AWS::NotFound)\r\n```\r\n\r\nDoes anyone has an example of creating SG and assigning inbound rules??'
2887,'','[ovirt] force volumes reload on volume locked? check.\n'
2886,'','linode cpu cores\nlinode compute model always returns 4 for cores.  As of very recently they no longer have the same amount of cores for every instance size.  Even before that change it was 8 cores\r\nhttps://blog.linode.com/2014/04/17/linode-cloud-ssds-double-ram-much-more/\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/linode/models/compute/flavor.rb'
2885,'',"[aws|elb] add support for ELB connection draining\nAdd support for ELB connection draining: http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/config-conn-drain.html\r\n\r\nThis allows you to view whether Connection Draining is enabled or disabled, and also to view the Timeout setting. You can also toggle the feature on/off, and change its Timeout setting.\r\n\r\nThe relevant tests pass locally for `FOG_MOCK=true`. I tried running them with mocking disabled, but ran into the following issue:\r\n\r\n```\r\n  AWS::ELB | policy_tests (aws, elb) +++++++++++++++++++  \r\n  AWS::ELB | models (aws, elb) +++++++++++++++++          \r\n          /Users/bgentry/Code/fog/tests/aws/models/elb/model_tests.rb\r\n            with vpc\r\n            create\r\n            success\r\n            AWS::ELB | models (aws, elb)\r\n          undefined method `ec2_compatibility_mode' for #<Fog::Compute::AWS::Real:0x007ff08eba0618> (NoMethodError)\r\n            /Users/bgentry/Code/fog/tests/aws/models/elb/model_tests.rb:61:in `block (4 levels) in <top (required)>'\r\n            /usr/local/opt/rbenv/versions/2.1.1/lib/ruby/gems/2.1.0/gems/shindo-0.3.8/lib/shindo.rb:79:in `instance_eval'\r\n            /usr/local/opt/rbenv/versions/2.1.1/lib/ruby/gems/2.1.0/gems/shindo-0.3.8/lib/shindo.rb:79:in `tests'\r\n            /Users/bgentry/Code/fog/tests/aws/models/elb/model_tests.rb:60:in `block (3 levels) in <top (required)>'\r\n```\r\n\r\nWhen I added a stub for that method to `Fog::Compute::AWS::Real`, I still had some very strange results from unrelated tests. Maybe it's because I have an old (non-VPC default) AWS account? Maybe somebody else can run those tests with `FOG_MOCK=false` ?\r\n\r\n/cc @mikehale @pedro"
2884,'','fix(rackspace): Fix for global endpoint\nThis fix is needed for an identity modification for the Rackspace provider.'
2882,'',"[google|compute] Some fixes for Images\n- Fix insert_image request body (add 'source' Hash to 'rawDisk')\r\n- Fix reload image to add the project to the properties"
2881,'','Rackspace: writing metadata is not string/hash insensitive, but saving it is\nYou can see something is odd if you run https://github.com/fog/fog/blob/master/lib/fog/rackspace/examples/storage/storage_metadata.rb twice and compare the output.\r\n\r\nThe first time looks normal:\r\n```\r\nCreating directory \'metadata-tester\'\r\nInitial Container Metadata\r\n\r\nAdding Container Metadata\r\n\tenvironment: demo\r\n\r\nUpdating Container Metadata\r\n\tenvironment: test\r\n\r\nUploading file\r\nInitial File Metadata\r\n\r\nAdding File Metadata\r\n\tpreview: true\r\n\r\nUpdating File Metadata\r\n\tpreview: false\r\n\r\nTo delete the directory and file please execute the delete_directory.rb script\r\n```\r\n\r\nThe second time you see two duplicate settings for environment:\r\n```\r\nCreating directory \'metadata-tester\'\r\nInitial Container Metadata\r\n\tenvironment: test\r\n\r\nAdding Container Metadata\r\n\tenvironment: test\r\n\tenvironment: demo\r\n\r\nUpdating Container Metadata\r\n\tenvironment: test\r\n\tenvironment: test\r\n\r\nUploading file\r\nInitial File Metadata\r\n\r\nAdding File Metadata\r\n\tpreview: true\r\n\r\nUpdating File Metadata\r\n\tpreview: false\r\n\r\nTo delete the directory and file please execute the delete_directory.rb script\r\n```\r\n\r\nThis reason is that we\'re adding string keys to the metadata.  After you save they\'re still string keys, but if you reload you see they\'ve been converted to symbols.  So there is a mismatch when you try to update `"environment"`, but the key is now `:environment`.\r\n\r\nMore details...\r\n\r\n```ruby\r\n# before saving\r\ndirectory.metadata.to_hash\r\n=> {:environment=>"test", "environment"=>"demo"}\r\n\r\n# after saving\r\ndirectory.metadata.to_hash\r\n=> {:environment=>"test", "environment"=>"demo"}\r\n\r\n# after reloading\r\ndirectory.metadata.to_hash\r\n=> {:environment=>"demo"}\r\n```\r\n'
2880,'','[google|compute] Improve Server support\n- Allow can_ip_forward option when creating a server\r\n- Allow not to allocate an external IP when creating a server\r\n- Use "Operation" instead of the "backoff_if_unfound" method when creating a server'
2879,'','[google|compute] Enable passing the google_key_location as a String\nGoogle::APIClient::KeyUtils.load_from_pkcs12 allows passing the contents\r\nof the PKCS12 key as a String instead of the PKCS12 file location.\r\n\r\nAllowing this option when Fog::Compute[:google] is initialized enables the\r\nautomation on those environments where you can not send a file.'
2878,'','Fog.mock! throw error for Rackspace :lon location\nRuntimeError: Unknown region :lon for service cloudFiles. Please use one of the following regions: :ord, :dfw, :syd, :iad, :hkg'
2876,'','openssl error when getting servers from amazon\ni have been using this  since last 2 weeks, but today i got one error like \r\nhostname "ec2.sa-east-1.amazonaws.com" does not match the server certificate (OpenSSL::SSL::SSLError)\r\n@aws_credentials = {\r\n          :provider => "AWS",\r\n          :aws_access_key_id => access_key_id,\r\n          :aws_secret_access_key => secret_access_key\r\n      }\r\nline 1:  conn2 = Fog::Compute.new(@aws_credentials.merge(:region => \'sa-east-1\'))\r\nline 2:  conn2.servers.all.each do |server|\r\n            end\r\nso i got that error in line 1, actually i donât have server in this \'sa-east-1\' region. but if give the region, which i have the server, it will not give any errors.\r\n\r\n'
2873,'','fog to fog-core version strictness?\nWe just hit [an issue](http://projects.theforeman.org/issues/5248) in Foreman using fog 1.21.0 when used with fog-core 1.22.0, as the Fog.class_from_string helper was moved out of core back into the vSphere provider (be69899, https://github.com/fog/fog-core/commit/e164cc7).\r\n\r\nShould the dependency in fog itself on fog-core be tighter so the versions are matched?  As it stands, fog 1.21.0 depended on at least 1.21.0, rather than ~> 1.21.0, which led to the incompatibility between 1.21.1 and fog-core 1.22.0.\r\n\r\nhttps://github.com/fog/fog/blob/master/fog.gemspec#L44'
2872,'',"[google|storage] Enabled :path_style for Google Cloud Storage for allowing CNAME buckets\ne.g. paperclip configuration:\r\n```ruby\r\nconfig.paperclip_defaults = {\r\n      storage: :fog,\r\n      fog_credentials: {\r\n        provider: provider,\r\n        google_storage_access_key_id: access_key_id,\r\n        google_storage_secret_access_key: secret_access_key,\r\n        path_style: true\r\n      },\r\n      fog_public: true,\r\n      fog_directory: host,\r\n      fog_host: 'http://' + host\r\n    }\r\n```"
2871,'',"Softlayer\nI've got some time budgeted to focus on SoftLayer tooling.  Here's an initial pull request adding a SoftLayer provider that follows the new modular approach (modeled pretty closely after the existing Brightbox patterns).\r\n\r\nI'm pushing this up now looking for early feedback.\r\n\r\nNext steps are: \r\n* `Compute` \r\n  * add more requests\r\n  * models/collections\r\n* `Storage`\r\n* `Image`\r\n* `DNS`\r\n* `Network`\r\n\r\nThx!"
2870,'','Make job polling requests for Dyn retryable within exconn by passing the idempotent option.\n'
2869,'icco','[google|compute] Add Region tests\nAdd "Region" tests'
2868,'','Requests to S3 are denied when using proxy\nHi\r\n\r\nI\'m having trouble getting Fog to work with S3 behind a proxy server.\r\nI\'m using fog-1.12.1 and excon-0.23.0.\r\n\r\nHere\'s how the proxy connection is currently configured:\r\n\r\n    class S3\r\n      ...\r\n      def new_fog_connection\r\n        Fog::Storage.new({\r\n          provider: @account.provider,\r\n          aws_access_key_id: @account.access_key_id,\r\n          aws_secret_access_key: @account.secret_access_key,\r\n          connection_options: {\r\n              proxy: {\r\n                host: @account.proxy.host,\r\n                port: @account.proxy.port,\r\n                scheme: @account.proxy.scheme\r\n              }\r\n          }\r\n        })\r\n      end\r\n    end\r\n\r\n\r\nAny request to S3 ends up being successfully proxied through to s3.amazonaws.com (Proxy server returns a 200), but S3 itself always returns a 403:\r\n\r\nirb(main):002:0> S3.new(:daily_spend).new_fog_connection.directories\r\nExcon::Errors::Forbidden: Expected(200) <=> Actual(403 Forbidden)\r\n  response => #<Excon::Response:0x007f725b42bf10 @data={:body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>693090729E153BA0</RequestId><HostId>VMJDR3qN2GDGETHK6e+sK7QGultuS7PH8Swg+E0L/CpT2angE4ll5hfl0qdoueRz</HostId></Error>", :headers=>{"x-amz-request-id"=>"693090729E153BA0", "x-amz-id-2"=>"VMJDR3qN2GDGETHK6e+sK7QGultuS7PH8Swg+E0L/CpT2angE4ll5hfl0qdoueRz", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Thu, 17 Apr 2014 20:06:49 GMT", "Server"=>"AmazonS3"}, :status=>403, :remote_ip=>"10.3.28.98"}, @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>693090729E153BA0</RequestId><HostId>VMJDR3qN2GDGETHK6e+sK7QGultuS7PH8Swg+E0L/CpT2angE4ll5hfl0qdoueRz</HostId></Error>", @headers={"x-amz-request-id"=>"693090729E153BA0", "x-amz-id-2"=>"VMJDR3qN2GDGETHK6e+sK7QGultuS7PH8Swg+E0L/CpT2angE4ll5hfl0qdoueRz", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Thu, 17 Apr 2014 20:06:49 GMT", "Server"=>"AmazonS3"}, @status=403, @remote_ip="10.3.28.98">\r\n\r\n\r\nIf a specific file is requested, then SignatureDoesNotMatch message is returned instead of AccessDenied, but it\'s the same 403 response code.\r\n\r\nI tried using s3cmd client on the same server and requests complete successfully when using it. Also, same code works on another server without any proxy settings.\r\nI saw another issue reported where versions of gems were identical to the ones I\'m using (https://github.com/fog/fog/issues/1964), but I\'m not sure if using proxy with S3 is altogether broken in this version of Fog or this is just something I\'m doing wrong. \r\n\r\nThanks for your help in advance!  '
2867,'','Added fix to allow progress bar to appear on VCD5.5\nThe progress parameter is no longer present for task api calls\r\nin VCD5.5, and so if progressbars are visible a Nil exception is\r\ngenerated.\r\n\r\nThis ensures that progress is set and the execution flow can continue'
2866,'','[google|compute] Update Addresses suport\n- Modify "list_aggregated_addresses" to support filters\r\n- Add "get_by_ip_address" model method\r\n- Add ability to assign/deassign an IP to a server'
2865,'','Add support for Google Cloud DNS\nURL: https://developers.google.com/cloud-dns/\r\nI plan to work on this.'
2864,'tokengeek',"Extracted fog-brightbox code to own repo\nThis is more a work in progress update for @geemus and other core folks.\r\n\r\nI've extracted the `providers/brightbox` subtree out to https://github.com/brightbox/fog-brightbox\r\n\r\nHaving tried to work within a subdirectory for the last month or two has highlighted a number of problems - most of which I think we guessed on the original issue https://github.com/fog/fog/issues/2681\r\n\r\nThe main killer which will affect other users later is that from an application basis, Bundler can not reference a gemspec in a subdirectory of a git repo.\r\n\r\nSo it has been impossible for our CI server or applications to reference the `master` version of `fog-brightbox` which has led us down the road of building prerelease gems and hosting gems internally.\r\n\r\nSo this will basically just lead to more requests for fog releases because the only clean way for provider gems to be used are either cutting a gem release or unpacking gems and using `path`\r\n\r\nI'm currently at the junction where I have an application that can reference `fog-core/master` but not `fog-brightbox/master` and I can't cut a prerelease gem that references the unreleased gem.\r\n\r\nSo in the application I'm forced to update the `Gemfile` to reference `fog-core` AND create a prerelease gem. The worst of both worlds.\r\n\r\nNow I knew this was a problem when we last discussed it but it's hit the point where it's too much work to justify and I'm really behind on a project working around this one problem.\r\n\r\nIf anyone can come up with workable alternatives I'll be happy to discuss.\r\n\r\nSo my intention is to clean up the main repo next week to cut down on things like loading providers tests, gemfiles referencing sub paths etc."
2863,'','[google|compute] Update Servers support\n- Add missing "Server" properties\r\n- Remove unnecessary property aliases\r\n- When destroying a "Server" asyncronously return the "Operation" model instead of the raw operation response\r\n- If zone is not set on "all" and "get" methods, use the list aggregated servers request (1 API call) instead of fetching all zones\r\n- Add "list_aggregated_servers" request\r\n- Fix "attach_disk" request\r\n- Fix "detach_disk" request\r\n- Add "get_server_serial_port_output" request\r\n- Add "reset_server" request\r\n- Add "set_server_disk_auto_delete" request\r\n- Add "set_server_scheduling" request\r\n- Fix "set_tags" request'
2862,'','[google|compute] Update Images support\n- Add missing "Image" properties\r\n- Add "ready?" method to model\r\n- Add "destroy" method to model\r\n- Use "Operation" instead of the "backoff_if_unfound" method when inserting an "Image"'
2861,'','RDS Promote Read Replicas\nAdds support for promoting AWS RDS read replicas \r\nhttp://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_PromoteReadReplica.html\r\n'
2860,'','. fix ruby-libvirt library require name (libvirt)\nBecause `tests/helper.rb` requires `ruby-libvirt` by the wrong library name (`libvirt`), provider specific tests are not run.\r\nFixes #2858\r\n'
2858,'','[libvirt] fix missing libvirt tests\nWhen running \r\n```\r\nbundle exec rake mock[libvirt]\r\n```\r\nno `libvirt` tests get run (below is the output):\r\n```\r\n  Skipping tests for libvirt due to missing `ruby-libvirt` gem.\r\n  \r\n  Fog::Compute[:libvirt] (libvirt)   \r\n  Fog::Compute[:libvirt] | create_domain request (libvirt)   \r\n  Fog::Compute[:libvirt] | define_domain request (libvirt)   \r\n  Fog::Compute[:libvirt] | interface model (libvirt)   \r\n  Fog::Compute[:libvirt] | nic model (libvirt)   \r\n  Fog::Compute[:libvirt] | pools request (libvirt)   \r\n  Fog::Compute[:libvirt] | server model (libvirt)   \r\n  Fog::Compute[:libvirt] | network model (libvirt)   \r\n  Fog::Compute[:libvirt] | volume model (libvirt)   \r\n  Fog::Compute[:libvirt] | nics collection (libvirt)   \r\n  Fog::Compute[:libvirt] | volumes collection (libvirt)   \r\n  Fog::Compute[:libvirt] | servers collection (libvirt)   \r\n  Fog::Compute[:libvirt] | interface model (libvirt)   \r\n  Fog::Compute[:libvirt] | interfaces collection (libvirt)   \r\n  Fog::Compute[:libvirt] | networks collection (libvirt)   \r\n  0 succeeded in 2.763479 seconds\r\n```\r\nI\'ve made sure that `ruby-libvirt` is actually installed by running:\r\n```shell\r\nbundle exec ruby   -e \'require "libvirt"\'\r\n```'
2857,'','Vsphere volume eager-zeroed fix\nI believe there\'s a bug in fog/lib/fog/vsphere/requests/compute/create_vm.rb that I encountered while exposing eager-zeroing in Foreman host creation.\r\n\r\nThis never enter the conditional (and thus never eager-zeroes the volume):\r\n```\r\n137           if operation == :add && disk.thin == false && disk.eager_zero\r\n138             payload[:device][:backing][:eagerlyScrub] = disk.eager_zero\r\n139           end\r\n```\r\nwhile using\r\n```\r\nif operation == :add && disk.thin == "false" && disk.eager_zero == "true"\r\n```\r\nworks because here these variables are string types and not bool types, really (ah, those pesky non-statically typed langages)\r\n\r\nSorry for not bothering making a PR, but I hope the "patch" above is simple enough :)\r\n'
2856,'','Add support for expunging node in cloudstack.\nIf true is passed, the vm is expunged immediately. False by default.'
2855,'','fixed misspelling\n`settng` should be `setting`'
2854,'icco','[google|compute] Improve Disks support\n- Add missing "Disk" properties\r\n- Remove unnecessary property aliases\r\n- Use "Operation" instead of the "backoff_if_unfound" method when inserting a "Disk" or "Snapshot"\r\n- When destroying a "Disk" asyncronous return the "Operation" model instead of the raw operation response\r\n- Add "list_aggregatted_disks" request\r\n- If zone is not set on "all" and "get" methods, use the list aggregated disks request (1 API call) instead of fetching all zones\r\n- Fix a bug when inserting a snapshot (description was not merged at the body request)\r\n- Fix model tests'
2853,'',"SQS get queue attributes fix\nPreviously `SQS#get_queue_attribtues` would fail to return anything when making a request, this was due to AWS expecting to receive the attributes array as a collection of indexed query params. Eg.\r\n\r\n```\r\nAttributeName.1 = 'QueueArn'\r\nAttributeName.2 = 'MessageRetentionPeriod'\r\n```\r\n\r\nInstead of a single key as it was previously.\r\n\r\nPlease see the AWS documentation for this endpoint http://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_GetQueueAttributes.html"
2852,'',"Pagination on Rackspace DNS records\nThis issue has popped up numerous times for Rackspace DNS _zones_, but was never corrected for _records_.\r\n\r\nThis issue #1172 is identical, but was closed referencing #1535, which is pagination for _zones_.\r\n\r\nThe max records per zone (by default) with Rackspace is 500, and the page limit is 100 by default.  Since the max records is relatively low, I've added a quick fix with the #all! method for our pipeline as this is a very crucial feature.\r\n\r\nI hope to refine this into an #each method with test coverage, but I needed a quick fix for now, and wanted to make the issue known."
2849,'',"Fix bugs in disk tests\nWasn't paying attention last night and broke the build. @frodenas mind taking a look?"
2848,'','[google|compute] Modify Snapshots\n- Add missing "Snapshot" properties\r\n- Fix "delete" request, as "Snapshots" doesn\'t require a zone\r\n- Added "destroy" and "ready?" methods to model\r\n- Removed "project" param\r\n- Removed custom "reload" method in favour of the standard fog method'
2847,'','[google|compute] Bring Flavors model and related requests up to feature parity\n- Add full "Machine Type" properties\r\n- Replace deprecated "connection" for "service"\r\n- Add "list_aggregated_machine_types" request\r\n- Modify "all" method to return the full list of machine types (instead\r\n  of the ones from the first zone)'
2846,'','[google|compute] Add Addresses support\n- Add "Addresses" model and collection\r\n- Add "list_aggregated_addresses" request\r\n- Modify "insert" request to allow "description" property'
2845,'tokengeek',"[fog-brightbox] Prepare for v0.0.2 release\nSorry for the noise - I'm planning a release of `fog-brightbox_v0.0.2` and since it's a subproject in the main repo, commits, PRs and tags end up on the main project.\r\n\r\n@geemus I'm starting to rethink the providers approach again!"
2844,'','[google|compute] Add Routes support\n- Add "Routes" model and collection\r\n- Add "delete_route" request\r\n- Add "get_route" request\r\n- Add "insert_route" request\r\n- Add "list_routes" request'
2843,'','[google|compute] Add Regions support\n- Add "Regions" model and collection\r\n- Add "get_region" request'
2842,'','[google|compute] Add Networks support\n- Add "Networks" model and collection\r\n- Modify "insert" request to allow "description" and "gatewayIPv4" properties'
2841,'','[google|compute] Add Projects support\n- Add "Projects" model and collection\r\n- Add "get_project" request\r\n- Add "set_common_instance_metadata" request'
2840,'','[google|compute] Add Firewalls support\n- Add "Firewalls" model and collection\r\n- Modify "insert" method to add "description" and "targetTags" properties\r\n- Modify "insert" method to not prepend network URI if is set by user'
2839,'','[google|compute] Complete Operations support\n- Add missing Operation attributes\r\n- Remove unnecessary attribute aliases\r\n- Add "zone_name" attribute for backward compatibility\r\n- Add "destroy" method for an Operation\r\n- Add "all" method for Operations\r\n- Fix a bug when building an empty response (ie on delete operations)\r\n- Return nil on NotFound Operations (behave like other fog resources)'
2838,'','[OpenStack] Use JSON instead of XML\nCurrent implementation will fail of OpenStack is required\r\nby itself because of Fog::XML::Connection.  Prefer to use\r\nJSON in any event. Replaced with Fog::Core::Connection.'
2837,'','[vcloud_director] fix progress reporting of tasks without a progress value\nSet progress to 0 in tasks that do not have progress which prevents the rendering of the progress of these tasks failing with a nil error.\r\n\r\nAccording to vcloud api: "Read-only indicator of task progress as an approximate percentage between 0 and 100. Not available for all tasks." (i.e. optional)\r\n\r\nhttp://pubs.vmware.com/vcd-55/index.jsp?topic=%2Fcom.vmware.vcloud.api.reference.doc_55%2Fdoc%2Ftypes%2FTaskType.html'
2836,'','[Rackspace] Fix #2835\nReplaces Fog::XML::Connection with Fog::Core::Connection so as to use \r\nJSON again instead of wrongly using XML.\r\n\r\nThis should also allow the Rackspace provider to once again work\r\nindependently via "require \'fog/rackspace\'"'
2835,'','[Rackspace] #2711 appears to have broken our provider\n**This issue may effect other fog providers as well**\r\n\r\nWhen running [this script](https://gist.github.com/elight/10203562) to connect to Rackspace using fog 1.21.0, I see the following:\r\n\r\n<img src="http://f.cl.ly/items/1G1Z0j0Q3l372g0P1J3H/Screen%20Shot%202014-04-08%20at%206.07.07%20PM.png"></img>\r\n\r\nThis simple script works when using `fog` 1.20.0.\r\n\r\nI also tested this against Ruby 2.0 and encountered the same bug.\r\n\r\nIt appears to be because #2711 replaced `Fog::Connection` with `Fog::XML::Connection` without updating the individual providers to `require \'fog/xml\'`.\r\n\r\nI suspect that we\'ve not had this issue reported because one or both of the following:\r\n\r\n1. Fog(-Rackspace) users aren\'t upgrading often\r\n1. They encounter the bug then downgrade without reporting it\r\n\r\nWhile the ecosystem makes it difficult to prove, I imagine that many fog downstream users consuming `fog` through `carrierwave` and `paperclip` both of which seem content to rely upon older fog versions.\r\n\r\n/cc @geemus @tokengeek @krames '
2834,'icco','Google Cloud Storage: does not match the server certificate (OpenSSL::SSL::SSLError)\nHiya,\r\n\r\nI have an issue which is aparently already solved for S3 connections. I configured my GCS bucket with a CNAME which produces now the OpenSSL error.\r\n```ruby\r\nExcon::Errors::SocketError (hostname "aaa.bbb.com.storage.googleapis.com" does not match the server certificate (OpenSSL::SSL::SSLError))\r\n```\r\nFor S3, it could have been solved by adding path_style: true to the Fog config. Unfortunately, this is not working for GCS configurations, it does not seem to be supported:\r\n```ruby\r\n[fog][WARNING] Unrecognized arguments: path_style\r\n```\r\nAre there any other suggestions?\r\n\r\nin application.rb\r\n```ruby\r\nconfig.paperclip_defaults = {\r\n      storage: :fog,\r\n      fog_credentials: {\r\n        provider: \'Google\',\r\n        google_storage_access_key_id: \'ccc\',\r\n        google_storage_secret_access_key: \'ddd\',\r\n        # path_style: true\r\n      },\r\n      fog_public: true,\r\n      fog_directory: \'aaa.bbb.com\',\r\n      fog_host: \'http://aaa.bbb.com\'\r\n    }\r\n```\r\n\r\nSetup:\r\nRuby 2.1.1\r\nRails 4.0.4\r\nPaperclip 4.1.1\r\nFog 1.21.0'
2832,'',"[google|compute] Adds load balancer support\n@icco I've added support for load balancing. Does this look all right?"
2831,'',"fix documentation of unmounting volumes\nlittle fix of the doc:\r\n>> server.unmount(ubuntu_image_uuid)\r\nNoMethodError: undefined method `unmount' for #<Fog::Compute::CloudSigma::Server:0x00000004739f48>\r\n        from (irb):84:in `<top (required)>'\r\n        from /home/toni/.gem/ruby/2.1.0/gems/fog-1.21.0/bin/fog:76:in `block in <top (required)>'\r\n        from /home/toni/.gem/ruby/2.1.0/gems/fog-1.21.0/bin/fog:76:in `catch'\r\n        from /home/toni/.gem/ruby/2.1.0/gems/fog-1.21.0/bin/fog:76:in `<top (required)>'\r\n        from /home/toni/.gem/ruby/2.1.0/bin/fog:23:in `load'\r\n        from /home/toni/.gem/ruby/2.1.0/bin/fog:23:in `<main>'\r\n>> server.unmount_volume(ubuntu_image_uuid)\r\n[] (works)\r\n"
2830,'tokengeek','[Brightbox] Test error when required args missing\nThis adds a test to confirm existing behaviour that ArgumentError is\r\nraised when `brightbox_client_id` or `brightbox_secret` is omitted.'
2829,'','[Rackspace] Remove circular requires from Storage\nThe fog DSL automatically requires files when `models` and `collections`\r\nhave been declared.\r\n\r\nWhen Metadata is required, it attempted to require both file, files,\r\ndirectory and directories, both trying to require the same.\r\n\r\nWhen fog/fog-core#32 was done, the ordering changed so that directory\r\nwas required first and referenced metadata which referenced Directory.\r\n\r\nFixes fog/fog#2825\r\n\r\n/cc @krames @elight '
2828,'','[core] fixing broken build\nPR 2820 uses a regular expression that is not supported in ruby 1.8.7. This reverts that PR.'
2827,'',"Don't use named capture groups for Ruby 1.8.7 compatibility\nFixes breakage in #2820"
2826,'','ISSUE-2824 Adding user_data to rackspace provider\nI tried to follow the style of this patch:\r\nhttps://github.com/xtoddx/fog/commit/24e4bae57fafe2f846c06554d4cf4b790466ecba\r\n\r\nSo you can actually submit user_data encoded or not\r\n\r\nresolve #2824'
2825,'','Improving load order in `fog-core` is triggering error in Rackspace Storage\nExample errors in Travis against `edge` https://travis-ci.org/fog/fog/jobs/22266536#L597\r\n\r\nSo I cleaned up the require ordering to be more correct in https://github.com/fog/fog-core/pull/32 but it seems to be triggering the above error.\r\n\r\nThe reason behind the change is that the requirements were set to require collections _then_ models yet collections are supposed to contain models (and most require the models themselves).\r\n\r\nSo I swapped them around so we require models, then collections (which reference the models) to be more correct.\r\n\r\nThere seems to be a circular reference between Files, Directories and Metadata making the requiring a bit messy.\r\n\r\n/cc @krames @elight '
2824,'',"Rackspace provider should support user_data and config_drive\nFrom about two days of trying to get this to work, it is my understanding that only the openstack provider supports user_data and config_drive for the compute module, and not rackspace...\r\n\r\nIf I'm right and this is not supported, it would be a much appreciated feature.\r\nThanks!"
2823,'','Add the ability to pass an options Hash to DataPipeline#describe_objects\n@tucker250\r\n\r\nThis pull enables the ability to page through results from the API call.\r\n'
2821,'',"Question about testing re-auth on 401's\nI'm working on the new OpenStack provider, and need to build some Minitest::Spec's around the logic to re-auth on token expiration, when a 401 is returned from the Identity service.\r\n\r\nI can't find specific Shindo tests related to doing that, and am just trying to formulate an appropriate approach. Advice?"
2820,'','Improve checking for Cloud Queue message IDs.\nThe previous regex failed if the queue name contained a "-".'
2819,'','Fix endpoint version detecting from rackspace_auth_url with trailing slash\n'
2818,'','Allow auth URLs without a trailing slash\nIssue: #2777'
2817,'',"Rackspace Cloudfiles Storage - get_object_https_url no longer supports PUT method. \nRackspace get_object_https_url PUT method has been removed from cloud files storage get_object_https_url method. It was there previously and now removed. Rackspace did not support the PUT method for temp urls and CORS. However, I don't believe this is the case anymore. Fog is now unable to create temp urls for uploads to CloudFiles. \r\n\r\nThanks, \r\nPhill"
2816,'','[google|compute] fix instance tags and remove zone lookup call\n@icco - sorry!  I thought I could leave that :squash in there, but it rips out the tags fingerprint.  Also passed in the zone_name so we can avoid another api call.'
2815,'','[fogdocker] info is now called json\nFix for #2806'
2814,'tokengeek','[Brightbox] Update testing to MiniTest::Spec\nUsing spec form is going to be the standard way to testing (but relying\r\non asserts). This update allows the test(s) to be picked up by the main\r\nrake task again.'
2813,'','Switch testing to MiniTest::Spec\nOfficial testing has been revised slightly to use MiniTest but in spec\r\nform BUT using asserts not expectations.'
2812,'','[HP] Unable to retrieve endpoint service url for availability zone from service catalog.  Fog v1.21.0\nI\'m following the guide on https://docs.hpcloud.com/bindings/fog/connect\r\n\r\nWhen I run this (I substituted my credentials here)\r\n\r\n```\r\nconn = Fog::Compute.new(\r\n       :provider      => "HP",\r\n       :hp_access_key  => "<my-access-key>",\r\n       :hp_secret_key => "<my-secret-key>",\r\n       :hp_auth_uri   => "https://region-a.geo-1.identity.hpcloudsvc.com:35357/v2.0/",\r\n       :hp_tenant_id => "<my-tenant-id>",\r\n       :hp_avl_zone => "az-2.region-a.geo-1"\r\n       )\r\n```\r\nI get this error\r\n```\r\n[fog][DEPRECATION] HP Cloud Compute V1 service will be soon deprecated. Please use `:version => v2` attribute to use HP Cloud Compute V2 service.\r\n\r\nRuntimeError: Unable to retrieve endpoint service url for availability zone \'az-2.region-a.geo-1\' from service catalog. \r\n```\r\nI\'ve tried both az-1.region-a.geo-1 and az-2.region-a.geo-1\r\n\r\nI would like to get this working with my ~/.fog file as well\r\n\r\nAnyone have this working with Fog v1.21.0?\r\n'
2811,'',"[google|compute] disk description and instances with scheduling options\n@icco - piling on another change... still pretty small so hopefully you're OK with the combined PR :)"
2810,'','[Rackspace|Monitoring] Add disabled flag to alarm.  Fixes issue #2731.\n[Rackspace|Monitoring] Add disabled flag to alarm.  Fixes issue #2731.'
2809,'','[google|compute] allow user to set disk description\n@icco - very small thing. Allow user to set a description, or provide a sane default.'
2808,'',"[core] locking rbovirt down to version 0.0.24 as the newly released 0.0.25 had\nThis pr is a stop gap to get fog building again.\r\n\r\nrbovirt released 0.0.25 and it changes some of the xml parsing. \r\n\r\n```\r\n  Fog::Compute[:ovirt] | interface model (ovirt)     \r\n    tests/ovirt/models/compute/interface_tests.rb\r\n      Fog::Compute[:ovirt] | interface model (ovirt)\r\n    undefined method `text' for nil:NilClass (NoMethodError)\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/rbovirt-0.0.25/lib/ovirt/interface.rb:46:in `parse_xml_attributes!'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/rbovirt-0.0.25/lib/ovirt/interface.rb:16:in `initialize'\r\n      /home/travis/build/fog/fog/lib/fog/ovirt/requests/compute/list_vm_interfaces.rb:14:in `new'\r\n      /home/travis/build/fog/fog/lib/fog/ovirt/requests/compute/list_vm_interfaces.rb:14:in `block in list_vm_interfaces'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/nokogiri-1.6.1/lib/nokogiri/xml/node_set.rb:237:in `block in each'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/nokogiri-1.6.1/lib/nokogiri/xml/node_set.rb:236:in `upto'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/nokogiri-1.6.1/lib/nokogiri/xml/node_set.rb:236:in `each'\r\n      /home/travis/build/fog/fog/lib/fog/ovirt/requests/compute/list_vm_interfaces.rb:13:in `collect'\r\n      /home/travis/build/fog/fog/lib/fog/ovirt/requests/compute/list_vm_interfaces.rb:13:in `list_vm_interfaces'\r\n      /home/travis/build/fog/fog/lib/fog/ovirt/models/compute/interfaces.rb:17:in `all'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/bundler/gems/fog-core-40277b90a2e1/lib/fog/core/collection.rb:139:in `lazy_load'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/bundler/gems/fog-core-40277b90a2e1/lib/fog/core/collection.rb:15:in `last'\r\n      tests/ovirt/models/compute/interface_tests.rb:4:in `block in <top (required)>'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo.rb:79:in `instance_eval'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo.rb:79:in `tests'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo.rb:38:in `initialize'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo.rb:13:in `new'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo.rb:13:in `tests'\r\n      tests/ovirt/models/compute/interface_tests.rb:1:in `<top (required)>'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo/bin.rb:61:in `load'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo/bin.rb:58:in `each'\r\n      /home/travis/.rvm/gems/ruby-2.1.1/gems/shindo-0.3.8/lib/shindo/bin.rb:58:in `block in run_in_thread'\r\n```"
2807,'','[server wait_for] throws error\nI\'m using the server.wait_for { ready? } and it intermittently throws the following error:\r\nundefined method `instancex_eval\' \r\n\r\n.rvm/gems/ruby-2.1.0/gems/fog-1.20.0/lib/fog/core/model.rb:67:in `block in wait_for\'", "/Users/kostasmamalis/.rvm/gems/ruby-2.1.0/gems/fog-1.20.0/lib/fog/core/wait_for.rb:5:in `wait_for\'", "/Users/kostasmamalis/.rvm/gems/ruby-2.1.0/gems/fog-1.20.0/lib/fog/core/model.rb:64:in `wait_for\'"\r\n\r\nmy code looks like this:\r\n\r\nlogging.info "server: #{server.id}"\r\n      server.wait_for { ready? }\r\n\r\nthe server is created, and the logging is showing that server isn\'t nil but the codes consistently throws the error above.'
2806,'',"[fogdocker] undefined method `info' for #<Docker::Container:0x007f4643fd0f30>\n`info` is called `json` in my version of the docker-api (version 1.7.6)\r\nfile https://github.com/fog/fog/blob/master/lib/fog/fogdocker/requests/compute/container_all.rb line 13"
2805,'','[google|compute] fix service_account scopes\nSetting scopes was failing since it didn\'t conform to Google API.  Added, "kind", "email", and allow for full URLs or short-cuts.\r\n\r\n@icco - going on the assumption it\'s better to submit discrete PRs for each thing versus a larger / broader one.'
2804,'','[openstack|network] updated create_router and update_router use symbol based\nkeys instead of string; removed dead code; this should address #2799'
2803,'',"Adding support for AWS IAM ListMFADevices API\nNothing fancy here, I've tested against a few accounts.  "
2802,'',"Rackspace - support setting admin pass during server creation\nThis PR fixes the Rackspace provider so it lets you set the admin password while creating a server.  The Fog documentation said the password was a read-only attribute only available in the response, but the service documentation says it is a read-write attribute.\r\n\r\nThis helps clear the way for Windows servers, because they don't generally support SSH.  Since you can't rely on uploading a public key, setting the password to a known value is useful.  If it is randomly generated, then projects like vagrant-rackspace would need to capture and persist the password.  It's easier to just let the vagrant user select the password and provide it to fog.\r\n\r\nDespite being a relatively small diff, it did cause me a lot of confusion, as there's a few special things happening with the password (i.e. the `adminPass` and `change_admin_password` methods)."
2801,'','[google] fixes set_tags\nNeed to set the fingerprint when changing instance tags.\r\n\r\n@icco - wdyt?'
2800,'','Added attributes to cloudapi responses recently to servers\n``compute_node`` and ``networks``'
2799,'','Dead code in OpenStack tests\nI spotted some dead code in tests/openstack/requests/network/router_tests.rb. Please see my notes on commit 55cffa7ad05b7d4621d7c3c7db78f395aa92238c for details.'
2797,'','Fix issue #2796 (AWS describe_dhcp_options request parsing)\nProperly initialize @dhcp_options for each dhcpOptionsSet'
2796,'','AWS describe_dhcp_options requests fail when more than one Dhcp Options Sets exist\n'
2795,'','Fix syntax errors in an OpenStack example script\n'
2794,'',"Adding support for IAM roles and AssumeRole for IAM API\nI noticed today that the IAM service does not support IAM roles and credentials from AssumeRole.  At first I thought this was a limitation from AWS, but another developer let me know that this works fine in boto.  So I've gone ahead and tossed together a patch, which adds this support.  I've tested it using ~./fog credentials and an IAM role.  The unit tests still run correctly also."
2793,'tokengeek','Provider examples are appearing in Yard API docs\nJust noticed that there is a lot of Rackspace only stuff in the API docs.\r\n\r\nhttp://www.rubydoc.info/gems/fog/toplevel\r\n\r\nMost are coming from `lib/fog/rackspace/examples` which when processed appear to be declaring constants and methods in the top level.\r\n\r\nI\'m assuming that requiring "fog/rackspace" isn\'t picking these up as well and it is just the options (or lack of) I\'m passing to `yardoc`. However since rubydoc is doing the same we probably need to exclude all examples globally.'
2792,'','[GH-1390] Remove redundant calls to Fog.credentials\nIf you use the supported means to create services such as:\r\n\r\n    Fog::Service.new(:provider => "Example")\r\n\r\nIt already loads the contents of `~/.fog` and filters the values based\r\non if they are recognised or required.\r\n\r\nThat means in a number of services that are initialising based on\r\n`options` or a value from `Fog.credentials` both are the same.\r\n\r\nThe `options` should have been loaded and merged from credentials in the\r\nservice "builder".'
2791,'',"Removed unicode NFC normalization of S3 object keys.\nS3 does not require normalization of S3 object keys and uses strict byte\r\ncomparison of object keys, not equivalent unicode character comparisons,\r\nto store and retrieve objects. This means that storing and retrieving objects\r\nwith fog would cause the objects to be inaccessible by other libraries,\r\nlanguages, and systems that don't normalize object keys. Given that there is\r\nno benefit to normalization, except perhaps reducing byte count of object\r\nkeys, it ought to be removed.\r\n\r\nThis resolves issue #2790."
2790,'','Fog should not unicode normalize S3 object keys\nDoing unicode normalization can and does change the bytes used for an S3 key:\r\n\r\n```ruby\r\n# foo.rb\r\nrequire \'rubygems\'\r\nrequire \'unf\'\r\n\r\nbytes1 = [101, 204, 129]\r\nbytes2 = [195, 169]\r\n\r\nputs "bytes1: #{bytes1.inspect}"\r\nputs "bytes2: #{bytes2.inspect}"\r\n\r\nchar1 = bytes1.pack(\'c*\')\r\nchar2 = bytes2.pack(\'c*\')\r\n\r\nputs "char1: #{char1}"\r\nputs "char2: #{char2}"\r\n\r\nnormalized1 = ::UNF::Normalizer.normalize(char1, :nfc)\r\nnormalized2 = ::UNF::Normalizer.normalize(char2, :nfc)\r\n\r\nputs "normalized1: #{normalized1.inspect}"\r\nputs "normalized2: #{normalized2.inspect}"\r\n\r\nbytes1_after = normalized1.bytes.to_a\r\nbytes2_after = normalized2.bytes.to_a\r\n\r\nputs "bytes1_after: #{bytes1_after.inspect}"\r\nputs "bytes2_after: #{bytes2_after.inspect}"\r\n```\r\n\r\n```plain\r\n$ ruby foo.rb \r\nbytes1: [101, 204, 129]\r\nbytes2: [195, 169]\r\nchar1: Ã©\r\nchar2: Ã©\r\nnormalized1: "\\303\\251"\r\nnormalized2: "\\303\\251"\r\nbytes1_after: [195, 169]\r\nbytes2_after: [195, 169]\r\n```\r\n\r\n[S3 does not require normalization](http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html) ("The name for a key is a sequence of Unicode characters whose UTF-8 encoding is at most 1024 bytes long.") and it\'s [not clear from the original pull request](https://github.com/fog/fog/pull/2110) why normalization is being done or why it is desirable. It\'s a bit surprising, in fact, since the official ruby aws sdk does not normalize the key and just uses the encoding you give it (in both v1 and the beta v2). As you\'ll see in a moment, it\'s even more surprising in practice.\r\n\r\nAn example in fog showing that normalization breaks things:\r\n\r\n```ruby\r\nrequire \'fog\'\r\nrequire \'stringio\'\r\nAWS_ACCESS_KEY_ID = "foo"\r\nAWS_SECRET_ACCESS_KEY = "bar"\r\nBUCKET = "my_bucket"\r\n\r\ns3 = Fog::Storage::AWS.new(aws_access_key_id: AWS_ACCESS_KEY_ID, aws_secret_access_key: AWS_SECRET_ACCESS_KEY)\r\n\r\nfirst_key = "my_special_ke\\314\\201y"\r\nsecond_key = "my_special_k\\303\\251y"\r\n\r\nputs first_key.inspect\r\n# => "my_special_kÃ©y"\r\nputs second_key.inspect\r\n# => "my_special_kÃ©y"\r\n\r\ns3.put_object(BUCKET, first_key, StringIO.new("first"))\r\ns3.put_object(BUCKET, second_key, StringIO.new("second"))\r\n\r\nputs s3.get_object(BUCKET, first_key).body.inspect\r\n# => "second"\r\nputs s3.get_object(BUCKET, second_key).body.inspect\r\n# => "second"\r\nputs s3.get_bucket(BUCKET, :prefix => "my_special_k").body["Contents"].size\r\n# => 1\r\n```\r\n\r\nThere is only one object because of the normalized object key.\r\n\r\nAn example in v2 of the aws sdk showing that not normalizing preserves the correct behavior:\r\n\r\n```ruby\r\nrequire \'rubygems\'\r\nrequire \'aws-sdk-core\'\r\nAWS_ACCESS_KEY_ID = "foo"\r\nAWS_SECRET_ACCESS_KEY = "bar"\r\nREGION = "us-east-1"\r\nBUCKET = "my_bucket"\r\n\r\nAws.config = {access_key_id: AWS_ACCESS_KEY_ID, secret_access_key: AWS_SECRET_ACCESS_KEY, region: REGION}\r\ns3 = Aws.s3\r\n\r\nfirst_key = "my_special_ke\\314\\201y"\r\nsecond_key = "my_special_k\\303\\251y"\r\n\r\nputs first_key.inspect\r\n# => "my_special_kÃ©y"\r\nputs second_key.inspect\r\n# => "my_special_kÃ©y"\r\n\r\ns3.put_object(bucket: BUCKET, key: first_key, body: "first")\r\ns3.put_object(bucket: BUCKET, key: second_key, body: "second")\r\n\r\nputs s3.get_object(bucket: BUCKET, key: first_key).body.inspect\r\n# => "first"\r\nputs s3.get_object(bucket: BUCKET, key: second_key).body.inspect\r\n# => "second"\r\n```\r\n\r\nThis behavior becomes particularly problematic when you have systems sharing object keys. If one normalizes and the other doesn\'t, they won\'t be able to see the same objects on S3. In our case we ran into this in our API service that allows S3 inputs and outputs for video transcoding.'
2789,'','Adds Gemfile for Travis to test against edge versions of dependencies\nAfter a few false starts this adds a new run to Travis that tests `fog` against the `fog-core` and `fog-json` git repos.\r\n\r\nIt also uses the latest version of the code in `providers` which is just `fog-brightbox` at the moment to catch anything broken there.'
2788,'','Correctly index SecurityGroupId parameter\nrun_instances does not follow the spec when it comes to formatting the input parameters.\r\n\r\nIn particular, if we pass an array as \'SecurityGroupId\' inside the \'NetworkInterfaces\' array, it does not get parameterized as "NetworkInterface.%d.SecurityGroupId.%d\'.\r\n\r\n\r\nSpec: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-RunInstances.html'
2787,'','[Vsphere] Isolate helper from core\n`Fog.class_from_string` was moved to core but is only used by the\r\nVSphere provider with very little capacity for reuse.\r\n\r\nThis moves it to the `Fog::Vsphere` namespace so we can delete it from\r\ncore.'
2786,'','Lock rake to 10.1 for Ruby 1.8.7\nRake has gone 1.9.3+ from 10.2 onwards so the Gemfile for 1.8.7\r\nspecifies this new constraint.'
2784,'','[core] Convert changelog to markdown\nThis pull request does the following:\r\n\r\n* Converts `changelog.txt` to `CHANGELOG.md`\r\n* Updates `rake changelog` to generate changelog in markdown\r\n* Adds `rake github_release` which will create a [github release object](https://github.com/fog/fog/releases) for each release in the changelog (if necessary).\r\n\r\nThe release information will be accessible via [atom feed](https://github.com/fog/fog/releases.atom)\r\n\r\nThe `github_release` task treats the `CHANGELOG.md` as the source of truth for release information. The task compares the `CHANGELOG.md` to current github release objects and in the process creates any missing github release objects. \r\n\r\nI have updated the `RELEASE.md` file to indicate that this task should be executed as the last step of the release process, however, it can be executed at any time independently of the release. '
2782,'','fixed examples for HPC access\nupdated the HP examples to reflect actual usage'
2781,'',"[openstack] Nonstandard ports in generated temp_urls.\nRespect a nonstandard Swift port when generating a temp_url, as reported in #2723. I don't have a good way of testing OpenStack changes, however, or even running the tests :unamused: \r\n\r\n(I trimmed some trailing whitespace while I was at it :lipstick: )"
2780,'',"Remove deprecated `host` Excon option from dynamodb\nThis addresses an excon warning:\r\n\r\n```\r\n[excon][WARNING] Invalid Excon request keys: :host\r\n/Users/pedro/.rvm/gems/ruby-1.9.3-p448/gems/excon-0.32.1/lib/excon/connection.rb:389:in `validate_params'\r\n/Users/pedro/.rvm/gems/ruby-1.9.3-p448/gems/excon-0.32.1/lib/excon/connection.rb:225:in `request'\r\n```\r\n\r\nThanks!"
2779,'','[core] Remove providers/ directory from core fog gem\nThe fog gem currently contains the provider(s) that were split into their own gems.'
2778,'','Issues with HP Cloud Documentation Examples\nUsing Fog 1.20.0\r\n\r\n* List server addresses \r\n\r\nThe new call seems to be conn.list_addresses according to the docs. Example 1 under "Request Address Operations" says I can use response.body[\'addresses\'], but response.body[\'floating_ips\'] comes back to me instead. \r\n\r\n* Return floating IP after get_address \r\nresponse = conn.get_address("<address_id>") # get the address, works \r\nresponse.body[\'address\'][\'ip\'] #doesn\'t work, your return message has changed, new method should be: response.body[\'floating_ip\'][\'ip\'] \r\n\r\nSame feedback; the address key does not exist but the floating_ip key does. \r\n2.0.0-p353 :029 > response.body[\'floating_ip\'][\'ip\'] \r\n=> "15.126.221.231" \r\n2.0.0-p353 :030 > response.body[\'address\'][\'ip\'] \r\nNoMethodError: undefined method `[]\' for nil:NilClass \r\nfrom (irb):30 \r\nfrom /home/watkinsv/.rvm/rubies/ruby-2.0.0-p353/bin/irb:12:in `<main>\' \r\n2.0.0-p353 :031 > \r\n\r\n\r\n* Creating a basic connection with Fog::Networking \r\n\r\nThe example at https://github.com/fog/fog/blob/master/lib/fog/hp/examples/networking.md#connecting-to-the-service does not get me connected to the networking service. \r\n\r\n2.0.0-p353 :044 > conn = Fog::HP::Networking.new( \r\n2.0.0-p353 :045 > :hp_access_key => "filtered", \r\n2.0.0-p353 :046 > :hp_secret_key => "filtered", \r\n2.0.0-p353 :047 > :hp_auth_uri => "https://region-a.geo-1.identity.hpcloudsvc.com:35357/v2.0/", \r\n2.0.0-p353 :048 > :hp_tenant_id => "10997079450630", \r\n2.0.0-p353 :049 > :hp_avl_zone => "region-b.geo-1", \r\n2.0.0-p353 :050 > ) \r\nNameError: uninitialized constant Fog::HP::Networking \r\nfrom (irb):44 \r\nfrom /home/watkinsv/.rvm/rubies/ruby-2.0.0-p353/bin/irb:12:in `<main>\' \r\n2.0.0-p353 :051 > \r\n\r\n\r\n\r\nRegarding the examples for HP Cloud Compute Service v13.5 found at https://github.com/fog/fog/blob/master/lib/fog/hp/examples/compute_v2.md#request-address-operations, some of the examples there are also incorrect. \r\n\r\n* List all available floating IP addresses fails: \r\n\r\n2.0.0-p353 :031 > responsev2 = conn_v2.list_server_addresses \r\nArgumentError: wrong number of arguments (0 for 1) \r\nfrom /home/watkinsv/.rvm/gems/ruby-2.0.0-p353/gems/fog-1.20.0/lib/fog/hp/requests/compute_v2/list_server_addresses.rb:16:in `list_server_addresses\' \r\nfrom (irb):31 \r\nfrom /home/watkinsv/.rvm/rubies/ruby-2.0.0-p353/bin/irb:12:in `<main>\' \r\n2.0.0-p353 :032 > \r\n\r\n\r\n\r\n* List addresses by network for a server fails: \r\n\r\n2.0.0-p353 :035 > conn_v2.list_server_addresses_by_network(\'027f0106-0529-4dc1-9619-4d9800678ad7\') \r\nArgumentError: wrong number of arguments (1 for 2) \r\nfrom /home/watkinsv/.rvm/gems/ruby-2.0.0-p353/gems/fog-1.20.0/lib/fog/hp/requests/compute_v2/list_server_addresses_by_network.rb:18:in `list_server_addresses_by_network\' \r\nfrom (irb):35 \r\nfrom /home/watkinsv/.rvm/rubies/ruby-2.0.0-p353/bin/irb:12:in `<main>\' \r\n2.0.0-p353 :036 >'
2777,'','OpenStack Authenticate only Auth URLs with a trailing slash\nWhen providing credentials such as:\r\n\r\n```\r\ncompute = Fog::Compute.new(\r\n  :provider => :openstack, \r\n  :openstack_api_key  => "xxx",\r\n  :openstack_username => "user",\r\n  :openstack_auth_url => "https://auth.example.de:5000/v2.0",  \r\n  :openstack_tenant   => "testing")\r\n```\r\n\r\nThis is what a user received:\r\n\r\n````\r\n/Users/jfischer/.rvm/rubies/ruby-2.0.0-p195/lib/ruby/2.0.0/uri/common.rb:176:in `split\': bad URI(is not URI?):  (URI::InvalidURIError)\r\n\tfrom /Users/jfischer/.rvm/rubies/ruby-2.0.0-p195/lib/ruby/2.0.0/uri/common.rb:211:in `parse\'\r\n\tfrom /Users/jfischer/.rvm/rubies/ruby-2.0.0-p195/lib/ruby/2.0.0/uri/common.rb:747:in `parse\'\r\n\tfrom /Users/jfischer/.rvm/gems/ruby-2.0.0-p195/gems/fog-1.15.0/lib/fog/openstack/compute.rb:409:in `authenticate\'\r\n\tfrom /Users/jfischer/.rvm/gems/ruby-2.0.0-p195/gems/fog-1.15.0/lib/fog/openstack/compute.rb:316:in `initialize\'\r\n\tfrom /Users/jfischer/.rvm/gems/ruby-2.0.0-p195/gems/fog-1.15.0/lib/fog/core/service.rb:68:in `new\'\r\n\tfrom /Users/jfischer/.rvm/gems/ruby-2.0.0-p195/gems/fog-1.15.0/lib/fog/core/service.rb:68:in `new\'\r\n\tfrom /Users/jfischer/.rvm/gems/ruby-2.0.0-p195/gems/fog-1.15.0/lib/fog/compute.rb:44:in `new\'\r\n````\r\n\r\nActually all the user has to fix is adding a trailing slash to the auth URL:\r\n\r\n```\r\ncompute = Fog::Compute.new(\r\n  :provider => :openstack, \r\n  :openstack_api_key  => "xxx",\r\n  :openstack_username => "user",\r\n  :openstack_auth_url => "https://auth.example.de:5000/v2.0/",  \r\n  :openstack_tenant   => "testing")\r\n```\r\n\r\nThe error messages is currently absolutely misleading.\r\nTherefore either the URL should also be recognized without a trailing slash or the error message should tell the user to add the slash.\r\n\r\nThis happens here:\r\n\r\nlib/fog/openstack/compute.rb\r\n\r\nLine: 393\r\n\r\n```\r\nif @openstack_auth_uri.path =~ /\\/v2.0\\//\r\n```\r\n\r\nBest\r\nJulian'
2776,'','Getting some difficulty with fog on amazon apis\nI am new with amazon and fog library, so i have been trying this code,  actually have one instance in my amazon account, but the code doesn\'t give anything with that.\r\n```\r\nrequire \'fog\' \r\naws_credentials = {\r\n  :aws_access_key_id => "ACCESS ID"\r\n  :aws_secret_access_key "SECRET ID"\r\n}\r\nconn2 = Fog::Compute.new(aws_credentials.merge(:provider => \'AWS\'))\r\nconn2.servers.all.each do |i|\r\n  puts i.id\r\nend\r\n```\r\n\r\nIs there any wrong with this stuff?'
2775,'','Rage4 udp limit support\nRage4 has added a new option to their api. This is the support for this new option.'
2774,'','Add a private IP by default to the openstack server mock\n'
2773,'','[openstack|storage] Fix extracted request\n`Fog::OpenStack::Storage#get_object_http_url` was extracted in\r\nhttps://github.com/fog/fog/commit/8012318d but did not get the\r\nmodules/classes to put it back into the structure.\r\n\r\nSo it had become a private method and failing some tests.'
2772,'',"[AWS][Local] Get public url of a folder without making API calls\nIs there a way to get a prefixed url for a folder without having to check about folder acl in aws?\r\n\r\nI also see that Directory.public_url in the Local storage returns nil, isn't possible to use the same ::File.join as in the File model just without the file key?"
2771,'','[OpenStack][Swift] can not upload large file\nI\'m using OpenStack Swift with fog and I want to upload large file (over 5GB) to swift storage. I checked this url.\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/openstack/docs/storage.md#upload-large-files\r\n\r\nWhen I upload 6GB file with this code to swift, I got these error messages.\r\n\r\n<pre>\r\n/home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/expects.rb:6:in `response_call\': Expected(201) <=> Actual(413 Request Entity Too Large) (Excon::Errors::RequestEntityTooLarge)\r\n  response => #<Excon::Response:0x007f8a1c4526c8 @data={:body=>"<html><h1>Request Entity Too Large</h1><p>The body of your request was too large for this server.</p></html>", :headers=>{"Content-Length"=>"108", "Content-Type"=>"text/html; charset=UTF-8", "X-Trans-Id"=>"tx5d6731c1c74549b3926fa-005327a909", "Date"=>"Tue, 18 Mar 2014 02:01:45 GMT"}, :status=>413, :remote_ip=>"10.200.9.112"}, @body="<html><h1>Request Entity Too Large</h1><p>The body of your request was too large for this server.</p></html>", @headers={"Content-Length"=>"108", "Content-Type"=>"text/html; charset=UTF-8", "X-Trans-Id"=>"tx5d6731c1c74549b3926fa-005327a909", "Date"=>"Tue, 18 Mar 2014 02:01:45 GMT"}, @status=413, @remote_ip="10.200.9.112">\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/response_parser.rb:26:in `response_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:398:in `response\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:268:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:288:in `rescue in request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:225:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:288:in `rescue in request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:225:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:288:in `rescue in request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:225:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/fog-1.20.0/lib/fog/core/connection.rb:56:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/fog-1.20.0/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/fog-1.20.0/lib/fog/openstack/storage.rb:151:in `request\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/fog-1.20.0/lib/fog/openstack/requests/storage/put_object.rb:37:in `put_object\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/fog-1.20.0/lib/fog/openstack/models/storage/file.rb:95:in `save\'\r\n        from /home/thirai/.rbenv/versions/2.0.0-p247/lib/ruby/gems/2.0.0/gems/fog-1.20.0/lib/fog/core/collection.rb:51:in `create\'\r\n        from fog_list.rb:34:in `<main>\'\r\n</pre>\r\n\r\nDoes anyone can upload large file to swift with fog ?\r\nTnanks.'
2770,'','Fixes class of error\nFixes a typo in my previous PR.  EOFError is a child of Excon::Errors::SocketError.'
2769,'',"[OpenStack] Host fog-openstack-tng under fog org\n@geemus HP and Rackspace are partnering on a Fog::OpenStack rewrite (Fog::OpenStackCommon) per #2682. Would you be willing to host under fog org but give @mwhagedorn, @krames, @wchrisjohnson, and I commit privs?\r\n\r\nThe problem right now is the project isn't at all visible to fog folks because of its [current location](https://github.com/fog-openstack-tng/fog-openstack-tng)."
2768,'','[google|compute] Change projects we search for images in.\nThis removes Google (which has no valid v1 images) and adds rhel-cloud and suse-cloud. It also wraps the lookups in a catch block for not-found exceptions because not everyone has access to everything.\r\n\r\nThis fixes https://github.com/fog/fog/issues/2743\r\n\r\nThis mimics the gcutil code, and is sadly the way Google wants us to do this check.\r\n\r\n@geemus and @kbockmanrs PTAL'
2767,'','[ovirt] fixed interfaces and volume list.\nThe return list is now always fog object and not rbovirt objects.'
2766,'','support pagination of results in AWS Data Pipeline query_objects\n@kbarrette - This is needed to fix pipely to render the instance graphs for pipelines with more than 100 historical instances.  Typically, this happens after a pipeline has run two or three times.'
2765,'','AWS network interfaces model set options\nCurrently the network interfaces model will not correctly assign IP addresses and security groups on creation of an interface; this change solves that.'
2764,'',"Tweak gemspec to be less specific for certain gems\nLessens the restrictions on fog-core and google-api-client. Trying to slowly remove the warnings you get when you run `rake build` such as:\r\n\r\n```\r\nWARNING:  pessimistic dependency on shindo (~> 0.3.4, development) may be overly strict\r\n  if shindo is semantically versioned, use:\r\n    add_development_dependency 'shindo', '~> 0.3', '>= 0.3.4'\r\n```\r\n\r\nbundle update diff:\r\n```diff\r\n$ diff -u old Gemfile.lock\r\n--- old\t2014-03-14 15:11:59.000000000 -0700\r\n+++ Gemfile.lock\t2014-03-15 03:45:13.000000000 -0700\r\n@@ -37,10 +37,10 @@\r\n       term-ansicolor\r\n       thor\r\n     docile (1.1.3)\r\n-    excon (0.31.0)\r\n+    excon (0.32.1)\r\n     extlib (0.9.16)\r\n-    faraday (0.8.9)\r\n-      multipart-post (~> 1.2.0)\r\n+    faraday (0.9.0)\r\n+      multipart-post (>= 1.2, < 3)\r\n     fast-stemmer (1.0.2)\r\n     ffi (1.9.3)\r\n     fission (0.5.0)\r\n@@ -48,9 +48,9 @@\r\n     fog-brightbox (0.0.1)\r\n       fog-core\r\n       fog-json\r\n-    fog-core (1.21.0)\r\n+    fog-core (1.21.1)\r\n       builder\r\n-      excon (~> 0.31.0)\r\n+      excon (~> 0.32)\r\n       formatador (~> 0.2.0)\r\n       mime-types\r\n       net-scp (~> 1.1)\r\n@@ -58,15 +58,16 @@\r\n     fog-json (1.0.0)\r\n       multi_json (~> 1.0)\r\n     formatador (0.2.4)\r\n-    google-api-client (0.6.4)\r\n+    google-api-client (0.7.1)\r\n       addressable (>= 2.3.2)\r\n       autoparse (>= 0.3.3)\r\n       extlib (>= 0.9.15)\r\n-      faraday (~> 0.8.4)\r\n+      faraday (>= 0.9.0)\r\n       jwt (>= 0.1.5)\r\n       launchy (>= 2.1.1)\r\n       multi_json (>= 1.0.0)\r\n-      signet (~> 0.4.5)\r\n+      retriable (>= 1.4)\r\n+      signet (>= 0.5.0)\r\n       uuidtools (>= 2.1.0)\r\n     highline (1.6.21)\r\n     jekyll (1.4.3)\r\n@@ -93,9 +94,9 @@\r\n     method_source (0.8.2)\r\n     mime-types (2.2)\r\n     mini_portile (0.5.2)\r\n-    minitest (5.3.0)\r\n+    minitest (5.3.1)\r\n     multi_json (1.9.0)\r\n-    multipart-post (1.2.0)\r\n+    multipart-post (2.0.0)\r\n     net-scp (1.1.2)\r\n       net-ssh (>= 2.6.5)\r\n     net-ssh (2.8.0)\r\n@@ -127,12 +128,13 @@\r\n     redcarpet (2.3.0)\r\n     rest-client (1.6.7)\r\n       mime-types (>= 1.16)\r\n+    retriable (1.4.1)\r\n     safe_yaml (0.9.7)\r\n     shindo (0.3.8)\r\n       formatador (>= 0.1.1)\r\n-    signet (0.4.5)\r\n+    signet (0.5.0)\r\n       addressable (>= 2.2.3)\r\n-      faraday (~> 0.8.1)\r\n+      faraday (>= 0.9.0.rc5)\r\n       jwt (>= 0.1.5)\r\n       multi_json (>= 1.0.0)\r\n     simplecov (0.8.2)\r\n```"
2763,'',"[google|compute] Allow for different auth types.\nThis fixes https://github.com/fog/fog/issues/2361 by allowing the user to set an option of :google_client when initializing fog to an authorized API client. \r\n\r\nAlso puts begin/rescue blocks in examples so erroring examples don't stop the entire flow of testing.\r\n\r\n@acasajus and/or @geemus mind taking a look?"
2762,'',"Fix a typo in error message that could cause problems for cut-n-pasters\nIf someone cut and pastes this knife.rb setting, they will get an error because 'rackspace' is misspelled. "
2760,'',"attempt to authorize ELB security group always fails\nIf ELB is used, in order to allow traffic to EC2 instances that it load balances, the following ingress security rule is needed:\r\n\r\nGroup: amazon-elb/amazon-elb-sg\r\nPort: (whatever port is listened on)\r\n\r\nAuthorizing this group results in the error message:\r\nFog::Compute::AWS::NotFound: Unable to find group 'amazon-elb/amazon-elb-sg'\r\n \r\nMore documentation for how it's handled in AWS is available here:\r\nhttp://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/using-elb-security-groups.html\r\n\r\n"
2758,'','[google|compute] fix mismatched variable names in disk.create_snapshot\nFixes mismatched variable names for disks.create_snapshot.\r\n\r\nVery minor update for you @icco'
2757,'',"[dns|aws] Return empty set on route53 if no records match on mock\nOn route53 AWS dns provider, when getting records by type a exception is thrown if no record matches. This behavior is different as the real one, that returns *nil* if no record matches instead of raising an exception.\r\n\r\nThis patch handles that case and creates an empty array in this case.\r\n\r\n```ruby\r\nrequire 'fog/aws/dns'\r\nFog.mock!\r\naws = { \r\n  :provider => 'AWS',\r\n  :aws_access_key_id => 'KEY_ID',\r\n  :aws_secret_access_key => 'SECRET_KEY'\r\n} \r\n\r\n\r\nzone = Fog::DNS.new(aws).zones.create(:domain => 'wadus')\r\nzone.records.get('wadus', 'AAAA')\r\n\r\nNoMethodError: undefined method `values' for nil:NilClass\r\nfrom gems/fog-1.20.0/lib/fog/aws/requests/dns/list_resource_record_sets.rb:79:in `list_resource_record_sets'\r\n```\r\n\r\nReal behaviour:\r\n\r\n```\r\nzone.records.get('wadus', 'AAAA')                                                                                               \r\n=> nil\r\n```\r\n\r\nPatched:\r\n\r\n````\r\nzone.records.get('wadus', 'AAAA')\r\n=> nil\r\n```"
2756,'','[rackspace|compute_v2] removing hard coded timeout in servers\nThis PR removes a hard coded pull request that was added to help reduce timeout issues in knife-rackspace. See this [thread](https://groups.google.com/forum/?fromgroups=#!topic/ruby-fog/vPRJYiQzq_A) for more information.'
2755,'','Minitest picks up tests in provider modules\nThis expands the pattern we match tests to run under minitest.\r\n\r\nThis will run anything under `test` or `providers/*/test` so includes tests written by providers.'
2754,'','[google|compute] Allow seting custom application/version for requests\n@icco - perhaps this would be welcome?'
2753,'',"[DigitalOcean] Skip consistently timing out tests\nThe server tests in digital ocean have been frequently timing out.\r\n\r\n* https://travis-ci.org/fog/fog/jobs/20605301#L1030\r\n* https://travis-ci.org/fog/fog/jobs/19765753#L1233\r\n...and many more\r\n\r\nEach timeout run wastes Travis resources and the time of the people who\r\nhave to check why their unrelated changes are failed.\r\n\r\nWe've even become so complacent about it, standard practice is to just\r\ncomment and merge.\r\n\r\nSo I'm disabling the tests until someone fixes it or we replace the\r\nserver tests with a cleaner approach, whichever comes first."
2752,'tokengeek','[Brightbox] Updates for gem/module\nAdds support file and implements minitest "hello world"'
2751,'','attempt at resolving fog issue# 2748\n@geemus please confirm this looks sane to you :)'
2749,'',"Adding S3 snapshot location for elasticache\nYou can now add a amazon resource location for a redis snapshot when creating an elasticache redis cluster.\r\n\r\nI'm not super familiar with all of Fog's internals yet so let me know if I missed a location where the attribute should be added."
2748,'',"AWS returns RequestLimitExceeded when using servers.create of >15 instances within a 1-2 second period (with 5+ tags per instance), but instances are created.\nDid some digging, turns out the def save within models/compute/server.rb creates the instance using run_instances() but then also does a loop over the tags list and runs create_tags() for each tag. I had about 7 tags applied using :tags within servers.create, which means that since these are not applied as an aggregate API call (which AWS supports according to the docs), I was sending them approx 15+ RunInstances calls, plus 15+ * 7~ (105~) CreateTags calls, which caused the RequestLimitExceeded to kick in. The thing that made me fishy here, is in almost every scenario, the instances were actually created, and in some scenarios 3-4~ tags would be applied to them.\r\n\r\nObviously in an ideal world, we would have this as an atomic operation (all succeed or all fail), but since it's separate API calls, we can't do that.\r\n\r\nI do think to alleviate this issue though, changing the below logic in models/compute/servers.rb to batch the tags into a single CreateTags call would make sense:\r\n\r\n```\r\n198           if tags = self.tags\r\n199             # expect eventual consistency\r\n200             Fog.wait_for { self.reload rescue nil }\r\n201             for key, value in (self.tags = tags)\r\n202               service.tags.create(\r\n203                 :key          => key,\r\n204                 :resource_id  => self.identity,\r\n205                 :value        => value\r\n206               )\r\n207             end\r\n208           end\r\n```\r\n\r\nThis will require changes to models/compute/tag*.rb as well as the create_tags method upstream from it I believe to accept batching."
2747,'','enhanced attributes for sakuracloud volume archive\nincluded `SizeMB` and `Plan`\r\n'
2746,'','Add vcloud bad content error\nThe Vcloud API responds to certain requests to modify VMs made from an unauthorized network with a simple termination of the connection, rather than an HTTP response.  Since the underlying cause is difficult to determine from the low-level Excon error which it raises, this change introduces a `MalformedResponse` error which may be caught and appropriately handled.'
2745,'',"[google] Don't swallow google errors in images.get\nCatch and raise only Fog::Errors::NotFound"
2744,'','VM rename isn\'t persistant\nRenaming a VM doesn\'t appear to work/persist:\r\n\r\nirb(main):085:0* vm\r\n=>       <Fog::Compute::VcloudDirector::Vm\r\n        id="vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\n        vapp_id="vapp-56ab1743-d41e-42c3-8bad-8d1a958dc119",\r\n        vapp_name="testbox",\r\n        name="centos65x64",\r\n        type="application/vnd.vmware.vcloud.vm+xml",\r\n        href="https://myvdc.example.com/api/vApp/vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\n        status="off",\r\n        operating_system="Red Hat Enterprise Linux 6 (64-bit)",\r\n        ip_address="",\r\n        cpu=2,\r\n        memory=2048,\r\n        hard_disks=[{"Hard disk 1"=>10240}]\r\n      >\r\n\r\nEditing it just as you would for cpu or memory changes it but it doesn\'t remain changed after a reload.\r\n\r\nirb(main):105:0* vm.name = "node1"\r\n=> "node1"\r\n\r\nirb(main):085:0* vm\r\n=>       <Fog::Compute::VcloudDirector::Vm\r\n        id="vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\n        vapp_id="vapp-56ab1743-d41e-42c3-8bad-8d1a958dc119",\r\n        vapp_name="testbox",\r\n        name="node1",\r\n        type="application/vnd.vmware.vcloud.vm+xml",\r\n        href="https://myvdc.example.com/api/vApp/vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\n        status="off",\r\n        operating_system="Red Hat Enterprise Linux 6 (64-bit)",\r\n        ip_address="",\r\n        cpu=2,\r\n        memory=2048,\r\n        hard_disks=[{"Hard disk 1"=>10240}]\r\n      >\r\n\r\nirb(main):085:0* vm.reload\r\n=>       <Fog::Compute::VcloudDirector::Vm\r\n        id="vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\n        vapp_id="vapp-56ab1743-d41e-42c3-8bad-8d1a958dc119",\r\n        vapp_name="testbox",\r\n        name="centos65x64",\r\n        type="application/vnd.vmware.vcloud.vm+xml",\r\n        href="https://myvdc.example.com/api/vApp/vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\n        status="off",\r\n        operating_system="Red Hat Enterprise Linux 6 (64-bit)",\r\n        ip_address="",\r\n        cpu=2,\r\n        memory=2048,\r\n        hard_disks=[{"Hard disk 1"=>10240}]\r\n      >'
2743,'icco',"[google|compute] Determine a way to search private (premium) projects\nSee PR: https://github.com/fog/fog/pull/2534#issuecomment-32297119\r\n\r\nPlease determine a way to be able to add premium or private projects (i.e. rhel-cloud) to the list of projects searched for images.\r\n\r\nThis currently requires us to keep a separate fork of fog and keep pulling in our commit to add rhel-cloud to the project search list to search for images. It seems that when this commit was pulled into fog, it caused problems for others because they don't have access to the project since it is a premium project.\r\n\r\nSee PR link for details from @icco and @geemus "
2742,'',"Add Ironic resource support in Openstack provider \nThere is no support for Ironic in Openstack provider. It is supposed to be a part of IceHouse release. I am planning to add Ironic support in Fuel   https://wiki.openstack.org/wiki/Fuel and I need ruby based binding. I've already written code but not tests yet."
2741,'tokengeek','Brightbox test updates\nUpdates to not rename users and accounts during test runs.\r\n\r\nFixes a timing issue now SQL instance snapshots have to be complete before source SQL instance can be deleted.'
2739,'','Allow dnsimple authentication via API tokens\nExactly as the subject states!'
2738,'','[google|compute] disk model: Add auto_delete option to get_as_boot_disk\nAdd the ability to automatically delete disk upon instance termination. Defaults to false to match GCE utils. Only can be applied to disks created before instance creation.'
2737,'','[google|compute] disk model: get_object fix for Ruby 1.8\nFix for Ruby 1.8. The .select{} returns an array in Ruby 1.8 instead of a Hash.'
2736,'','SystemStackError fog 1.20.0 -> rbvmomi 1.6\nI am using fog 1.20.0 with rbvmomi 1.6 and when I attempt a connection to my VCenter 5.1 server I am receiving the following error:\r\n\r\n/usr/local/rvm/gems/ruby-1.9.3-p545/gems/fog-1.20.0/lib/fog/core/collection.rb:80: stack level too deep (SystemStackError).  I just wanted to know if this was something that was planning on being fixed or should I try using something else.\r\n\r\nHere is the code listed on that line:\r\ndef inspect\r\n      Thread.current[:formatador] ||= Formatador.new\r\n      data = "#{Thread.current[:formatador].indentation}<#{self.class.name}\\n"\r\n      Thread.current[:formatador].indent do\r\n        unless self.class.attributes.empty?\r\n          data << "#{Thread.current[:formatador].indentation}"\r\n          data << self.class.attributes.map {|attribute| "#{attribute}=#{send(attribute).inspect}"}.join(",\\n#{Thread.current[:formatador].indentation}")\r\n          data << "\\n"\r\n        end\r\n        data << "#{Thread.current[:formatador].indentation}["\r\n        unless self.empty?\r\n          data << "\\n"\r\n          Thread.current[:formatador].indent do\r\n            data << self.map {|member| member.inspect}.join(",\\n")\r\n            data << "\\n"\r\n          end\r\n          data << Thread.current[:formatador].indentation\r\n        end\r\n        data << "]\\n"\r\n      end\r\n      data << "#{Thread.current[:formatador].indentation}>"\r\n      data\r\n\r\n\r\nThanks!\r\n'
2735,'','Add ability to clone complete volumes to a new path\nThere\'s a clone() function for volumes already, but that seems to only clone the Fog metadata to a new blank volume. I need to clone the actual disk, so this patch adds clone_volume to accomplish that\r\n\r\nAlso, my libvirt hypervisor seems to report capacities/allocations as "10" instead of "10G", meaing the unit detection crashes - I\'ve added a separate commit for that,'
2734,'','[ovirt] add support for ca cert\n'
2733,'','ability to supply serviceAccounts on image create\nTakes an array of service accounts, with an email and scopes to add to an\r\ninstance on creation.\r\n\r\nThis will take the form:\r\n```\r\n      :service_accounts => [\r\n          :email => "123845678986@project.gserviceaccount.com",\r\n          :scopes => [\r\n              \'https://www.googleapis.com/auth/devstorage.read_write\'\r\n          ]\r\n      ]\r\n```\r\n\r\nFor more information: https://developers.google.com/compute/docs/authentication#using, or the documentation at: https://developers.google.com/compute/docs/reference/latest/instances'
2732,'',"Fog-Mime / Fog-Json\nTLDR; would a pull request creating `Fog-Mime` like [`Fog-Json`](https://github.com/fog/fog-json) be something worthwhile?\r\n\r\n**Is `mime-types` only in `Fog` for `Fog::Local`? Can't seem to see where else its used?**\r\n\r\n~~Whilst putting together [`MultiSync`](https://github.com/karlfreeman/multi_sync) I became frustrated with the slight variances in MIME type detection which led to me to write [`MultiMime`](https://github.com/karlfreeman/multi_mime) (as you can imagine its heavily inspired by [`MultiJson`](https://github.com/intridea/multi_json)).~~\r\n\r\n~~It appears digging into Fog a bit more that it internally sets the [`content_type`](https://github.com/fog/fog/blob/e1770354c9be10cf863c4f9371d851efc077a462/lib/fog/aws/models/storage/file.rb#L217) on S3 PUT via the [file's `content_type` method](https://github.com/fog/fog/blob/1f12a196e37d0038a5116b7c609e65882a741ee6/lib/fog/local/models/storage/file.rb#L30-L36).~~\r\n\r\n~~If the decision here is that [MIME::Types](https://github.com/halostatue/mime-types) is the best MIME type detection then I could only agree but just like Json there are edge cases where it would be good to offer some flexabiity? Would Fog consider MIME type detection the same as Json and extract it from Fog's core?~~.\r\n\r\nNot applicable as this appears to just be for `Fog::Local` :unamused:."
2731,'','Rackspace monitoring alarm object does not support disabled option\nPer the API documentation alarms support a disabled flag:\r\nhttp://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/service-alarms.html\r\n\r\nHowever, the corresponding Fog object does not appear to support this flag:\r\nhttps://github.com/fog/fog/blob/master/lib/fog/rackspace/models/monitoring/alarm.rb#L9-16'
2730,'','Fix wrong aliases at Fog::Volume::SakuraCloud::Archive\nFix Bug: archives returns nil.\r\n\r\n```\r\n volume.archives\r\n=> [  <Fog::Volume::SakuraCloud::Archive\r\n    id=nil,\r\n    name=nil\r\n  >,\r\n-- snip --\r\n```\r\n\r\nExpect below.\r\n\r\n```\r\n=> [  <Fog::Volume::SakuraCloud::Archive\r\n    id="112500514887",\r\n    name="CentOS 5.10 64bit (åºæ¬ã»ãã)"\r\n  >,\r\n-- snip --\r\n```'
2729,'','Follow DEPRECATION message for sakuracloud\nupdate to `Fog::Core::Connection` from `Fog::Connection`\r\n\r\n```\r\n[fog][DEPRECATION] Fog::XML::Connection is deprecated use Fog::Core::Connection instead\r\n```\r\n'
2728,'','[rackspace|compute_v2] add virtual interface support.\nThis should fix issue #2696'
2727,'','Fog::Compute::AWS::Error -- InUse => Address 192.168.xx.xx is in use.\nWhile trying to create a aws instance with pre defined private ipaddress it fails with\r\n\r\n(Fog::Compute::AWS::Error -- InUse => Address 192.168.xx.xx is in use. -- /usr/lib64/ruby/gems/1.9.1/gems/excon-0.31.0/lib/excon/middlewares/expects.rb:10:in `response_call\')\r\n\r\nTried to find servers with the ipaddress but no servers are attached,\r\n\r\nirb(main):011:0> conn.servers.select { |s| s.private_ip_address == "192.168.xx.xx" }\r\n=>   <Fog::Compute::AWS::Servers\r\n    filters={}\r\n    []\r\n  >\r\n\r\n'
2726,'','Support VPC security group modifictions for RDS\n'
2725,'','[Openstack|Volumes] available? check method\navailable? simply returns whether the volume is being used or its\r\navailable. This is convenient for applications using the Fog API to\r\ncheck if they can use a Volume by calling\r\n\r\n```ruby \r\nopenstack.volumes.select(&:available)\r\n```'
2724,'','question: Can Fog sync between two remote folders\nCan Fog sync between two remote folders?\r\n\r\nlike we do with s3cmd --sync s3://blabla s3://blabla2\r\n\r\n'
2723,'','TempUrl support for OpenStack Swift running on port other than 80/443\nHi all,\r\n\r\nWe have an OpenStack Havana deploymenent with Swift running on Port 8080. Currently this causes problems when getting a tempurl via fog. \r\n\r\nIn "fog/openstack/requests/storage/get_object_https_url.rb": create_temp_url the @port property is not used when returning the temp url. Changing that code to the following works for us (of course one would need to do more tests on this and probably only set the port if it is other than the default port):\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/openstack/requests/storage/get_object_https_url.rb#L58 :\r\n "#{scheme}://#{@host}:#{@port}#{object_path_escaped}?temp_url_sig=#{sig}&temp_url_expires=#{expires}"\r\n\r\n--\r\nThomas\r\n'
2722,'','[Docker] attribute aliases fixed\n'
2721,'','Load connection parameters from file\nIs there any way to do this?  Say, `Fog::Compute.from_file(...)`?'
2720,'','[GH-2706] Update ruby-libvirt dependency to 0.5\nAlso removed guard related to JRuby since the important part is opting\r\ninto lib-virt'
2719,'','Setup logging to write to file\nLooking for a way to set Fog::Logger to the logger of my application.\r\n\r\nIs there a way to pass in a logger object when opening a new connection?\r\n\r\ni.e. `Fog::Compute.new(connection_options.merge(:logger => MyApp::Logger))`'
2717,'','[GH-2630] Bring in Minitest\nThis adds Minitest as a dependency and replaces the old `rake test`\r\nby a Rake test runner.\r\n\r\nTravis now includes the Minitest run before the Shindo run'
2716,'','[aws/security_group] update mock search and revoke\n* update #normalized_permissions to work with GroupId\r\n* fix #describe_security_groups ip-permission.group* filters'
2715,'',"Update to attempt to alleviate confusion between Directory.new and get.\nMay want to have Directory metadata load only on #each instead of #get. If so, we'll want to revisit this later. But this is a stop gap because of issues like #2714 coming up.\r\n\r\n/cc @krames \r\n"
2714,'',"Fog::Storage (Rackspace) directories.get is very slow\nWe use Rackspace as a backup storage. It's been developed through queue file by file, today with increased load it started to eat too much CPU:\r\n\r\n```\r\nrs_object = Fog::Storage.new(:provider => 'Rackspace'...).directories.get('dir')\r\nrs_object.bucket_obj.files.new(...)\r\nrs_object.save\r\n```\r\n\r\nBy some reason it returns redundant details (bytes, count), but all it needs just to upload a file. \r\nWe use instantiation each time, how can we cache it? Maybe persistance connection may help?"
2713,'','[cloudstack] servers.get will now find VM in projects for normal users\nWe have noticed that fog will not find VMs towards Cloudstack 3.0.6 with a normal user account if the VM was deployed in a project.\r\n\r\nThis issue only occurs for non-admin users.\r\n\r\nTo find VMs for a normal user you need to send 2 requests. One without projectid in case the VM is deployed in the default view and one with projectid set to _-1_ to search in all projects.\r\n\r\nThis pull-request proposes a solution where the second request will be made in case the first won\'t return the VM.\r\n\r\nFollowing script was used to test this behaviour:\r\n\r\n```ruby\r\n#!/usr/bin/env ruby\r\nrequire \'fog\'\r\n\r\n# Precreate a vm in default view and specify id here\r\nvm_in_default_view = \'b6c88916-55d6-456b-a81b-b1ed6c478fdb\'\r\n\r\n# Create a vm in a project and specify ids here\r\nproject = \'4e86ebcb-a4ae-4da2-a407-795dab48d409\'\r\nvm_in_project = \'589a324d-ae24-4a61-b5e8-6a24075603b8\'\r\n\r\n# Use other VMs for testing with admin account\r\nvm_in_default_view = \'445ee23f-d0d1-49c5-8f6b-f7e3e1684633\'\r\nproject = \'091ecbe5-f107-46e3-ad6d-62d7b9d6ee98\'\r\nvm_in_project = \'4321de7f-ec47-4332-8144-e0cc3bed6c45\'\r\n\r\n## CASE A\r\nputs\r\nputs "Check if we can find the machine in the default view"\r\nvm = Fog::Compute[:Cloudstack].list_virtual_machines(\'id\' => vm_in_default_view)\r\nif not vm[\'listvirtualmachinesresponse\'].empty?\r\n  puts "[A]: VM in default view found, " + vm[\'listvirtualmachinesresponse\'][\'virtualmachine\'][0][\'name\']\r\nelse\r\n  puts "[A]: VM in default view NOT found"\r\nend\r\n\r\n## CASE B\r\nputs\r\nputs "Check if we can find the machine in the project"\r\nvm = Fog::Compute[:Cloudstack].list_virtual_machines(\'id\' => vm_in_project)\r\nif not vm[\'listvirtualmachinesresponse\'].empty?\r\n  puts "[B]: VM in project found, " + vm[\'listvirtualmachinesresponse\'][\'virtualmachine\'][0][\'name\']\r\nelse\r\n  puts "[B]: VM in project NOT found"\r\nend\r\n\r\n## CASE C\r\nputs\r\nputs "Check if we can find the machine in the project with projectid specified"\r\nvm = Fog::Compute[:Cloudstack].list_virtual_machines(\'id\' => vm_in_project, \'projectid\' => project)\r\nif not vm[\'listvirtualmachinesresponse\'].empty?\r\n  puts "[C]: VM in project found, " + vm[\'listvirtualmachinesresponse\'][\'virtualmachine\'][0][\'name\']\r\nelse\r\n  puts "[C]: VM in project NOT found"\r\nend\r\n\r\n## CASE D\r\nputs\r\nputs "Check if we can find the machine in the project with projectid set to \'-1\'"\r\nvm = Fog::Compute[:Cloudstack].list_virtual_machines(\'id\' => vm_in_project, \'projectid\' => \'-1\')\r\nif not vm[\'listvirtualmachinesresponse\'].empty?\r\n  puts "[D]: VM in project found, " + vm[\'listvirtualmachinesresponse\'][\'virtualmachine\'][0][\'name\']\r\nelse\r\n  puts "[D]: VM in project NOT found"\r\nend\r\n\r\n## CASE E\r\nputs\r\nputs "Check if we can find the machine in the default view with projectid set to \'-1\'"\r\nvm = Fog::Compute[:Cloudstack].list_virtual_machines(\'id\' => vm_in_default_view, \'projectid\' => \'-1\')\r\nif not vm[\'listvirtualmachinesresponse\'].empty?\r\n  puts "[E]: VM in default view found, " + vm[\'listvirtualmachinesresponse\'][\'virtualmachine\'][0][\'name\']\r\nelse\r\n  puts "[E]: VM in default view NOT found"\r\nend\r\n```\r\n\r\n#### Following is the result for admin user\r\n\r\n```bash\r\nCheck if we can find the machine in the default view\r\n[A]: VM in default view found, esup-1247-3\r\n\r\nCheck if we can find the machine in the project\r\n[B]: VM in project found, esup-1247-4\r\n\r\nCheck if we can find the machine in the project with projectid specified\r\n[C]: VM in project found, esup-1247-4\r\n\r\nCheck if we can find the machine in the project with projectid set to \'-1\'\r\n[D]: VM in project found, esup-1247-4\r\n\r\nCheck if we can find the machine in the default view with projectid set to \'-1\'\r\n[E]: VM in default view NOT found\r\n```\r\n\r\n#### Following is the result for a normal user\r\n\r\n```bash\r\nCheck if we can find the machine in the default view\r\n[A]: VM in default view found, esup-1247-1\r\n\r\nCheck if we can find the machine in the project\r\n[B]: VM in project NOT found\r\n\r\nCheck if we can find the machine in the project with projectid specified\r\n[C]: VM in project found, esup-1247-2\r\n\r\nCheck if we can find the machine in the project with projectid set to \'-1\'\r\n[D]: VM in project found, esup-1247-2\r\n\r\nCheck if we can find the machine in the default view with projectid set to \'-1\'\r\n[E]: VM in default view NOT found\r\n```'
2712,'',"[vcloud_director] network model fence_mode and ip_shared attributes\n\r\nUpdates to the network Model now it is based on get_network_complete:\r\n\r\nnetwork.fence_mode returns the FenceMode of the network: 'isolated' or 'natRouted'\r\n\r\nnetwork.is_shared returns the IsShared attribute of the network: 'true' or 'false' (as a String).\r\n\r\nArguably is_shared (and also is_inherited) should return a Ruby boolean - happy to update with more code to correct this.\r\n\r\n\r\n\r\n\r\n"
2711,'',"[core] Deprecate Fog::Connection\nThis reapplies the deprecation warnings that were originally part of\r\n7ee3535 when using Fog::Connection request.\r\n\r\nUnfortunately the Mock world does not exercise any of the code affected\r\nby this change so I missed that I had adjusted the signature of the\r\nmethod.\r\n\r\nIf you pass a parser argument into Fog::Connection you should switch to\r\nusing Fog::XML::SAXParserConnection and pass the parser as the first\r\nargument to `#request`\r\n\r\nIf you don't it is better to use Fog::Core::Connection to get rid of the\r\nbackwards compatibility code and XML dependency.\r\n\r\nThis will make fog VERY NOISY since you'll get output for every request\r\non out of date services."
2710,'',"7ee3535d99 causes login failure in vcloud_director\nRunning the vcloud_director Real tests against fog master gives:\r\n\r\n```\r\n   wrong number of arguments (1 for 2) (ArgumentError)\r\n      /Users/mike/git/alphagov/fog/lib/fog/xml/sax_parser_connection.rb:24:in `request'\r\n      /Users/mike/git/alphagov/fog/lib/fog/vcloud_director/requests/compute/post_login_session.rb:28:in `post_login_session'\r\n      /Users/mike/git/alphagov/fog/lib/fog/vcloud_director/compute.rb:453:in `login'\r\n      /Users/mike/git/alphagov/fog/lib/fog/vcloud_director/compute.rb:351:in `org_name'\r\n      /Users/mike/git/alphagov/fog/tests/vcloud_director/models/compute/helper.rb:22:in `organization'\r\n      /Users/mike/git/alphagov/fog/tests/vcloud_director/models/compute/network_tests.rb:6:in `block in <top (required)>'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo.rb:79:in `instance_eval'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo.rb:79:in `tests'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo.rb:38:in `initialize'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo.rb:13:in `new'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo.rb:13:in `tests'\r\n      /Users/mike/git/alphagov/fog/tests/vcloud_director/models/compute/network_tests.rb:3:in `<top (required)>'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:61:in `load'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:58:in `each'\r\n      /Users/mike/.rbenv/versions/1.9.3-p448/lib/ruby/gems/1.9.1/gems/shindo-0.3.8/lib/shindo/bin.rb:58:in `block in run_in_thread'\r\n```\r\n\r\nThis appears to have been introduced in 7ee3535d99c167aa24ddfc894151c0f1f323edb2\r\n\r\nMock tests are working btw. Looking into why that is the case now."
2709,'','Add Ruby 2.1.1 to testing matrix\n'
2708,'',"[core] Replace Fog::Connection with stable version\nFog::Connection mixed in XML parsing via the `parser` argument which\r\nwasn't much use for the majority of APIs using JSON.\r\n\r\nThis adds the deprecation warning and attempts to update providers to\r\nthe correct version of Connection that they need.\r\n\r\nEither the cleaner `Fog::Core::Connection` or if reliant on the XML\r\nparsing still `Fog::XML::SAXParserConnection`\r\n\r\nThe SAX parser will be moving to `fog/xml` fairly soon."
2707,'',"subnet_id and security_groups_id can't co exists\nThis call for `provider` = `aws`\r\n\r\n    connection.servers.create(\r\n          :availability_zone  => config[:availability_zone],\r\n          :security_group_ids => config[:security_group_ids],\r\n          :tags               => config[:tags],\r\n          :flavor_id          => config[:flavor_id],\r\n          :ebs_optimized      => config[:ebs_optimized],\r\n          :image_id           => config[:image_id],\r\n          :key_name           => config[:aws_ssh_key_id],\r\n          :subnet_id          => config[:subnet_id]\r\n        )\r\n\r\nends with\r\n\r\n    >>>>>> ------Exception-------\r\n    >>>>>> Class: Kitchen::ActionFailed\r\n    >>>>>> Message: InvalidParameterCombination => The parameter groupName   cannot be used with the parameter subnet\r\n\r\n\r\nIf I don't pass `security_group_ids` and pass `subnet_id` it can create the instance with `default` security group\r\n\r\nif I remove `subnet_id` and pass `security_group_ids` it stops with\r\n\r\n     Message: VPCIdNotSpecified => No default VPC for this user\r\n\r\nSo how can I start an instance with `security_group_ids` preferred `vpc`\r\n\r\nThanks!"
2706,'','dependency on outdated version of ruby-libvirt\n[`ruby-libvirt` is currently at 0.5.2](http://libvirt.org/ruby/news.html), but [the `.gemspec` still requires the 0.4.x series](https://github.com/fog/fog/blob/master/fog.gemspec#L69).  This is apparently [blocking `vagrant-libvirt` from working with `ruby-libvirt` 0.5.2](https://github.com/pradels/vagrant-libvirt/issues/158).  Based on the announced changes in the 0.5.x series, I suspect it might be possible to ignore the dependency and have it still work with 0.5.2, but of course it would be better if `fog` officially supported `ruby-libvirt` 0.5.2.'
2705,'',"[vcloud_director] Allow for specification of vcloud_token via ENV\nThis change permits the use of an external login method for vCloud\r\nDirector, relying on the fact that the password is only needed to\r\ncreate a session in the API, subsequently accessed via the token.\r\n\r\nIn effect, this means that users do not need to store a valid\r\npassword in the FOG_RC, significantly reducing the risk footprint.\r\n\r\nThe default token lifetime is '30 minutes idle' - any activity\r\nextends the life by another 30 mins. This makes this a very workable\r\nsolution for general user sessions."
2704,'','[AWS/vpc] Fix VPC creation mock\nIt would always return the first VPC instead of the created VPC'
2703,'',"Don't read entire file into memory when saving to local blob storage.\nWe are using the local blobstore as a backend for concurrent uploads and\r\nobserved that memory was leaking quite quickly as GC cannot keep up.\r\n\r\nSo here, when the dest, src are  both local files, instead of calling\r\nFile.read, simply copy the file."
2702,'','[vsphere|compute] Expose template names and UUIDs\n'
2700,'tokengeek','[Brightbox] Extract to provider module [GH-2674]\nThis moves all the Brightbox lib files to a `providers` subdirectory as a prototype of moving the repo files around.\r\n\r\nA new gemspec exists which has built `fog-brightbox v0.0.1` - https://rubygems.org/gems/fog-brightbox\r\n\r\nI have a branch of our CLI application (https://github.com/brightbox/brightbox-cli) using this which appears to be working.\r\n\r\n`fog` now depends on `fog-brightbox` which brings all the functionality back.\r\n\r\nThe shindo tests have not been moved and (locally) pass.'
2699,'',"[openstack] Include auto-assigned IPs in floating_ip_addresses\nIn the OpenStack server model, the method floating_ip_addresses returns only manually-assigned public IP addresses, but omits IP's assigned via the auto_assign_floating_ip flag in nova.conf.  This patch allows floating_ip_addresses to return all floating addresses.\r\n\r\nRepro A:\r\n1. Configure auto-assignment of public IP's from a global pool\r\n2. Launch an instance, and confirm the auto-assigned IP with 'nova list' (e.g. IP is 192.168.1.13)\r\n3. Find server in fog interactive, then 'server.floating_ip_addresses'\r\nExpect: ['192.168.1.13']\r\nActual: []\r\n\r\nRepro B:\r\n1. Configure auto-assignment of public IP's from a global pool\r\n2. Launch an instance, and confirm the auto-assigned IP with 'nova list' (e.g. IP is 192.168.1.13)\r\n3. Allocate a floating IP to the tenant (e.g. 192.168.1.17), and associate it with the new instance.  Instance now has two public IP's\r\n4. Find server in fog interactive, then 'server.floating_ip_addresses'\r\nExpect: ['192.168.1.17','192.168.1.13']\r\nActual: ['192.168.1.17']\r\n\r\nThanks for fog!"
2698,'',"AWS signature code is flip flopping around failure on JRuby in 1.9 mode\nSo far today I've seen two failures in the AWS signaturev4 -      tests/aws/signaturev4_tests.rb tests\r\n\r\n- https://travis-ci.org/fog/fog/jobs/19188395\r\n- https://travis-ci.org/fog/fog/jobs/19173640\r\n\r\nBoth are on JRuby in 1.9 mode. Are (highly likely) unrelated to the changes being tested.\r\n\r\nMerging in one of these changes immediately means it passes...\r\n\r\n- https://travis-ci.org/fog/fog/jobs/19189567"
2697,'','Require `json` or `xml` in provider cores\nSince `fog-json` was extracted from `fog` it means if you rely on:\r\n\r\n    require "fog/provider/compute"\r\n\r\n`Fog::JSON` was not defined although it was supposed to be a supported\r\nuse case.\r\n\r\nThis adds the requires for JSON or XML based APIs based on a quick scan\r\nof each provider to declare the required part.\r\n\r\nAWS seems to be relying on both. Which is nice.\r\n\r\nProviders relying on native code dependencies were ignored.'
2696,'krames',"[rackspace] Add Virtual Interfaces to Servers\nAs far as I can find in Fog, there's not way to add virtual interfaces to servers with fog:\r\nhttp://docs.rackspace.com/servers/api/v2/cn-devguide/content/api_virt_interfaces.html\r\n\r\nThis is something we need for our workflow we're using with `fog`, so I'll see if I can get this implemented :+1: "
2694,'','Remove trailing whitespace\nThis is an EPIC fix of all the trailing whitespace.'
2693,'tokengeek','[internetarchive] Correct test tagging\nThe provider is declaring itself as "internetarchive" which does not\r\nmatch the tags "internet_archive" used on the tests.\r\n\r\nSince we blacklist the tests that are run, it meant they continued to\r\nrun even if no credentials were present.'
2692,'tokengeek','[Brightbox] Support Cloud SQL maintenance windows\nEnables setting of `maintenance_weekday` and `maintenance_hour` values\r\nto specify the maintenance window where updates may be applied to the\r\nSQL instance.'
2691,'','Use Travis ENV for the tests ENV!\nWere setting the FOG_MOCK environment setting in the rake task, covering\r\nup that we were running the tests this way (even though well known).\r\n\r\nThis makes it a lot clearer that in the Travis CI environment we are\r\nusing FOG_MOCK since it appears in the testing matrix.'
2690,'','[core] Make the wait timeout truly global\nThe Rackspace helper changed the Fog.timeout global for all live tests\r\nso the core test which expected "600" failed since it was now "2000"\r\n\r\nSince it is a global setting it has been moved to the global test helper\r\n\r\nIt can now also be controlled by the FOG_TEST_TIMEOUT env variable.'
2689,'',"[Brightbox] Remove SQL instance snapshot attr\nThis didn't make it into the final API"
2688,'',"Mock out the full AWS EC2 network interface attachment system\nThis adds mocking for the relationship between instances, network interfaces, subnets, and VPCs. It also includes subnet validation so that interface and subnet addresses must be within the subnets of their parents (and can't conflict with other subnets). I apologize for the large size, I felt it was better to submit something complete so that it would actually test well. This also represents about what I could get done in a day.\r\n\r\nI also apologize for a handful of white space changes. My editor removes trailing whitespace. ;-)\r\n\r\nPlease let me know if you have any feedback!\r\n"
2687,'',"Joyent Manta\nAre there plans to add support for Joyent's [Manta](http://www.joyent.com/products/manta) storage service to Fog? "
2685,'','disable ssl verify\n'
2684,'tokengeek','[Brightbox] Destroy snapshot after completion\nThis works around an issue where you can not detect if a Cloud SQL\r\nInstance is being snapshotted.\r\n\r\nA new API restriction is that you can no longer delete an instance that\r\nis being snapshotted so this suddenly began failing.\r\n\r\nNow we look for a new snapshot and poll until it is ready only then can\r\nwe safely issue the destroy command.'
2683,'',"[vcloud_director] Add get_network_complete non-lossy API request.\nThe existing get_network request uses a parser that translates the XML from vCloud Director into ruby-style snake case data structures, but unfortunately loses some information along the way.\r\n\r\nThis PR adds a 'get_network_complete' method that just uses the general purpose ToHashDocument parser, and so preserves the entire body.\r\n\r\nThis also enables loading this content directly into post_create_org_vdc_network, as suggested by the API docs.\r\n"
2681,'','Modular repo management\nSo we have extracted `fog-core` and `fog-json` into their own repos and created gems for them.\r\n\r\nWe have decided to link the version in `fog-core` to `fog` which may or may not be desirable.\r\n\r\nWe have immediately hit a problem related to repo management. To keep modules under the fog organisation it means @geemus is having to do repo and user management for each new one.\r\n\r\nAs a developer I have a complex network of depends whilst checking things work after extraction.\r\n\r\nBy splitting fog into multiple repos (rather than gems) then we start to get problems in managing all of these repos.\r\n\r\nI\'m starting to wonder if we should take the approach of Rails or Rspec and have the `fog` repo containing all of the gems and build tools to create the `fog` meta gem and all the providers / core.\r\n\r\nThat makes it easier to keep `fog` and `fog-core` in sync.\r\n\r\nThis would make it easier to just check out one repo as a developer, run all tests with a higher degree of confidence. We have been wondering about "integration" tests between all the providers parts.\r\n\r\nROM (https://github.com/rom-rb/rom) is a much simpler project that has just gone back  from multiple repos to one because of the overhead.\r\n\r\nI\'ve got a feeling it may get worse whilst we clean up the codebase across providers initially.\r\n\r\nSo any views, past experiences etc. ?\r\n\r\n/cc @geemus @elight '
2680,'','fog is slow to require\nOn my development system, adding fog to the Gemfile of my rails app adds nearly 1 second to the boot time, so I did some rough tests to see how fog compares to requiring other gems. All tests are with MRI 2.1 and fog 1.20.\r\n\r\nHere\'s the baseline:\r\n\r\n    â¡ time ruby -e "exit"\r\n    0.03s user 0.01s system 59% cpu 0.060 total\r\n\r\nHere\'s fog:\r\n\r\n    â¡ time ruby -rfog -e "exit"\r\n    1.14s user 0.09s system 98% cpu 1.256 total\r\n\r\n.. and here\'s a few other libraries for comparison:\r\n\r\n    â¡ time ruby -runicorn -e "exit"\r\n    0.16s user 0.02s system 87% cpu 0.206 total\r\n\r\n    â¡ time ruby -rrack -e "exit"\r\n     0.10s user 0.01s system 82% cpu 0.136 total\r\n\r\n    â¡ time ruby -rrails -e "exit"\r\n    0.30s user 0.05s system 93% cpu 0.375 total\r\n\r\nIt\'s surprising to me that loading fog is more than 3x slower than loading rails. Is there setup happening at require time that could be delayed to the first time a fog object is instantiated?'
2679,'','[aws|iam] Add get_account_summary.\nAdds support for the [`GetAccountSummary`](http://docs.aws.amazon.com/IAM/latest/APIReference/API_GetAccountSummary.html) IAM API action.'
2678,'',"Fixing the set_metadata request on google provider\nI fixed the `set_metadata` request which didn't work. \r\nAccording to google API reference (https://developers.google.com/compute/docs/reference/latest/instances/setMetadata) a fingerprint property should be supplied with the request body."
2677,'',"Mock out the attachment of network interfaces from the instance's perspective\nHere's another one for ya:\r\nSince Fog already implements the tracking of network interface attachments I thought: Why not include them in the describe_instances output?  Let me know what you think.  I am certain there are areas for improvement in this code."
2676,'','[Rackspace] Incorrectly requiring all of fog for Fog::Storage.new\n'
2675,'elight',"Fog::Storage.new causing all providers to be required\nTo replicate:\r\n\r\n```ruby\r\nrequire 'fog/rackspace'\r\n\r\np Fog.providers\r\nFog::Storage.new(args)\r\np Fog.providers\r\n```\r\n\r\nVery different output between the two <code>p</code>s."
2674,'tokengeek','Extract Brightbox provider to module\nWith our push towards fog becoming modular and the release of `fog-core` we need to get a few providers extracted and work on the pain points.\r\n\r\nSo this is for the **Brightbox** provider.\r\n\r\nSo what I have working is a `fog-brightbox` gem that is a fork of `fog` using `fog-core` and `fog-json`.\r\n\r\nThis works:\r\n* in isolation (Shindo tests)\r\n* when as a dependency required by our CLI tool (https://github.com/brightbox/brightbox-cli)\r\n* when as a dependency required by `fog`\r\n\r\nThe issues remaining are:\r\n\r\n- [ ] Official repo required so `fog/fog-brightbox` is needed (FAO @geemus)\r\n- [ ] Our Shindo helper (now in a different gem) is not getting picked up so in https://github.com/fog/fog/blob/master/tests/compute/helper.rb the `Brightbox::Compute::TestSupport` is not available.\r\n\r\n'
2673,'','Added find_by_name to openstack identity-users model and tests\nHello folks,\r\n\r\nFor our swift-service on anynines, we need the method `find_user_by_name` on the users collection on the  openstack fog adapter.\r\n\r\nI would really appreciate, if you could add that feature to the next release. :heart: \r\n\r\nGreetz\r\nMarkus'
2672,'','Reduce Travis CI burden\nThis excludes the duplicated Ruby 2.1.0 run (without coverage)\r\n\r\nAlso drops testing of Ruby 1.9.2.\r\n\r\nSo two less boxes used and faster results I hope.'
2671,'','[core] Use fog-core v1.21.0\nRather than tracking the Github repo, this references the gem directly.\r\n\r\nLocally seeing an issue with 1.8.7 / unf gem test which surprised not\r\nseeing on Travis.'
2670,'',"[core] Remove remaining services\nServices are ideally shared across providers so belong as part\r\nof `fog-core` this removes the files that had been left over from\r\nthe extraction work.\r\n\r\nIt also removes the duplicated `require` calls that were in place.\r\n\r\nAll `fog/{provider}/core` files reference `fog/core` which already\r\nrequires the services.\r\n\r\n**Note** this may put us out of sync between `fog` and `fog-core`\r\nsince fog v1.21.0 is *next* but fog-core v1.21.0 is already out.\r\n\r\nI'm not certain if https://github.com/fog/fog-core/pull/14 was part of that release or not."
2669,'',"Fixing [excon][WARNING] Invalid Excon request keys log noise when trying...\nCurrently when trying to use assume_role, fog generates the following noisy warning.  It doesn't affect the operation of the request, but does clog up the output.\r\n\r\n```\r\n[excon][WARNING] Invalid Excon request keys: :host\r\n/Library/Ruby/Gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:389:in `validate_params'\r\n/Library/Ruby/Gems/2.0.0/gems/excon-0.31.0/lib/excon/connection.rb:225:in `request'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.20.0/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.20.0/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.20.0/lib/fog/aws/sts.rb:121:in `request'\r\n/Library/Ruby/Gems/2.0.0/gems/fog-1.20.0/lib/fog/aws/requests/sts/assume_role.rb:31:in `assume_role'\r\n```"
2668,'','Fog throwing HTTP 400 / 500 when adding CNAME DNS record to Rackspace\nSo I have been messing around with the Fog. My goal is to create a DNS CNAME record each time a new application is made by adding it to my Rackspace DNS page as an entry.\r\n\r\nThe basic usecase is that I create an app:\r\n\r\n"rhc app-create test <app-type>"\r\nThe namespace is called ns in this instance.\r\nSo it will create a CNAME record on the broker called "test-ns.example.com". It will then try to register this record with my Rackspace account so that people outside of the broker can find the application and SSH to it.\r\n\r\nSo here is the issue.. I am using the following code to register an application:\r\n\r\n```ruby\r\n def register_application(app_name,namespace,public_hostname)\r\n      fqdn="#{app_name}-#{namespace}.#{@domain_suffix}"\r\n      #create a CNAME record\r\n      update = {\r\n       :value => public_hostname,\r\n       :name => fqdn,\r\n       :type => "CNAME",\r\n       :ttl\t=> 30\r\n      }\r\n      Rails.logger.info "FQDN=#{fqdn}. #{@rackspace_dns_zoneid}"\r\n      Rails.logger.info "Debug message inserted by Kyle Crumpton."\r\n      zone=rackspace.zones.get(@rackspace_dns_zoneid)\r\n      res = zone.records.create(update)\r\n    end\r\n```\r\n\r\nThe @rackspace_dns_zoneid, FQDN, and update parameters all reflect correctly what they should be.\r\nHere is the error when I try and run this method on the Rails Console:\r\n\r\nirb(main):003:0> d.register_application(\'testapp1\',\'testns1\', \'node1.example.com\')\r\nFog::DNS::Rackspace::BadRequest: [HTTP 400 | ] Validation failed. -\r\n    from /usr/local/share/gems/gems/excon-0.28.0/lib/excon/middlewares/expects.rb:6:in `response_call\'\r\n    from /usr/local/share/gems/gems/excon-0.28.0/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n    from /usr/local/share/gems/gems/excon-0.28.0/lib/excon/connection.rb:361:in `response\'\r\n    from /usr/local/share/gems/gems/excon-0.28.0/lib/excon/connection.rb:254:in `request\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/core/connection.rb:57:in `request\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/service.rb:43:in `request\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/dns.rb:115:in `request\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/requests/dns/add_records.rb:28:in `add_records\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/models/dns/record.rb:62:in `create\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/models/dns/record.rb:39:in `save\'\r\n    from /usr/local/share/gems/gems/fog-1.18.0/lib/fog/core/collection.rb:52:in `create\'\r\n    from /usr/local/share/gems/gems/openshift-origin-dns-rackspace-1.10.16/lib/openshift/rackspace_plugin.rb:71:in `register_application\'\r\n    from (irb):3\r\n    from /usr/share/gems/gems/railties-3.2.13/lib/rails/commands/console.rb:47:in `start\'\r\n    from /usr/share/gems/gems/railties-3.2.13/lib/rails/commands/console.rb:8:in `start\'\r\n    from /usr/share/gems/gems/railties-3.2.13/lib/rails/commands.rb:41:in `<top (required)>\'\r\n    from script/rails:54:in `require\'\r\n    from script/rails:54:in `<main>\'irb(main):004:0>\r\n\r\nSo my question is.. has anyone ever seen anything like this happening? Here is some more of the trace if it helps:\r\n\r\n\r\n2014-02-12 21:15:08.602 [ERROR] Encountered error during execute \'[HTTP 400 | ] Validation failed. - \' rollback pending: false (pid:1579)\r\n2014-02-12 21:15:14.141 [ERROR] Reference ID: 359f13e3fdab3c0724aa01c522d32285 - [HTTP 400 | ] Validation failed. -\r\n  /usr/local/share/gems/gems/excon-0.28.0/lib/excon/middlewares/expects.rb:6:in `response_call\'\r\n  /usr/local/share/gems/gems/excon-0.28.0/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n  /usr/local/share/gems/gems/excon-0.28.0/lib/excon/connection.rb:361:in `response\'\r\n  /usr/local/share/gems/gems/excon-0.28.0/lib/excon/connection.rb:254:in `request\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/core/connection.rb:57:in `request\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/service.rb:43:in `request\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/dns.rb:115:in `request\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/requests/dns/add_records.rb:28:in `add_records\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/models/dns/record.rb:62:in `create\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/rackspace/models/dns/record.rb:39:in `save\'\r\n  /usr/local/share/gems/gems/fog-1.18.0/lib/fog/core/collection.rb:52:in `create\'\r\n  /usr/local/share/gems/gems/openshift-origin-dns-rackspace-1.10.16/lib/openshift/rackspace_plugin.rb:71:in `register_application\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/gear.rb:123:in `register_dns\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/pending_ops/register_dns_op.rb:9:in `execute\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/pending_app_op_group.rb:75:in `block in execute\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/pending_app_op_group.rb:64:in `each\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/pending_app_op_group.rb:64:in `execute\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/application.rb:1557:in `run_jobs\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/application.rb:676:in `block in add_features\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/application.rb:1623:in `run_in_application_lock\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/application.rb:669:in `add_features\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/models/application.rb:253:in `create_app\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/app/controllers/applications_controller.rb:147:in `create\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/implicit_render.rb:4:in `send_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/abstract_controller/base.rb:167:in `process_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/rendering.rb:10:in `process_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/abstract_controller/callbacks.rb:18:in `block in process_action\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:481:in `block in _run__2585324845023905795__process_action__3526227800655018281__callbacks\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:215:in `block in _conditional_callback_around_386\'\r\n  /usr/share/gems/gems/openshift-origin-controller-1.18.0/lib/openshift/controller/action_log.rb:80:in `set_logged_request\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:214:in `_conditional_callback_around_386\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:403:in `_run__2585324845023905795__process_action__3526227800655018281__callbacks\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:405:in `__run_callback\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:385:in `_run_process_action_callbacks\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:81:in `run_callbacks\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/abstract_controller/callbacks.rb:17:in `process_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/rescue.rb:29:in `process_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/instrumentation.rb:30:in `block in process_action\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/notifications.rb:123:in `block in instrument\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/notifications/instrumenter.rb:20:in `instrument\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/notifications.rb:123:in `instrument\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/instrumentation.rb:29:in `process_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/params_wrapper.rb:207:in `process_action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/abstract_controller/base.rb:121:in `process\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/abstract_controller/rendering.rb:45:in `process\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal.rb:203:in `dispatch\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal/rack_delegation.rb:14:in `dispatch\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_controller/metal.rb:246:in `block in action\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/routing/route_set.rb:73:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/routing/route_set.rb:73:in `dispatch\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/routing/route_set.rb:36:in `call\'\r\n  /usr/share/gems/gems/journey-1.0.4/lib/journey/router.rb:68:in `block in call\'\r\n  /usr/share/gems/gems/journey-1.0.4/lib/journey/router.rb:56:in `each\'\r\n  /usr/share/gems/gems/journey-1.0.4/lib/journey/router.rb:56:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/routing/route_set.rb:612:in `call\'\r\n  /usr/share/gems/gems/mongoid-3.1.4/lib/rack/mongoid/middleware/identity_map.rb:34:in `block in call\'\r\n  /usr/share/gems/gems/mongoid-3.1.4/lib/mongoid/unit_of_work.rb:39:in `unit_of_work\'\r\n  /usr/share/gems/gems/mongoid-3.1.4/lib/rack/mongoid/middleware/identity_map.rb:34:in `call\'\r\n  /usr/share/gems/gems/sass-3.2.6/lib/sass/plugin/rack.rb:54:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/best_standards_support.rb:17:in `call\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/etag.rb:23:in `call\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/conditionalget.rb:35:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/head.rb:14:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/params_parser.rb:21:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/flash.rb:242:in `call\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/session/abstract/id.rb:210:in `context\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/session/abstract/id.rb:205:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/cookies.rb:341:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/callbacks.rb:28:in `block in call\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:405:in `_run__2339041322041708277__call__741858123488100523__callbacks\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:405:in `__run_callback\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:385:in `_run_call_callbacks\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:81:in `run_callbacks\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/callbacks.rb:27:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/remote_ip.rb:31:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/debug_exceptions.rb:16:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/show_exceptions.rb:56:in `call\'\r\n  /usr/share/gems/gems/railties-3.2.13/lib/rails/rack/logger.rb:32:in `call_app\'\r\n  /usr/share/gems/gems/railties-3.2.13/lib/rails/rack/logger.rb:16:in `block in call\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/tagged_logging.rb:22:in `tagged\'\r\n  /usr/share/gems/gems/railties-3.2.13/lib/rails/rack/logger.rb:16:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/request_id.rb:22:in `call\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/methodoverride.rb:21:in `call\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/runtime.rb:17:in `call\'\r\n  /usr/share/gems/gems/activesupport-3.2.13/lib/active_support/cache/strategy/local_cache.rb:72:in `call\'\r\n  /usr/share/gems/gems/rack-1.4.5/lib/rack/lock.rb:15:in `call\'\r\n  /usr/share/gems/gems/actionpack-3.2.13/lib/action_dispatch/middleware/static.rb:63:in `call\'\r\n  /usr/share/gems/gems/rack-cache-1.2/lib/rack/cache/context.rb:136:in `forward\'\r\n  /usr/share/gems/gems/rack-cache-1.2/lib/rack/cache/context.rb:143:in `pass\'\r\n  /usr/share/gems/gems/rack-cache-1.2/lib/rack/cache/context.rb:155:in `invalidate\'\r\n  /usr/share/gems/gems/rack-cache-1.2/lib/rack/cache/context.rb:71:in `call!\'\r\n  /usr/share/gems/gems/rack-cache-1.2/lib/rack/cache/context.rb:51:in `call\'\r\n  /usr/share/gems/gems/railties-3.2.13/lib/rails/engine.rb:479:in `call\'\r\n  /usr/share/gems/gems/railties-3.2.13/lib/rails/application.rb:223:in `call\'\r\n  /usr/share/gems/gems/railties-3.2.13/lib/rails/railtie/configurable.rb:30:in `method_missing\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/rack/request_handler.rb:97:in `process_request\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_request_handler.rb:521:in `accept_and_process_next_request\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_request_handler.rb:274:in `main_loop\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/rack/application_spawner.rb:206:in `start_request_handler\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/rack/application_spawner.rb:171:in `block in handle_spawn_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/utils.rb:470:in `safe_fork\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/rack/application_spawner.rb:166:in `handle_spawn_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server.rb:357:in `server_main_loop\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server.rb:206:in `start_synchronously\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server.rb:180:in `start\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/rack/application_spawner.rb:129:in `start\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/spawn_manager.rb:253:in `block (2 levels) in spawn_rack_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server_collection.rb:132:in `lookup_or_add\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/spawn_manager.rb:246:in `block in spawn_rack_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server_collection.rb:82:in `block in synchronize\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server_collection.rb:79:in `synchronize\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server_collection.rb:79:in `synchronize\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/spawn_manager.rb:244:in `spawn_rack_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/spawn_manager.rb:137:in `spawn_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/spawn_manager.rb:275:in `handle_spawn_application\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server.rb:357:in `server_main_loop\'\r\n  /usr/share/gems/gems/passenger-3.0.21/lib/phusion_passenger/abstract_server.rb:206:in `start_synchronously\'\r\n  /usr/share/gems/gems/passenger-3.0.21/helper-scripts/passenger-spawn-server:102:in `<main>\' (pid:1579)\r\n2014-02-12 21:15:14.142 [INFO ] Completed 500 Internal Server Error in 16029ms (Views: 0.5ms) (pid:1579)\r\n\r\nNow the funny part; when I run the equivalent code on my local system as a simple ruby script it works like a charm.\r\n\r\nAny ideas? thank you.'
2667,'','Use fog-json\nThis extracts the JSON encoding/decoding wrappers around MultiJson to a\r\nseparate gem.\r\n\r\nProviders can use this shared behaviour in their standalone modules as\r\nwe work through things.'
2666,'','[Brightbox] Replace use of Fog::Connection\n`Fog::Connection` is a wrapper around XML parsing behaviour which is no\r\nlonger in `fog-core` but will be moved to `fog-xml`\r\n\r\nSo should be using `Fog::Core::Connection` for the simpler behaviour.'
2665,'','[AWS/elasticache] Added mocking for parameter groups\n'
2664,'','[vsphere] fix broken detection of existing network interface type\nCommit 035129e40f1b05b12427fa7ea2fbcfd2cd5d42d4 has broken the detection of existing network interface type by overwriting a supplied Class with the VirtualE1000 class.'
2663,'','Changes to rely on fog-core\nThis references `fog-core` and removes the files it now contains.\r\n\r\nThis supersedes #2645 and covers #1253 and #2602\r\n\r\nIt currently references the `fog-core` by Github repo but we should\r\nupdate to target the released gem (`v1.21.0`)'
2662,'tokengeek','Fix Joyent service declarations\nWhen the Joyent provider was merged in it was after a reworking of how\r\nrequires and services were declared.\r\n\r\nThis meant the call to `service` was no longer correct.\r\n\r\nThis updates the signature and the mocked tests now pass (locally at\r\nleast) however the structuring and placement of the files may not be\r\ninconsistent with the results of [GH-1712]'
2661,'','[aws|compute] nonexisting region results in a socket warning rather than error\nWhen creating a Compute instance for aws provided, if a nonexisting region is given a socket warning is generated:\r\n\r\n    WARNING: SocketError getaddrinfo Name or service not known\r\n\r\nValidation of a given region required.\r\nFix with unit tests provided as part of another pull request: https://github.com/fog/fog/pull/2631'
2660,'','[sakuracloud] Create provider for sakuracloud (Japan) (Replace of #2625)\nThis PR is replace of #2625.\r\n\r\nrebase to master and squash commits following:\r\n\r\n```\r\nlist ssh_keys and create disk\r\nadd models and requests for  create computer\r\ncreate server at once\r\nadd bin and route file\r\nupdate create_with\r\nwrite getting_started wip. and create helper methods.\r\nadd sakura to mock_helper\r\nadd bin and route file\r\nwrite getting_started wip. and create helper methods.\r\nadd mocks and test\r\ncreate tests and write getting started\r\nwritenig provider for sakuracloud ,wip\r\nlist ssh_keys and create disk\r\nadd models and requests for  create computer\r\ncreate server at once\r\nadd bin and route file\r\nupdate create_with\r\nwrite getting_started wip. and create helper methods.\r\nadd sakura to mock_helper\r\nadd bin and route file\r\nwrite getting_started wip. and create helper methods.\r\nadd mocks and test\r\ncreate tests and write getting started\r\nmv getting_started to docs\r\nmv getting_started to docs\r\nuse snake_case for models\r\nfix: wrong usage of :aliases\r\nupdate doc. replace to snake_case from class\r\nupdate mocks format\r\nFix: remove commas for Ruby 1.8.7\r\nduplicate example\r\nuse create method with option if atatch volume\r\nremove empty line (checking travis works..)\r\nfix args for core/provider.rb#service\r\n```\r\n\r\n'
2659,'','[cloudsigma] adding firewall_policy attribute and ready? method for servers\nPull request for issue #2635'
2658,'','Add docker support\nThis patch adds support for running containers and managing images on Docker (http://docker.io).\r\n\r\nIt depends on a fix to the docker-api gem ( https://github.com/swipely/docker-api/pull/82 ) that in now merged.'
2657,'','Allow for Blue Box blocks to be created with IPv6 addresses only\nThe Blue Box API allows for this, and we use it for Travis CI.\r\n\r\nMerging in this PR would mean we could drop using our fork, which was meant as a stop gap.'
2655,'','Openstack identity url\nwhen using the autho url from a keystone or horizon, its necessary to use "/tokens" on the end of the url to get a authenticate working'
2653,'',"add config_disk attribute to rackspace compute_v2 server\nProbably fixes #2651, but it's not clear how to test this."
2652,'','support rackspace storage delete_at and delete_after headers\nRackspace Cloud Files allows the caller to set a time in the future\r\nafter which the uploaded asset will be automatically deleted.\r\n\r\nhttp://docs.rackspace.com/files/api/v1/cf-devguide/content/Storage_Object_Services-d1e4300.html\r\n\r\nThis commit adds `deleted_at` and `deleted_after` attributes to the\r\n`rackspace/models/storage/file.rb`. They are then added to the HTTP\r\nheaders when requested.\r\n\r\nThanks to @smashwilson for a lot of help with this'
2651,'',"[rackspace|compute] Add support for config_drive\nThis should be very similar to the same attribute for openstack #2119, but could also be resolved by rebuilding rackspace on openstack #1733. You know, if you're insanely ambitious."
2649,'','[openstack|compute] Allow to use Symbol when specifying the hash of NICs\nWhen use VM with NICs that was introduce in #1669, at this time the key of hash can only use String.\r\nThis commit allows to use Symbol as the key of hash.\r\nFor example, it is useful when generate hash from yaml.'
2648,'','Cannot list security groups using HPV2\nWhen I create a non v2 HP Compute object I get the following message:\r\n> [fog][DEPRECATION] HP Cloud Compute V1 service will be soon deprecated. Please use :version => v2 attribute to use HP Cloud Compute V2 service.\r\n\r\nOk, so I use v2 instead, however, I am unable perform essential actions like listing on security groups using the V2 class:\r\n\r\n>Class: Fog::Compute::HPV2::Real\r\n> NoMethodError: undefined method list_security_groups for Fog::Compute::HPV2::Real\r\n\r\nIs this functionality on the roadmap for the HPV2 class?  When will the V1 class be deprecated?  I would like to use the HPV2 class, but cannot without the security group functionality.\r\nThank you,\r\nIz'
2647,'','[hp|compute_v2] Removes security groups\nPer @rupakg security groups have been moved to a new network service and should not be present in compute v2.'
2646,'','Implement replaceroute\nNoticed that fog had "create" and "delete" but no "replace" which is super useful for handling failover changes without downtime.'
2645,'','[core] fog-core extraction\nThe [fog](/fog/fog) side of #2602.'
2643,'','use current region for subnet checks when creating DB and Cache subnet groups\n'
2642,'','[vsphere] return cloned vm object by default\nUsing the instance id for finding vm and keeping template path if given in options.\r\n\r\nFinding by name never seemed to work for me, this fixes that.\r\n\r\n@nirvdrum are you the person to look at this?\r\n\r\nI made this change for a PR on foreman https://github.com/theforeman/foreman/pull/1183'
2641,'','add Iops to snapshot model\nAdd IOPS support to snapshot model. '
2640,'','Passing a subset of files to a block passes the entire bucket, instead.\nWe were trying to delete some fake test data we had pushed to S3.\r\n```\r\nall_files = connection.directories.get(bucket_name).files\r\nfakes = all_files.select {|file| file.key.match(some_regex) }\r\nfakes.class\r\n#=>Fog::Storage::AWS::Files\r\nfakes.count\r\n#=> 2\r\n```\r\nAbove, 2 is the right number. That\'s how many files match our regex. Yet, somehow:\r\n```\r\nfakes.each {|file| p file.key}\r\n#=>  "a-massive"\r\n"list-of"\r\n"all-files"\r\n"in-the-bucket"\r\n```\r\nGuess what happens if you call:\r\n```\r\nfakes.each(&:destroy)\r\n```\r\nWhat happens is you destroy all the files, not the subset.  Not expected behavior.'
2639,'','Use endpoint, port, and path_style options in AWS storage Mock\nOur tests were assuming these options were used, but when mocking they were not. So we are using the same initialization code that the Real class uses.'
2638,'',"Tests and fixes for Elasticache VPC subnet groups\nBased off @jtopper's work (PR #2403). Added some finishing touches to the models and removed status, because it's not actually a part of Elasticache subnet groups for some bizarre reason (see  http://docs.aws.amazon.com/AmazonElastiCache/latest/APIReference/API_CacheSubnetGroup.html vs http://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_DBSubnetGroup.html)"
2637,'',"[hp] Empty list of servers on HPCloud v13.5\nHi, thanks for this great software.\r\nI just migrated my account from v12.12 to v13.5. After migration, I created a VM in us-west zone-1 using horizon console. The VM was exist in the console, but the fog was always returning an empty server list. The fog itself has successfully connected to HP's endpoint with my credential without any problem. FYI, this problem is not exist prior the migration.\r\nCan anyone help me on this issue? Thank you."
2636,'','Display number of instance store volumes per instance flavor.\nDisplay number of the instance store volumes available to each instance type.\r\n\r\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html'
2635,'','[CloudSigma] firewall policies not reported or assignable\nBasic support for firewall policies has been added, but an assigned firewall policy is not reported for a NIC that has one assigned to it, nor is it possible to assign a policy that already exists to a NIC.'
2634,'','[rackspace | queues] Use case-insensitive header access for Location.\nI just hit an issue regarding a change in header case in the Cloud Queues `/claims` endpoint. Specifically, the header that used to be "Location" is now "location", so `claim#create` can no longer extract the claim\'s ID from the response:\r\n\r\n```\r\nundefined method `split\' for nil:NilClass\r\n/home/ash/.rbenv/versions/2.1.0/lib/ruby/gems/2.1.0/gems/fog-1.19.0/lib/fog/rackspace/models/queues/claim.rb:112:in `create\'\r\n/home/ash/.rbenv/versions/2.1.0/lib/ruby/gems/2.1.0/gems/fog-1.19.0/lib/fog/rackspace/models/queues/claim.rb:46:in `save\'\r\n/home/ash/.rbenv/versions/2.1.0/lib/ruby/gems/2.1.0/gems/fog-1.19.0/lib/fog/rackspace/models/queues/claims.rb:36:in `create\'\r\n```\r\n\r\n```ruby\r\n[2] pry(#<Fog::Rackspace::Queues::Claim>)> response.headers\r\n=> {"content-type"=>"application/json; charset=utf-8",\r\n "location"=>"/v1/queues/peril_events/claims/52ebe1463ac24e595a263f25",\r\n "Connection"=>"close",\r\n "X-Project-Id"=>"629538",\r\n "content-length"=>"2550"}\r\n```\r\n\r\n/cc @krames @elight'
2633,'','[libvirt|compute] Allow volumes to have backing volumes\nUseful for qcow2 volumes, so you can do COW layering of disks.\r\n\r\nhttp://libvirt.org/formatstorage.html#StorageVolBacking'
2632,'','AWS RDS - enhancements to IOPS support\nSome fixes for missing features of Iops. E.g. Iops value was not returned from describe_db_instances or the pending value hash. It should also be available to snapshots.\r\n'
2631,'','[openstack] Add more observable states for openstack models.\nSupport `server.failed?` and `volume.ready?`.'
2630,'tokengeek','Prototype replacing Shindo testing with minitest\nWe discussed changing testing frameworks as part of #1266\r\n\r\nThe decision was to switch to using `minitest` with tagging support.\r\n\r\nWe do not want to replace everything immediately but bring in the gems, update some of the shared tests and core tests.\r\n\r\nSorting out helpers so they are available.\r\n\r\nSince Shindo does broad tests (1 expensive operation, many assertions) we need to work out the best structure for the tests so you can see a good level of detail.\r\n\r\nThis work should not affect mocking work or dividing into providers since providers may be able to use their own testing framework.'
2628,'','[openstack] image.update_image_members expects are incorrect #2627\nCorrect expected HTTP response code for `Fog::Image::OpenStack.update_image_members` call.'
2627,'','[openstack] image.update_image_members expects are incorrect\nCurrently, the request expects `[200,202]` while the API says the the call returns `204 No Content`.\r\nhttp://docs.openstack.org/api/openstack-image-service/1.0/content/adding-a-member-to-an-image.html'
2625,'','create provider for sakuracloud(Japan)\nSupports\r\n\r\n- Compute\r\n- Volume\r\n\r\nPlease see `lib/fog/sakuracloud/docs/getting_started.md `\r\n'
2624,'geemus',"Arrange fog 1.20.0 release\n@geemus It's been about a month since 1.19.0 was released.\r\n\r\nCan we get a new version cut?\r\n\r\nThanks."
2623,'tokengeek','[Brightbox] Remove old #destroy request\nAll the "destroy" methods were renamed to "delete" but this file was not\r\nremoved.'
2622,'','[vcloud_director] fix typo as per #2621\n'
2621,'',"[vcloud_director] EdgeGatewayServiceConfiguration has a typo for Persistence Method\nline 78 in EdgeGatewayServiceConfiguration refers to [:method]:\r\n\r\n                        xml.Method service_profile[:Persistence][:method]\r\n                        if service_profile[:Persistence][:Method] == 'COOKIE'\r\n\r\nThis should be ':Method' as per line 79.\r\n"
2620,'tokengeek',"[Brightbox] Add support for Cloud SQL service\nThis adds support for Brightbox's Cloud SQL DBaaS.\r\n\r\nIt is currently still part of the Compute service so all resources can\r\nbe managed from one connection to the service."
2619,'','[hp|compute_v2] added security group support\nThis PR adds security groups to the compute_v2 services for the HP. A lot of this code was re-used from the compute service.\r\n\r\n@rupack Do you want to give this a quick glance?\r\n\r\n@geemus I also noticed that out of the 3 providers that support security groups (aws, hp, and openstack) all three of have a slightly different interface. I added `SecurityGroup#authorize_port_range` to match the aws interface, but I wonder if we should take the time to define a common interface for SecurityGroups. I am leaning towards the OpenStack implementation as it has a much more OO interface. Thoughts?'
2618,'','Update AWS flavors with new M3 Instance Types\n*Accouncement*: http://aws.typepad.com/aws/2014/01/aws-update-new-m3-features-reduced-ebs-prices-reduced-s3-prices.html\r\n*Instance Types*: http://aws.amazon.com/ec2/instance-types/'
2616,'','Aws run instance attach network interfaces\n'
2615,'tokengeek',"Make Coveralls opt-in\nDue to looking for a value of 'false' whenever I run tests locally\r\nwithout the `COVERAGE` env variable coverage is very slowly, still\r\ncalculated - it then aborts without doing anything because I'm not using\r\na CI setup.\r\n\r\nThis adds the setting in for Travis to opt in and should exclude\r\ncoverage work for anyone running tests locally."
2614,'tokengeek','[Brightbox] Add CloudIp#destination_id\nAbstraction over the number of possible mapped targets to consistently\r\naccess the identifier.'
2613,'',"There is a bug here or maybe i'm using the gem wrong...\nedit: this is a new version \r\n\r\nYou should merge the ACLs after merging the meta_hash if not the new permission will be overwritten by the old one.\r\nIf Before you had a directory with :\r\nX-Container-Read: .r:*,.rlistings\r\n\r\nand you make your directory private again. The new read_acl will be overwritten by the old one in the mata_hash\r\n\r\nNormally i think that first you should merge the default/previous options and then you apply the new ones and at the end you apply the user specified options if there is any \r\n"
2612,'',"There is a bug here or maybe i'm using the gem wrong...\nyou should merge the ACLs after merging the meta_has if not The new permission will be overwritten by the old one.\r\nIf Before you had a directory with :\r\nX-Container-Read: .r:*,.rlistings\r\n\r\nand you make your directory private again. The new read_acl will be overwritten by the old one in the mata_hash"
2611,'','[aws] align hashrockets, remove whitespace\njust a style fix.'
2610,'',"AWS run_instances model doesn't allow attaching existing network interfaces\nWhen creating instances using the run_instances model, it doesn't appear to currently be possible to attach existing interfaces during instance creation."
2609,'','Add ability to assocation address to private ip address\nAdd ability to associate an AWS elastic ip to a private address on a network interface.'
2608,'','add ability to assocation address to private ip address\nAdd ability to associate an AWS elastic ip to a private address on a network interface.'
2607,'','Add ability to use private ip address to associate address\nAdding ability to associate an address to a private ip address on a network interface.'
2606,'','[rackspace|compute_v2] added key_name and modified key_pair= to KeyPair Objects\n[rackspace|compute_v2] added key_name and modified key_pair= to take KeyPair objects as well as strings in order to be more compatible with other fog providers'
2605,'','Flag AWS EBS-Optimized Instances\nThis kind of goes against the size theme thats currently in place, but I think this is useful information to have.  Id also love to get dedicated EBS throughput and MAX IOPS in there as well. \r\n\r\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html'
2604,'','List AWS EBS-Optimized Instances\nWould be really helpful to specify EBS information at the flavor level.  This kind of goes against the `size` theme thats currently in place, but its certainly useful to say the least. \r\n\r\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html'
2603,'','Fog error: Invalid value for field \'resource.networkInterfaces[0].accessConfigs[0].natIP\': \'false\'.  Must be an IP address\nProblems with Foreman and the GCE module, which uses fog 1.19.0 when provisioning a new GCE instance the following error occurs causing the provision to fail\r\n\r\nFog error: Invalid value for field \'resource.networkInterfaces[0].accessConfigs[0].natIP\': \'false\'.  Must be an IP address\r\n\r\nI know this popped up if the value was "true" (https://github.com/fog/fog/pull/2377) before, potentially the same issue?\r\n\r\nstack trace - http://fpaste.org/71294/05694951/ '
2602,'','[Core] Split out a "fog-core" gem separate from "fog" and providers\nCC: @krames @rupakg @tokengeek @geemus \r\n\r\n@krames and I had a meeting with @geemus yesterday where we discussed taking action with respect to #1250, #1253, and #1266.  This issue attempts to capture the relevant points as I begin to step in it. :wink: \r\n\r\nThese are clearly important issues to, at least, the fog development community.  They\'ve been discussed for over year.\r\n\r\nBut they\'ve been discussed for over a year.  Someone has to take action first.  I\'m stepping up to be that <strike>patsy</strike> <strike>sucker</strike> person.\r\n\r\nI believe, as you all seem to as well, that these issues hinder the growth and adoption of fog by other developers.  My personal pain point came when attempting to reuse Fog::OpenStack::Orchestration within Rackspace. Not only was testing proving difficult, but reuse proved to be practically impossible.\r\n\r\nFrom the discussion, the beginning of all good things for fog\'s future seem to hinge on separating a "fog-core" gem from "fog".  This would enable providers to create their own separate "fog-\\<provider\\>" gems. "fog" will then require "fog-core" and the provider gems.\r\n\r\nEssentially, this is the first step toward #1253.\r\n\r\nIt is my intent to ensure that these changes remain architectural only and do not result in any API breakages.\r\n\r\nThis split then enables #1266. \r\n\r\n"fog-core"\'s test suite, at this time, appears to be minimal. This, at least, gives it the virtues of being easy to separate from the rest of fog and also easy to port to another testing framework than shindo.\r\n\r\nIndividual providers will then have the option to extract their provider implementation and test suites into a separate gem and repo. Among other things, this will allow the providers to adopt whichever testing framework they choose. Responsibility for implementation and testing of provider behavior will then lie solely with the provider.\r\n\r\nI\'ll have a public repo up [here](https://github.com/elight/fog-core) soon.  At this time, I\'ve extracted the pieces required by lib/fog/core.rb into fog-core and what I believe are the attendant shindo tests.\r\n\r\nNext, I\'ll have a fog-core branch [in my personal fork of fog]((https://github.com/elight/fog) which will be absent the pieces in [fog-core](https://github.com/elight/fog-core).  However, this fog will require fog-core.\r\n\r\nFinally, I\'ll ensure that fog and fog-core are working by separating out "fog-rackspace".  I\'ll attempt to use fog-rackspace with solely fog-core at first. That is, in a few brief months, I\'ve seen at least a couple requests for "let me use just a single provider without loading everything else". Then I\'ll augment my branch of fog to require fog-rackspace, remove the rackspace provider from fog, and test again.  If this works, then this issue can then be closed out.\r\n\r\nAssuming this is a success, I hope to later fulfill other aspects of #1253 in later issues and PRs.\r\n\r\n@geemus: \r\n\r\nPerhaps version should be specified in core and both fog and core should be synchronized on version?  We don\'t have to do it thusly.  But Connection encodes the fog version in the HTTP request header. Connection will reside in fog-core. And we want fog to depend on fog-core and not the reverse. Thoughts?'
2600,'','Fixed error when accessing files via atmos where keys contain spaces\nWhen trying to iterate of all files in a directory, using atmos, If the key of a file contains a space an error would occur. Escaped the file path for header and get lookups.'
2599,'','Rage4 dns support\nThis is adding support for the Rage4 dns api.\r\nhttp://gbshouse.uservoice.com/knowledgebase/articles/109834-rage4-dns-developers-api'
2598,'','[aws|dns] omit ttl for alias records\ncloses #2592\r\n\r\n/cc @CpuID I think this should solve your issue, could you check it out and see? Thanks!'
2597,'',"[core] Add ability to specify IP Address for SSH, SCP and sshable?\nThis PR addresses issue #2584 and allows to you specify an `ssh_ip_address` that will allow you to specify the desired address for SSH, SCP, and sshable? If this value is not specified it falls back to the previous behavior of using the `public_ip_address`.\r\n\r\nI also fixed a broken core servers test that wasn't properly verify required attributes/methods on server models.\r\n\r\n@geemus This PR touches ever server model in fog and it's hard to test. If you could give this an extra set of eyes, it would be much appreciated. "
2596,'','Make disassociate_address mock idempotent, by not requiring instance data\n'
2594,'',"Joyent analytics\nThis branch adds support for interacting with Joyent's analytics API and tweaks a few minor issues with the Joyent Compute implementation.  "
2593,'','Enhance openstack neutron support\n'
2592,'',"Route 53 ChangeResourceRecordSets API Calls do not require TTL if deleting Alias Target RRSet's.\nFrom http://docs.aws.amazon.com/Route53/latest/APIReference/API_ChangeResourceRecordSets.html\r\n\r\n-----------------------------------------------\r\n\r\nTTL (Required for All Except Alias Resource Record Sets)\r\nThe resource record cache time to live (TTL), in seconds. Note the following:\r\n\r\nIf you're creating an alias resource record set for an Elastic Load Balancing load balancer, omit TTL. Route 53 uses the Elastic Load Balancing TTL. For the current TTL value for Elastic Load Balancing, see the introduction to Using Domain Names With Elastic Load Balancing.\r\n\r\nIf you're associating this resource record set with a health check (if you're adding a HealthCheckId element), we recommend that you specify a TTL of 60 seconds or less so clients respond quickly to changes in health status.\r\n\r\nType: Integer\r\n\r\nDefault: None\r\n\r\nParent: ResourceRecordSet\r\n\r\n-----------------------------------------------\r\n\r\nCurrently fog produces the following error when using trying to .destroy a Fog::DNS::AWS::Record object:\r\n\r\n```\r\n/usr/local/var/rbenv/versions/2.0.0-p353/lib/ruby/gems/2.0.0/gems/fog-1.18.0/lib/fog/core/attributes.rb:180:in `requires': ttl is required for this operation (ArgumentError)\r\n\tfrom /usr/local/var/rbenv/versions/2.0.0-p353/lib/ruby/gems/2.0.0/gems/fog-1.18.0/lib/fog/aws/models/dns/record.rb:87:in `attributes_to_options'\r\n\tfrom /usr/local/var/rbenv/versions/2.0.0-p353/lib/ruby/gems/2.0.0/gems/fog-1.18.0/lib/fog/aws/models/dns/record.rb:30:in `destroy'\r\n```"
2591,'',"[Rackspace]  Handle whitespace in keypair names on deletion\nFixes #2586\r\n\r\nNames can contain whitespaces but we weren't handling that case."
2590,'','[rackspace|queues] Mocks for Cloud Queues\nThis implements mocking for all requests in the Queues service for Rackspace. All (previously pending) tests now pass with `FOG_MOCK=1`.'
2589,'','Fix typo puplic -> public\nSmall typo fix'
2587,'',"[Rackspace] Add all bulk file operations\nWe'll shortly have extract archive (thanks to @codeodor for #2583).  But we should support the other Cloud Files bulk operations as well."
2586,'','Unable to destroy keypair\nI\'m sure Im doing something wrong here, but everything is auto-generated so not sure what this is :P\r\n\r\n```\r\n kp =fk.key_pairs.first\r\n =>   <Fog::Compute::RackspaceV2::KeyPair\r\n    name="MYNAME",\r\n    public_key="ssh-rsa BLAHBLAH BLAH Generated by Nova\\n",\r\n    private_key=nil,\r\n    user_id=nil,\r\n    fingerprint="0e:1f:80:20:73:7a:3d:27:24:2e:36:18:b4:fa:c5:6b"\r\n  > \r\n\r\n1.9.3p385 :066 > kp.destroy\r\nFog::Compute::RackspaceV2::BadRequest: [HTTP 400 | ] Fog::Compute::RackspaceV2::BadRequest - \r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/excon-0.28.0/lib/excon/middlewares/expects.rb:10:in `response_call\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/excon-0.28.0/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/excon-0.28.0/lib/excon/connection.rb:361:in `response\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/excon-0.28.0/lib/excon/connection.rb:254:in `request\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/fog-1.18.0/lib/fog/core/connection.rb:57:in `request\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/fog-1.18.0/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/fog-1.18.0/lib/fog/rackspace/service.rb:43:in `request\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/fog-1.18.0/lib/fog/rackspace/compute_v2.rb:152:in `request\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/fog-1.18.0/lib/fog/rackspace/requests/compute_v2/delete_keypair.rb:18:in `delete_keypair\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/fog-1.18.0/lib/fog/rackspace/models/compute_v2/key_pair.rb:49:in `destroy\'\r\n\tfrom (irb):66\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/railties-3.2.13/lib/rails/commands/console.rb:47:in `start\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/railties-3.2.13/lib/rails/commands/console.rb:8:in `start\'\r\n\tfrom /var/www/gamekick/shared/bundle/ruby/1.9.1/gems/railties-3.2.13/lib/rails/commands.rb:41:in `<top (required)>\'\r\n\tfrom script/rails:6:in `require\'\r\n\tfrom script/rails:6:in `<main>\'\r\n```\r\n'
2585,'','Remove :host key in SNS request method to eliminate excon error\nAnother one related to #2265'
2584,'',"[openstack] Fog::Compute::Server#sshable? is not working for VM with private IP only\nHi All,\r\n\r\nMany thanks for this great software.\r\n\r\nI used fog (v1.19.0) to create a new VM on OpenStack. The VM only has private IP, and so does my master vm. Both machines are in the same subnet.\r\n\r\nMy codes uses `sshable?` after submitting VM's specification in order to wait until the SSH is available for provisioning. However, `sshable?` was always returning false although the VM's ssh server was already running (I could do ssh to the VM from master).\r\n\r\nBecause of this, I replaced `sshable?` with custom codes that will wait until port 22 of the VM is accessible. By doing so, my codes are working good now.\r\n\r\nI wonder whether this is a limitation of `sshable?` where the VM should have a public IP, or this is a bug?\r\n\r\nAny comments are very welcome!"
2583,'',"Add support for Rackspace's Extract Archive API call\nSee http://docs.rackspace.com/files/api/v1/cf-devguide/content/Extract_Archive-d1e2338.html\r\nfor documentation on the API call.\r\n\r\n@elight had the key insights that helped with this, and @jnoller let me know of the existence of Extract Archive."
2582,'','Add Support for Rage4 DNS API\nIs anyone interested in developing support for the Rage4 DNS API?\r\n\r\nhttp://gbshouse.uservoice.com/knowledgebase/articles/109834-rage4-dns-developers-api'
2581,'','[dnsimple] Add support for versioned API\nThis patch implements support for the recently released [DNSimple versioned API](http://blog.dnsimple.com/2014/01/versioned-api/).\r\n\r\nI also took the time to cleanup the documentation a little bit removing attributes we deprecated since the last refresh.'
2580,'','Making local file interface follow AWS file interface\nTrying to use local file storage in place of AWS, but the encryption attribute does not exist on Fog::Storage::Local::File.\r\n\r\nMaking this a no-op to preserve the same API as Fog::Storage::AWS::File.'
2579,'','rm rspec dependency\nas requested by #2224 and in the spirit of #1266'
2578,'','[OpenStack] Decode body to array\nHi, im use Selectel (http://storage.selectel.ru) cloud with openstack swift (auth api v1.0), when i try to get_container, im got an error:\r\n\r\n```\r\nNoMethodError: undefined method `each\' for #<String:0x007ff7aaaf9f98>\r\n\tfrom /Users/bugagazavr/Documents/Ruby/fog/lib/fog/openstack/models/storage/directories.rb:31:in `get\'\r\n\tfrom (irb):2\r\n\tfrom /Users/bugagazavr/.rvm/gems/ruby-2.1.0/gems/railties-4.1.0.beta1/lib/rails/commands/console.rb:90:in `start\'\r\n\tfrom /Users/bugagazavr/.rvm/gems/ruby-2.1.0/gems/railties-4.1.0.beta1/lib/rails/commands/console.rb:9:in `start\'\r\n\tfrom /Users/bugagazavr/.rvm/gems/ruby-2.1.0/gems/railties-4.1.0.beta1/lib/rails/commands/commands_tasks.rb:69:in `console\'\r\n\tfrom /Users/bugagazavr/.rvm/gems/ruby-2.1.0/gems/railties-4.1.0.beta1/lib/rails/commands/commands_tasks.rb:40:in `run_command!\'\r\n\tfrom /Users/bugagazavr/.rvm/gems/ruby-2.1.0/gems/railties-4.1.0.beta1/lib/rails/commands.rb:17:in `<top (required)>\'\r\n\tfrom bin/rails:4:in `require\'\r\n\tfrom bin/rails:4:in `<main>\'\r\n```\r\n\r\nBecause selectel cloud send me `data.body` as string, not array\r\n\r\n```\r\n>> id.directories.get(\'awesome\', :preffix => \'system\')\r\n#<Excon::Response:0x007fa8dd463d58\r\n @body=\r\n  "[{\\"hash\\": \\"b996ceaba5a3f8ba5c18131062380436\\", \\"last_modified\\": \\"2014-01-15T18:12:06.865730\\", \\"bytes\\": 295, \\"name\\": \\"system/member/photo/12/test.png\\", \\"content_type\\": \\"image/png\\"}]",\r\n```\r\n\r\nThis is a small fix that allows you to convert a string into an array if it is not.'
2576,'','[vcloud_director] fix media type in post_upload_vapp_template\n'
2575,'tokengeek',"Update Nokogiri version\nPlease check http://www.osvdb.org/show/osvdb/101458. Nokogiri Version 1.5.11 should be installed. I didn't had time to run tests on this."
2574,'','Update rubygems to fix travis in ruby 1.8\n'
2573,'','[google] Expose Google API client, compute and api_url for easier debugging\n'
2572,'','Rackspace/examples; cloudfiles directory is set to public, therefore fil...\n...e is accessible.'
2571,'','Added OpenStack support for add/remove_security_group functionality\nTalked about this at https://github.com/fog/fog/issues/2557'
2570,'','s3 region can\'t set to "sydney"\ns3 region can\'t set to "sydney".\r\n\r\nMy s3 bracket\'s region is Sydney. But in fog, I can only use default region \'us-east-1\' to get it works. If I set it to "sydney", it will give me error `getaddrinfo: The requested name is valid, but no data of the requested type was found.  (SocketError)`\r\n\r\nActually, does it matter to set a inaccurate region? Will that affect performance?'
2569,'','Check if security group is nil, fixes #2507\nCheck if security group is nil, fixes #2507\r\n\r\ncc: @geemus '
2568,'','[dnsimple] make get_domain also match to domain name\nAs the real DNSimple behaviour, `get_domain` also accept a string argument to get an specific domain, but using the mocked behaviour, only passing the `id` is allowed.\r\n\r\nThe idea is to match against both `id` and `name` when calling to `get_domain`.\r\n\r\n```\r\n[1] pry(main)> require \'fog/dnsimple\' \r\n[2] pry(main)> dnsimple = Fog::DNS.new(:provider => "DNSimple", :dnsimple_email => \'test@example.com\', :dnsimple_password => \'mypassword\')\r\n[3] pry(main)> dnsimple.zones.get(\'wadus.me\')\r\n=>   <Fog::DNS::DNSimple::Zone\r\n    id=1969,\r\n    domain="wadus.me",\r\n    created_at="2011-02-28T09:49:56Z",\r\n    updated_at="2014-01-10T15:16:32Z"\r\n  >\r\n[4] pry(main)> dnsimple.zones.get 1969\r\n=>   <Fog::DNS::DNSimple::Zone\r\n    id=1969,\r\n    domain="wadus.me",\r\n    created_at="2011-02-28T09:49:56Z",\r\n    updated_at="2014-01-10T15:16:32Z"\r\n  >\r\n```'
2565,'','[OpenStack] Fixed formatting errors\n'
2564,'',"Fixes for AWS Mocking\nWas writing some unit tests for code that uses AWS 'associate_address' method... found issues in mock code.\r\n\r\nlib/fog/aws.rb\r\nPreviously chose 4xRandom numbers between 0 and 999, now uses the Mock random_ip which returns numbers that will be within acceptable number range.\r\nOld method was returning invalid numbers that then failed to pass range checks.\r\n\r\nlib/fog/aws/requests/compute/associate_address.rb\r\nRe-fetch address if we have to look up public-ip using allocation-id, otherwise it remains nil and the ip-address/instance aren't updated correctly.\r\n\r\nlib/fog/aws/requests/compute/describe_addresses.rb\r\nThe allocate-address request uses allocation-id to look up ip address if allocation-id is given instead of public-ip, so added that as searchable in mock data."
2563,'','Support for new HVM-based instance types on Amazon EC2\nSimply added the following new instance types (all SSD) to the AWS flavors hash:\r\n\r\ni2.xlarge\r\ni2.2xlarge\r\ni2.4xlarge\r\ni2.8xlarge\r\ncr1.8xlarge'
2562,'','[openstack|compute] Adding compute docs\nAdding compute docs'
2561,'',"[OpenStack] Getting Started Guide\nPorts the Rackspace Getting Started Guide to OpenStack.\r\n\r\n(Don't mind the source branch name)"
2560,'','[OpenStack] Ported fog Rackspace storage docs to OpenStack\n'
2557,'','A way to update security groups on instance in OpenStack?\nI\'ve been looking around, and there doesn\'t seem to be any real option for doing this (unless it\'s hidden, or I am not good at looking).  \r\n\r\nIs there a way that I can update the security groups on a running instance?  I have been trying to do server.security_groups = groups, which doesn\'t actually seem to update the security_groups.  When I do a  server.security_groups afterwards, nothing has been updated.\r\n\r\nI\'ve also tried doing something like @service.update_server(server_id, {"security_groups"=>groups}, but I get a "Segmentation fault (core dumped)" issue when I do that.  \r\n\r\nAm I doing something wrong, or is there currently no way of doing this?'
2556,'icco','[google|storage] Add put_object_acl request\nThis PR adds `put_object_acl` request method (similar with `put_bucket_acl` request in #2555). I tested it with following code:\r\n```ruby\r\nrequire \'./lib/fog/google\'\r\n \r\nstorage = Fog::Storage::Google.new(...)\r\n \r\ncurrent_acl = storage.get_object_acl(\'acl-test-12312312323\', \'test\').body\r\n \r\nnew_acl = current_acl\r\nnew_acl[\'AccessControlList\'].push(\r\n  {"Scope" => {"type" => \'AllUsers\'}, "Permission"=> \'READ\'}\r\n)\r\n \r\nstorage.put_object_acl(\'acl-test-12312312323\', \'test\', new_acl)\r\n```\r\n\r\nBTW, after #2509 will be accepted, I plan to move methods that are similar with `put_bucket_acl` [request](https://github.com/allomov/fog/blob/47f5a04c3e3e7fd43e4c1482f7a515c59bc61c0a/lib/fog/google/requests/storage/put_bucket_acl.rb) to [requests helper](https://github.com/allomov/fog/blob/4574ff45b64002a8b9f2c7fcd9eedf9b54a702f1/lib/fog/google/helpers/requests_helper.rb).\r\n\r\nBest wishes :boy:'
2555,'icco','[google|storage] Fix put_bucket_acl request\nI don\'t see how `put_bucket_acl` request could work before and rewrote it using [current documentation for ACLs](https://developers.google.com/storage/docs/accesscontrol#About-Access-Control-Lists). I tested it with following code: \r\n```ruby\r\nrequire \'./lib/fog/google\'\r\n \r\nstorage = Fog::Storage::Google.new(...)\r\n \r\ncurrent_acl = storage.get_bucket_acl(\'acl-test-12312312323\').body\r\n \r\nnew_acl = current_acl\r\nnew_acl[\'AccessControlList\'].push({"Scope" => {"type" => \'AllUsers\'}, "Permission"=> \'READ\'})\r\n \r\nstorage.put_bucket_acl(\'acl-test-12312312323\', new_acl)\r\n```'
2554,'',"[google] Fix get_bucket_acl request method in Google Cloud Storage\nThis PR fixes `get_bucket_acl` method visibility :\r\nBefore:\r\n```ruby\r\nrequire './lib/fog/google' \r\nstorage = Fog::Storage::Google.new(...) \r\nstorage.methods.grep(/^get_b/)       # => [:get_bucket]\r\n```\r\nAfter:\r\n```ruby\r\nrequire './lib/fog/google' \r\nstorage = Fog::Storage::Google.new(...) \r\nstorage.methods.grep(/^get_b/)       # => [:get_bucket, :get_bucket_acl]\r\n```\r\n"
2553,'',"Document: error in ruby-libvirt dependency description\nhttps://github.com/fog/fog/blob/master/lib/fog/libvirt/models/compute/README.md\r\n\r\n - the interaction with libvirt is done through the official libvirt gem called 'libvirt-ruby'.\r\n + the interaction with libvirt is done through the official libvirt gem called 'ruby-libvirt'.\r\n\r\nofficial libvirt gem is ruby-libvirt."
2552,'','How to add libvirt dependency from another gemspec?\nafter v1.17.0 there is a commit\r\nhttps://github.com/fog/fog/commit/77d17085f22f9bb2472f511653cb4e6a23f3227c#diff-ebc7a16e41d6b42010f22cf407abfec8\r\n\r\nIt require another gem which depends on fog to add environment variable to add_runtime_dependency.\r\n\r\nIt is an issue in vagrant-libvirt project, that is fog/libvirt driver plugin on vagrant.\r\nhttps://github.com/pradels/vagrant-libvirt/pull/88\r\n\r\nA question is \r\n"How to add libvirt dependency  from another package with keeping users not to know dependency details?"\r\n\r\nI can not find a document to say an answer.\r\nhttps://github.com/fog/fog/blob/master/lib/fog/libvirt/models/compute/README.md'
2551,'',"[Rackspace] Monitoring pagination fix\nMonitoring-specific soluton to pagination. 'marker' was being extracted but not stored.\r\n\r\nCloses #2469\r\n\r\nWe could still use a more generic pagination solution. Started looking at this a little this afternoon."
2550,'','Fog is loading more classes than necessary\nI wrote a simple script to test Rackspace Monitoring pagination. Then I added a little code at the bottom to check which Fog classes were loaded:\r\n\r\n```ruby\r\nclasses = []                                                                                                                                                                                                                                                                                                                \r\nObjectSpace.each_object do |o|                                                                                                                                                                                                                                                                                              \r\n  next unless o.is_a?(Module)                                                                                                                                                                                                                                                                                               \r\n  name = o.to_s                                                                                                                                                                                                                                                                                                             \r\n  next unless name =~ /^Fog/                                                                                                                                                                                                                                                                                                \r\n  classes << name                                                                                                                                                                                                                                                                                                           \r\nend                                                                                                                                                                                                                                                                                                                         \r\nclasses.sort!                                                                                                                                                                                                                                                                                                               \r\n                                                                                                                                                                                                                                                                                                                            \r\nFile.open("loaded_classes.txt", "w") do |f|                                                                                                                                                                                                                                                                                 \r\n  classes.each do |c|                                                                                                                                                                                                                                                                                                       \r\n    f.write("#{c}\\n")                                                                                                                                                                                                                                                                                                       \r\n  end                                                                                                                                                                                                                                                                                                                       \r\nend\r\n```\r\n\r\nIt turns out that there are a ***lot*** of classes being loaded that aren\'t needed (946 total though how many of those are superfluous for this particular task, I cannot say). For instance, I\'m seeing HP and AWS classes loaded.\r\n\r\nWhen I go into pry, it looks like the request methods haven\'t been loaded.  That is, I don\'t see any of the requests specified in network.rb on <code>Fog::HP::Network.instance_methods(false)</code>.\r\n\r\nEven so, fog should probably be using autoload throughout.\r\n\r\nAs data points, [cloud-queues](https://github.com/adregner/cloud-queues) was written specifically because the author didn\'t want a large footprint. Also, there was [this StackOverflow question from last week](http://stackoverflow.com/questions/20913518/build-fog-gem-with-just-required-providers-and-limit-dependencies/20914797#20914797).\r\n\r\nThere seems to be some anecdotal demand to slim down Fog.'
2549,'','Return Private IPs in an array using AWS Describe Network Interface\nPreviously if there were more than one private ip on an elastic network interface, the value would be overwritten by each subsequent private ip. This returns the group as an array.'
2547,'','AWS SQS signature mismatch and Excon warning fixes\nAttempting to perform SQS operations in 1.19.0 fails with the following error because commit 8c5ea5d removes the `host` and `port` needed to generate the signature correctly:\r\n\r\n```\r\n#<Excon::Response:0x007fdfcdecdb78 @data={:body=>"<?xml version=\\"1.0\\"?><ErrorResponse xmlns=\\"http://queue.amazonaws.com/doc/2009-02-01/\\"><Error><Type>Sender</Type><Code>SignatureDoesNotMatch</Code><Message>The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.</Message><Detail/></Error><RequestId>3c3fbde1-cc14-5255-9d5d-f6a76af4f112</RequestId></ErrorResponse>", :headers=>{"Server"=>"Server", "Date"=>"Wed, 08 Jan 2014 01:06:40 GMT", "Content-Type"=>"text/xml", "Content-Length"=>"436", "Connection"=>"close", "x-amzn-RequestId"=>"3c3fbde1-cc14-5255-9d5d-f6a76af4f112"}, :status=>403, :remote_ip=>"72.21.202.145"}, @body="<?xml version=\\"1.0\\"?><ErrorResponse xmlns=\\"http://queue.amazonaws.com/doc/2009-02-01/\\"><Error><Type>Sender</Type><Code>SignatureDoesNotMatch</Code><Message>The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.</Message><Detail/></Error><RequestId>3c3fbde1-cc14-5255-9d5d-f6a76af4f112</RequestId></ErrorResponse>", @headers={"Server"=>"Server", "Date"=>"Wed, 08 Jan 2014 01:06:40 GMT", "Content-Type"=>"text/xml", "Content-Length"=>"436", "Connection"=>"close", "x-amzn-RequestId"=>"3c3fbde1-cc14-5255-9d5d-f6a76af4f112"}, @status=403, @remote_ip="72.21.202.145">\r\n```\r\n\r\nI\'ve rolled back that commit and removed `host` from the request args being passed to Excon, which was generating a warning.\r\n\r\nRelated to https://github.com/fog/fog/issues/2284'
2546,'',"[aws|fog] Don't pass :host to Excon request\nSee issue #2284"
2545,'','Changed openstack server model to build security group objects without generating deprication warning messages\n'
2544,'','[rackspace|compute_v2] updates key_pair model to pass additional attributes\nupdates key_pair model to pass additional attributes onto compute service. (You can now pass public and private keys via the model)'
2543,'','Pass params necessary to upload key pairs.\nThe original implementation did not pass the required attributes to upload\r\nan existing key pair up to the API. This commit addresses that problem\r\nwhile maintaining backwards compatibility. The 2nd argument was changed\r\nfrom a string to a hash, a deprecation warning is generated.'
2542,'icco',"[google] Disk.ready? should not reload the data\nit's done in wait_for in other models and providers"
2539,'','[cloudstack] Add models and requests to support CloudStack advanced network API\nAdd models and requests to support CloudStack advanced network API, which should be used in Cloud Foundry BOSH-CloudStack-CPI project. Most of these features belong to ClousStack API 4.0.x\r\n\r\nThese features include firewall management, associating IP address to vm, enabling static nat, and vlan ip range management etc.\r\n\r\nFiles affected:\r\n\r\nlib/fog/cloudstack/models/compute/firewall.rb\r\nlib/fog/cloudstack/models/compute/firewalls.rb\r\nlib/fog/cloudstack/models/compute/ipaddress.rb\r\nlib/fog/cloudstack/models/compute/ipaddresses.rb\r\nlib/fog/cloudstack/models/compute/key_pair.rb\r\nlib/fog/cloudstack/models/compute/key_pairs.rb\r\nlib/fog/cloudstack/models/compute/nat.rb\r\nlib/fog/cloudstack/models/compute/nats.rb\r\nlib/fog/cloudstack/models/compute/network.rb\r\nlib/fog/cloudstack/models/compute/networks.rb\r\nlib/fog/cloudstack/models/compute/ostype.rb\r\nlib/fog/cloudstack/models/compute/ostypes.rb\r\nlib/fog/cloudstack/models/compute/vlan.rb\r\nlib/fog/cloudstack/models/compute/vlans.rb\r\nlib/fog/cloudstack/requests/compute/associate_ip_address.rb\r\nlib/fog/cloudstack/requests/compute/copy_template.rb\r\nlib/fog/cloudstack/requests/compute/create_firewall_rule.rb\r\nlib/fog/cloudstack/requests/compute/create_tags.rb\r\nlib/fog/cloudstack/requests/compute/create_template.rb\r\nlib/fog/cloudstack/requests/compute/create_vlan_ip_range.rb\r\nlib/fog/cloudstack/requests/compute/delete_tags.rb\r\nlib/fog/cloudstack/requests/compute/delete_vlan_ip_range.rb\r\nlib/fog/cloudstack/requests/compute/disable_static_nat.rb\r\nlib/fog/cloudstack/requests/compute/disassociate_ip_address.rb\r\nlib/fog/cloudstack/requests/compute/enable_static_nat.rb\r\nlib/fog/cloudstack/requests/compute/list_tags.rb\r\nlib/fog/cloudstack/requests/compute/list_vlan_ip_ranges.rb\r\ntests/cloudstack/requests/assosiate_ip_address_tests.rb\r\ntests/cloudstack/requests/create_vlan_range_tests.rb\r\ntests/cloudstack/requests/delete_vlan_range_tests.rb\r\ntests/cloudstack/requests/disable_static_nat_tests.rb\r\ntests/cloudstack/requests/disassosiate_ip_address_tests.rb\r\ntests/cloudstack/requests/enable_static_nat_tests.rb\r\ntests/cloudstack/requests/list_vlan_range_tests.rb'
2538,'',"add aws storage multipart upload mocks\nAre there tests for the mocks themselves? I couldn't find any but I might've missed them. Apologies, I'm new to Fog."
2537,'','[vcloud_director] configuring dhcp service in edgegateway\n'
2536,'','Default region deprecation\nIssues a deprecation warning if the Rackspace Fog user is relying on the existing default region.'
2535,'icco','[google|compute] more additions and corrections\n'
2534,'icco','[google|compute] Add rhel-cloud to project search list\n'
2533,'icco','[google|compute] auth needs additional scope to insert images\n'
2532,'','Remove duplicate entries\nI have several entries due to multiple SSH keys!'
2531,'','[vcloud_director] missing post_capture_vapp functionality\n'
2530,'','[vcloud_director] Implement post_create_catalog_item\n'
2529,'','add attach and detach disk\n'
2527,'',"Dynect Record and Zone put requests are idempotent.\nDynect's Record and Zone put requests are idempotent and should be flagged as such to allow excon to retry the requests."
2526,'','[digitalocean|compute] Set scrub data to true for all server destroy requests\nThis should fix https://github.com/fog/fog/issues/2525.'
2525,'','Digital Ocean API is not told to scrub (securely delete) VM on destroy\nMajor security issue: the Digital Ocean API has a parameter on the destroy call to securely scrub the root blockdev on VM destroy, preventing future customers from reading the data left on disk by your VM.\r\n\r\nThis is surely a digitalocean security issue, but they\'re passing it on to users by making it a parameter - rather shitty of them.  This is documented in their API at https://cloud.digitalocean.com/api_access - see "scrub_data".\r\n\r\nFog does not pass this parameter, leaving Fog-destroyed VMs vulnerable to later customers stealing the data contained on them.'
2524,'','Bundler causing test fails for 1.8.7\nIt looks like all 1.8.7 tests are failing (https://travis-ci.org/fog/fog/builds/16099974). http://bundler.io/compatibility implies that bundler still works with 1.8.7...\r\n\r\nAny thoughts @geemus?'
2523,'icco','[google|compute] Improve support for Tags, Addresses, Snapshots\n Some additions to help get the google compute support up to complete v1 support. Specifically I added delete snapshot, address support, tag support for firewalls and setTag for instances. Still more to do to get to complete v1 support. But I like the google compute api. It is very clean and straightforward.  Sorry i did not do mocks....'
2522,'','[aws] mock setup block device deleteOnTermination\n'
2521,'','[Cloudsigma | Compute]\nThe create method seems to be having issues.  These are not happening in mock mode so I\'m guessing that something behind the scenes has changed.\r\n\r\nusing ruby1.9.1 and fog gem 1.19\r\n\r\nIssued this in mock\r\n conn = Fog::Compute.new(\r\n    :provider => \'cloudsigma\',\r\n    :cloudsigma_username => \'cloudsigmaaccount@example.com\',\r\n    :cloudsigma_password => \'example123\',\r\n\t:cloudsigma_host => \'lvs.cloudsigma.com\' )\r\n\t\r\nserver = conn.servers.create :name => "Fogfabric - #{Time.now().to_i}", \r\n:cpu => \'2000\', \r\n:mem => \'2147483648\', \r\n:vnc_password => \'foobar\'\r\n\r\nthen took mock off and put in my real account/password for conn and got the following...\r\nirb(main):007:0> server = conn.servers.create :name => "Fogfabric - #{Time.now().to_i}",\r\nirb(main):008:0* :cpu => \'2000\',\r\nirb(main):009:0* :mem => \'2147483648\',\r\nirb(main):010:0* :vnc_password => \'foobar\'\r\nNoMethodError: undefined method `first\' for "":String\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/error.rb:31:in `slurp_http_status_error\'\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/connection.rb:58:in `rescue in request\'\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/connection.rb:53:in `request\'\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/connection.rb:98:in `create_request\'\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/requests/create_server.rb:6:in `create_server\'\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/models/server.rb:44:in `create\'\r\n        from /home/ubuntu/fog/lib/fog/cloudsigma/models/server.rb:36:in `save\'\r\n        from /home/ubuntu/fog/lib/fog/core/collection.rb:52:in `create\'\r\n        from (irb):7\r\n        from /usr/bin/irb:12:in `<main>\'\r\n\r\nI did a fetch to pull the latest main.\r\n\r\nThe fog gem stand alone DOES work in the way that cloudsigma shows in their fog.io documentation\r\n\r\n'
2520,'','[aws] mock block device mapping on run_instances\nset up volumes based on block device mappings provided in the `#run_instances` call'
2519,'','Fix DhcpOption#associate\nThis is calling the wrong API method.\r\n\r\n@geemus'
2518,'','Fix subnet mocking, related to #2510\nSubnet mocking would return a set of all the current subnets on create (incorrectly) and thus when .first is called, the wrong subnet would be return for all but the first subnet created.\r\n\r\nAs a result, this left ``self.data`` in a bad state, and would cause the Network ACL tests to fail randomly depending on test ordering.\r\n\r\nThanks to @fcheung for finding a test that would cause this failure consistently. \r\n\r\n@reemus\r\n\r\nRelated to #2510'
2517,'',"[digitalocean|compute] Allow bootstrapping with keys rather than paths\nAllows specifying public_key and private_key instead of public_key_path and private_key_path. Useful for Heroku where you don't have direct access to the filesystem and need to specify keys in environment variables."
2516,'','[storm_on_demand] don\'t pass host to request\nsame issue as https://github.com/fog/fog/issues/2248\r\n\r\nThis gets rid of the warning "[excon][WARNING] Invalid Excon request keys: :host"  when making requests with storm_on_demand'
2515,'','[digitalocean|compute] Add created_at timestamp as attribute of server\nI recently switched an app from EC2 over to Digital Ocean and one of the differences in the API was that EC2 instances returned a `created_at` field on the `Server`, whereas Digital Ocean did not. After digging into the raw response Digital Ocean sends back, it turns out all we need to do is add the field as an attribute of the `Server` and it all just works.\r\n\r\nExample:\r\n```ruby\r\n2.0.0p247 :002 > fog.servers.get(567)\r\n =>   <Fog::Compute::DigitalOcean::Server\r\n    id=567,\r\n    name="name",\r\n    state="active",\r\n    image_id=12345678,\r\n    region_id=4,\r\n    flavor_id=66,\r\n    public_ip_address="1.2.3.4",\r\n    private_ip_address=nil,\r\n    backups_active=false,\r\n    created_at="2013-12-06T13:54:06Z"\r\n  > \r\n```'
2514,'','[AWS|EC2] request_spot_instances.rb requires that date parameters be iso...\nFix for #2465 \r\n\r\n`Time#iso8601` does appear to be in 1.8.7 after all http://ruby-doc.org/stdlib-1.8.7/libdoc/time/rdoc/Time.html#method-i-iso8601'
2513,'','drop dependency on deprecated ruby-hmac gem, fixes #2034\nRuby 1.8 compiled against OpenSSL 0.9.8 supports SHA256 for some time now.\r\nRef: https://github.com/ruby/ruby/blob/ruby_1_8_7/ChangeLog#L12025-L12029'
2512,'','ignore more Ruby version manager files\nBoth rbenv and rvm now generate some files that have no bearing on\r\nthe project, and leave the local repo in a dirty state.'
2511,'','Add Ruby 2.1.0 to the test matrix\n'
2510,'','failing network acl tests on travis.\n@drcapulet - this travis failure (https://travis-ci.org/fog/fog/jobs/15987405#L1068) seems likely to be related to your recent ACL work, could you take a look?'
2509,'icco','[google] Fix Google Engine tests\nGoogle Engine live tests fail after v1 update. More fixes coming.'
2508,'',"Make test output more verbose if Provider is not available for live tests.\nI had some time to manage that \r\n\r\nLive tests are passing in case when service is unavailable. For instance you've put wrong key name into `.fog` file and when you ran `bundle exec rake live[<provider>]` tests always pass. The only thing you can see is a warning \r\n```\r\nSkipping tests for <provider> due to lacking credentials \r\n(add some to '.../fog/tests/.fog' to run them)\r\n``` \r\nThere are ~30 similar lines there and I'm not sure every one are reading them. I've spent some time to understand what is wrong and I think this situation needs more verbose output. \r\n"
2507,'','[AWS|Compute] groups throws undefined method `ip_permissions\' when bootstraping a server\nIn Mock mode, trying to bootstrap group option leads to undefined method error:\r\n\r\n```ruby\r\n> fog                                                 \r\n  Welcome to fog interactive!\r\n  :default provides AWS, BareMetalCloud, Bluebox, Brightbox, Clodo, Cloudstack, DNSMadeEasy, DNSimple, Dreamhost, GoGrid, HP, IBM, Linode, Local, OpenStack, Openvz, Ovirt, Rackspace, RiakCS, Voxel, Vsphere and Zerigo\r\n>> Fog::mock!\r\ntrue\r\n>> compute = Fog::Compute.new provider: \'AWS\', region: \'us-east-1\', aws_access_key_id: ACCESS_KEY,\r\n                aws_secret_access_key: SECRET_ACCESS_KEY\r\n#<Fog::Compute::AWS::Mock:0x8d347c8 @use_iam_profile=nil, @aws_credentials_expire_at=2013-12-26 12:49:46 +0530, @aws_access_key_id="XXXXXXXXXXXX", @region="us-east-1">\r\n>> compute.servers.bootstrap groups: [\'security_group_name\']\r\nNoMethodError: undefined method `ip_permissions\' for nil:NilClass\r\n\tfrom /home/gaurish/.rvm/gems/ruby-2.1.0/gems/fog-1.19.0/lib/fog/aws/models/compute/servers.rb:90:in `bootstrap\'\r\n\tfrom (irb):3:in `<top (required)>\'\r\n\tfrom /home/gaurish/.rvm/gems/ruby-2.1.0/gems/fog-1.19.0/bin/fog:76:in `block in <top (required)>\'\r\n\tfrom /home/gaurish/.rvm/gems/ruby-2.1.0/gems/fog-1.19.0/bin/fog:76:in `catch\'\r\n\tfrom /home/gaurish/.rvm/gems/ruby-2.1.0/gems/fog-1.19.0/bin/fog:76:in `<top (required)>\'\r\n\tfrom /home/gaurish/.rvm/gems/ruby-2.1.0/bin/fog:23:in `load\'\r\n\tfrom /home/gaurish/.rvm/gems/ruby-2.1.0/bin/fog:23:in `<main>\'\r\n```\r\n\r\nThis only occurs in mock mode, Real works fine'
2506,'',"[AWS][Compute] user_data doesn't handle zip files, crashes with Fog::JSON::EncodeError\nI am trying to provision an ec2 instance using fog, here is the code that I am using:\r\n\r\n```ruby\r\n    compute = Fog::Compute.new provider: 'AWS',\r\n                region: 'us-east-1', aws_access_key_id: ACCESS_KEY,\r\n                aws_secret_access_key: SECRET_ACCESS_KEY\r\n    options = {\r\n              image_id: 'ami-xxxxxx',\r\n              flavor_id: 'm1.small',\r\n              #custom security group created in AWS Account with open ports\r\n              groups: ['myGroup'],\r\n              private_key_path: '~/.ssh/id_rsa',\r\n              public_key_path: '~/.ssh/id_rsa.pub',\r\n              username: 'ec2-user',\r\n              user_data: File.read(Rails.root.join('public', 'somefile.zip'))\r\n            }\r\n    compute.servers.bootstrap options\r\n```\r\n\r\nWhen, I run this. I get following error:\r\n\r\n```ruby\r\n    Fog::JSON::EncodeError: string contains null byte\r\n```\r\n\r\nAs you may notice, above. I am supplying a ZIP file for `user_data` option. And this is what I think the problem occurs.\r\n\r\nso the solution is to open the file in binary mode & manually apply Base64 encoding\r\n\r\n```ruby\r\nfile = File.open(path, 'rb') #path => path to zip file\r\ncontents = file.read\r\nfile.close\r\nuser_data = Base64.encode64 contents\r\n```\r\n\r\nnow, this user_data can be safely passed into options[:user_data] hash without null byte errors. This is issue on which there is little documentation, so I had to scan the source code which has time consuming. so hoping this can be fixed.\r\n\r\n\r\n**Version:** `Fog v1.19`"
2505,'',"fix error - 'invalid excon request keys: :host' for bluebox\nrelated to #2248"
2504,'','Fixing defect with handling of multiple <item> \nFixing defect with handling of multiple <item> elements in reponse to describe-reservations'
2503,'icco','[google|compute] Rescue from Fog::Errors::NotFound instead of Excon\nUse Fog::Errors::NotFound as raised by build_excon_response'
2500,'',"[aws|elb] Mimic real behavior in create_load_balancer mock\nThis PR mimics the behavior like the real one, as a availability_zones can be nil on real class and not in mock class.\r\n\r\nAt this moment, I ran into an error in `availability_zones.first.gsub(/[a-z]$/, '')` in a Chef elb cookbook that assumes availability_zones as an optional argument, so its default value it's `nil`.\r\n\r\nI tried to write a spec to catch this behaviour, but it was difficult to me."
2499,'','refactor DataPipeline format conversion, allowing for arrays of refs\n@kbarrette'
2498,'',"[Rackspace | Storage] Mocks for the Storage service\nHello! I've created mocks for all of the Rackspace Storage requests, as well as mocking the Identity service's `create_token` request and a little adjustment in the CDN service to support them. I now get a clean run of all tests in `tests/rackspace/requests/storage/`, `tests/rackspace/models/storage/`, and `tests/rackspace/storage_tests.rb` with all of the `pending if Fog.mocking?` guards removed."
2497,'',"[Rackspace | Compute] 1.8.7 fix plus better passwd -l handling\nBroke 1.8.7 test suite (parsing error) with my previous PR. This fixes that.\r\n\r\nAlso, new servers that have been passwd -l'd now return nil for their password.\r\n\r\n"
2496,'','Reject unnecessary methods creation in Core Collection \n@geemus what do you think about such approach? It is going to save time on method creation/removing.'
2495,'','Rackspace: nil the password field on a Server when passwd locking the server\n'
2494,'icco','Update to Google Compute Engine API v1\nplus some disk goodies'
2493,'','[xenserver] Fixed misspelling\nFixed misspeling at StorageManager class.'
2492,'','Rackspace: Root lock server by default unless specified otherwise\nDo a "passwd -l root" by default unless the user specifically asks to leave the password unlocked.'
2491,'','[vcloud_director] add Mock for post_create_network, improve Mock tests\n* Hopefully resolves #2489 since we are no longer futzing with the pre-existing networks in the Mock data.\r\n\r\n'
2490,'','Add support for AWS VPC Network ACLs\nThis adds in complete support for network ACLs on AWS VPCs, related to #1721'
2489,'','[vcloud_director] edge gateway failure on CI\nhttps://travis-ci.org/fog/fog/jobs/15643275#L533\r\n\r\n@nosborn @restebanez - looks like one of the recent merges broke some testing here, could one of you take a peak and see if you could help us sort this out?'
2488,'','[vcloud_director] s/@end_point/end_point/\n'
2487,'','[vcloud_director] fix to input format for post_create_org_vdc_network\nNoticed error in input format surrounding IpRanges, where input missing the IpRange elements (instead was just created in Generator)'
2486,'','[AWS] Add Assign Private IPs\nAdd ability to assign private ips to an elastic network interface on AWS. Not quite sure about the tests, so I would be happy to update if there are any suggestions for improving. '
2485,'','[vcloud_director] post_create_org_vdc_network\nAllows creation of an OrgVdcNetwork in isolated or natRouted mode.\r\n\r\nI have Mock code available for this too, but wanted to keep this pull req simple and add that later.\r\n\r\n\r\n'
2484,'','Added option to create readonly attributes\nAdded option to Create readonly attributes.'
2483,'','Update S3 ACL whitelist\n@geemus\r\n\r\nUpdates the S3 ACL whitelist to include all values documented here: http://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html'
2482,'',"use Excon :persistent option\nExcon now has a `:persistent` option, which is `false` by default.\r\nFog was already non-persistent by default, however this will change some behavior.\r\n\r\nFog was closing the socket (if it existed) _before_ making the request, then leaving it open.\r\nNow the socket will be closed _after_ a non-persistent request.\r\nThe request will also include `Connection: close` to notify the server.\r\n\r\nThis means that a non-persistent request made _after_ a persistent request\r\nwould use the persistent socket (if one exists), then close it.\r\nThis is consistent with the new Excon behavior.\r\nIf you'd rather continue to call `reset` _before_ non-persistent requests, just let me know.\r\n"
2481,'','vApp rename via put_vapp_name_and_description\n* Adds the elusive PUT-vAppNameAndDescription request.\r\n* Tested ok externally, but risky to test against current non-Mock tests.\r\n* Mocks to come later, getting ducks in row before getting basic vapp/vm Mock framework together. \r\n\r\n/cc @nosborn '
2480,'','ignore .ruby-version\n'
2479,'','[vcloud_director] Add delete_network request\n'
2478,'','Vcloud director get execute query mock\nFind all and by-name Mock for Query API orgVdcNetwork\r\n* Just for OrgVdcNetwork for now\r\n* Be clear about what options/queries are unimplemented\r\n* Expand tests to cover mocks\r\n* comment to explain gnarly test logic\r\n* :page=1 results handled'
2477,'','[general] Allow default wait_for interval to be overriden globally.\nAllow overriding wait_for interval globally the same way as timeout.'
2476,'','Release Gem Version\nHey guys, can you release a new gem version?\r\n\r\nThanks!'
2475,'',"[xenserver] Adding more XenServer Models\nIn this pull request i've added a few models (Blob, Bond, CrashDump, DrTask, GpuGroup, HostCrashDump and HostPatch)\r\n\r\nThere are more to come. =D"
2474,'',"Add exponential backoff to Google Compute Engine's backoff_if_unfound.\nEven with backoff_if_unfound, I frequently see Fog::Errors::NotFound when creating a GCE instance.  For me, this happens most often in europe-west1-b, about 50% of the time; I see the same thing, but less often, in us-central zones.  Adding an exponential backoff factor to backoff_if_unfound resolved this issue for me.\r\n\r\nI arrived at a backoff factor of 1.6 by finding the minimum value at which the existing value of up to 10 retries would reliably succeed for me.  It's unclear to me if the Fog::Errors::NotFound errors occur because of (my lack of) physical proximity - I'm on the west coast of the United States - or if there's something unique about europe-west1-b.  As such, the backoff factor and retry count may need adjustment for other users."
2473,'','Use OpenSSL::Digest instead of deprecated OpenSSL::Digest::Digest\nOpenSSL::Digest::Digest has been discouraged to use from very ancient era such as Ruby 1.8 https://github.com/ruby/ruby/blob/ruby_1_8_7/ext/openssl/lib/openssl/digest.rb#L51\nand finally was deprecated recently. https://github.com/ruby/ruby/pull/446'
2472,'',"[xenserver] Updated models to have all attributes from version 6.2.0\nIn this pull request, i've added all the missing attributes for xenserver version 6.2.0.\r\n\r\nIn the next ones, i will add the missing models, update the reference methods to return the object instead of the reference and define some missing methods as well.\r\n\r\nI'm breaking it in smaller pull requests, so this is the first one."
2471,'','Allow custom Mock.not_implemented message\nFor Mock mode in vcloud_director/.../get_execute_query.rb (and others), we can only feasibly mock certain operations. This pull req will allow us to communicate to the user what is not implemented and why.'
2470,'',"[aws|rds] Support Iops parameter\nAllow an RDS instance to be provisioned with an amount of provisioned IOPS.\r\n\r\nI didn't see an obvious place where this should be tested, please let me know if I need to add tests for this."
2468,'','Queue started\n'
2467,'','Fixed bug in XenServer console\n There is not __consoles attribute in server model. When renamed to consoles, it worked perfectly! \r\n\r\nAfter that, renamed consoles method to get_consoles, to not overwrite consoles attribute.'
2466,'','Add ready? method to aws VPC and Subnet models\n'
2465,'',"[aws|ec2] request_spot_instances does not coerce time parameters\nI noticed today that `request_spot_instances`, which takes 2 time options ('ValidUntil', 'ValidFrom') requires the caller to do\r\n\r\n    compute.request_spot_instances 'some_ami', 'm1.small', 0.05, 'ValidUntil' => some_time.iso8601\r\n\r\nthat is, the onus is on the caller to turn date/times into the string format required by aws. \r\n\r\nThis feels wrong to me (and I think it means that the `spot_request` model) is also wrong in this respect.\r\n\r\nI'm very happy to just fix `request_spot_instances`, but I was wondering whether this is something that should be done more systematically. For example, should AWS::Real#request walk the params hash and convert any instances of Time?"
2464,'','[vcloud_director] Fix Guest admin password settings\nThese patches fix some missing points in the way guest customizations are handled.\r\nCommit messages should be quite clear, but to sum up:\r\n* setting "admin password auto" was retrieved but not shown\r\n* "admin password" handling was partially implemented (i.e., was not retrieved and never set in .save)\r\n\r\nWith these fixes is now possible to do with fog the same operations allowed by the VMWare console.'
2463,'','ecloud api version bump\nfixes #2451'
2462,'','openstack modifications\n* add model and collection for security group rules\r\n* add mock data for networks\r\n* returns address in create_server mock\r\n* proper security group rule mocks\r\n* proper security group mocks'
2461,'','Modified AWS S3 mock, so that it errors when creating an existing bucket\nAWS S3 returns a BucketAlreadyOwnedByYou error when attempting to create a bucket that already exists, in a region other than the default. This commit modifies the mocked object to reflect this. See the issue in more detail here: https://github.com/fog/fog/issues/2446'
2460,'',"[google] Implement operation model\nCheck that server and disk destroy operation starts successfully\r\nImplement get and delete requests\r\nHandle 204 responses without body\r\nReturn excon response with same status as the api returned\r\nDelete delete_operation api method that doesn't exist\r\nAdd mocks for operations and use them in disk and server"
2459,'','[vcloud_director] ensure that MetadataEntry is a list\n'
2457,'','Ensure vpc created in a test doesn\'t affect another\nRunning tests in a specific order that sometimes happens causes subnet_groups_tests to fail. Delete the vpc created in another test when done\r\n\r\n```\r\nshindo tests/aws/models/elb/model_tests.rb tests/aws/requests/compute/dhcp_options_tests.rb   tests/aws/requests/rds/subnet_groups_tests.rb\r\n\r\n...\r\n\r\n  AWS::RDS | subnet group requests (aws, rds)\r\n    success\r\n      #create_db_subnet_group + returns "fog-test-537c"\r\n+ returns "A subnet group"\r\n- returns "0c805332-da26-1ccd-6160-ddcc98c977c5"\r\n        expected => "0c805332-da26-1ccd-6160-ddcc98c977c5"\r\n        returned => "e15217ad-4225-3a2c-0848-c50b98c0f15f"\r\n```\r\n'
2456,'','[google] Instances are created without description, and disk size is ignored\nHandle hash merge! properly'
2455,'',"Added parameter to force request timeout on xen\nNow, its possible to force request timeout by setting the parameter `xenserver_timeout` when openning connection\r\n\r\ncloses #1866\r\n\r\n```ruby\r\n@connection = Fog::Compute.new({\r\n    :provider => 'XenServer',\r\n    :xenserver_url => @host,\r\n    :xenserver_username => @user,\r\n    :xenserver_password => @pass,\r\n    :xenserver_timeout => 300\r\n})\r\n```"
2454,'','Make changes to a copy of the options parameter\nIf the method alters the options hash, clients calling this method in a loop\r\nwill unwittingly be sending a different hash on the second and subsequent calls.\r\n\r\nAlteration of the options hash is causing failure in the backup gem, in cases where there are more than 1000 objects to delete. See https://github.com/meskyanichi/backup/pull/510\r\n\r\nAbout the test: as this is behaviour which is tested in the Mock version of the method, I have duplicated code between the Real and Mock versions.'
2453,'','[aws|rds] Implement `ready?` for subnet group.\n'
2452,'','[vcloud_director] update name, description and storage_profile for vm\nimplemented fog#put_vm api, which will update vm name, description and storage profile'
2451,'','Verizon Terremark "invalid API version"\nWith fog 1.18.0, I\'m getting the following error:\r\n\r\n> Excon::Response:0x007f90d1fbc4a8 @data={:body=>"<Error message=\\"An invalid API version was specified in the request header.\\" majorErrorCode=\\"412\\" minorErrorCode=\\"InvalidVersionSpecified\\"\r\n\r\nI get this when I try:\r\n\r\n    connection = Fog::Compute.new(provider: :ecloud)\r\n    connection.organizations.each {|org| ... }'
2450,'','Readme: Added syntax highlighting for ruby code fragments\nAdded syntax highlighting in Readme'
2449,'','changed shutdown to reboot in reboot server method\nThe command to reboot a xen sever was wrong. Changed to the correct method.'
2448,'','[vcloud_director] Fix medias#create - issue #2440\n'
2447,'','Fix typo in documentation\nWhile grepping for gendered pronouns, I found this typo. :smile:'
2446,'','[AWS] S3 Mock behaves differently than AWS S3 in non-default region\nWhen creating an AWS S3 bucket in any region other than "us-east-1", if the bucket already exists, then AWS returns with a BucketAlradyOwnedByYou error. In the default region, AWS succesfully responds with the already existing bucket. \r\n\r\nFog Mock does not reflect the difference in behaviour between the different S3 endpoints. Instead, trying to create an already existing bucket responds with success, and the handle to the existing bucket.\r\n\r\n'
2445,'','[AWS|RDS] Support for creating and removing subnet groups.\n'
2444,'','Update excon dependency to version ~>0.30.0\n'
2443,'','[AWS|Storage] fixed signed urls when using session tokens\nthe session token needs to be added to the signature as a header\r\n(as well as being included in the query string)'
2442,'','Add agent host info for Rackspace Cloud Monitoring\nImplements these Rackspace Cloud Monitoring API calls - http://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/service-agent-host_info.html\r\n'
2441,'','Disable coveralls on travis with jruby\nCauses an error\r\n\r\nCoveralls encountered an exception:\r\nJava::JavaLang::OutOfMemoryError\r\nJava heap space'
2440,'','[vcloud_director] medias#create functionality is broken\nThe medias#create functionality is broken. this is due to the recent ensure_list changes.  '
2439,'',"return NS and SOA records - https://github.com/fog/fog/issues/2419\nThis allows us to work with NS subdelegations, as well as the NS and SOA records while the type can't be changed, the values and TTLs can be modified."
2438,'',"[rackspace|queues] update claim to set claim_id on claimed messages\nCurrently tests are failing because we can't delete a message that has been claimed with out a `claim_id`. This PR updates the claiming logic to set the `claim_id` when a message is claimed."
2437,'tokengeek','[Brightbox] Code style clean up\nFirst pass at cleaning up the code to a better, more consistent style.'
2436,'','[Linode] Add NodeBalancer support\nhttps://www.linode.com/api/nodebalancer\r\n\r\nNodeBalancers are hosted loadbalancers in the Linode ecosystem'
2435,'tokengeek',"[Brightbox] Clean up Cloud IP mapping code\nWhen passing an object that responds to `identity` which is all of our\r\nresources, we can pass the resource's identifier in to the API call to\r\nmake it easier to use without maintaining a list of classes.\r\n\r\nServer's need to use the interface for the destination so they override\r\na new `mapping_identity` method which is picked up first.\r\n\r\nAnything else (such as a String identifier) is passed directly to the\r\nAPI request as before."
2434,'','[google] Alias flavor_id and machine_type for consistency with other providers\n'
2433,'tokengeek','[Brightbox] Minor cleanup\nFixes a yard tag typo and removes a commented constant.'
2432,'','[aws] style fix for address model\njust aligning some hashrockets.'
2431,'',"Disable specific tests that don't pass on jruby 1.7.5+\nDue to https://github.com/jruby/jruby/issues/1265\r\n\r\n@geemus Thanks for applying #2429, this is probably a better solution that won't hide other errors on jruby builds"
2430,'',"[dnsimple] remove host from request\nRemove host from request  in `dns/dnsimple` to avoid `excon` warnings:\r\n\r\n```\r\n[excon][WARNING] Invalid Excon request keys: :host\r\n/home/selu/.rbenv/versions/2.0.0-p195/lib/ruby/gems/2.0.0/gems/excon-0.28.0/lib/excon/connection.rb:217:in `request'\r\n/home/selu/git/fog/lib/fog/core/connection.rb:57:in `request'\r\n/home/selu/git/fog/lib/fog/core/deprecated/connection.rb:20:in `request'\r\n/home/selu/git/fog/lib/fog/dnsimple/dns.rb:88:in `request'\r\n/home/selu/git/fog/lib/fog/dnsimple/requests/dns/get_domain.rb:27:in `get_domain'\r\n/home/selu/git/fog/lib/fog/dnsimple/models/dns/zones.rb:19:in `get'\r\n```"
2429,'',"all? not working in JRuby 1.7.5+. Configure Travis\nThat's the reason the travis build is failing on jruby, the override of `each` in Collection stopped working after 1.7.4\r\nhttps://github.com/jruby/jruby/issues/1265"
2428,'','[digitalocean] Add support for private networking\n'
2427,'','Update for Rackspace Cloud Monitoring\nIt seems that agent related API calls are missing\r\n* http://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/service-agent-host_info.html\r\n* http://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/service-agent.html\r\n\r\nThere might be other APIs missing. I can help identify them if someone is interested adding them.'
2426,'','[aws] Added networkInterfaceId and networkInterfaceOwnerId to aws addresses \nAdded networkInterfaceId and networkInterfaceOwnerId for DescribeAddressesResponseItemType to aws address parser and model.'
2425,'','Need to list block in the argument list to access the variable\nThis caused our scp_download call to give us the following error:\n\n`Net::SCP::Error: SCP did not finish successfully (1)`'
2424,'','[openstack|storage] updating request to use the proper file structure\n'
2423,'','[rackspace|queues] adding YARD docs\n'
2422,'icco','[google] Raise Fog::Errors::NotFound on 404\n'
2421,'icco','[google] Implement disk mocks and enable tests\nAvoid repeating api_version\r\nAdd persistent disk to insert_server mock\r\nUse Fog::Mock.delay properly instead of Fog.timeout'
2420,'',"HP Provider namespaces seem wrong for Network and DNS\nThe network and DNS components of fog look for a provider in the Fog::\\<service\\>::\\<provider\\> namespace, but these are defined instead in the Fog::\\<provider\\>::\\<service\\> namespace:\r\nlib/fog/dns.rb:          return Fog::DNS.const_get(Fog.providers[provider]).new(attributes)\r\nlib/fog/network.rb:        return Fog::Network.const_get(Fog.providers[provider]).new(attributes)\r\n\r\nDefined in hp area as:\r\nFog::HP::Network\r\nFog::HP::DNS\r\n\r\nThis will cause issues such as the following when they are used:\r\n```\r\nINFO warden: Calling IN action: #<VagrantPlugins::HP::Action::ConnectHP:0x0000000388a970>\r\n INFO connect_hp: Connecting to HP... v2\r\nERROR warden: Error occurred: uninitialized constant Fog::Network::HP\r\n INFO warden: Beginning recovery process...\r\n INFO warden: Recovery complete.\r\n INFO warden: Beginning recovery process...\r\n INFO warden: Recovery complete.\r\nERROR warden: Error occurred: uninitialized constant Fog::Network::HP\r\n INFO warden: Beginning recovery process...\r\n INFO warden: Recovery complete.\r\nERROR warden: Error occurred: uninitialized constant Fog::Network::HP\r\n INFO warden: Beginning recovery process...\r\n INFO warden: Calling recover: #<Vagrant::Action::Builtin::Call:0x00000002b8a9a0>\r\n INFO warden: Recovery complete.\r\n INFO warden: Beginning recovery process...\r\n INFO warden: Recovery complete.\r\n INFO environment: Running hook: environment_unload\r\n INFO runner: Running action: #<Vagrant::Action::Builder:0x00000002fe3ab0>\r\n/home/sullivanjp/.vagrant.d/gems/gems/fog-1.18.0/lib/fog/network.rb:17:in `const_get': uninitialized constant Fog::Network::HP (NameError)\r\n    from /home/sullivanjp/.vagrant.d/gems/gems/fog-1.18.0/lib/fog/network.rb:17:in `new'\r\n```"
2419,'',"There is no ability to manipulate sub-delegation NS records via Fog (tested with Route 53)\nDue to the behaviour in lib/fog/aws/models/dns/records.rb on Line 37:\r\n\r\n 36           # leave out the default, read only records\r\n 37           data = data['ResourceRecordSets'].reject {|record| ['NS', 'SOA'].include?(record['Type'])}\r\n\r\nWe do not return any NS or SOA records in record lookups. We also can't do a record.find() and a destroy on the resulting object because of this.\r\n\r\nThis possibly makes sense for the NS and SOA record/s for the zone itself, but sometimes you have NS records in a zone for a subdomain, to perform delegation.\r\n\r\nPlease provide such a capability, thanks."
2418,'','Building files tree is illegally slow\nBasically, topic says it all. If I want to put all buckets and folders and files inside it into something like directories_tree array\\hash, then what is the best way to do it? So far I tried this:\r\n\r\n```ruby\r\nclass CloudTree\r\n \r\n  def initialize\r\n    @connection  = Fog::Storage.new({ provider: \'aws\', aws_access_key_id: access_key, aws_secret_access_key: secret_key })\r\n  end\r\n\r\n  def directories_tree\r\n    @connection.directories.map do |bucket|\r\n      { name: bucket.key, children: objects(bucket) }\r\n    end\r\n  end\r\n\r\n  def objects(bucket)\r\n    objects = bucket.files\r\n    tree    = {}\r\n\r\n    objects.map(&:key).each do |path|\r\n      current  = tree\r\n      path.split("/").inject("") do |sub_path, dir|\r\n        sub_path = File.join(sub_path, dir)\r\n        current[sub_path] ||= {}\r\n        current = current[sub_path]\r\n        sub_path\r\n      end\r\n    end\r\n    return_tree(bucket, tree)\r\n  end\r\n\r\n  def return_tree(root, node)\r\n    node.map do |path, subtree|\r\n      obj = root.files.get((path.include?(\'.\') ? path.sub(/^\\//, \'\') : (path.gsub(\'/\', \'\') + \'/\')))\r\n      if obj\r\n        {\r\n                    url: obj.public_url,\r\n               name: File.basename(path),\r\n           children: return_tree(root, subtree),\r\n        }\r\n      end\r\n    end\r\n  end\r\n```\r\n\r\nand then like this:\r\n\r\n```\r\ncloud_tree.directories_tree\r\n```\r\n\r\nBut it\'s *terribly* slow, like takes minutes sometimes if there are a lot of items in may buckets. Any advise on it? (using 1.18.0)'
2417,'','[hp] Fix connection section for newer services.\n'
2416,'',"add in 'AssociatePublicIpAddress' to launch configuration creation\n"
2415,'','[openstack|storage] adding missing request methods to Storage service.\nIt appears that some openstack request methods were created, but not added to the service. This PR fixes that.'
2414,'','Rackspace public_url always returns nil\nWhen I try to get csn host for container I always get nil. I expected to get host name starting with ec8c.. (see screenshot)\r\n\r\n![cloud files - rackspace 2013-11-20 22-00-45](https://f.cloud.github.com/assets/78866/1586293/de008b2e-5226-11e3-96a7-60c62709c2c1.jpg)\r\n\r\n```\r\nconnection = Fog::Storage.new({\r\n      :provider                 => \'Rackspace\',\r\n      :rackspace_username       => username,\r\n      :rackspace_api_key        => api_key\r\n    })\r\n\r\nconnection.directories.get("whatever").public_url # nil\r\nconnection.directories.get("whatever").cdn_cname # nil\r\n\r\n```\r\n\r\nOr I\'m doing it wrong an there is another way to get this url?'
2413,'',"Glacier vault.rb delete_notification_configuration now passes vault id\nfixed AWS::Glacier::Vault.delete_notification_configuration so that it passes the vault's ID to the underlying core request."
2412,'',"Add new AWS EC2 flavors to the compute model\nThere's a collection of new AWS EC2 instance sizes we don't have flavor id's for. The purpose of this pull request is to implement those sizes."
2411,'','Fix exception if listing raw vSphere volumes (thinProvisioned method missing)\n'
2410,'',"Socket closed (OpenSSL::SSL::SSLError)\nHi, I am using Fog (1.18.0) on my JRuby (1.7.4) project using multi-threading. I keep getting the error\r\n```ruby\r\nSocket closed (OpenSSL::SSL::SSLError)\r\n```\r\nwhen I have 300+ threads simultaneously trying to upload a 400Kb image to Google storage. A couple of hundred requests go smoothly but eventually I get the error described below. I am already using the following configurations\r\n```ruby\r\n:persistent => false,\r\n:connection_options => {\r\n  :ssl_verify_peer => false,\r\n  :nonblock => false,\r\n  :connection_timeout => 360\r\n}\r\n```\r\n\r\nAny help is welcome. Thanks.\r\n\r\nFull stack trace here:\r\n```ruby\r\nSocket closed (OpenSSL::SSL::SSLError)\r\norg/jruby/ext/openssl/SSLSocket.java:170:in `connect'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/ssl_socket.rb:76:in\r\n`initialize'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:373:in\r\n`socket'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:122:in\r\n`request_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/mock.rb:42:in\r\n`request_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/instrumentor.rb:22:in\r\n`request_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:15:in\r\n`request_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:15:in\r\n`request_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:15:in\r\n`request_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:251:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/idempotent.rb:12:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:10:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:10:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:268:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:260:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/idempotent.rb:12:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:10:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:10:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:268:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:260:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/idempotent.rb:12:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:10:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/middlewares/base.rb:10:in\r\n`error_call'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/excon-0.28.0/lib/excon/connection.rb:268:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/fog-1.18.0/lib/fog/core/connection.rb:57:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/fog-1.18.0/lib/fog/core/deprecated/connection.rb:20:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/fog-1.18.0/lib/fog/google/storage.rb:300:in\r\n`request'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/fog-1.18.0/lib/fog/google/requests/storage/put_object.rb:33:in\r\n`put_object'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/fog-1.18.0/lib/fog/google/models/storage/file.rb:126:in\r\n`save'\r\n/home/heavy/.rvm/gems/jruby-1.7.4/gems/fog-1.18.0/lib/fog/core/collection.rb:52:in\r\n`create'\r\n```"
2409,'','Openstack public_url not implemented\nHi, \r\n\r\nI have a problem with openstack swift provider.\r\n\r\nI\'m trying to use fog with carrierwave and carrierwave is using the public_url method to get the url. In :\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/openstack/models/storage/directory.rb#L36\r\nthis metohd raise the NotImplementedError\r\n```\r\n2.0.0p247 :005 > storage = Fog::Storage.new({:provider => \'OpenStack\', :openstack_api_key => ENV[\'OS_PASSWORD\'], :openstack_username => ENV["OS_USERNAME"], :openstack_auth_url => ENV["OS_AUTH_URL"] + \'/v2.0/tokens/\', :openstack_tenant => ENV["OS_TENANT_NAME"]})\r\n```\r\n```\r\n2.0.0p247 :006 > storage.directories[2].files[1].public_url\r\nNotImplementedError: NotImplementedError\r\n\tfrom /Users/piotr/.rvm/gems/ruby-2.0.0-p247@scali/gems/fog-1.18.0/lib/fog/openstack/models/storage/directory.rb:37:in `public_url\'\r\n\tfrom /Users/piotr/.rvm/gems/ruby-2.0.0-p247@scali/gems/fog-1.18.0/lib/fog/openstack/models/storage/files.rb:69:in `get_url\'\r\n\tfrom /Users/piotr/.rvm/gems/ruby-2.0.0-p247@scali/gems/fog-1.18.0/lib/fog/openstack/models/storage/file.rb:83:in `public_url\'\r\n\tfrom (irb):6\r\n\tfrom /Users/piotr/.rvm/gems/ruby-2.0.0-p247@scali/gems/railties-4.0.1/lib/rails/commands/console.rb:90:in `start\'\r\n\tfrom /Users/piotr/.rvm/gems/ruby-2.0.0-p247@scali/gems/railties-4.0.1/lib/rails/commands/console.rb:9:in `start\'\r\n\tfrom /Users/piotr/.rvm/gems/ruby-2.0.0-p247@scali/gems/railties-4.0.1/lib/rails/commands.rb:62:in `<top (required)>\'\r\n\tfrom bin/rails:4:in `require\'\r\n\tfrom bin/rails:4:in `<main>\'\r\n2.0.0p247 :007 > \r\n```'
2408,'','[hp] Fix a few more documentation page links.\n'
2407,'','[hp] Fix links in some documentation pages.\n'
2406,'','[hp] Add documentation and examples for the provider for HP Cloud Services\n'
2405,'',"Support bootstrapping coreos servers in the rackspace cloud\nIts possible to kick coreos in the rackspace cloud using fog:\r\n\r\n```ruby\r\n    @service.servers.bootstrap :name => server_name, \r\n                               :flavor_id => flavor.id, \r\n                               :image_id => '430d35e0-1468-4007-b063-52ee1921b356',\r\n                               :public_key => public_key,\r\n                               :private_key => private_key,\r\n                               :username => 'core'\r\n```\r\n\r\nHowever bootstrapping fails ssh auth.\r\n\r\nI believe the issue may be that conventional servers first generate a root password, and bootstrapping takes that, and implements public key auth only, and disables passworded login, whereas for coreos it only ever uses keyed auth. By the time the server is created, the ability to connect via password or key is gone. After a coreos server is kicked using fog it is not possible to ssh to the server using the core user (root user is not used) using the key provided, which makes me think that the server creation step needs to be adjusted to support coreos\r\n\r\nHere is an example of creating a server in the cloud with coreos using supernova: http://coreos.com/docs/rackspace/\r\n\r\nI don't know much about how fog creates servers and how they need to be created in this case, but with some guidance I'd be happy to hash this out and PR it. "
2404,'','[rackspace|queues] adding examples for rackspace queues\n[rackspace|queues] adding examples for rackspace queues'
2403,'','Support for Elasticache cache subnet groups (AWS).\n'
2402,'','Add uncommitted property to the vsphere datastore object\n'
2401,'','[vSphere] Add request to set VM annotations in vSphere\nAllow setting vSphere annotations via a request.\r\n\r\nImplements the request part of #1755\r\nReplaces #2136 '
2400,'',"[aws|dns] Don't set mock changes to INSYNC immediately, only after some timeout\nAllows more real testing with mocks"
2399,'','[aws:storage] path_style option availability\nThe path_style option should be available regardless of how an\r\nendpoint override is specified'
2398,'',"Discussion: Can we publish provider docs to fog.io?\nI was wondering if we could come up with a process to take the docs/examples in the fog repo and publish them on fog.io under a 'provider' section. We already have Rackspace docs and I am planning to push the HP docs there as well.\r\n\r\nSo, since the docs are already in MD format, it should be fairly easy to run it under Github pages. \r\nAnother question is, do we want to keep the docs under 'fog' repo or should it be moved under the fog.io repo? The latter gives us the advantage to keep the doc issues and patches separate and clean from code updates in fog.\r\n\r\nAny thoughts?\r\n\r\n/cc @geemus @krames @dprince "
2397,'',"fog 1.18.0 calculates bad signature for private S3 objects\nI don't know how to debug this further but when I do a `object.url` and get a signed URL back, it has a bad signature. I've tried every released version of fog and it doesn't work until Fog 1.10.1."
2396,'nirvdrum','"[WARNING] Unable to load the \'unf\' gem." Does fog depend on unf or not?\nWhen I run my rspec tests, I get a warning:\r\n\r\n[fog][WARNING] Unable to load the \'unf\' gem. Your AWS strings may not be properly encoded.\r\n\r\nIf unf is necessary, let us depend on it. If not, let us remove the warning. I am willing to make a pull request in either case. Just let me know.\r\n\r\nEnvironment:\r\n- Mac OSX Mountain Lion\r\n- Rails 4.0.1\r\n- fog 1.18.0\r\n- rspec 2.14.1\r\n\r\nHow to reproduce:\r\n- strike up a Rails app\r\n- add fog and rspec to Gemfile (in my case fog is a dependency to asset_sync)\r\n- run "rspec" on the command line'
2395,'',"[vsphere|compute] restore default guest_id so setting it is optional\ncc @MarcGrimme, @ekohl\r\n\r\nI suspect this wasn't intentional, as it now means the guest_id has to be set: http://projects.theforeman.org/issues/3653"
2394,'','Improve support for VPC Security Groups in RDS\n* Ensures create_db_instance passes VPC args onwards\r\n* Bumps API version so that VPC results are returned in describe calls\r\n\r\nWhen merged, should close #2379 '
2393,'','[rackspace] fixing broken tests caused by bad helper\n'
2392,'','AWS AutoScalying/adding spot price to launch configurations\nHi!\r\n\r\nThis PR adds the possibility of adding a spot price to a launch configuration. The Price is a float.\r\n\r\nThanks,\r\n\r\nRodrigo'
2391,'','Add IAMInstanceProfile support to launch configs\nReopening #2353 from a new branch.'
2390,'','Write logger output to stderr to conform to convention\nWriting log to stdout causes issues when piping.'
2389,'','[vcloud_director] tests become pending on absence of testable resources\nThese test function better if they are pending if no resources support them\r\n\r\n(Sorry for the piecemeal delivery of this - should be the last one)'
2388,'','[AWS] Modify vpc attribute\nthis adds the modify_vpc_attribute call.'
2387,'','[aws] Implement mock for Route 53 list_resource_record_sets\n'
2386,'','[bluebox] remove :host from excon request\n'
2385,'','fix Terremark ecloud environments nil reference\nThis fixes an error I was getting:\r\n\r\n> undefined method [] for nil:NilClass\r\n/Users/sarah/.rvm/gems/ruby-2.0.0-p247/bundler/gems/fog-b7a1f6fc2806/lib/fog/ecloud/models/compute/environments.rb:18:in block in all'
2384,'','[aws|compute]: Add index for describe_images parameters that use them\nThe documentation for the [describe_images call](http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeImages.html) notes that the ExecutableBy, Owner, and ImageId parameters must use an index as a suffix. '
2383,'',"[vcloud_director] fix vms_tests to be pending when run on empty environment\nIf the tests are run on an environment that doesn't have any vms then the test will be pending rather than failing with a nil as the code was doing before\r\n"
2382,'','[google|compute] Implement Load balancer support\nOne would need to implement https://developers.google.com/compute/docs/reference/latest/#TargetPools and https://developers.google.com/compute/docs/reference/latest/#Routes'
2381,'','SocketError with hostname-style S3 Bucket when using https endpoint\nI\'m using Cloudflare as a CDN, and am uploading files with Carrierwave.\r\n\r\nI have created a bucket called `cdn.example.com` which perfectly matches my CNAME of where I want to dish out my CDN content from.\r\n\r\nI configured carrierwave + fog as such:\r\n\r\n`production.rb`\r\n\r\n```\r\n  AWS_ACCESS_KEY_ID     = \'xyz\'\r\n  AWS_SECRET_ACCESS_KEY = \'xyz\'\r\n  S3_BUCKET_NAME        = \'cdn.example.com\'\r\n  CDN_HOST              = \'http://cdn.example.com\'\r\n```\r\n\r\n`carrierwave.rb`\r\n\r\n```\r\nCarrierWave.configure do |config|\r\n\r\n  config.storage = :fog\r\n\r\n  config.fog_credentials = {\r\n    :provider              => \'AWS\',\r\n    :aws_access_key_id     => AWS_ACCESS_KEY_ID,\r\n    :aws_secret_access_key => AWS_SECRET_ACCESS_KEY,\r\n    :region                => \'us-east-1\'\r\n  }\r\n\r\n  config.asset_host     = CDN_HOST\r\n  config.fog_directory  = S3_BUCKET_NAME\r\n  config.fog_public     = true\r\n  config.fog_attributes = {\r\n    \'Cache-Control\' => "max-age=#{1.year.to_i}"\r\n  }\r\nend\r\n```\r\n\r\nWhen trying to upload a file, it stalls and gives the following error:\r\n\r\n`Excon::Errors::SocketError (hostname "cdn.example.com.s3.amazonaws.com" does not match the server certificate (OpenSSL::SSL::SSLError)):`\r\n\r\nIf I change the bucket name to something that doesn\'t resemble a hostname, it appears to work fine.\r\n\r\nIf I add the following to my config:\r\n\r\n`:endpoint => \'http://s3.amazonaws.com\'`\r\n\r\nIt DOES work then, but it\'s not secure. Is there anyway I can still use https? It doesn\'t seem to be a problem normally using https if the bucket name is just a normal word and not a host name.'
2380,'',"[aws|elb] support for cross zone load balancing\nSupport for cross zone load balancing, as described here: http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#AZ-Region\r\n\r\nI'm a little uncertain about the model side of things - should I be caching the value? It's a slightly odd value in that it feels like an attribute of the load balancer, but as far as I can tell it is only returned by describe_load_balancer_attributes, not by describe_load_balancers"
2379,'',"No support for VpcSecurityGroups in RDS instance creation for AWS\nVpcSecurityGroups parameter passed to create_db_instance are silently ignored because the request implementation doesn't currently support it.\r\n\r\nOpening a ticket and hoping to follow up with a PR shortly."
2378,'icco','[google|compute] Add support for instance tags\n'
2377,'',"[google|compute] natIP is set to true when it must be an ip\nAs described in https://developers.google.com/compute/docs/reference/latest/instances networkInterfaces[].accessConfigs[].natIP\r\nFixes Fog::Errors::Error: Invalid value for field 'resource.networkInterfaces[0].accessConfigs[0].natIP': 'true'.  Must be an IP address"
2376,'tokengeek','[Brightbox] Add new SSL cert metadata attributes\nNow adding `valid_from` and `issuer` to model'
2375,'','added new DBaaS regions for Rackspace\n'
2374,'','Get VcloudDirector working again in fog interactive. Fixes #2373.\n'
2373,'','VcloudDirector broken in fog interactive\nBackup /root/.fog before running this.\r\n<pre>\r\necho ":default:\r\n  :vcloud_director_host: bogus_host\r\n  :vcloud_director_username: bogus_username\r\n  :vcloud_director_password: bogus_password\r\n" > /root/.fog\r\necho "VcloudDirector.organizations" | fog\r\n</pre>\r\noutputs "LoadError: no such file to load -- fog/vclouddirector/compute".\r\n\r\nI\'m able to reproduce this in fog 1.18 on CentOS 6 using system ruby 1.8.7 or software collection ruby 1.9.3.  I\'m working up a patch now.'
2372,'',"[vsphere] clone a VM onto a specific network?\nTrying to figure out if it's possible to use vm_clone to clone a VM onto a specific network in vpshere. Reading the code, I see a network_label option, but it doesn't seem to work as I think.\r\n\r\nAnyone do this successfully?"
2371,'tokengeek',"[Brightbox] Fix test issue with reusing servers\nTo save time, we hoped to use an existing server to read the interface\r\nJSON and it did a naive selection of the first server.\r\n\r\nServer's that are deleted have two relevant characteristics. 1) They no\r\nlonger have interfaces and 2) they are reported in the output in their\r\ndeleted state for an hour after being removed.\r\n\r\nSince the test was not filtering for active servers, subsequent runs\r\ncould pick up a deleted server and fail to find the identifier for it's\r\nmissing first interface.\r\n\r\nThis simplifies matters by creating a new server for the test."
2370,'','Remove :host key in RDS request method to eliminate excon warning\nSame as #2265.  Gets rid of warning:\r\n\r\n    [excon][WARNING] Invalid Excon request keys: :host\r\n\r\nfor RDS requests.'
2369,'',"Remove stray private key\nI don't know what this key is, but I'm going to presume it shouldn't be in the repo or in the published gems.  Let's hope it's not real.\r\n\r\nIt seems to have come from the enormous PR #2332, and I can't find any references to the filename in the codebase."
2368,'',"[general] An attribute called attributes causes stack level too deep error\n`/Users/rad/.rvm/gems/ruby-1.9.3-p448/gems/fog-1.17.0/lib/fog/core/attributes.rb:23: stack level too deep (SystemStackError)`\r\n\r\nThat's because I have this in one of my models:\r\n\r\n`attribute :attributes`\r\n"
2367,'','Support for getting keypair from openstack compute api\nFrom the Openstack API\r\nGET v2/\u200b{tenant_id}\u200b/os-keypairs/\u200b{keypair_name}\u200b \r\nShows a keypair associated with the account.\r\n\r\nCurrently fog supports list_key_pair, create_key_pair, and delete_key_pair.  It would be nice to also have get_key_pair so that other applications can connect with it (Ansible, Fabric, etc...).\r\n\r\n'
2365,'','No support for ModifyVpcAttribute in AWS\nThe ModifyVpcAttribute method is not currently supported either as a request type or as part of the vpcs model.\r\n\r\n(Leaving an issue rather than a PR in case others have chance to look at this before I do)'
2363,'','Fix bugs in OpenStack Host\nThere are 2 issues here.\r\n\r\nThe first is that the OpenStack host has an attribute called service. When the model is created, this overrides the parent attribute (formerly "connection") that is used to make all the requests to the OpenStack API. Changed this to service_name to avoid the collision.\r\n\r\nThe second issue is that for several services, OpenStack returns a NotFound when requesting host details. Added a rescue block to prevent this from raising.'
2362,'','[rackspace] changing service catalog implementation\nThis PR re-implements the service catalog for the Rackspace Cloud. In addition to being more efficient, it provides the following fixes:\r\n\r\n* If a user requests service endpoint for region X and the service only has one endpoint which is in region Y, it will return region Y. It now throws an exception.\r\n* Service net endpoints are now pulled from the catalog rather than being built by the service.\r\n'
2361,'icco',"[google|compute] Support for tokens\nHi there,\r\n\r\n Currently the google compute object only allows to use a certificate file to authz with google. It'd be nice to be able to do the same with an access/refresh token. That way fog could easily be used by a web page able to get the an oauth2 token."
2360,'','Added content_encoding attribute to Rackspace storage\nAdded content_encoding attribute to Rackspace storage.\r\n\r\nAmazon storage already has it and according to [this](http://docs.rackspace.com/files/api/v1/cf-devguide/content/Enabling_File_Compression_with_the_Content-Encoding_Header-d1e2198.html) Rackspace also allow setting the content-encoding.'
2359,'','[openstack|compute] Basic examples for Compute\nThis contains some basics examples on how to set up a VM, do power\r\noperations, and find floating IP pools. It should be enough for a\r\nbeginner to get started and familiar with Fog so that more complex\r\nthings can be searched by the user.'
2358,'',"Joyent's Fog::Server does not include flavor (package) used\nOne of the attributes of Joyent SmartMachines is the flavor -- package used to create or resize the machine.  sdc-listmachines returns this value for each of the hosts. Fog should also be able to read/return this value from the API."
2357,'','cannot seem to get fog to connect to s3 at all...\nI ran into this problem trying to use another gem that uses fog and wanted to attempt to debug if it was that other gem or me or fog but here\'s what I get...\r\n\r\n```\r\nExcon::Errors::SocketError: hostname "typkit.rwboyer.com.s3.amazonaws.com" does not match the server certificate (OpenSSL::SSL::SSLError)\r\n```\r\n\r\nUsing the latests greatest gems on rubygems for Fog and for excon as of today (and the previous versions as well)...\r\n\r\nI get the same exact errors using even this really simple code:\r\n\r\n```\r\nfog = Fog::Storage.new(\r\n    :provider => "AWS",\r\n    :aws_access_key_id => ENV[\'AMAZON_ACCESS_KEY_ID\'], \r\n    :aws_secret_access_key => ENV[\'AMAZON_SECRET_ACCESS_KEY\']\r\n)\r\n\r\ndirectory = fog.directories.get("typkit.rwboyer.com")\r\n```\r\n\r\nthe environment is fine considering it\'s used for all my production s3 stuff just doesn\'t seem to work here. What am I doing wrong or is it some sort of bug???\r\n\r\nThanks\r\n\r\nRB'
2356,'','Improve vsphere network interfaces\n'
2355,'','Allows custom username for aws spot instances\nExtension of https://github.com/fog/fog/commit/135c30944bf01a8c2a044a1cf3b219d3104ff4d1 for spot instances.'
2354,'','[rackspace] fixing broken tests\nFixing broken tests'
2353,'','Support IamInstanceProfile for launch configs\nAutoScaling launch configurations can take IamInstanceProfile arguments on creation.  This PR adds support to the fog model to allow this behaviour.'
2351,'',"Issue running vSphere provider and Fog\nI'm not sure what's wrong here. Are there known issues with Fog and vSphere appliances?\r\n\r\n```bash\r\n2.0.0-p247 :001 > require 'fog'\r\n[fog][WARNING] Unable to load the 'unf' gem. Your AWS strings may not be properly encoded.\r\n => true \r\n2.0.0-p247 :002 > \r\n2.0.0-p247 :003 >   compute = Fog::Compute.new(\r\n2.0.0-p247 :004 >     :provider => 'vSphere',\r\n2.0.0-p247 :005 >     :vsphere_username => myusername,\r\n2.0.0-p247 :006 >     :vsphere_password => mypassword,\r\n2.0.0-p247 :007 >     :vsphere_server   => serverip,\r\n2.0.0-p247 :008 >     :vsphere_expected_pubkey_hash => hash,\r\n2.0.0-p247 :009 >     )\r\n => #<Fog::Compute::Vsphere::Real:70207033816940 [...]> \r\n2.0.0-p247 :010 > \r\n2.0.0-p247 :011 >   compute.servers\r\nFog::Compute::Vsphere::NotFound: 14 was not found\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/vsphere/requests/compute/get_virtual_machine.rb:27:in `get_vm_ref'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/vsphere/requests/compute/list_vm_interfaces.rb:32:in `list_vm_interfaces'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/vsphere/models/compute/interfaces.rb:18:in `all'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:141:in `lazy_load'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:15:in `empty?'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:86:in `block in inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/formatador-0.2.4/lib/formatador.rb:92:in `indent'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:79:in `inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/model.rb:29:in `block (2 levels) in inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/model.rb:29:in `map'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/model.rb:29:in `block in inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/formatador-0.2.4/lib/formatador.rb:92:in `indent'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/model.rb:26:in `inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:89:in `block (3 levels) in inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:17:in `map'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:17:in `map'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:89:in `block (2 levels) in inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/formatador-0.2.4/lib/formatador.rb:92:in `indent'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:88:in `block in inspect'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/formatador-0.2.4/lib/formatador.rb:92:in `indent'\r\n\tfrom /Users/lanceblais/.rvm/gems/ruby-2.0.0-p247/gems/fog-1.18.0/lib/fog/core/collection.rb:79:in `inspect'\r\n\tfrom /Users/lanceblais/.rvm/rubies/ruby-2.0.0-p247/bin/irb:13:in `<main>'2.0.0-p247 :012 > \r\n```"
2350,'',"Update cloud_watch.rb\nI see excon related errors when upgraded fog to version 0.18.0 from 0.15.0:\r\n\r\n[excon][WARNING] Invalid Excon request keys: :host\r\n/usr/lib/ruby/gems/1.8/gems/excon-0.28.0/lib/excon/connection.rb:217:in `request'\r\n/usr/lib/ruby/gems/1.8/gems/fog-1.18.0/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/usr/lib/ruby/gems/1.8/gems/fog-1.18.0/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/usr/lib/ruby/gems/1.8/gems/fog-1.18.0/lib/fog/aws/cloud_watch.rb:153:in `_request'\r\n/usr/lib/ruby/gems/1.8/gems/fog-1.18.0/lib/fog/aws/cloud_watch.rb:148:in `request'\r\n/usr/lib/ruby/gems/1.8/gems/fog-1.18.0/lib/fog/aws/requests/cloud_watch/get_metric_statistics.rb:42:in `get_metric_statistics'\r\n\r\nIt can be fixed by the following change."
2349,'','[aws|cloudwatch] remove :host key from request\n'
2348,'','Directories#all breaks when :local_root folder is missing for Fog::Storage::Local\nTh local storage provider assumes the configured `:local_root` folder may not be present yet, for instance [here](https://github.com/fog/fog/blob/master/lib/fog/local/storage.rb#L87). However, `Directories#all` didn\'t. It would raise ("No such file or directory") when called before any object is created. This PR fixes this by returning an empty `Directories` instance instead.'
2347,'','[vcloud_director] changed edgeGateway tests to use task mocking\n'
2346,'','[vcloud_director] Ensure task :Owner is always present.\n'
2345,'','Fixing bugs in edgegate service configuration\n\r\n- included few missing fields.\r\n- removed data manipulation logic from request layer. this should be added to models. \r\n\r\n'
2344,'','[vcloud_director] fixing firewall config to follow api documentation\nChange include following fixes:\r\n1. policy, description and port fields are not mandatory.\r\n2. Request layer should be dump and should not do smart handling of\r\ndata. Accepting data in same format as documented in api doc =>\r\nhttps://pubs.vmware.com/vcd-51/index.jsp#doc/index.html\r\n3. SourceIp and destinationIp fields are used to control source and destination\r\nfor traffic. These fields are included in documentation, but there is\r\nno other field provided to accept ips.\r\n'
2343,'','[OS|Volume] Add listing/showing volume types\n'
2342,'',"Fix initialization of instances array in AWS autoscaling group\nI'm not sure why I left the instances array in the old style in #2161, but @josegonzalez pointed out that it was causing the instances collection to be empty.\r\n\r\nWasn't sure how to really test this, since the mock autoscaling group doesn't actually create instances, and implementing that seemed like a larger project than I'm ready to take on right now!  I did run it against a live autoscaling group with instances though, and confirmed that they are showing up in the instance collection."
2341,'','Remove override of instances instance-setting in autoscale groups\nFixes issue introduced in ef47f6316ead386f9274f5c4bc4f828946e0ef54\r\n\r\nPlease merge this in soon!'
2340,'',"RouteTable Bug in 1.8\nReceiving the following error.\r\n\r\nfog-1.17.0/lib/fog/aws/models/compute/route_table.rb:33: warning: don't put space before argument parentheses.\r\n\r\nFix is very simple."
2339,'','Improve vsphere shutdown\n'
2338,'','ls\n'
2337,'','[Vcloud_director] Test improvements for real environments\n* Fixes for tests that failed on a fresh environment I tested on \r\n* Fix for a test that fails subtly if the firewall rule already exists. It now fails fast and stops that group of tests, and uses a less likely id, and describes that it is a rule added by the test. '
2336,'',"[aws|data_pipeline] don't pass host to request\nI ran into a similar issue to fog/fog#2248.  Tried the same fix as e57058f.  Verified working.  /cc @kbarrette"
2335,'',"Fix parser typo in AWS #describe_internet_gateways\nThis was causing the following error when attempting to do anything with an internet gateway that had been tagged:\r\n\r\n    Excon::Errors::SocketError: EndTag: '</' not found (Nokogiri::XML::SyntaxError)\r\n\r\n"
2334,'',"Username being overrided\nWhen trying to launch a spot instance with AWS the username that I defined during the setup of the server is being overridden.\r\n\r\nI added a || so that if the username is already manually defined by the user, it won't get  overridden."
2333,'',"rake mock[<provider>] and live[<provider] tasks\nIn a case of inspired laziness, I decided I'd rather implement this:\r\n\r\n```sh\r\n$ rake -vT\r\n...\r\nrake live[provider]  # Run live tests against a specific provider\r\nrake mock[provider]  # Run mocked tests for a specific provider\r\n...\r\n```\r\n\r\n```sh\r\n$ rake mock['rackspace']\r\n# runs rackspace tests using mocks...\r\n```\r\n\r\nthen send someone instructions to run `export FOG_MOCK=false && bundle exec shindont tests/rackspace` or `export FOG_MOCK=false && bundle exec shindont tests/rackspace`.  Less typing.\r\n\r\nNote: the provider names are from the tests folder instead of the keys for Fog.providers.  It's the same for most, but there is are discrepencies for multi-word providers (gogrid, internetarchive, baremetalcloud, stormondemand, vclouddirector and vmfusion)."
2332,'','[hp] Merge latest HP provider updates (hpfog 0.0.22)\n0.0.22 10/16/2013\r\n=================\r\n- add support for new LoadBalancer provider\r\n  - add load balancer model and request layer with mocking support\r\n  - add node model and request layer with mocking support\r\n  - add virtual_ip, protocol and algorithm models and request layer with mocking support\r\n- add support for new DNS provider\r\n  - add domain model and request layer with mocking support\r\n  - add record model and request layer with mocking support\r\n\r\n0.0.21 06/11/2013\r\n=================\r\n- add support for new Networking (Neutron) provider (Grizzly release)\r\n  - add network model and request layer with mocking support\r\n  - add router model and request layer with mocking support\r\n  - add subnet model and request layer with mocking support\r\n  - add port model and request layer with mocking support\r\n  - add floating ip model and request layer with mocking support\r\n  - add security group/rule model and request layer with mocking support\r\n- add support for new Compute V2 provider (Grizzly release)\r\n  - remove support for security group/rule model and request layer\r\n  - revise support for server, flavor, image, keypair, floating ip, metadata models and request layers\r\n  - add support for availability zone model and request layer\r\n  - add support for volume attachment model and request layer\r\n- add support for new BlockStorage V2 (Cinder) provider (Grizzly release)\r\n  - add volume model and request layer with mocking support\r\n  - add snapshot model and request layer with mocking support\r\n  - add volume backups model and request layer with mocking support\r\n  - remove bootable volume model as it now accessible via volume model\r\n- add support for caching auth credentials\r\n- add filter query support to all new V2 collections\r\n- add side by side support for both Compute and BlockStorage, V1/V2 providers'
2331,'','[Rackspace] Fix broken tests and exception handing\nThis PR fixes some failing tests against the live rackspace cloud. It also adds validation errors to the BadRequest exception messages for the Rackspace monitoring service.'
2330,'','[aws|compute] mock instance tenancy on servers\n'
2329,'tokengeek','[Brightbox] Add SSL settings to load balancer\nThis allows passing a SSL cert and key to a load balancer to use SSL.\r\n\r\nIf a certificate is present, the expiry time and certificate subject are\r\navailable.'
2328,'','Ecloud live specification\nVerizon\'s cloud has something called the "Living Specification" that uses an endpoint full of dummy data.\r\n\r\nI set out to expose this data by removing some hardcoded paths throughout the models. When it came time to test the changes I made, it was easy enough to use the same spec for testing against (when not mocked) just by changing some test configs. Now anybody can test against ecloud w/o having an account or doing any setup.\r\n\r\nHere is a copy of my tests/.fog\r\n```yaml\r\ndefault:\r\n  :ecloud_username: me@myhost.com\r\n  :ecloud_password: T3rr3m@rk\r\n  :ecloud_authentication_method: :cloud_api_auth\r\n  :ecloud_organization_uri: /organizations/2\r\n```\r\n\r\nI did comment out one test, since the Living Specification doesn\'t include any InternetServices that can be deleted.'
2327,'','[AWS] Please document how to update the flavor of an existing (& stopped) instance\nI\'ve tried setting the flavor / flavor_id and saving, but that throws an error about "Resaving an existing object may create a duplicate" because it\'s already persisted.\r\n\r\nWhat is the prescribed method of updating the flavor of an instance using Fog?'
2326,'',"[vsphere|compute] Added the ability to create and destroy new volumes.\nSeeking feedback before I bother writing the mocks.  This appears to be working pretty well for me though.  I'm able to create new volumes and destroy existing ones."
2325,'','[rackspace|storage] implement get_http_url and get_https_url. \nThis PR adds `get_http_url` and `get_https_url` to `Fog::Rackspace::Files` and will complete the final todo on issue #2103.'
2324,'','[google|compute] Change disks.all to get all disks\nChanges disks.all to actually look at all zones and return all disks and switches first parameter to a filter to match servers.all.\r\n\r\nAlso, small code clean up of snapshot variable names.'
2323,'','aws/compute: Hotfix, wrong Name argument for copy_image\nJust a simple fix'
2322,'','Add s3 bucket tagging support\n'
2321,'','[vcloud_director] Add EnableLogging field to FirewallService XML\nThis field controls the "log network traffice for firewall rule" option.\r\n\r\nManually tested against a vcloud director instance.'
2320,'','Replaced the \'unicode\' gem with \'unf\' so it\'ll work with JRuby.\nFixes #2279: Remove dependency on "unicode" gem.'
2319,'','JRuby test fixes.\n'
2318,'','More unicode jruby cleanup\n'
2317,'tokengeek','[core] Make `ruby-libvirt` dependency optional\nThe `ruby-libvirt` dependency was commented out since it is rarely used\r\nand a pain for developers to prepare.\r\n\r\nThe comment was removed in https://github.com/fog/fog/commit/b373e55a8f32b24c11fe4b20e773c1428df9d811\r\nto protect JRuby but made it a requirement for MRI (& others).\r\n\r\nThis adds another guard based around the setting of `FOG_USE_LIBVIRT`\r\nenvironment variable.\r\n\r\nThis hopefully will mean anyone wanting to use it can just set that\r\nrather than editing the gemspec.\r\n\r\nFixes #2316'
2316,'tokengeek','LibVirt has been added as a dependency by accident\nIn https://github.com/fog/fog/commit/b373e55a8f32b24c11fe4b20e773c1428df9d811 to guard against JRUBY using `ruby-libvirt` the comment was removed.\r\n\r\nThis has made `ruby-libvirt` a dependency for everyone again.\r\n\r\nFix shortly...'
2315,'',"JRuby fixes\nI'm not wild about conditionally loading things in the gemspec, but for development dependencies this shouldn't be a problem.  I do expect the libvirt tests to fail as a result, but I don't have that configured locally, so I'll need to see the failures in Travis to adjust.  And the unicode hack is just to get things loading for now -- a proper fix for #2279 will be forthcoming once this and PR #2312 have landed."
2314,'','[vSphere] Implementation of feature to specify scsi_controller type at create time\nThis feature is an implementation for creating virtual machines with a userdefined storage controller on bases of the Vsphere VirtualSCSIController.\r\nIf you don\'t pass a userdefined storage controller the VirtualLsiLogicController will be used (as before).\r\nIf you want to specify the storage controller by userself do it as follows:\r\n```\r\nvm=compute.servers.create(\r\n   "name" => "..", \r\n   "cluster" => compute.datacenters.first.clusters.first.name, \r\n   "datacenter" => compute.datacenters.first.name, \r\n   "memory_mb"=>1024, \r\n   "cpus"=>2, \r\n   "guest_id"=>"rhel6_64Guest", \r\n   "scsi_controller" => { "type" => "ParaVirtualSCSIController", "shared" => true }, \r\n   "interfaces"=>[interface,], \r\n   "volumes"=>[volume]\r\n)\r\n```\r\n'
2313,'geemus',"Semantic Versioning (and Pessimistic Versioning Constraint) recommendation\nI noticed some projects using Fog are setting very specific versioning constraint.  For example, https://github.com/mitchellh/vagrant-rackspace/issues/34 happened because both vagrant-aws and vagrant-rackspace are using 3 digits of precision.\r\n\r\nThe fog RELEASE.md says that Fog follows semantic versioning.  Several other projects have put up notices suggesting to use 2 digits of precision for projects that follow semver.  See https://github.com/intridea/multi_json, for example.\r\n\r\nI added a similar notice, but softened the language because I don't think there is a clear understanding on what semantic versioning means for a project like Fog, which has multiple providers backed by services that are all evolving at their own pace."
2312,'','Added testing in JRuby for Travis.\n'
2311,'','Add a reload() method to the vSphere service.\nLike other compute services, it would be useful if vSphere also\r\nsupported reload(). The method should reestablish any session state\r\nrequired for Fog when network errors arise (EPIPE, etc).\r\n\r\nFixes: #2307'
2309,'','Removed errant :host argument\nSimilar to #2292 and others, this :host argument was causing problems.'
2308,'','added tests for monigtoring zones\nPulled in branch - so, like, you can see these awesome changes.'
2307,'',"VSphere should provide a mechanism to reload the connection\nSimilar to other compute objects, when Fog encounters an EPIPE error it would be convenient to be able to call reload() on the VSphere object returned from from Fog.Compute.new(:provider => 'vsphere')."
2306,'','[cloudstack] Add features to support the advanced networking features\nThere should be some advanced networking features supported in fog, includes: nat, vlan, ipaddress, network, disk_offering, key_pair, ostype, firewall.'
2305,'','Invalid Excon request keys: :host, :port (add v1) dupes #2304\nas in  #2248, pull #2304 added line 88/89 edits  as per @geemus request'
2304,'','Invalid Excon request keys: :host, :port\nas explained https://github.com/fog/fog/issues/2248 is preventing authentication with hp cloud.'
2303,'','[vcloud_director] strftime not iso8601 for ruby 1.8.7\nOops.'
2302,'nosborn','[vcloud_director] Mocking for tasks.\n'
2301,'','Aws resv end v1.15\n'
2300,'','[core] log warning for unrecognized arguments\nLogging a warning for these should be sufficient, since the request may still succeed.\r\nAlso make it clear where messages are coming from.\r\nSee also #2285'
2299,'','Update create_server.rb\nFixed issue when creating new xen-vm with HVM-bootpolicy  argument, it still remains empty.'
2298,'MarcGrimme','[vSphere] Implemented feature to specify a socket cpu layout as specified\n[vSphere] Implemented feature to specify a socket cpu layout as specified in vmware API. If not used numCoresPerSocket is left out and default VMware behaviour is used.\r\n\r\nExample for creation of vm:\r\n```\r\ncompute.servers.create("name" => "myname", "cluster" => compute.datacenters.first.clusters.first.name, "datacenter" => compute.datacenters.first.name, "memory_mb"=>1024, "cpus"=>2, "corespersocket"=>2,"guest_id"=>"rhel6_64Guest", "interfaces"=>[interface,], "volumes"=>[volume])\r\n```\r\nWill end up with 1 socket with 2 cores instead of 2 sockets with 1 core each. \r\nThis seams to have some performance advantages (might be dependent on guest OS).\r\n\r\n[vSphere] also fixed bug in vm_reconfig_memory: wrong memory value passed to reconfig_hardware (memory in bytes instead of memory in MB).'
2297,'','AWS describe reservation end date\nadded in version 2013/10/01 '
2296,'',"When creating a new xenserver VM, the attribute HVM_boot_policy remains empty\nBug is in xenserver/requests/compute/create_server.rb\r\nin line 30:\r\n\r\nHVM_boot_params\r\nHVM_boot_params\r\n\r\nat least one of them should be:\r\nHVM_boot_policy\r\n\r\nI'm quite a newbie to the whole open-source world. So... I'm sorry this issue isn't reported well,\r\nI'm more than willing to learn if someone wouldn't mind to explain the correct way of creating a new issue.\r\n\r\nThanks!"
2295,'',"[google|storage] Fix integration with new excon version.\nThanks for this @burns, I've left a few comments below. I can merge when you're done.\r\n\r\nThis should fix #2294. "
2294,'',"Invalid Excon request keys: :host for Google Cloud Storage\nI tried fixing this (https://github.com/icco/fog/compare/fix_gcs_excon) but can't get it right for the life of me. @geemus et al, mind taking a look? GCS is broken with the most recent version of Fog.\r\n\r\nThis also reminds me I eventually want to migrate the GCS package to the new JSON API, which would be immune to this issue."
2293,'','Fix external IP config for GCE.\n'
2292,'',"[aws|iam] Don't pass :host to Excon request\nRelated issues: #2262, #2265 & #2284.  Tested on my AWS account scripts."
2291,'',"[vcloud_director] fixes so that non configured gateway are supported\nCurrently the get_edge_gateway call bombs on non-configured edge gateways as they don't contain all the expected fields and configuration.\r\n\r\nThis pull request fixes that by checking before traversing the xml. There is a second requirement that fills in the missing parts, but I wanted to submit this as it stops the code breaking on some environments. \r\n\r\nI've tested it on 4 different environments that are in different states, but acknowledge that more automation around this logic is a future requirement, once we can manipulate edge gateway configuration\r\n\r\n\r\n\r\n/cc @nosborn "
2290,'','[rackspace|block_storage] fixing merge issue\n'
2289,'','tests for configure edge gateways\nAdded tests for configuring edge_gateway. \r\n\r\nTests run in mock as well as non-mock mode.\r\n\r\nIn non-mock mode, it runs against a real edge gateway and configures the firewall services. It adds a firewall rule which is disabled by default and the rule is for added for not so important/used port. Test reverts the firewall back to its original state after the run.\r\n\r\n\r\n'
2288,'','[vcloud_director] improved tests for #ensure_list!\nCovering required behaviour around the contents of the lists - that they remain intact if data already exists'
2286,'','corrected name of edgegateway generator\nRenamed generator to have name same as the top level xml_node it generates.'
2285,'','[aws|storage] remove unused :path option\n\r\n'
2284,'',"Invalid Excon request keys: :scheme, :host\nI am using Nokogiri to scrape my old site and upload the 400 pages of content to my new site. There are a lot of file uploads that I need to do (carrierwave), and this was working perfect before I updated fog/excon.\r\n\r\nNow I get this error: `Invalid Excon request keys: :scheme, :host`\r\n\r\nMy script involves downloading and uploading 200mb files so it makes it kind of a pain to debug for my exact use-case, so I'm hoping someone has an idea before I do that.\r\n\r\nEdit: I forgot to mention, this is for S3.\r\n\r\nThanks!"
2283,'','AWS IAM userless key management\n- Implement mocks for create_acces_key, list_access_keys, update_access_keys\r\n\r\n- support fog.access_keys without specifying user as amazon does: http://docs.aws.amazon.com/IAM/latest/APIReference/API_ListAccessKeys.html'
2282,'',"Removed host params for excon connections\nI am not familiar enough with your code to know if this is the right way to solve this, but I gave it a shot.  We are seeing excon errors in the new 1.16.0 version which is resolved by the following change.  Here is a summary of the error we are seeing:\r\n\r\nInvalid Excon request keys: :host\r\n/Users/cheiron/.rvm/gems/ruby-2.0.0-p247@simple_deploy.beta.6/gems/excon-0.27.6/lib/excon/connection.rb:232:in `request'\r\n/Users/cheiron/.rvm/gems/ruby-2.0.0-p247@simple_deploy.beta.6/gems/fog-1.16.0/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/cheiron/.rvm/gems/ruby-2.0.0-p247@simple_deploy.beta.6/gems/fog-1.16.0/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/cheiron/.rvm/gems/ruby-2.0.0-p247@simple_deploy.beta.6/gems/fog-1.16.0/lib/fog/aws/cloud_formation.rb:101:in `request'\r\n"
2281,'',"[aws|storage] ensure connection uses correct scheme, host and port\nCurrently, the `:scheme`, `:host` and `:port` are determined in\r\n`#request_params` and passed as request parameters. However, passing\r\nthese as request parameters does not override the URI used to establish\r\nthe connection, which is used by Excon for the underlying socket.\r\nExcon now considers these to be invalid request parameters.\r\n\r\nThis patch defers establishing the connection until the proper URI is\r\nknown, while still allowing the `:persistent` option to work as long as\r\nthe URI doesn't change.\r\n\r\n---\r\nI have a few questions I'll add as line notes."
2280,'nosborn','[vcloud_director] Change input options structure.\n  #put_guest_customization_section_vapp\r\n  #put_network_connection_system_section_vapp\r\n\r\nAlthough no longer documented, the previous options structure is still\r\naccepted and is mutated into the new structure. This behaviour is likely\r\nto be deprecated at some point.'
2279,'','Remove dependency on "unicode" gem\nCommit 20a0f7d introduced the "unicode" gem as dependency for fog.  This is a C extension that apparently doesn\'t use FFI.  As such, it won\'t install on JRuby unless the experimental C extensions support is enabled.  Even if it were enabled, it\'d destroy performance on JRuby since it couldn\'t be used multi-threaded any longer.'
2278,'',"[SoftLayer] Adding new provider, a couple of questions / issues\nHi everyone,\r\n\r\nI have a few questions regarding a new provider. I am currently working on SoftLayer provider, here it is: https://github.com/Technicolor-Portico/fog/tree/softlayer\r\n\r\nIt is still work in progress. Following is now complete:\r\n\r\n- all services\r\n- all requests\r\n- all complex and simple types, array types also supported\r\n- mocks based on returned data types\r\n- object masks are supported\r\n- regular hashes / arrays can be passed in place of complex types and they're being validated\r\n\r\nWhat's left:\r\n\r\n- tests in development\r\n- a couple of issues around passing complex types to the API\r\n- models have to be added later as I need to figure out what qualifies to be a model and how should it be generated\r\n\r\nMy questions / issues:\r\n\r\n1. Could the code size be an issue in accepting pull request? It's over 60 MB of stuff, ~4k files with tests.\r\n2. I am struggling making unit tests work, I get this in Travis:\r\n\r\n```\r\n$ bundle install\r\nFetching gem metadata from https://rubygems.org/.......\r\nFetching gem metadata from https://rubygems.org/..\r\nResolving dependencies...\r\n...\r\nYour bundle is complete!\r\nUse `bundle show [gemname]` to see where a bundled gem is installed.\r\n$ bundle exec rake travis\r\nexport FOG_MOCK=true && bundle exec shindont\r\nWARNING: SimpleCov is activated, but you're not running Ruby 1.9+ - no coverage analysis will happen\r\nWARNING: SimpleCov is activated, but you're not running Ruby 1.9+ - no coverage analysis will happen\r\n/home/travis/build/Technicolor-Portico/fog/lib/fog/bin.rb:7:in `const_get': uninitialized constant Kernel::SoftLayer (NameError)\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/gems/shindo-0.3.8/lib/shindo/bin.rb:65:in `join'\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/gems/shindo-0.3.8/lib/shindo/bin.rb:65:in `run_in_thread'\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/gems/shindo-0.3.8/lib/shindo/bin.rb:72\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/gems/shindo-0.3.8/bin/shindont:7:in `require'\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/gems/shindo-0.3.8/bin/shindont:7\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/bin/shindont:23:in `load'\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/bin/shindont:23\r\n\tfrom /home/travis/.rvm/gems/ruby-1.8.7-p374/bin/ruby_noexec_wrapper:14\r\nrake aborted!\r\n```\r\n\r\nObviously I am missing something. Are there any instructions on how to fully enable unit tests for a new provider? Like a list of steps what has to be added where? Apologies if this is an obvious question.\r\n\r\nI am also open to any questions / suggestions / criticism at this early stage."
2277,'','[linode|compute] Avoid passing host to request.\nOne more instance of a `:host` key creeping into the Excon request params. That should clear the remainder of Linode issues.\r\n\r\nReferences #2248\r\n\r\nThanks for the prompt fix on [linode|dns]!'
2276,'','[rackspace] fixing broken tests\nIf `:rackspace_region` is specified in `tests/.fog` it causes the default region tests to break. This PR sets the `:rackspace_region` to `nil` in the default tests in order to override any settings provided by `Fog.credentials`'
2275,'',"[Rackspace] invalid credentials never returns.\nWhen using an invalid API key the call Fog::Compute.new it does not return.  The stack trace looks like it is in a loop because of a rescue.\r\n\r\n```\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/requests/identity/create_token.rb:15:in `create_token'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:35:in `request'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/requests/identity/create_token.rb:15:in `create_token'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:35:in `request'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/requests/identity/create_token.rb:15:in `create_token'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:35:in `request'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/requests/identity/create_token.rb:15:in `create_token'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/identity.rb:63:in `initialize'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/core/service.rb:68:in `new'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/core/service.rb:68:in `new'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:103:in `authenticate_v2'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/service.rb:30:in `authenticate'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/compute_v2.rb:167:in `authenticate'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/rackspace/compute_v2.rb:141:in `initialize'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/core/service.rb:68:in `new'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/core/service.rb:68:in `new'\r\n/Users/kevin/.rvm/gems/ruby-2.0.0-p195@puppet_modules/gems/fog-1.15.0/lib/fog/compute.rb:29:in `new'\r\n/Users/kevin/Projects/vagrant/Rakefile:15:in `get_service'\r\n```"
2274,'','[vcloud_director] making sure that edgegateway has correct list elements\n@nosborn : Could you please take a look?'
2273,'','Better error handing around SSH\nThis [Google group thread](https://groups.google.com/forum/?fromgroups=#!topic/ruby-fog/hlLvYMLIxMg) summarizes an issue where a user accidentally specified an invalid key and lost a lot of time trying to track down why bootstrapping a server kept hanging. \r\n\r\nI would like to suggest either better error handing around this issue and/or adding an environment variable similar to `EXCON_DEBUG`  to enable ssh logging. '
2272,'',"Remove webmock.\nNow that VCR has gone, WebMock can probably go too. I'm assuming the only remaining mention of WebMock is a workaround for the presence of WebMock.\r\n\r\n/cc @dgutov"
2271,'','[vcloud_director] Fancy progress bar for async tasks.\n'
2270,'','[vcloud_director] More request methods\n'
2269,'',"fog requires mime-types >= 0\nI'm preparing mime-types 2.0 for release, and it has some breaking API changes (not for most uses, but some esoteric features). The most important API change is that mime-types 2.0 no longer supports Ruby 1.8.\r\n\r\nIf this matters, the gemspec needs to be changed from >= 0 to ~> 1.16."
2268,'','[Rackspace] Miscellaneous fixes\nThis contains the following fixes:\r\n\r\n* removes `:host` from authenticate_v1\r\n* fixes issue creating database instances and users\r\n* fixes autoscale tests\r\n* fixes monitoring entity tests'
2267,'','[aws|storage] mark post_object_restore test pending unless mocking\n'
2266,'nosborn','[vcloud_director] Do ensure_list in request methods.\nMitigation for Fog::ToHashDocument. This is (still) a short-term fix\r\nuntil we get to real response parsers.'
2265,'',"Invalid Excon request keys: :host - 16 methods affected by excon change\n@geemus we can't release fog with these errors\r\n\r\ndescribe_availability_zones\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/describe_availability_zones.rb:33:in `describe_availability_zones'\r\n```\r\ndescribe_images\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/describe_images.rb:54:in `describe_images'\r\n```\r\ndescribe_security_groups\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/describe_security_groups.rb:43:in `describe_security_groups'\r\n```\r\nrun_instances\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/run_instances.rb:121:in `run_instances'\r\n```\r\nterminate_instances\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/terminate_instances.rb:33:in `terminate_instances'\r\n```\r\ndescribe_instances\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/describe_instances.rb:76:in `describe_instances'\r\n```\r\ncreate_security_group\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/create_security_group.rb:29:in `create_security_group'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_group.rb:238:in `save'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/collection.rb:52:in `create'\r\n```\r\nauthorize_port_range\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/authorize_security_group_ingress.rb:54:in `authorize_security_group_ingress'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_group.rb:104:in `authorize_port_range'\r\n```\r\ndelete_security_group\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/delete_security_group.rb:36:in `delete_security_group'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_group.rb:126:in `destroy'\r\n```\r\ndescribe_tags\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/describe_tags.rb:30:in `describe_tags'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/tags.rb:21:in `all'\r\n```\r\ndescribe_auto_scaling_groups\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:146:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:140:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/auto_scaling/describe_auto_scaling_groups.rb:105:in `describe_auto_scaling_groups'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/auto_scaling/groups.rb:31:in `get'\r\n```\r\ndescribe_launch_configurations\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:146:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:140:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/auto_scaling/describe_launch_configurations.rb:81:in `describe_launch_configurations'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/auto_scaling/configurations.rb:28:in `get'\r\n```\r\ndescribe_auto_scaling_groups\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:146:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:140:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/auto_scaling/describe_auto_scaling_groups.rb:105:in `describe_auto_scaling_groups'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/auto_scaling/groups.rb:31:\r\n```\r\ndescribe_launch_configurations\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:146:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:140:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/auto_scaling/describe_launch_configurations.rb:81:in `describe_launch_configurations'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/auto_scaling/configurations.rb:28:in `get'\r\n```\r\ncreate_auto_scaling_group\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:146:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:140:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/auto_scaling/create_auto_scaling_group.rb:93:in `create_auto_scaling_group'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/auto_scaling/group.rb:114:in `save'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/collection.rb:52:in `create'\r\n```\r\ncreate_launch_configuration\r\n```\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:146:in `_request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/auto_scaling.rb:140:in `request'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/auto_scaling/create_launch_configuration.rb:74:in `create_launch_configuration'\r\n```\r\n"
2264,'','[vcloud_director] Improve query service support\n'
2263,'',"[openstack] Fix mocking for create server request.\nA simple test like this\r\n\r\n```ruby\r\nrequire 'spec_helper'\r\n\r\ndescribe 'Bug' do\r\n  it 'should not fail' do\r\n    compute = Fog::Compute.new(\r\n      :provider => 'openstack',\r\n      :openstack_username => 'user',\r\n      :openstack_api_key => 'pass',\r\n      :openstack_tenant => 'tenant',\r\n      :openstack_auth_url => 'http://auth/url',\r\n    )\r\n\r\n    server_def = {\r\n      :name => 'name',\r\n      :image_ref => 'image_ref',\r\n      :flavor_ref => 'flavor',\r\n      :key_name => 'key_name',\r\n      :user_data => 'user_data',\r\n    }\r\n\r\n    server = compute.servers.create(server_def)\r\n  end\r\nend\r\n```\r\n\r\nfails with:\r\n\r\n     ArgumentError:\r\n       Missing required arguments: openstack_auth_url\r\n\r\nfor fog > 1.8.0.\r\n\r\nLooks like it was introduced in [fog 1.9.0](https://github.com/fog/fog/blob/v1.9.0/lib/fog/openstack/requests/compute/create_server.rb#L65)"
2262,'','[aws|compute] remove :host from request parameters\n'
2261,'','SignatureDoesNotMatch: fog fails to authorize ports\nFog is unable to authorize ports, here is how to reproduce it (excon 0.27.4 and fog master 409edda4441e96ef1d0f43bfeac69ea5105ac5f5)\r\n\r\nThe creation works, you can see errors but it doesn\'t raise an exception:\r\n```\r\n>> compute.security_groups.create(name: \'jander\', description: \'bla\')\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/create_security_group.rb:29:in `create_security_group\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_group.rb:238:in `save\'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/collection.rb:52:in `create\'\r\n(irb):191:in `<main>\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/workspace.rb:80:in `eval\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/workspace.rb:80:in `evaluate\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/context.rb:254:in `evaluate\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:159:in `block (2 levels) in eval_input\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:273:in `signal_status\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:156:in `block in eval_input\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:243:in `block (2 levels) in each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:229:in `loop\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:229:in `block in each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:228:in `catch\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:228:in `each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:155:in `eval_input\'\r\n./bin/fog:76:in `block in <main>\'\r\n./bin/fog:76:in `catch\'\r\n./bin/fog:76:in `<main>\'\r\n  <Fog::Compute::AWS::SecurityGroup\r\n    name="jander",\r\n    description="bla",\r\n    group_id="sg-fd027496",\r\n    ip_permissions=nil,\r\n    ip_permissions_egress=nil,\r\n    owner_id=nil,\r\n    vpc_id=nil\r\n  >\r\n```\r\nYou can find the security group but it shows errors\r\n```\r\n\r\n>> a=compute.security_groups.get(\'jander\')\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/describe_security_groups.rb:43:in `describe_security_groups\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_groups.rb:66:in `all\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_groups.rb:90:in `get\'\r\n(irb):192:in `<main>\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/workspace.rb:80:in `eval\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/workspace.rb:80:in `evaluate\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/context.rb:254:in `evaluate\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:159:in `block (2 levels) in eval_input\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:273:in `signal_status\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:156:in `block in eval_input\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:243:in `block (2 levels) in each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:229:in `loop\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:229:in `block in each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:228:in `catch\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:228:in `each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:155:in `eval_input\'\r\n./bin/fog:76:in `block in <main>\'\r\n./bin/fog:76:in `catch\'\r\n./bin/fog:76:in `<main>\'\r\n  <Fog::Compute::AWS::SecurityGroup\r\n    name="jander",\r\n    description="bla",\r\n    group_id="sg-fd027496",\r\n    ip_permissions=[],\r\n    ip_permissions_egress=[],\r\n    owner_id="076395046979",\r\n    vpc_id=nil\r\n  >\r\n```\r\nAuthorizing throws an exception\r\n```\r\n>> a.authorize_port_range(Range.new(80,80),  cidr_ip: \'0.0.0.0/0\')\r\nInvalid Excon request keys: :host\r\n/Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/authorize_security_group_ingress.rb:54:in `authorize_security_group_ingress\'\r\n/Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_group.rb:104:in `authorize_port_range\'\r\n(irb):193:in `<main>\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/workspace.rb:80:in `eval\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/workspace.rb:80:in `evaluate\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/context.rb:254:in `evaluate\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:159:in `block (2 levels) in eval_input\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:273:in `signal_status\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:156:in `block in eval_input\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:243:in `block (2 levels) in each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:229:in `loop\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:229:in `block in each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:228:in `catch\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb/ruby-lex.rb:228:in `each_top_level_statement\'\r\n/Users/restebanez/.rvm/rubies/ruby-1.9.3-p392/lib/ruby/1.9.1/irb.rb:155:in `eval_input\'\r\n./bin/fog:76:in `block in <main>\'\r\n./bin/fog:76:in `catch\'\r\n./bin/fog:76:in `<main>\'\r\nFog::Compute::AWS::Error: SignatureDoesNotMatch => The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/expects.rb:10:in `response_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:374:in `response\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:268:in `request\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/idempotent.rb:11:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:282:in `rescue in request\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/idempotent.rb:11:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:282:in `rescue in request\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/idempotent.rb:11:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:282:in `rescue in request\'\r\n\tfrom /Users/restebanez/.rvm/gems/ruby-1.9.3-p392/gems/excon-0.27.4/lib/excon/connection.rb:231:in `request\'\r\n\tfrom /Users/restebanez/public_repos/fog/lib/fog/xml/sax_parser_connection.rb:36:in `request\'\r\n\tfrom /Users/restebanez/public_repos/fog/lib/fog/core/deprecated/connection.rb:18:in `request\'\r\n\tfrom /Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:435:in `_request\'\r\n\tfrom /Users/restebanez/public_repos/fog/lib/fog/aws/compute.rb:430:in `request\'\r\n\tfrom /Users/restebanez/public_repos/fog/lib/fog/aws/requests/compute/authorize_security_group_ingress.rb:54:in `authorize_security_group_ingress\'\r\n\tfrom /Users/restebanez/public_repos/fog/lib/fog/aws/models/compute/security_group.rb:104:in `authorize_port_range\'\r\n\tfrom (irb):193:in `<main>\'\r\n\tfrom ./bin/fog:76:in `block in <main>\'\r\n\tfrom ./bin/fog:76:in `catch\'\r\n\tfrom ./bin/fog:76:in `<main>\'>> \r\n\r\n```\r\n\r\nThanks!\r\n\r\nRodrigo'
2260,'nosborn','[vcloud_director] Configure edge gateway services\nConfigures firewall, nat and load balancer services for an edge gateway. \r\n\r\nImplemented service layer to accept a configuration hash and do post to the vmware api.\r\n\r\naccepting all the required as well as optional fields specified in vmware api documentation. User can opt to not provide the optional fields.\r\n'
2259,'','Vcloud director/fix instantiation and tags creation\nHi @nosborn!\r\n\r\nThis PR fixes the instantiation of a vapp from a catalog_item model and the tags creation. They were fully broken.\r\n\r\nIt also fixes some syntax errors i found on post_deploy_vapp\r\n\r\nthanks,\r\n\r\nRodrigo'
2258,'',"[AWS|SQS] Fix iam credentials not being refreshed\nWhen using temporary IAM credentials, SQS wasn't checking whether they were expired or not"
2257,'','Various atmos enhancements around file meta-data\nExtract created_at, content_length, content_type from headers when reading files. \r\nAdd explicit system metadata request method and file_size (atmos does not report directly on file sizes > 10mb)'
2256,'','[vcloud_director] Improve support for query service.\n'
2255,'','[vcloud_director] Add post_instantiate_vapp_template request.\n'
2254,'','[vcloud_director] Raise provider-specific exceptions.\nHEADS UP: This is a breaking change for anyone rescuing Excon errors.'
2253,'','[vcloud_director] Mocking for vDC storage profiles.\n'
2252,'','Vcloud director xmlns\n'
2251,'','[openstack] remove :host from Excon request params\nA few others were removed in #2239'
2250,'','[rackspace|storage] fixed broken object test\n'
2249,'','Issue 2242 - atmos storage passes invalid parse attribute.  \nGrab parse attribute before it hits the excon connection\r\n\r\nSee also: \r\nhttps://github.com/fog/fog/issues/2242'
2248,'','AWS SimpleDB Fails with "Invalid Excon request keys: :host" for excon version 0.27.0 and later.\nExcon does not allow :host to be specified in the request params (see VALID_REQUEST_KEYS in excon/lib/constants.rb). I removed line 185 in lib/fog/aws/simpledb.rb and it workds as expected. It looks like it changed in version 0.27.0 about a week ago. They split the valid keys for connections and requests (https://github.com/geemus/excon/commit/1952b93e3826a66ab60b5da03da9a4e8c3d648d5). Also, this appears to affect at least other AWS services that I looked at and possibly everywhere that excon is used by fog.'
2247,'',"[rackspace] Adding Default UUID Queue Name\nBased on my conversation with @brianhartsock here https://github.com/fog/fog/pull/2237#issuecomment-26021181, I have decided that it's a much better approach to generate a UUID if a client id has not been specified rather than my previous approach of only adding a client id in testing.\r\n\r\nIn order to implement this, I had to add a UUID library. The google-api-tools gem uses uuidtools, so I decided that I would just stick with that. Do you mind adding an additional dependency @geemus? \r\n\r\nOn a side note, it looks like the queueing service has been updated to expect a UUID for a client id, so my previous approach would have failed anyways! "
2246,'','[vcloud_director] Corrected edge_gateway schema and removed bad test\nFixes to VCloud Director Edge Gateway tests and schema after running tests against a new and clean org'
2245,'','[vcloud_director] vm should return false if power action returns bad_request\nAlso using fog_logger for logging exceptions.\r\n\r\n@nosborn : Could you please take a look ?'
2244,'geemus','Ship a new version of fog\nThere have been a [ton of changes](https://github.com/fog/fog/compare/v1.15.0...master) since the last release back in August. I think itâs about time to release version 1.16.0. Tests are passing on Travis. What issues need to be resolved before a new gem can be pushed? Perhaps you could create a tag or a milestone for these issues so they could be prioritized?'
2243,'','[vcloud_director] Yet more request methods.\n'
2242,'','Excon 0.27.1 breaks requests where :parse => true\nRan into this problem after running a bundle update.\r\n\r\nAny request where parse is true will now fail as Excon is removing invalid request keys.\r\n\r\nSample Fog request: \r\n\'\'\'\r\n          request(\r\n            :body => generate_create_firewall_acls_request(data),\r\n            :expects => 201,\r\n            :method => "POST",\r\n            :headers => {},\r\n            :uri => data[:uri],\r\n            :parse => true\r\n          )\r\n\'\'\'\r\n\r\nAnd the line in question in Excon is here:\r\nhttps://github.com/geemus/excon/commit/1952b93e3826a66ab60b5da03da9a4e8c3d648d5#diff-93618fc68cdc1fde818cf4abd7102a14R361\r\n'
2241,'','Generalize server and floating ip create for openstack\n'
2240,'',"Behave IAM policy group methods like user policy\nAt this moment, `Fog::AWS::IAM.get_group_policy` returns group policy in a different way that `Fog::AWS::IAM.get_group_policy` despite of API docs say the same.\r\n\r\nIn `Fog::AWS::IAM.get_group_policy` the data isn't contained in a `Policy` key and `PolicyDocument` returns a flat string with JSON data, while `Fog::AWS::IAM.get_user_policy` returns the JSON data inside a `Hash`.\r\n\r\nTo accomplish this the following changes are done:\r\n\r\n- [x] Create mock group with `policies` and `created_at` keys\r\n- [x] Create mock methods for `get_group_policy` and `put_group_policy` requests, enable them in tests\r\n- [x] Run specs for `get_group_policy`\r\n- [x] Return `PolicyDocument` inside `Policy` section and return `PolicyDocument` as a Hash in `get_group_policy` parser"
2239,'','removing unnecessary :hosts parameters from dynect and openstack requests\nWhenever tests are run with a Excon 0.27, we get the following warnings from the dynect and openstack requests:\r\n\r\n```\r\nThe following keys are invalid: :host\r\n```\r\n\r\nThis PR hopefully removes all of them.'
2238,'','[openstack] make a couple storage tests pending if mocking\n'
2237,'','[rackspace] tweaking queue tests\nThis PR fixes a LINKS_FORMAT already defined error as well adds a default testing value for `:rackspace_queues_client_id` in order to make it easier to run Rackspace tests.'
2236,'','fixing typo in raising exception\nThis was not caught on Travis because it runs test in mock mode. This causes failures when we run tests in non-mock mode.'
2235,'','[rackspace] removing :host from list of request parameters. See PR #2223...\nRemoving :host from list of request parameters. See https://github.com/fog/fog/pull/2223#issuecomment-25938863 for details.\r\n\r\nThanks @burns'
2234,'','[vcloud_director] Remove vcr.\n'
2233,'','vSphere vm_clone a template to another datacenter/resource pool\nIs it possible to clone a template to a VM in another datacenter?  I have a vm template that exists in datacenter "Foo" and I\'d like to deploy a VM from that template to datacenter "Bar".  I\'m able to clone to datacenter "Foo", presumably because its the same datacenter where the template resides.\r\n\r\nFrom reading the docs, it seems like `resource_pool` is the option to use for specifying the destination?  Here\'s what I\'m trying:\r\n\r\n```\r\nconnection = Fog::Compute.new(credentials)\r\n\r\noptions = {"wait"=>true,\r\n "numCPUs"=>1,\r\n "memoryGB"=>1,\r\n "datacenter"=>"Foo",\r\n "datastore"=>"VM NFS Mount",\r\n "network_label"=>"172.10.16.x",\r\n "resource_pool"=>["Bar", "Bar Cluster"],\r\n "template_path"=>"centos_6_4",\r\n "power_on"=>true,\r\n "customization_spec"=>\r\n  {"domain"=>"example.com",\r\n   "hostname"=>"test01",\r\n   "ipsettings"=>\r\n    {"gateway"=>["172.10.16.1"],\r\n     "ip"=>"172.10.31.2",\r\n     "subnetMask"=>"255.255.240.0"}},\r\n "name"=>"Test01"}\r\n```\r\n\r\nThis results in:\r\n\r\n```\r\n/usr/lib/ruby/gems/1.8/gems/fog-1.15.0/lib/fog/vsphere/requests/compute/get_resource_pool.rb:16:in `get_raw_resource_pool\': undefined method `resourcePool\' for nil:NilClass (NoMethodError)\r\n        from /usr/lib/ruby/gems/1.8/gems/fog-1.15.0/lib/fog/vsphere/requests/compute/vm_clone.rb:97:in `vm_clone\'\r\n        from ./deploy.rb:148\r\n```\r\n\r\nLeaving off the `resource_pool` option, it clones successfully to the same datacenter, so as I said no problem there.  \r\n\r\nI\'m sure that Bar and Bar Cluster exist, to I\'m not sure what I\'m doing wrong.  Let me know if I can grab some debug info. \r\n\r\nGreat work on fog and thanks for the help.'
2232,'','[vcloud_director] Implement get*_metadata_item requests.\n'
2231,'','[vcloud_director] Use x-vcloud-authorization header.\nApparently vCloud Director can be configured to not send vcloud-token cookies.'
2230,'nosborn','[vcloud_director] Implement more API requests.\n'
2229,'','vapp returns false if power action returns bad_request\nFixed issue - where vapp model throws exception(400 Bad Request) if it fails to execute\r\npower action. This happens because the current state of vapp\r\ndoes not let user execute the action.\r\n\r\ne.g If vapp is in power_off state, it throw bad_request if user executes\r\npower_off, suspend,reboot or shutdown action.\r\n\r\nIn such case, fog model should return false instead of throwing exception.\r\nprinting the error message for debug.'
2228,'','[vcloud_director] Getting Edge Gateways details\nSupport the listing of the Edge Gateways for a VDC, and the details of on individual Edge Gateway\r\n\r\n/cc @sneha @nosborn '
2227,'','vapp returns false if power action returns bad_request\nFixed issues - where fog models throw exception if it fails to\r\nexecute power action on vapp. This happens because the current state\r\nof vapp does not let user execute the action.\r\ne.g If vapp is in power_off state, it throw bad_request if user executes power_off, suspend,reboot or shutdown action.\r\n\r\nIn such case we should return false instead of throwing exception. Also printing the error message.\r\n\r\n@nosborn : Could you please take a look?'
2226,'','Temp url generation interface modification according to the aws and openstack providers\nImplements:\r\n- File#url\r\n- Files#get_http_url\r\n- Files#get_https_url\r\n- Storage#get_object_http_url\r\n- Storage#get_object_https_url\r\n\r\nRefactors:\r\n- Storage#generate_object_temp_url\r\n\r\nTests:\r\n- requests/storage/object_tests.rb -> tests get_object_https_url, get_object_http_url\r\n\r\nThis is according to the discussion here: https://github.com/fog/fog/issues/2103\r\n'
2225,'',"[AWS] Can't change size of EBS root volume\nI've been having trouble changing the root volume size when creating an instance.\r\n\r\nEverything works if I do not change the block device mapping (leave it default). \r\n\r\nHowever, if I include the block device mapping in the options to servers.create, it fails with the error:\r\nSignatureDoesNotMatch => The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.\r\n\r\nI'm getting the block device mapping from the image. If I include the mapping with the options, whether I change it or not, it fails.\r\n\r\nMy same code works with Fog 1.6 (I found another project - knife-ec2 - doing the same thing, and it's fog dependency was set to Fog 1.6, so I though I would try)\r\n\r\nTo be clear, I have thoroughly verified that the configuration is correct and works, only by changing the block device mapping do I run into the bug.\r\n\r\nAny help?\r\nThanks"
2224,'','Update to RSpec 2\nAfter merging #2223, all of `fog`âs [dependencies are up-to-date](https://gemnasium.com/fog/fog) except `rspec`, which requires a relatively major update from 1.3. I donât feel comfortable doing this update myself but I think itâs worth doing.'
2223,'','Update excon dependency to version ~>0.27.0\n'
2222,'','[google|compute] Upgrade to v1beta16\nMan, I thought this would break a lot of stuff, but looks like it broke nothing...\r\n\r\nhttps://groups.google.com/forum/#!topic/gce-announce/LSVBtuAutwc'
2221,'','[google|compute] Fix metadata bug.\nWorks for when you have metadata, but no sshKeys metadata.'
2220,'','Update vcr dependency to version ~>2.6\n'
2219,'','Update webmock dependency to version ~>1.14\n'
2218,'','Update excon dependency to version ~>0.26.0\n'
2217,'nosborn','[vcloud_director] Enable media uploading\n'
2216,'','Auto update\nThis PR fills out the Rackspace Auto Scale implementation by adding missing tests, fogisms to models, along with  examples. It also contains a couple bug fixes.\r\n\r\nThe only outstanding issue for auto scale is a getting started document which will be included in another PR.'
2215,'','[rackspace|blockstrage] fixed mock error\nfixed snapshot_id being nil'
2214,'','Fog::Rackspace::Monitoring.new() hangs if given bad credentials\nIf you feed Fog::Rackspace::Monitoring bad credentials, it hangs indefinitely until you get this error about your stack being too big:\r\n\r\nhttps://gist.github.com/jayofdoom/d9073b6781ca5c058bae\r\n\r\nThis happens with a bad api_key, a bad username, or both.\r\n\r\nI personally am going to investigate and hopefully patch this, but wanted to file a bug in advance.'
2213,'','OpenStack orchestration update_stack fixes.\nThe update_stack call requires an ID and NAME to be included in\r\nthe URL of the PUT request.\r\n\r\nSee API docs here:\r\n\r\n  http://api.openstack.org/api-ref-orchestration.html'
2212,'',"OpenStack Orchestration fixes\nFixes the status code checks for the Orchestration requests so they match what Heat actually returns.\r\n\r\nAlso, fixes an issue where some HTTP 2xx responses didn't get jsonified properly."
2211,'','[vcloud_director] Add post_capture_vapp request.\n'
2210,'','[vcloud_director] Add get_*_ovf_descriptor methods.\n'
2209,'','[vcloud_director] Fix :UndeployPowerAction in post_undeploy_vapp\n'
2208,'','Aws autoscaling/fix tag assignment\nhi @geemus,\r\n\r\nThis PR fixes the tags assignment when an auto scaling group is created. It now accepts a hash instead of an array of hashes. \r\n\r\nRodrigo'
2207,'nosborn','[vcloud_director|tests] Fix some edge cases.\n'
2206,'','Openstack provider: Temp url support for Files\nThe PR aims at providing a common interface for creating temporary urls from files. The additions are corresponding to the HP provider temporary url methods. \r\nWe should be able to create temporary urls from File objects. The PR keeps the get_object_https_url function to keep the OpenStack provider backwards compatible. It just adds the temp url method generation methods according to the HP provider to guarantee a common interface for Openstack providers.\r\n\r\nThis pull requests adds the #temp_signed_url function to the Fog::Storage::Openstack::File class for generating temporary urls.\r\n\r\nIn addition it refactors the get_object_https_url request:\r\n- addition of the #generate_object_temp_url method\r\n- refactoring of the #get_object_https_url method -> extract body to private function (#create_temp_url)\r\n'
2205,'','Vcloud director/miscellany of improvments\nHi @geemus and @nosborn,\r\n\r\nThis PR is a set miscellany of small improvements for vcloud director:\r\n- using post_undeploy_vapp\r\n- power_off for a vm\r\n- when a vapp is created successfully returns the vapp-id\r\n- shutdown method was duplicate\r\n- ready? method implemented\r\n- accessing to the parent vapp even if the vm is orphan (query result)\r\n- memory is an integer\r\n\r\nThanks,\r\n\r\nRodrigo'
2204,'nosborn','[vcloud_director] Add remaining vApp/VM power actions.\n'
2203,'nosborn','[vcloud_director] Add get_supported_systems_info request.\n'
2202,'nosborn','[vcloud_director] Request method renaming.\nThis renames most request methods in line with page names in the vCloud\r\nAPI documentation. Previous method names remain as deprecations.'
2201,'','All OpenStack heat requests must contain User/Key.\nUpdates the OpenStack Orchestration request() method\r\nso that all requests contain the X-Auth-User and X-Auth-Key\r\nheaders.\r\n\r\nHeat requires these parameters so that it can make subsequent requests\r\nbased on the users behalf.\r\n\r\nFor reference see here:\r\n\r\nhttps://github.com/openstack/python-heatclient/blob/master/heatclient/common/http.py#L186'
2200,'','[vcloud_director] Add tests for task model.\n'
2199,'','[vcoud_director] Add media requests and model\n'
2198,'','Fix AWS S3 POST object restore SignatureDoesNotMatch error\nPOST object restore was using the bucket_name as a host prefix rather than in the canonical path as AWS was expecting. This resulted in getting results such as:\r\n\r\n```xml\r\n<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\r\n<Error>\r\n  <Code>SignatureDoesNotMatch</Code>\r\n  <Message>\r\n    The request signature we calculated does not match the signature you provided.\r\n    Check your key and signing method.\r\n  </Message>\r\n  <StringToSignBytes>â¦</StringToSignBytes>\r\n  <RequestId>â¦</RequestId>\r\n  <HostId>â¦</HostId>\r\n  <SignatureProvided>â¦</SignatureProvided>\r\n  <StringToSign>POST\r\nAAjA1/2lcgEFNlhuhHDHBw==\r\napplication/xml\r\nMon, 30 Sep 2013 18:08:03 +0000\r\n{bucket_name}/{object_name}?restore</StringToSign>\r\n  <AWSAccessKeyId>â¦</AWSAccessKeyId>\r\n</Error>\r\n```\r\n\r\nI narrowed it down to the StringToSign generated by `post_object_restore` not including the `bucket_name`. I\'m not sure why this used to work honestly. Maybe AWS got stricter?'
2197,'','Hp provider addition: ensure that hp_auth_version is loaded as symbol\nWe had some problems with this configuration key. If the key is not a symbol within the configuration file, the provider raises NotFound errors. This small fix guarantees that the configuration value is always passed as a symbol.'
2196,'nosborn','[vcloud_director] More mocking (1.8.7 compliant)\n'
2195,'','Add alias for openstack availablilty zone server attribute\nThe availability zone attribute in server API messages is actually\r\nOS-EXT-AZ:availability_zone.  Adding the alias will correctly map the\r\navailability zone values into fog responses.'
2194,'nosborn','Revert "[vcloud_director] More mocking."\nThis reverts commit b19f2f0e7eddb80eb78d65757fb2dfbb8db19dd0.\r\n\r\nSeems to contain a 1.9-ism, backing out until found.'
2193,'icco','[google] Add mock data\nMock data for google provider'
2192,'','Fix issue #2187\nA test and a fix for issue #2187 where Rackspace Server.create incorrectly mutates the options passed to it and a fix which creates a deep copy of the options and mutates that instead'
2191,'','[openstack|storage] add bulk delete and SLO support\nThese are essentially the same changes that have already been made for Rackspace.\r\nI was holding off on this until some error handling changes were committed to Swift (openstack/swift@3e6f929).\r\nThere are still a few test failures dealing with object paths returned in PUT request error messages,\r\nbut the [patch for that](https://review.openstack.org/#/c/48863) should be committed to Swift soon.'
2190,'','[google|compute] Update bootstrap image to debian-7-wheezy-v20130816.\nJust keeping things up to date.'
2189,'nosborn','[vcloud_director] Better mocking and documentation.\n'
2188,'','support "name" on cloudstack deploy\nThe \'name\' option is supported, but wasn\'t implemented for some reason, for CloudStack. This meant spinning up VMs with Fog would result in a random, UUID, name for the VM. The name flows through to the VM as its hostname, so this was pretty gruesome.\r\n\r\nThis tiny patch fixes that behaviour.'
2187,'','Compute.servers.bootstrap mutates the :networks option\n["front", "back"].each { |serverName| \r\n    puts("#{serverName} networks: " + @settings[:networks].to_s)\r\n    server = getCompute().servers.bootstrap     \\\r\n            :name => serverName,\r\n            :flavor_id => ...,\r\n            :image_id => ...,\r\n            :public_key_path => ...,\r\n            :private_key_path => ...,\r\n            :networks => @settings[:networks]   \r\n    puts ("Ok!")\r\n}\r\n\r\nOutput:\r\n\r\nfront networks: ["omitted", "11111111-1111-1111-1111-111111111111", "00000000-0000-0000-0000-000000000000"]\r\nOk!\r\nback networks: [{:uuid=>"omitted"}, {:uuid=>"11111111-1111-1111-1111-111111111111"}, {:uuid=>"00000000-0000-0000-0000-000000000000"}]\r\n[WARNING] Received exception \'795: unexpected token at \'Forbidden\r\n\r\nAccess was denied to this resource.\r\n\r\n Networks (00000000-0000-0000-0000-000000000000,11111111-1111-1111-1111-111111111111) required but missing  \'\' while decoding>> 403 Forbidden\r\n\r\nThe problem is that inside the bootstrap method something modifies the passed in :networks array (apparently changing it to the REST api format)\r\n'
2186,'','[vSphere] Support datacenters that are located below folders not in root...\n## Background ##\r\nIn big vmware installations datacenters might be organized in subfolders.\r\nNormally the vmware datacenters are located in the "root" folder of vmware but when having loads of dcs it is a common approach to organize the dcs in different folders.\r\n\r\nRight now fog cannot cope with this problem.\r\n\r\nIf a datacenter is located in different folders no guests can be queried or selected as the referring datacenter cannot be found.\r\n\r\n## Solution ##\r\n\r\nThis solution add a path to each datacenter that points to the location of the dc.\r\nThe path is an array of parent locations of the dc and will be recursively evaluated when searched for the dc name (see *raw_getpathmo* in *lib/fog/vsphere/requests/compute/list_datacenters.rb*).\r\n\r\nLet me know what you think.\r\n\r\nThanks Marc.'
2185,'','[vSphere] Support passing of a distributed switch for each interface.\n## Background: ##\r\nRemark: This is only related to the vSphere implementation of fog.\r\n\r\nIt is not yet possible with fog to create a nic (nic backing) on a vmware guest on different distributed switches that host the same network but are located in different datacenters.\r\nUntil now there is no option to add a nic with a specific distributed switch aside the nic configuration.\r\n\r\nThis leads to guests not being created.\r\nError message:\r\n```\r\nRbVmomi::Fault: failed to create vm: InvalidArgument: A specified parameter was not correct.\r\nspec.deviceChange.device.port.switchUuid\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/lib/fog/vsphere/requests/compute/create_vm.rb:27:in `rescue in create_vm\'\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/lib/fog/vsphere/requests/compute/create_vm.rb:8:in `create_vm\'\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/lib/fog/vsphere/models/compute/server.rb:211:in `save\'\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/lib/fog/core/collection.rb:52:in `create\'\r\n        from (irb):15:in `<main>\'\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/bin/fog:54:in `block in <main>\'\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/bin/fog:54:in `catch\'\r\n        from /usr/share/foreman/.gem/ruby/1.9.1/gems/fog-1.11.1/bin/fog:54:in `<main>\'\r\n```\r\n\r\nThe message *A specified parameter was not correct. spec.deviceChange.device.port.switchUuid* is the relevant error message from vmware.\r\n\r\nThe error is located at the place where the raw network is selected from vsphere as follows (lib/fog/vsphere/requests/compute/get_network.rb):\r\n```\r\n          @connection.serviceContent.viewManager.CreateContainerView({\r\n            :container  => dc.networkFolder,\r\n            :type       =>  ["Network"],\r\n            :recursive  => true\r\n          }).view.select{|n| n.name == name}.first\r\n```\r\n\r\nThis will select the first distributed switch to be found matching the required network name. Nevertheless if the same network is used in different dcs always the same distributed switch is selected.\r\nThis will fail in one of the two dcs as a special distributed switch is required.\r\n\r\n## Solution: ##\r\nIt would be an option to pass the required distributed switch along with the interface to be created (optional).\r\nIf there is no distributed switch passed as option the code is executed as before but otherwise the network for this given distributed switch is selected.\r\n\r\nThe solution might look as follows:\r\n```\r\n          @connection.serviceContent.viewManager.CreateContainerView({\r\n            :container  => dc.networkFolder,\r\n            :type       =>  ["Network"],\r\n            :recursive  => true\r\n          }).view.select { |n| n.name == name and (not distributedswitch_name or n.config.distributedVirtualSwitch.name == distributedswitch_name)}.first\r\n```\r\n\r\nThis pull request solves this critical problem with this aproach.\r\n\r\nAny better ideas?\r\n\r\nLet me know what you think.\r\nMarc.\r\n'
2184,'nosborn','[vcloud_director] Add get_supported_versions request.\n'
2183,'','[google] Zone is a required parameter of machine_types request\nFixes ArgumentError: Missing required parameters: zone when calling get_machine_type'
2182,'icco','[google] Create zone and zones models\nThe models were missing with a TODO\r\n\r\nPreparing a pull request with mock data too'
2181,'','[rackspace] hardcoding flavor_id used by mock data\nThis PR hopes to address issue https://github.com/fog/fog/issues/2138. \r\n\r\nThe Rackspace mock implementation creates flavors with an random id. It seems these failures creep up when the randomly generated flavor id is 0 as the flavor helper uses 0 to tst not found exceptions.  This PR just hard codes flavor ids to 3.'
2180,'','mock sns\nmocks create_topic and publish for basic needs.'
2179,'',"Local storage's File quacks like other Directories\nEven though it doesn't accept any options, it'd be nice if it accepted them\nanyway in the name of duck typing and allowing backends to be more swappable."
2178,'nosborn','[vcloud_director] Start mocking requests.\n- also adds get_current_session request'
2177,'','allow custom hp_service_type\nThe private class method [`.get_endpoint_from_catalog`](https://github.com/fog/fog/blob/master/lib/fog/hp.rb#L200) in `hp.rb` depends on `options[:hp_service_type]` which was hardcoded "Object Storage", as can be seen [here](https://github.com/fog/fog/blob/master/lib/fog/hp/storage.rb#L268). \r\n\r\nFor my setup to work, I need to be able to override this option. So I added `:hp_service_type` to the recognizable options and made "Object Storage" an overrideable default. This also seems in line with what was presumably the purpose of the `hp_service_type` option in the first place. '
2176,'','[vcloud_director|tests] Fixes and cleanup\nAs previously but without the unintended irony.'
2174,'','added put_record for dynect\n'
2173,'','[openstack|storage] remove deprecated response block from request\nPassing a response block to `Excon::Connection#request` was deprecated in favor of passing `:response_block`.'
2172,'','[rackspace] remove deprecated response block from request\nPassing a response block to `Excon::Connection#request` was deprecated in favor of passing `:response_block`.\r\nThis was only being used with `Storage::Rackspace#get_object`, which was setting `:response_block` _and_ passing that block to the request.'
2171,'','AWS::Compute security groups-  ICMP type rules created incorrectly\nNot sure if this is an AWS API bug or fog (or both, with the former not doing proper error checking):\r\n\r\nICMP rules created using fog (where a specific ICMP type is chosen) get created as $description/$type - I.E: "Echo Request/8"\r\n\r\nThe rule gets created fine, no issues.  However, the rule does not actually work - echo request traffic does not reach the instance (verified with tcpdump).\r\n\r\nHowever, if you create an ICMP rule through the web interface it gets created as "$description" - I.E "Echo Request" - note that the type is not postfixed - This rule actually works.\r\n\r\nAlso - in the API docs, it seems that there are two valid arguments for creating ICMP rules - either by specifying \'icmp\' as the protocol, or by passing the type at this point: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-AuthorizeSecurityGroupIngress.html\r\nThis could potentially have something to do with it..\r\n\r\nIf I get some free time I\'ll throw something together with the official ruby SDK and see what that does.'
2170,'','cloudstack model for security group rule missing icmpcode/type handling\nIn the cloudstack model for security group rules there is currently no handling for icmpcode and icmptype.  Cloudstack treats these vars separately to startport and endport.'
2169,'',"[rackspace] updating to only parse json if the body of the response has data \nWe are still seeing issues like https://github.com/fog/fog/pull/2163, which seems to occur with some json parsers. This PR update's the Rackspace provider to only attempt to parse a response if it contains data."
2166,'','[vcloud-director] fixed fog to load vdc with single or zero resource entities\nFog code fails to describe the vdcs with zero or single resource entities.\r\n\r\nThis is because the underlying API does not return Array, when vdc has single or no resource entities. \r\n\r\nThis causes parser to return following : \r\n - String (in case of zero resource entities)\r\n - Hash (in case of one resource entity)\r\n - Array (in case of more than one resource entities)\r\n\r\nThe fog throws error since it always expects an array. Fixed this behavior.\r\n'
2165,'','Fog::Storage::OpenStack::Real#put_object: Don\'t use data when block is provided\nWithout adding the WebMock-related lines, the `#put_object` test passes, but the `#get_object` after it fails, because the object gets created with empty body.\r\n\r\nWith WebMock properly disabled, I get `Excon::Errors::HTTPStatusError` wth status 499, because that\'s what Swift returns when [Content-Length header value is provided and doesn\'t match the request](http://blog.chmouel.com/2012/02/06/anatomy-of-a-swift-put-query-to-object-server/). The obvious fix is not to use the `data` argument at all when `block` is provided.\r\n\r\n```\r\n      put_object with block\r\n        #put_object(\'fogobjecttests\', \'fog_object\', &block) - succeeds\r\n        Expected(201) <=> Actual(499 Unknown)\r\n  request => {:chunk_size=>1048576, :connect_timeout=>60, :debug_request=>true, :debug_response=>true, :headers=>{"User-Agent"=>"fog/1.15.0", "Content-Type"=>nil, "X-Auth-Token"=>"MIIE8gYJKoZIhvcNAQcCoIIE4zCCBN8CAQExCTAHBgUrDgMCGjCCA8sGCSqGSIb3DQEHAaCCA7wEggO4eyJhY2Nlc3MiOiB7InRva2VuIjogeyJpc3N1ZWRfYXQiOiAiMjAxMy0wOS0yMlQwMzo0NjowNS4yMjM4MjIiLCAiZXhwaXJlcyI6ICIyMDEzLTA5LTIzVDAzOjQ2OjA1WiIsICJpZCI6ICJwbGFjZWhvbGRlciIsICJ0ZW5hbnQiOiB7ImRlc2NyaXB0aW9uIjogIlRlbmFudCBmb3IgdXNpbmcgZnJvbSB0aGUgd2ViIHNlcnZpY2VzIiwgImVuYWJsZWQiOiB0cnVlLCAiaWQiOiAiMTY0YzY1NzMwN2YwNDIxMmI0MDgxMzZiODE2ZWY3NDMiLCAibmFtZSI6ICJyZXNlbGxlcl90ZW5hbnQifX0sICJzZXJ2aWNlQ2F0YWxvZyI6IFt7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjMzLjEwOjgwODAvdjEiLCAicmVnaW9uIjogIkRldmVsb3AiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMzMuMTA6ODA4MC92MS9BVVRIXzE2NGM2NTczMDdmMDQyMTJiNDA4MTM2YjgxNmVmNzQzIiwgImlkIjogIjdkN2EzMThkMTU1MDRmMzc4ZWNhM2I3ZmU5YjY3ZWIyIiwgInB1YmxpY1VSTCI6ICJodHRwOi8vMTkyLjE2OC4zMy4xMDo4MDgwL3YxL0FVVEhfMTY0YzY1NzMwN2YwNDIxMmI0MDgxMzZiODE2ZWY3NDMifV0sICJlbmRwb2ludHNfbGlua3MiOiBbXSwgInR5cGUiOiAib2JqZWN0LXN0b3JlIiwgIm5hbWUiOiAic3dpZnQifV0sICJ1c2VyIjogeyJ1c2VybmFtZSI6ICJyZXNlbGxlcl91c2VyIiwgInJvbGVzX2xpbmtzIjogW10sICJpZCI6ICI1NDA2MmE5ZmRiZjY0MzVlYTQwMmRhNDZhMjk1OGE1OCIsICJyb2xlcyI6IFt7Im5hbWUiOiAiX21lbWJlcl8ifSwgeyJuYW1lIjogIlJlc2VsbGVyQWRtaW4ifV0sICJuYW1lIjogInJlc2VsbGVyX3VzZXIifSwgIm1ldGFkYXRhIjogeyJpc19hZG1pbiI6IDAsICJyb2xlcyI6IFsiOWZlMmZmOWVlNDM4NGIxODk0YTkwODc4ZDNlOTJiYWIiLCAiZDU5ZWIwYTk1MWZmNDcxMTgwMWM3YmNjNTdhMTk4OWQiXX19fTGB-zCB-AIBATBcMFcxCzAJBgNVBAYTAlVTMQ4wDAYDVQQIEwVVbnNldDEOMAwGA1UEBxMFVW5zZXQxDjAMBgNVBAoTBVVuc2V0MRgwFgYDVQQDEw93d3cuZXhhbXBsZS5jb20CAQEwBwYFKw4DAhowDQYJKoZIhvcNAQEBBQAEgYB-t-mNoxauDhRZbjsjuGJNnw8aEpyfqYEyTKosJLlguSYxoLrrUauYDYzTRt7MzxxbUIFaltFlLKPzJx1xHWDN8rkuLa9IpbvNPvAUOt6hOZ2OG71uu1B1eUWxrmzAeis4krmVnwBYxS3QvOS40mzO65NkO61D9TGOXBGtPoOeAA==", "Content-Length"=>0, "Host"=>"192.168.33.10:8080", "Transfer-Encoding"=>"chunked"}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::ResponseParser, Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>nil, :nonblock=>true, :omit_default_port=>false, :read_timeout=>60, :retry_limit=>4, :ssl_verify_peer=>true, :tcp_nodelay=>false, :uri_parser=>URI, :write_timeout=>60, :host=>"192.168.33.10", :path=>"/v1/AUTH_164c657307f04212b408136b816ef743/fogobjecttests/fog_block_object", :port=>"8080", :query=>nil, :scheme=>"http", :user=>nil, :password=>nil, :__construction_args=>{:host=>"192.168.33.10", :path=>"", :port=>"8080", :query=>nil, :scheme=>"http", :user=>nil, :password=>nil, :debug_response=>true, :headers=>{"User-Agent"=>"fog/1.15.0"}}, :request_block=>#<Proc:0x007f5e99ba6a68@/home/gutov/vc/fog/tests/openstack/requests/storage/object_tests.rb:53>, :expects=>201, :method=>"PUT", :retries_remaining=>4}\r\n  response => #<Excon::Response:0x007f5e99996c50 @data={:body=>"<html><h1>Client Disconnect</h1><p>The client was disconnected during request.</p></html>", :headers=>{"Last-Modified"=>"Sun, 22 Sep 2013 03:46:05 GMT", "Content-Length"=>"89", "Content-Type"=>"text/html; charset=UTF-8", "Date"=>"Sun, 22 Sep 2013 03:46:06 GMT"}, :status=>499, :remote_ip=>"192.168.33.10"}, @body="<html><h1>Client Disconnect</h1><p>The client was disconnected during request.</p></html>", @headers={"Last-Modified"=>"Sun, 22 Sep 2013 03:46:05 GMT", "Content-Length"=>"89", "Content-Type"=>"text/html; charset=UTF-8", "Date"=>"Sun, 22 Sep 2013 03:46:06 GMT"}, @status=499, @remote_ip="192.168.33.10"> (Excon::Errors::HTTPStatusError)\r\n          /home/gutov/.rbenv/versions/1.9.3-p429/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/expects.rb:10:in `response_call\'\r\n          /home/gutov/.rbenv/versions/1.9.3-p429/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n          /home/gutov/.rbenv/versions/1.9.3-p429/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:350:in `response\'\r\n          /home/gutov/.rbenv/versions/1.9.3-p429/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:248:in `request\'\r\n          /home/gutov/vc/fog/lib/fog/core/connection.rb:57:in `request\'\r\n          /home/gutov/vc/fog/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n          /home/gutov/vc/fog/lib/fog/openstack/storage.rb:145:in `request\'\r\n          /home/gutov/vc/fog/lib/fog/openstack/requests/storage/put_object.rb:28:in `put_object\'\r\n          /home/gutov/vc/fog/tests/openstack/requests/storage/object_tests.rb:53:in `block (4 levels) in <top (required)>\'\r\n          tests/helpers/succeeds_helper.rb:6:in `instance_eval\'\r\n          tests/helpers/succeeds_helper.rb:6:in `block in succeeds\'\r\n...\r\n```\r\n\r\nNotes:\r\n\r\n* I haven\'t found a better place to put the WebMock workaround.\r\n* The Rackspace code may need a similar fix.'
2164,'',"fix missing record data in dynect dns\ncurrently, when fog requests all records:\r\n*   make a NodeList request\r\n    *   returns a list of nodes (domains)\r\n*   for each domain, make a secondary AnyRecord request for each domain\r\n    *   returns a list of records (without data)\r\n\r\nThe resulting Record objects do not contain the data of where the record points (address or cname). 'rdata' is nil\r\n\r\nI've changed the process to be:\r\n*   make an AllRecord request\r\n    *   returns a list of records (without data)\r\n*   make a secondary request to *Record (using the type returned from the AllRecord request)\r\n    *   this returns a *complete* record object (including data)\r\n\r\nThe number of requests to Dynect API is the same, but the resulting objects contain all of the information.\r\n\r\nTODO:\r\n- [x] Please help me integrate with fog testing\r\n- [ ] Not sure if there are any code style preferences\r\n- [x] I had to remove (comment) the API Version header, not sure what the correct value for this is --- Dynect documentation is a bit difficult to work through\r\n- [x] Some clean up required"
2163,'',"[rackspace] Don't parse JSON in delete_server response\nThe Rackspace API replies with an empty response to delete_server\r\nrequests, but includes a header enforcing the application/json\r\ncontent-type.\r\n\r\nThis commit disables JSON parsing on `delete_server` requests,\r\nwhich prevents the appearance of these warnings:\r\n\r\n> [WARNING] Error Parsing response json - 781: unexpected token at ''"
2162,'','Fog AWS snapshot status reports different values than AWS-SDK library\nI\'ve been working on some code that snapshots some AWS volumes and checks the status of those volumes to ensure that they are ready.\r\n\r\nI found a strange issue where the AWS-SDK returns the correct status and Fog doesn\'t, I\'ve tested this using the following code snippet in gist \r\n\r\nhttps://gist.github.com/actionjack/6636642\r\n\r\nWhen I execute the code the AWS connection says it\'s completed 100% but the fog code say\'s it\'s pending. When I check the console I can see it\'s completed :-(\r\n\r\n"Creating new snapshot(s)"\r\n"Created snapshot of AZ1.Volume.1 with snapshot id of snap-2397b93c"\r\n"Created snapshot of AZ1.Volume.2 with snapshot id of snap-2097b93f"\r\n"Snapshot id is snap-2397b93c"\r\n:completed\r\n100\r\n"This is the value from the fog library: ...progress=nil,\\n state=\\"pending\\"..."\r\n"----------------------------------------------------------"\r\n:completed\r\n100\r\n"This is the value from the fog library: ...progress=nil,\\n state=\\"pending\\"..."\r\n"Snapshot id is snap-2097b93f"\r\n:completed\r\n100\r\n"This is the value from the fog library: ...progress=nil,\\n state=\\"pending\\"..."\r\n"----------------------------------------------------------"\r\n:completed\r\n100\r\n"This is the value from the fog library: ...progress=nil,\\n state=\\"pending\\"..."\r\n'
2161,'','AutoScaling Group initializer attribute assignment\nAttempts to fix issue #1284.  I ran into the problem when passing min_size and max_size to the constructor of an AWS AutoScaling Group. It would not set the attributes because the "XML-style" name was being set first and overriding the subsequent "ruby-style" name.  More specifically, this was happening:\r\n\r\n```ruby\r\ngroup = Fog::AWS::AutoScaling::Group.new({min_size: 1, max_size: 2})\r\ngroup.min_size # => 0\r\ngroup.max_size # => 0\r\n```\r\n\r\nFollowing your advice from #1284, I set the default values using attribute setters instead of attributes[\'AttrName\'] ||=.  Also, since this happens before calling super, I just used direct assignment instead of the ||= conditional assignment.\r\n\r\nI\'m not too familiar with shindo, and I\'m also not sure if the issue has more subtle implications than what I\'ve tested here, so let me know if this needs some work.'
2159,'','Fix for https urls in atmos.\nURI::HTTP doesn\'t accept/use a "scheme" param, so all urls are being created with "http", regardless of whether service.ssl? is true or not.'
2158,'','Can\'t generate https urls for Atmos\nThe "public_url" method code in lib/fog/atmos/models/storage/file.rb is unable to generate an "https" url. It\'s attempting to pass a "scheme" param to URI::HTTP.build, but URI::HTTP.build doesn\'t use a "scheme" param, so the scheme is being ignored and always defaults to "http". No version of URI::HTTP\'s "build" method has accepted a "scheme" param since at least ruby 1.8.7, including ruby 2.0, so I\'m not sure when this ever would have worked.\r\n\r\nURI::HTTP.new accepts a "scheme" param, but it returns a URI object, not an actual url, so it\'s not a direct replacement.\r\n\r\nURI::HTTPS.build can be used to generate an https url. So, a fix is (starting at line 110):\r\n\r\nklass = (service.ssl?) ? URI::HTTPS : URI::HTTP\r\nuri = klass.build(:host => service.host, :port => service.port.to_i, :path => "/rest/objects/#{self.objectid}")\r\n\r\nI can submit a pull request if necessary.'
2157,'','[vcloud_director] Added support for deleting vApps.\nAdded `destroy` method to `vapp`. '
2156,'','Add basic edge gateway support for Vcloud director \nDraft pull request to add Edge Gateways to VCloudDirector.\r\n\r\nThis adds the ability to get information about the edge gateways of a VMware Virtual Data Centre. The data is pretty raw but its enough to know the current state of firewall rules and NAT settings, as well as network connectivity. \r\n\r\nPlease add comments below\r\n\r\n/cc @nosborn @philandstuff @snehaso'
2155,'','[vcloud_director] Fix listing catalog items when only a single item exists\nListing catalog items fails if the catalog only contains a single item. This is caused by `data[:CatalogItems][:CatalogItem]` containing a hash instead of expected list of hashes. Fix it by wrapping hash in a list, i.e. the same way it is handled in case of organizations.'
2154,'','Added Coveralls.io coverage badge to README.md\n'
2153,'','fix for linode using public ip blocks in 192.*\nLinode now assigns some public ip addresses in the 192.* range, which is ignored by the current regex.  This causes public_ip_address to throw an exception'
2152,'','Add ability to associate public ip with VPC instance on creation\nAdds support for public ip address association with VPC instances, similar to EC2-Classic.\r\nRequires updating the AWS API version for compute to 2013-08-15.'
2151,'','Quick doc update with some available EBS properties\nIt took me a few tries to get the properties right so I figured a quick update to the docs may save some one a few mins in the future.'
2150,'','Vcloud director poweroff support\nAdd support for powering of vms, and support for powering on/off vApps.'
2149,'','[vcloud_director] rename undeploy.rb to match other request files\n'
2148,'','The Getting Started section of README.md is outdated\nThere is no Compute module at the root level. \r\n\r\nActually, most of the readme is outdated and needs revision.'
2147,'',"[vcloud_director] whitespace cleanup\nI thought I'd get all of the bogus whitespace out of the way. There are no functional changes in this, it's just indentation, chomping, alignment, etc."
2146,'','[vcloud_director] Add ability to undeploy vApp\n'
2145,'kkanev','CloudSigma Firewall Policies\nAdd model for Rule and FW Policies\r\nRetrieve FW Policies'
2144,'',"Rackspace Cloud Files URL contains %252D\nWhen uploading files with dashes in them using paperclip, the return url I get back contains %252D instead of the '-'. For example: \r\n\r\nhttp://zzz.com/images/products/7/original/test%252Dbloodymary.jpg?1379196904\r\n\r\nthe correct url should be: \r\nhttp://zzz.com/images/products/7/original/test-bloodymary.jpg?1379196904\r\n\r\nthe file is stored correctly on rackspacecloud files. any ideas on what is causing this? \r\n\r\nI was able to repoint fog to S3 and I was not able to duplicate the issue. A file with the dashes is being stored properly on S3 and the return URL is correct. \r\n\r\nusing \r\ngem 'fog', '~> 1.15.0'\r\ngem 'paperclip', '~> 3.5.1'"
2143,'','[vcloud_director] Deconflate Org name and FullName.\n'
2142,'',"[vcloud_director] Integrate tests\n- add tags for `rake test`\r\n- use `tests/.fog` not bespoke environment variables\r\n- vapp_life_cycle_tests made pending; extra requests arise after\r\n  71a303415b695aeba463ee4e795c3f9885c83f92\r\n\r\nFor confidentiality reasons I'm not able to provide an updated VCR cassette.\r\n"
2141,'','openstack | add min_count, max_count, return_reservation_id\nopenstack | add min_count, max_count, return_reservation_id for the create_server method.'
2140,'','[rackspace|compute_v2] adding private network creation/deletion examples\nadding private network creation/deletion examples'
2139,'eyardimci','Fixes redshift typo that prevented parsing more than one reserved_node in response\n'
2138,'krames','failing mock rackspace test\n@krames could you take a quick look at this: https://travis-ci.org/fog/fog/jobs/11272207#L320 (seems likely to be a quick fix, but I figured I would let you take a look just in case). Thanks!'
2137,'','Rackspace Cloud Storage Australia region\nRackspace recently launched the data centre in Sydney, but **fog** does know nothing about it. There is only UK/US endpoints here: https://github.com/fog/fog/blob/master/lib/fog/rackspace.rb#L11\r\n\r\nIs any plan to release Sydney endpoint https://syd.identity.api.rackspacecloud.com/v2.0 here?'
2136,'','Add support for vSphere annotations\nAllow setting vSphere annotations via a request.\r\nAlternatively, an array of key/value pairs could be passed and processed (set_vm_customvalues).\r\n\r\nImplements the request part of #1755'
2135,'','[vcloud_director] Fix copy & paste fail.\n'
2134,'',"[vcloud_director] Allow for multiple Orgs.\nContrary to the existing comment, there isn't always a single Org.\r\n"
2133,'','Orchestration rebase\nRebase of  tkadauke\'s pull request for OpenStack Orchestration:\r\n\r\nPartial support for OpenStack\'s "heat" component which allows (among other things) creation of multiple VMs in a single step using a JSON-based template language. Implemented so far is CRUD for the "stack" model, which handles creation and deletion of VM groups. More things might follow later.'
2132,'','Fixing incorrect boolean expression; should have been string comparison\nEnables correct values for several boolean redshift cluster and snapshot fields.'
2131,'','openstack | add min_count, max_count, return_reservation_id\nadds the ability to create multiple nodes in one request to the openstack provider.  '
2130,'','[vcloud_director] Improve support for Tasks.\n- add Organization#tasks\r\n- add Task#cancel\r\n- rename Task#expirity_time to expiry_time\r\n- Task#progress is an integer\r\n- add missing Task#start_time\r\n- expose Task attributes introduced in 5.1 API'
2129,'','support for additional AWS Data Pipeline API endpoints\n@kbarrette'
2128,'',"AWS Data Pipeline delete endpoint does not return a JSON body string\nI was getting a JSON parse error from the delete_pipeline method.  Looks like Amazon's API may have changed since this was implemented."
2127,'','Adding notifications for Rackspace Monitoring\nAdding the ability for to add/edit/delete Rackspace Monitoring notifications'
2126,'',"Fix parameter group assignment when creating AWS::Elasticache clusters\nFixed an issue where if you specified a parameter group on AWS Elasticache cluster creation, it wasn't assigned to the parameter group."
2125,'','[rackspace|block_storage] updated Volume#create to honor snapshot_id attribute\nThe Volume#create method does not pass the `snapshot_id` attribute to the request layer. This PR address that.'
2124,'tokengeek','Brightbox updates\nSeries of updates to the Brightbox provider'
2123,'','Can\'t list directories or access files with AWS as provider on jruby.\nHere\'s a small script that demonstrates the problem. It woks perfectly on ruby-1.9.3, but fails as described with jruby:\r\n\r\n```ruby\r\nrequire \'fog\'\r\n\r\n# I\'ll assume a bucket named "some-bucke" that contains a single file named "file.txt"\r\n\r\nstorage = Fog::Storage.new({\r\n  :provider => "AWS",\r\n  :aws_access_key_id => \'scret stuff\',\r\n  :aws_secret_access_key => \'secret stuff\'})\r\n\r\nputs storage.directories.to_s\r\n# Will output the list of buckets on ruby-1.9.3 but just [] on jruby 1.7.4 (1.9.3p392)\r\n\r\nputs storage.directories.get("some-bucket").files.to_s\r\n# Will output the list of files on ruby-1.9.3 but just [] on jruby\r\n# Strangely enough, storage.directories.get("some-bucket") does return a Directory with jruby,\r\n# but the key is nil\r\n\r\nstorage.directories.get("some-bucket").files.get("file.txt")\r\n# Will return the file as expected on ruby-1.9.3\r\n# Throws "bucket_name is required" on jruby with the following stack trace:\r\n# ArgumentError: bucket_name is required\r\n#   from /home/migimunz/.rvm/gems/jruby-1.7.4/gems/fog-1.15.0/lib/fog/aws/requests/storage/get_object.rb:31:in `get_object\'\r\n#   from /home/migimunz/.rvm/gems/jruby-1.7.4/gems/fog-1.15.0/lib/fog/aws/models/storage/files.rb:63:in `get\'\r\n#   from (irb):20:in `evaluate\'\r\n#   from org/jruby/RubyKernel.java:1093:in `eval\'\r\n#   from org/jruby/RubyKernel.java:1489:in `loop\'\r\n#   from org/jruby/RubyKernel.java:1254:in `catch\'\r\n#   from org/jruby/RubyKernel.java:1254:in `catch\'\r\n#   from /home/migimunz/.rvm/rubies/jruby-1.7.4/bin/irb:13:in `(root)\'\r\n```\r\n\r\nI\'ve tried this with the latest version of fog from github as well, the same thing happens.'
2122,'',"Add ability to specify availability zone for subnet during creation\nThe AvailabilityZone option wasn't being passed to create_subnet so I attempted to add it."
2121,'',"Use meaningful error messages when interacting with Linode resources\nI hope these simple changes save other people some debug time. Instead of raising nil and swallowing an exception these will now output a meaningful error message. I was getting the following error when using this via knife and passing in an image ID that no longer exists:\r\n\r\n```\r\ngems/fog-1.14.0/lib/fog/core/collection.rb:115:in `new': Initialization parameters must be an attributes hash, got NilClass nil (ArgumentError)\r\n\tfrom gems/fog-1.14.0/lib/fog/linode/models/compute/images.rb:15:in `get'\r\n\tfrom bundler/gems/knife-linode-02ecd558b064/lib/chef/knife/linode_server_create.rb:190:in `run'\r\n\tfrom gems/chef-11.4.2/lib/chef/knife.rb:460:in `run_with_pretty_exceptions'\r\n\tfrom gems/chef-11.4.2/lib/chef/knife.rb:173:in `run'\r\n\tfrom gems/chef-11.4.2/lib/chef/application/knife.rb:123:in `run'\r\n\tfrom gems/chef-11.4.2/bin/knife:25:in `<top (required)>'\r\n\tfrom bin/knife:23:in `load'\r\n\tfrom bin/knife:23:in `<main>'\r\n```\r\n\r\nThanks!"
2120,'','Rackspace AutoScale\nImplemented a new feature for Rackspace that allows people to scale their servers up or down based on "scaling policies". A policy determines the behaviour of a particular scaling action. Webhooks activate policies - and can be tied to Cloud Monitoring (i.e. if CPU falls beneath a certain number), or executed anonymously using a unique link.\r\n\r\nEach group also has its own configuration sets: one that dictates the general state of the group (its name, etc.) and another that dictates the behaviour of a new server which is spawned (flavor ID, networks, personality file, load balancers, etc.)\r\n\r\nI\'m new to Shindo tests and Mock data, so there might be a few discrepancies. Feel free to point out and comment on any potential improvements :)'
2119,'','[openstack|compute] Add support for config_drive\nAdd support for the [config_drive extended attribute](http://api.openstack.org/api-ref.html#ext-os-createserverext) when creating a server.'
2118,'','Add mocks for AWS STS GetFederationToken api call\nAlso includes request docs and fix to parser that led to PackedPolicySize response containing newlines. '
2117,'','[vcloud_director] Fix module name.\n'
2116,'','[Rackspace|Compute] Make Next Gen Servers the default server implementation for Rackspace\nIt has been several months since we added a deprecation notice for the first gen servers. Since then, all of the downstream libraries that I am aware of have been updated to use the next gen servers. This PR finally switches the default compute implementation to the next gen servers.\r\n'
2115,'','[Rackspace| Load Balancers] fixing broken tests\nThis PR fixes a broken test'
2114,'','[vcloud_director] Use options in instantiate.\nPass options param through to service.instantiate_vapp_template.'
2113,'',"[vcloud_director] 'Set-Cookie' may be lowercase\nAs per @b7f8db97b15f1dc48541f5f2781f70fb2b743267 for the vcloud provider, required for (at least one|some) vCloud service providers."
2112,'tokengeek','Introduction of VCR has broken live tests\nUpdated fog to run just our provider tests against my dev server and VCR errors started appearing.\r\n\r\n```\r\n$ FOG_RC=config/dev_app FOG_MOCK=false bundle exec shindont +brightbox\r\n...\r\n  Fog::Compute[:brightbox] | flavors (brightbox)\r\n      tests/compute/models/flavors_tests.rb\r\n        success\r\n        Fog::Compute[:brightbox] | flavors (brightbox)\r\n      - succeeds\r\n\r\n      tests/compute/models/flavors_tests.rb\r\n\r\n\r\n================================================================================\r\nAn HTTP request has been made that VCR does not know how to handle:\r\n  POST http://honcho.dev/token\r\n\r\nThere is currently no cassette in use. There are a few ways\r\nyou can configure VCR to handle this request:\r\n...\r\n  35 failed, 1 pending, 60 succeeded in 7.347761 seconds\r\n```\r\n\r\nThere are a number of problems here:\r\n\r\n* VCR needs to be correctly set up on a per provider basis\r\n* VCR is an alternative mocking system so should not be running when `FOG_MOCK = false`\r\n* An alternative mocking system gives us another combination of tests not being ran. The CI passes our official tests.\r\n* VCR is using Webmock rather than the Excon adapter\r\n* VCR can pick up and record sensitive information so guidance needs to be in place. I\'m assuming the vcloud instance recorded is an off Internet instance because reversing the Basic Authorization is trivial.\r\n* ISTR someone asking about using VCR before and "no" was said for some reasons. I don\'t know if the reasons still stand or not.\r\n\r\nI\'m going to work on the initial problems to get our providers specs working again. Hopefully as simple as allowing non VCR HTTP calls.\r\n\r\nI don\'t mind VCR (although I\'ve been fighting with it on another project) so I don\'t need convincing it could be a good idea it\'s just currently preventing my doing any testing.\r\n\r\nVCR was introduced as part of the VcloudDirector work in https://github.com/fog/fog/commit/99dd30fe3f66577c14917f5dc83dc6f767e7b033\r\n\r\n/cc @restebanez @geemus '
2111,'','[rackspace] mock support for Rackspace Monitoring\nMock support for the recently added Rackspace Monitoring.'
2110,'','Fix aws escape\nI was working with objects whose key contains a âdirectoryâ prefix and the path separator was being escaped so that the object public_url was of the form `directory%2Fkey` when it should be `directory/key`, this pull request permits forward slash characters in the keys when escaping them. As a bonus I Unicode normalised the input key too.'
2109,'','[redshift] Support for AWS Redshift\nHi,\r\n\r\nThis is the initial support for AWS Redshift. It includes all requests and corresponding parsers. Also added request tests, but are incomplete (due to timing constraints).\r\n\r\nThanks,\r\n-Efe'
2108,'',"directory.files.create method not accepting :body attribute\nI have this code in my rails project:\r\n\r\ndef get_rack_service\r\n    header = {:provider => 'Rackspace', :rackspace_username => 'xxx', :rackspace_api_key => 'yyy'}\r\n    return Fog::Storage.new(header)\r\nend\r\n\r\ndef begin_upload(file, bin)\r\n    service = get_rack_service\r\n    directory = service.directories.get(bin)\r\n    directory.files.create :key => File.basename(file.path), :body => file\r\n    return service.head_containers\r\nend\r\n\r\nI am getting an error with the .create function, saying that I have too many parameters (1 for 0). When I remove the :key attribute, it complains that I need a :key attribute, but when I remove the :body attribute, everything works fine, except that it uploads an empty file, which doesn't help me at all. The only upside is that the title of the file appears correctly.\r\n\r\nWhat's even more strange is that I copied and pasted this exact code from another project, in which the code works just fine. The only differences between the two projects are:\r\n\r\n1. I am using mongoid in the troubled project, rather than ActiveRecord in the working project.\r\n\r\n2. I am attempting to upload a temp file (prior to saving the model) created by CarrierWave in the troubled project, as opposed to uploading a file that has already been saved to the database in my working project.\r\n\r\nboth projects are using CarrierWave to get the file."
2107,'','Issue #2105 Requested change\nadded network interface config settings for new AWS accounts with "default VPCs" (see AssociatePublicIpAddress, API#2013-07-15)'
2106,'icco','Create a Snapshot based on a Disk\nThis patch introduces 2 ways of inserting a snapshot.\r\n1. By calling disk#create_snapshot\r\n2. By "inserting" into the snapshot collection (snapshot#create)\r\n\r\nThe latter doesn\'t directly map back to the Google API (create is not exposed on the snapshots collection), but I\'ve implemented it here in any case. I\'m open to discussing whether we should to this (the latter) at all (because validating all the params becomes a little more complex).'
2105,'',"NetworkInterface.n.AssociatePublicIpAddress\nSee API documentation below - can we please add this option to AWS::Real run_instances\r\n\r\n* * *\r\n\r\n## NetworkInterface.n.AssociatePublicIpAddress\r\n_Indicates whether to assign a public IP address to an instance in a VPC. The public IP address is associated with a specific network interface. If set to true, the following rules apply:_\r\n\r\n_Can only be associated with a single network interface with the device index of 0. You can't associate a public IP address with a second network interface, and you can't associate a public IP address if you are launching more than one network interface._\r\n\r\n_Can only be associated with a new network interface, not an existing one._\r\n\r\n*Type: Boolean*\r\n\r\n_*Default:* If launching into a default subnet, the default value is true. If launching into a nondefault subnet, the default value is false._"
2104,'',"NoMethodError:undefined method 'request' for #Excon::Errors::SocketError\nOnly HTTPStatusError has request and response\r\n\r\nFixes NoMethodError:undefined method 'request' for #<Excon::Errors::SocketError:0x62540a41>\r\n\r\n```\r\nNoMethodError:undefined method `request' for #<Excon::Errors::SocketError:0x62540a41>, \r\n/gems/fog-1.15.0/lib/fog/joyent/compute.rb:169:in `request'\r\n/gems/fog-1.15.0/lib/fog/joyent/requests/compute/list_machines.rb:16:in `list_machines'\r\n/gems/fog-1.15.0/lib/fog/joyent/models/compute/servers.rb:12:in `all'\r\n/gems/fog-1.15.0/lib/fog/core/collection.rb:141:in `lazy_load'\r\n/gems/fog-1.15.0/lib/fog/core/collection.rb:22:in `map'\r\n```\r\n"
2103,'','[rackspace|storage] implement get_http_url and get_https_url\nPaperclip currently uses  `get_http_url` and `get_https_url` to retrieve temporary urls. These methods should be implemented for the Rackspace storage provider.\r\n\r\nHere is the relevant line of source from paperclip  \r\nhttps://github.com/thoughtbot/paperclip/blob/master/lib/paperclip/storage/fog.rb#L143'
2102,'','[rackspace|monitoring] adding mocks for get_entity\n'
2101,'','AWS API is out of alignment with Fog \nUsing Fog::AWS::RDS to try to run the describe_db_log_files function, kept getting this error: \r\n> InvalidAction => Could not find operation DescribeDBLogFiles for version 2012-09-17 (Fog::AWS::RDS::Error)\r\n\r\nThe current AWS API is dated 2013-05-15. \r\n> ![aws_screen_shot](https://f.cloud.github.com/assets/4998387/1044937/5122ea96-101b-11e3-927a-394dff4fb9db.png)\r\n\r\n\r\nThis error was confusing, because Fog has an identical DescribeDBLogFiles class. Initially, I thought the error was coming from inside of Fog, rather than referencing the AWS API. \r\n\r\nCorrections to consider: \r\n1. It would be nice if the error message was a little more explicit, to help the user avoid confusion. \r\n2. The @version option below worked for my code. I was also able to override the version from my initialize function in my own code. \r\n\r\n        def initialize(options={})\r\n          @use_iam_profile = options[:use_iam_profile]\r\n          setup_credentials(options)\r\n          @connection_options = options[:connection_options] || {}\r\n\r\n          @region = options[:region] || \'us-east-1\'\r\n          @host = options[:host] || "rds.#{@region}.amazonaws.com"\r\n          @path = options[:path] || \'/\'\r\n          @persistent = options[:persistent] || false\r\n          @port = options[:port] || 443\r\n          @scheme = options[:scheme] || \'https\'\r\n          @connection = Fog::Connection.new("#{@scheme}://#{@host}:#{@port}#{@path}", @persistent, @connection_options)\r\n          # @version = options[:version] || \'2012-09-17\' #\'2011-04-01\'\r\n          @version = options[:version] || \'2013-05-15\'\r\n        end\r\n'
2100,'','Aws signature fix\nSmall tweaks the the AWS storage'
2099,'',"Shouldn't the default AWS RDS API version match the code's interface\nThe code is geared toward the 2013-05-15 version of RDS API, but the default version is still set to 2012-09-17:\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/rds.rb#L171\r\n\r\nShould the default version be bumped? "
2098,'','[aws|compute] Cleaned up unnecessary parsers.\nWhile digging through the parsers for aws compute I noticed there was a huge amount of duplication of the basic parser that seemed unnecessary. This pull request removes all the unnecessary parsers and points everything that pointed to the old parsers over to the basic parser.'
2097,'','Update references to MultiJson to Fog::JSON\nReplaces all direct use of `MultiJson` to `Fog::JSON`.\r\nAll affected services require `fog/json` via `fog/core`.\r\n\r\n`Fog::JSON` will now "slurp" errors raised by `MultiJson` and raise `Fog::JSON::EncodeError` or `Fog::JSON::DecodeError`. These can now be rescued explicitly if desired (there were only 2 cases of this).\r\n\r\nAlso updates `Fog::Errors::Error` so it will use the error message of the error being "slurped" if the optional message is not given.'
2096,'',"require mime/types in Fog::Storage\nEliminate need to `require 'mime/types'` by requiring this in `fog/storage`.\r\nAll affected services require `fog/storage` either directly or via `fog/core`."
2095,'',"[rackspace|queues] Addition of Rackspace Cloud Queues\nAdded Rackspace Cloud Queues support.\r\n\r\nCouple things to note:\r\n\r\n* Service Catalog tests don't work yet since it is just in preview and not available in all regions\r\n* Edit Meta-data is not included\r\n* Really interested in feedback on how to handle client-ids and claiming messages.  Both are non-standard concepts in Fog so I did some weird things to make it work.\r\n* I did NOT support V1 authentication.  It has a lot of boiler plate code and figured new services should support the old Auth model.  This may not be the right call but I like having to write and test less code.\r\n* The API returns some really weird status codes sometimes.  Likely need to work with them to tweak the codes."
2094,'',"Consistent json parsing for edge cases (fixes #2090)\n*Note: This isn't really ready to merge yet.  It adds a test that passes under yajl (which is what has been used for testing), but exposes issus with other common json coders like oj and json.*\r\n\r\nThe test might be a bit over the top, but it seemed like a good opportunity to show how [appraisals](https://github.com/thoughtbot/appraisal) can help if you have to test multiple gemsets.\r\n\r\nIn order to setup:\r\n```shell\r\nrake appraisal:install\r\n```\r\n\r\nTest just yajl:\r\n```shell\r\nrake appraisal:yajl test:one['tests/core/json_tests.rb']\r\n```\r\n\r\nTest each json coder:\r\n```shell\r\nrake appraisal test:one['tests/core/json_tests.rb']\r\n```\r\n"
2093,'','[rackspace|compute_v2] Flavor list returns details\nThis avoids forcing iteration through the flavor list and calling get on\r\neach member to obtain the full details of flavors.'
2092,'',"carrierwave and eager loading\nCurrently, by default, applications using fog via carrierwave experience a painful delay the first time `Fog::Storage.new` is triggered for a particular provider, because although fog itself is `require`d at application load, the classes under Fog::Storage aren't.\r\n\r\nI understand this is because fog is big and nobody wants to load the whole thing unless they have to, but what's the suggested solution for a gem like carrierwave?\r\n\r\n- Should they trigger an otherwise unnecessary call to `Fog::Storage.new` on init?\r\n- Should they tell users to create an initializer which `require`s the appropriate Fog::Storage classes?\r\n\r\nIs there another option? From fog's perspective, what's the least fragile and least painful path for the long term?\r\n\r\nThis has been discussed previously on [stackoverflow](http://stackoverflow.com/a/17974084/1546887), and I'm working on a solution for carrierwave [here](https://github.com/carrierwaveuploader/carrierwave/issues/1198)."
2091,'','[rackspace] test tweaks\nUpdating Rackspace tests to make them more robust'
2090,'',"Rackspace server destroy - Unnecessary warning\nI'm getting this error doing a server destroy:\r\n[WARNING] Error Parsing response json - 784: unexpected token at ''\r\n\r\nThe warning is happening because the service is returning an HTTP 204 with no response body.  The [documentation](http://docs.rackspace.com/servers/api/v2/cs-devguide/content/Delete_Server-d1e2883.html) states that this is the expected behavior.  Fog doesn't need to parse the response."
2089,'','[google|compute] Fix a bug when dealing with multiple ssh keys\nThis pull request does two things. First, I added a check to make sure the zone we were turning a server up in actually exists. Second, I made sure to append new ssh keys instead of overwriting them.'
2088,'','[Rackspace|Load Balancers] Added get_stats and mock for create_load_balancer\nAdded get_stats for Rackspace Load Balancers.  Also added a mock for create_load_balancer.'
2087,'',"Create Compute::RackspaceV2::Real.list_snapshot_images\nProvide the ability to request snapshot images from the list of images.  Also made a small doc/comment change in list_images to correct the link to Rackspace's documentation."
2086,'','[rackspace] Fixes potential recursive loop\nThis pull request addresses issue #2080. If fog is given invalid credentials, fog will continue to re-authenticate until a stack trace exception occurs.\r\n\r\nThis PR introduces a a `request_without_retry` method which is used by the `create_token` request method.'
2085,'','[openstack | storage] Allow passing Content-Disposition header when saving file\nAllows to save Content-Disposition as part of the file metadata'
2084,'',"[rackspace] fix excluding extra characters in Rackspace.escape\nThis regex was subtly broken when extra excluded chars were passed in. The only extra excluded chars passed in (inside fog) is `'/'`, which coincidentally combines with the leading `.-` to make the character range `.-/`. Easily fixed by making sure that `-` is always last in the character class."
2083,'','[rackspace] fix non-SSL public CDN URLs\nThe implementation of `Fog::Storage::Rackspace#ssl?` was broken when initialized with `rackspace_cdn_ssl: false`. Added tests and fixed the implementation.'
2082,'','Add fog Elasticache security group mocking\n'
2081,'','Adding example to bootstrap server with custom ssh_key\nSimple example based on create_server to use bootstrap to create a server with a generated ssh_key'
2080,'',"Recursive loop in rackspace compute authentication\nI stumbled on this when trying to run one of the examples without valid auth files set. \r\n```\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:40:in `rescue in request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:35:in `request'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/requests/identity/create_token.rb:19:in `create_token'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:67:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/identity.rb:63:in `initialize'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:103:in `authenticate_v2'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/service.rb:30:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/compute_v2.rb:167:in `authenticate'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/rackspace/compute_v2.rb:141:in `initialize'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/workspace/fog/lib/fog/compute.rb:29:in `new'\r\n```"
2079,'kkanev','[CloudSigma] Volumes not working correctly\nHello,\r\n\r\nI tried to add a volume to a server with this command:\r\n\r\n```\r\nserver.mount_volume(\'9816464e-b519-4869-a691-5d34c9ea7e3f\', device = \'virtio\', dev_channel = \'0:0\', boot_order = \'1\')\r\n```\r\n\r\nWhen I do a pp.server it\'s looks fine:\r\n\r\n```\r\n<Fog::Compute::CloudSigma::Server\r\n[...]\r\n    volumes=[    <Fog::Compute::CloudSigma::MountPoint\r\n      device="virtio",\r\n      dev_channel="0:0",\r\n      drive="9816464e-b519-4869-a691-5d34c9ea7e3f",\r\n      boot_order="1"\r\n    >],\r\n    nics=[]\r\n  >\r\n```\r\n\r\nIf I do a server.update I got this kind of error:\r\n\r\n```\r\nFog::CloudSigma::Errors::RequestError: User fbf100e6-636a-41df-bbe9-914d690b4bb9 does not have (\'MOUNT\',) resource permissions on 9816464e-b519-4869-a691-5d34c9ea7e3f\r\n        from /var/lib/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/expects.rb:10:in `response_call\'\r\n        from /var/lib/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/response_parser.rb:8:in `response_call\'\r\n        from /var/lib/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:349:in `response\'\r\n        from /var/lib/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:247:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/lib/fog/core/connection.rb:57:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/lib/fog/core/deprecated/connection.rb:20:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/lib/fog/cloudsigma/connection.rb:54:in `request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/lib/fog/cloudsigma/connection.rb:108:in `update_request\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/lib/fog/cloudsigma/requests/update_server.rb:8:in `update_server\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/lib/fog/cloudsigma/models/server.rb:54:in `update\'\r\n        from (irb):75:in `<top (required)>\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/bin/fog:76:in `block in <top (required)>\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/bin/fog:76:in `catch\'\r\n        from /var/lib/gems/1.9.1/gems/fog-1.15.0/bin/fog:76:in `<top (required)>\'\r\n        from /usr/local/bin/fog:23:in `load\'\r\n        from /usr/local/bin/fog:23:in `<main>\'\r\n```\r\n\r\nWhen I start the server and take a look to the VNC console, the server doesn\'t find any boot device. If I add the volume using the web ui it works but I can see the added device with fog.\r\n\r\nFeel free to ask me anymore details.'
2078,'','[rackspace] fixing more broken tests\nFixes broken tests; fixes connection deprecation warnings; adds missing exceptions to compute class'
2077,'',"[aws|compute] add route table support for VPC's\nThis implements everything required to create, describe, delete, and associate route tables in fog. Comes complete with tests and mocks. If anything needs to be changed please let me know!\r\n\r\nThis also changes VPC mocks to create a default route table, the same behavior which happens with a VPC on Amazon. We have added additional tests to vpc's in order to make sure this behaves properly.\r\n\r\ncloses #1108 and also closes #1720"
2075,'','[rackspace|monitoring] Add alarm update test\nThe bug that previously caused this test to return an unexpected status (502) has been fixed, uncommenting the test.'
2074,'','[rackspace] fixing broken tests\nThis fixes a bug with the updated error handling.'
2073,'','[openstack|image] strip unused headers in #update_image\n* strip unused headers in #update_image\r\n* update tests to pass both live and mocked\r\n* updated #create_image Mock to behave more like Real (symbols required)'
2072,'','[rackspace] added transaction id to monitoring exceptions\nAdding transaction id to monitoring exceptions. I also updated exception handling to pass the service into the `slurp` method for compute, databases, dns and load balancers.'
2071,'','[openstack|storage] Added temporary signed URL support\nThis commit allows user to configure ```:openstack_temp_url_key``` parameter to be able to use ```get_object_https_url``` functionality.'
2070,'','[openstack|compute] update flavor tests\n- Update mocks and reorder tests so both live and mocked tests pass.\r\n- Ensure #remove_flavor_access sends `tenant_id` as a String.  \r\n  If sent as an Integer, the server will return 500.  \r\n  (#add_flavor_access works either way)'
2069,'amoghe','[google|compute] Fix some issues with GCE examples and disk requests.\n@amoghe please take a look. Some small issues found while running `rake google:smoke:compute`.'
2068,'icco',"[google|compute] Fix up the 'disk' api\nA recent patch to introduce support for creating disks from\r\nsnapshots had a few problems:\r\n1. Incorrect URL (to the snapshot resource) was being sent\r\n2. Ruby syntax errors.\r\n\r\nI looked into adding Shindo tests for this, but am not able to\r\nsince this request relies on a pre-existing snapshot which we\r\nuse for disk creation."
2067,'','[core] exclude :headers from symbolization for real this time\nThis PR revisits PR #2056 where I did not really exclude headers from symbolization. Good catch @burns!\r\n\r\nI have also added lots of tests.'
2066,'',"[openstack|compute] update volume tests\nThese tests were not being run, as they were marked `pending unless Fog.mocking?`.\r\nI've updated the key names in the schema so they will pass.\r\nI've also changed the `Time` format for `CreatedAt` to `String`,\r\nsince the validator has no means to check that a string is a parsable time."
2065,'icco','[google|compute] get/list snapshots\nThis patch...\r\n 1. Adds the Snapshot collection and model\r\n 2. Adds the get/list requests\r\n 3. adds some examples\r\n'
2064,'icco','[google|compute] Accept/propagate the correct params when creating a new disk\nThis patch tries to match the [API](https://developers.google.com/compute/docs/reference/latest/disks/insert)  w.r.t disk insert(create). The user is now expected to pass one of ```image_name``` or ```size``` and ```snapshot``` when creating a disk.\r\n'
2063,'',"[google|compute] When 'insert'ing a disk, don't try to create an image.\nThis patch avoids trying to create an image when trying to insert a disk (because we don't have sufficient information to create an image at that point).\r\n\r\nI'll fix up the ```insert_disk``` in a subsequent patch (align it better with the [API](https://developers.google.com/compute/docs/reference/latest/disks/insert))"
2062,'','[issue 2061] fix to_json to include attr_accesor items\n'
2061,'',"attr_accessor class items are not included in calls to to_json\nAn exmaple is if you call to_json for lib/fog/aws/models/compute/server.rb, ':architecture' will not be included since it is an attr_accessor in the class, instead of an attribute."
2060,'',"AWS Mock Mode doesn't work.\nI switched to Mock mode\r\nFog.Mock!\r\nbut when I get images list it always return nil.\r\nself.connection.images.get(image_id)\r\n\r\ndef connection\r\n  Fog::Compute.new(@auth)\r\nend\r\n\r\nIt works when REAL mode but doesn't work on MOCK mode\r\nThanks."
2059,'icco',"[google|compute] Add 'status' attribute to GCE images.\nSubsequent 'get' or 'reload' of the image will cause this to be\r\npopulated, and the user will be able to tell when it is 'READY'."
2058,'','Add support for AWS m3.xlarge and m3.2xlarge instance flavors\n'
2057,'','[google|compute] Fix insert disk to deal with changes to insert image.\nFixes a bug when creating a disk based off of an already existing image.\r\n\r\n@jordanbull or @amoghe, wanna do a quick review? '
2056,'','[core] Exclude :headers hash from symbolize_credentials\nThis PR excludes :headers from the symbolization make it possible to override default headers.'
2055,'','[rackspace|storage] Retrieve both SSL and non-SSL public URLs for a file\nThis request actually bleeds out of Rackspace land into the generic storage API. It would be great to have a way to get both the SSL and non-SSL public URLs for a file without creating 2 separate Storage instances with `rackspace_cdn_ssl: true` on one but not on the other.\r\n\r\nI have a real world use case where we store and use both URLs after creating a file and it would be great if it were easier to access both of them. If this is something that would be considered I can start working on a pull request.\r\n\r\nThoughts?'
2054,'','[rackspace|monitoring] Refactored alarm class\nreplaced entity_id and check_id attributes with entity and check attributes \r\nremoved entity_id from base module.\r\n'
2053,'',"[aws|elb] add new style default security group\n* AWS VPC enabled accounts have a new style security\r\n  group separate from the 'amazon-elb-sg' group.\r\n* added describe account attributes call\r\n* use account attributes to determine elb security group"
2052,'','Allow legacy v1 auth for OpenStack\nThis allows using "legacy" v1 auth for OpenStack, since we still use this version in production.\r\nI had no idea how to write better tests, so if you could advise - please do.'
2051,'','fixes #1434 : How to use vcloud fog services\nThis introduces a base of examples for the vcloud API integration with fog'
2050,'','[AWS|ASG] filter mocked results for describe_auto_scaling_policies\nThis is the same issue as was fixed for ASGs in #2040 / de274452\r\n\r\nBecause Policies#get uses this method to fetch a single Policy, it was\r\nalways returning the first Policy in the data set, not the one that\r\nactually matched the specified Policy name. Likewise, providing a filter\r\nfor `AutoScalingGroupName` did not actually filter the returned data\r\nfrom this call when mocked.'
2049,'','[google|compute] Allow users to create images.\nIn order to support this, we change the Image#save to accept\r\nparams from the user, and call insert_image. Also, we populate\r\nthe image model with the project name before returning the\r\nobject to the user.'
2048,'','use params instead of prep\nIn the transfer from rackspace-monitoring-rb to fog prep got changed to params, updating compare to match.'
2047,'','[rackspace|identity] Added error handling to service catalog\nUpdated service catalog to be more resilient against service catalog changes. It should now gracefully skip services/endpoints with unknown schema changes/errors. In the worse case scenario it skip loading the catalog and users can revert to manually supplying endpoints.'
2046,'',"Fix for token timeout on CDN\nWhen the rackspace cloud files auth_token expires, getting a public_url would attempt a reauthentication from the CDN service object that was missing authentication options, partly because they weren't being passed correctly and partly because the object was not storing :rackspace_username and :rackspace_api_token locally."
2045,'kevinykchan',"[joyent|storage| storage provider for joyent manta service\nI'm currently working on this\r\n\r\nprogress: https://github.com/kevinykchan/fog/tree/joyent-manta"
2044,'tokengeek','[Brightbox] Collaboration model updates\nThis expands on the new collaboration models that enable management of users to add model actions mapping to the lower level requests.\r\n\r\nAlso fixes `connection` deprecation warnings introduced in the branch.'
2043,'','Protect against missing fields in rackspace endpoint documents\nThis PR will prevent catastrophic failure when building a list of endpoints where some endpoints have missing fields.\r\n\r\nIn a specific case a rackspace api endpoint returned no region key\r\n\r\n\'{"tenantId"=>"654557", "publicURL"=>"https://backup.api.rackspacecloud.com/v1.0/654557"}\'\r\n\r\nAs a guard against this case, this commit sets the region to be global\r\nshould it not be defined in the endpoint hash\r\n\r\nThis is the simplest fix possible, we could expand it to validate keys, have defaults etc. '
2042,'','[Cloudstack|Compute] Add support for keypair and userdata when creating ...\nChange to be able to specify a keypair and userdata when creating a cloudstack vm.'
2041,'',"NoMethodError: undefined method `downcase' for nil:NilClass\nThis error randomly started happening using fog with the rackspace compute endpoint. I tried updating to 1.14.0 but no luck. Looks like the serivce endpoint fields returned from rackspace have changed:\r\n\r\n https://github.com/fog/fog/blob/master/lib/fog/rackspace/models/identity/service_catalog.rb#L73\r\n\r\nWe should probably guard against missing values or validate data being returned, and also coordinate in future api changes like this through release notifications.\r\n\r\nNoMethodError: undefined method `downcase' for nil:NilClass\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:73:in `block in endpoints_from_array'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:72:in `each'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:72:in `endpoints_from_array'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:66:in `add_endpoints'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:54:in `block in from_response'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:52:in `each'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/models/identity/service_catalog.rb:52:in `from_response'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/identity.rb:68:in `authenticate'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/identity.rb:63:in `initialize'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/service.rb:103:in `authenticate_v2'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/service.rb:30:in `authenticate'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/compute_v2.rb:160:in `authenticate'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/rackspace/compute_v2.rb:134:in `initialize'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/fog-1.14.0/lib/fog/compute.rb:29:in `new'\r\n\tfrom (irb):19\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/railties-3.2.13/lib/rails/commands/console.rb:47:in `start'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/railties-3.2.13/lib/rails/commands/console.rb:8:in `start'\r\n\tfrom /home/bfosberry/.rvm/gems/ruby-1.9.3-p385@gamekick/gems/railties-3.2.13/lib/rails/commands.rb:41:in `<top (required)>'\r\n"
2040,'','[AWS|ASG] Filters for ASGs.\nAlso filter mocked results for `describe_auto_scaling_groups`. Not having this filter was causing an issue in test environments. Because Groups#get uses this method to fetch a single ASG, it was always returning the first ASG in the data set, not the one that actually matched the specified ASG name.'
2039,'','[vsphere] Fix NoMethodError: undefined method in list_virtual_machines\nFix for \r\n\r\n```\r\n1.9.3-p429 :055 >   vms = connection.list_virtual_machines({\'instance_uuid\' => "50111611-26e1-6576-a9c0-0c7ad15a47be"})\r\nNoMethodError: undefined method `get_virtual_machine\' for Fog::Compute::Vsphere:Class\r\n  from /Users/csanchez/dev/fog/lib/fog/vsphere/requests/compute/list_virtual_machines.rb:12:in `list_virtual_machines\'\r\n  from (irb):55\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/cli.rb:619:in `console\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor/task.rb:27:in `run\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor/invocation.rb:120:in `invoke_task\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor.rb:344:in `dispatch\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor/base.rb:434:in `start\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/bin/bundle:20:in `block in <top (required)>\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/friendly_errors.rb:3:in `with_friendly_errors\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/bin/bundle:20:in `<top (required)>\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/bin/bundle:19:in `load\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/bin/bundle:19:in `<main>\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/bin/ruby_noexec_wrapper:14:in `eval\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/bin/ruby_noexec_wrapper:14:in `<main>\'\r\n  ```\r\n'
2038,'','[vsphere] Need to turn off vm and wait until off before destroying\nSome times it takes a bit for the vm to stop and fails to destroy because vm is still running, so wait for it to be completely stopped'
2037,'','[vsphere] searchIndex.FindByUuid datacenter parameter must be a RbVmomi::VIM::Datacenter\nThis call fails because datacenter has to be a RbVmomi::VIM::Datacenter object, not a string\r\n\r\n```\r\nvm = connection.get_virtual_machine("50111611-26e1-6576-a9c0-0c7ad15a47be", "XXX")\r\nRbVmomi::Fault: InvalidRequest: vmodl.fault.InvalidRequest\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/gems/rbvmomi-1.6.0/lib/rbvmomi/connection.rb:61:in `parse_response\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/gems/rbvmomi-1.6.0/lib/rbvmomi/connection.rb:90:in `call\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/gems/rbvmomi-1.6.0/lib/rbvmomi/basic_types.rb:203:in `_call\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/gems/rbvmomi-1.6.0/lib/rbvmomi/basic_types.rb:74:in `block (2 levels) in init\'\r\n  from /Users/csanchez/dev/fog/lib/fog/vsphere/requests/compute/get_virtual_machine.rb:15:in `get_vm_ref\'\r\n  from /Users/csanchez/dev/fog/lib/fog/vsphere/requests/compute/get_virtual_machine.rb:6:in `get_virtual_machine\'\r\n  from (irb):18\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/cli.rb:619:in `console\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor/task.rb:27:in `run\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor/invocation.rb:120:in `invoke_task\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor.rb:344:in `dispatch\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/vendor/thor/base.rb:434:in `start\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/bin/bundle:20:in `block in <top (required)>\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/lib/bundler/friendly_errors.rb:3:in `with_friendly_errors\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/gems/bundler-1.3.5.1/bin/bundle:20:in `<top (required)>\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/bin/bundle:19:in `load\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429@global/bin/bundle:19:in `<main>\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/bin/ruby_noexec_wrapper:14:in `eval\'\r\n  from /Users/csanchez/.rvm/gems/ruby-1.9.3-p429/bin/ruby_noexec_wrapper:14:in `<main>\'1.9.3-p429 :019 >\r\n```\r\n\r\nThis call works \r\n\r\n    vm = connection.get_virtual_machine("50111611-26e1-6576-a9c0-0c7ad15a47be", connection.get_raw_datacenter("XXX"))\r\n\r\n'
2036,'','[AWS|ELB] fix and mock improvements\n* Restore policy.cooke and policy.expiration methods\r\n* In the mocks always store policy data in one way and transform it as appropriate in describe calls.'
2035,'','[google|compute]: [RFC] Expose disk snapshots on the disk model\nThe GCE [API](https://developers.google.com/compute/docs/reference/latest/disks/createSnapshot) exposes createSnapshot as part of the disk API (a la ```/disks/disk/createSnapshot```).\r\n\r\nWe could expose this in the following fashion:\r\n\r\n```ruby\r\ndisk = compute.disks.get(\'my-disk\')\r\ndisk.create_snapshot(:name => "Snapshot-at-#{Time.now.to_i}")\r\n```\r\n\r\nWe could also expose the snapshots collection (which would have its own get,insert,list, delete) but could reuse this code for insertion.\r\n\r\nAlso, list_snapshot could be exposed on the ```disk``` itself, so that we can query for snapshots of a particular disk (which is a subset of the ```snapshots.all``` operation). \r\n\r\nComments?'
2034,'',"ruby-hmac VS openssl/hmac\nWith fog (1.9.0) one of dependencies is **ruby-hmac**, but there is a warning to use OpenSSL's one https://github.com/topfunky/ruby-hmac\r\n\r\nAny reason to stay with ruby-hmac version>?"
2033,'','[google|compute] images improvements\n* images.get support all projects\r\n\r\n@icco thoughts ?'
2032,'','[google|compute] improve disks support\n* disk.all should return empty Fog::Compute::Google::Disks\r\n* zone in disks.get is now optional\r\n* fix typo on examples\r\n\r\n@icco thoughts ?'
2031,'',"[google|compute] servers.get don't catch errors\n* If server is not present in first tested zone an error is raised\r\n  and not catched\r\n\r\n@icco thoughts ?"
2030,'','[digitalocean] define public_ip_address\nFunctions such as sshable? require the field public_ip_address, so this change modifies digitial ocean server.rb to resolve any issues with the built-in Fog functions.'
2029,'','[AWS|ELB] policy model update\nUpdates the ELB policies collection to be initialized with the result of calling `DescribeLoadBalancerPolicies` instead of relying on the limited data in `DescribeLoadBalancers`. The policies are cached until the ELB is reloaded.\r\n\r\nI also discovered that when creating a public key policy AWS accepts a cert *or* the public key for the cert, but always returns the public key. To simplify the tests I am always passing the public key of the cert.\r\n\r\nRef fog/fog#2014'
2028,'icco',"[google|compute] Query global projects when get/list'ing compute images.\n    This patch refactors some of the code that would query global\r\n    projects when get'ing images. It makes the list of global projects\r\n    a constant on the Images collection, so that both 'get' and 'list'\r\n    can use the same list of projects to query.\r\n    \r\n    Also, when bootstrapping/create'ing a server, the validation of\r\n    the specified image name is done by trying to 'get' the image\r\n    instead of 'save'ing it.\r\n"
2027,'','Fixed an uninitialized constant error\n'
2026,'','[google|storage] Make public_url function easier to read and change acl request to deal with nokogiri changes.\nAs found in #2025.'
2025,'icco','Google Storage: generation of public URLs is broken\nSpecifically, this check (reformatted for better readability):\r\n\r\n```ruby\r\n  def public_url\r\n    requires :directory, :key\r\n\r\n     if service.get_object_acl(directory.key, key).\\\r\n       body[\'AccessControlList\'].detect { |entry|\r\n         entry[\'Scope\'][\'type\'] == \'AllUsers\' && entry[\'Permission\'] == \'READ\'\r\n       }\r\n      if directory.key.to_s =~ /^(?:[a-z]|\\d(?!\\d{0,2}(?:\\.\\d{1,3}){3}$))(?:[a-z0-9]|\\.(?![\\.\\-])|\\-(?![\\.])){1,61}[a-z0-9]$/\r\n        "https://#{directory.key}.storage.googleapis.com/#{key}"\r\n      else\r\n        "https://storage.googleapis.com/#{directory.key}/#{key}"\r\n      end\r\n    else\r\n      nil\r\n    end\r\n  end\r\n```\r\n\r\nNotice that it tries to check ```entry[\'Scope\'][\'type\'] == \'AllUsers\'``` and ```entry[\'Permission\'] == \'READ\'```\r\n\r\nWith some debugging information, turns out that the object returned is:\r\n\r\n```\r\n{ "Owner"=> { "ID"=> someID },\r\n  "AccessControlList"=>\r\n  [\r\n      { \r\n         "Scope"=> { \r\n                     #<struct Nokogiri::XML::SAX::Parser::Attribute> => nil,\r\n                     "ID" => someID,\r\n                   },\r\n        "Permission"=>"FULL_CONTROL"\r\n      }\r\n  ]\r\n},\r\n\r\n```\r\n\r\nIf you look at the ```AccessControlList``` entry, you will notice that its "value" is a an array (of ACLs). Each item in this array is a Hash with 2 pairs, the first key being ```Scope``` and the next is ```Permission```. Now, the code indexes into the ```Permission``` correctly, but check for ```type``` is always bad (because there is no type). What we want instead is to access the ```SAX::Parser::Attribute``` object (whose value is always nil), because it contains the information we want, namely:\r\n\r\n```\r\n#<struct Nokogiri::XML::SAX::Parser::Attribute\r\n           localname="type",\r\n           prefix=nil,\r\n           uri=nil,\r\n           value="UserById">\r\n```\r\n\r\n... we want to check if its ```value=AllUsers``` and if allUsers have ```Permission=READ```'
2024,'','Adding support for Rackspace Cloud Monitoring\nThis PR integrates a gem ([rackspace-monitoring-rb](https://github.com/racker/rackspace-monitoring-rb)) that is used to provide ruby bindings to cloud monitoring.  A small amount of additional coverage of the API was added, as well as complete unit test coverage of both the request and model layers.'
2023,'','Google Compute: creating a new image doesnt accept the preferredKernel param from user\nThe code does this:\r\n\r\n```ruby\r\n        def insert_image(image_name, source)\r\n          api_method = @compute.images.insert\r\n          parameters = {\r\n            \'project\' => @project,\r\n          }\r\n          body_object = {\r\n            "name" => image_name,\r\n            "sourceType" => "RAW",\r\n            "source" => source,\r\n            "preferredKernel" => \'\',\r\n          }\r\n\r\n          result = self.build_result(\r\n            api_method,\r\n            parameters,\r\n            body_object=body_object)\r\n          response = self.build_response(result)\r\n        end\r\n```\r\n\r\nNotice that preferredKernel is always ```\'\'```.\r\n\r\nNow, the [API](https://developers.google.com/compute/docs/reference/latest/images/insert) doc for image creation says that the following are needed:\r\n\r\n```\r\n  {\r\n    "name":""\r\n    "preferredKernel":""\r\n    "sourceType":""\r\n    "description":""\r\n    "rawDisk":\r\n    {\r\n      "source":""\r\n    }\r\n  }\r\n```\r\n\r\n... and in order to craft the correct ```rawDisk.source``` one would probably verify that the URL exists etc, but that would need for storage creds to be setup etc, so I\'m going to punt on that and let the GCE backend deal with those errors (if URL doesnt exist, or is inaccessible).'
2022,'',"Google Compute: creating a new image does not work\nThe code calls ```reload``` instead of actually saving the image. If this is a new image that the user is trying to create, the ```create``` is going to fail with resource-not-found (obviously, because it doesn't exist yet).\r\n\r\nWorking on a patch for this..."
2021,'','Remove whitespace from the Rackspace V2 test\n'
2020,'icco',"[google] client.images doesn't list google public images\nclient.images only lists images on client's project.\r\nthis add on listing all images provided by google\r\n"
2018,'','[Vcloud] Adding case insensitivity for set-cookie header\nThis is related to issue https://github.com/fog/fog/issues/2017'
2017,'',"case senstive set-cookie header\nIn [lib/fog/compute.rb#do_login](https://github.com/fog/fog/blob/2f3c63359584ffcf9992bb091eed9fa8607c84b1/lib/fog/vcloud/compute.rb#L234), we use 'Set-Cookie' with `S` upper case and `C` upper case\r\n\r\nAs per [rfc-2616](http://www.ietf.org/rfc/rfc2616.txt), message headers should be case insenstive, and one of the vendors returns set-cookie in lower case it with lower case, which is causing issues currently.\r\n\r\n"
2016,'',"Accept public_key and public_key_path when creating GCE server\nEarlier, the code forced the user to specify the :public_key_path\r\noption when creating the server. In some cases, the user may want\r\nto pass in the key itself (string), and not a path. This patch\r\nchanges the code to use the #public_key method, which will first\r\ncheck if the key was specified, and only attempt to read the file\r\nif it wasn't specified."
2015,'icco','Google Compute disk object not being populated correctly\nThe response on the wire comes back correctly, see...\r\n\r\n```ruby\r\n{\r\n "kind"=>"compute#disk",\r\n "id"=>"REDACTED",\r\n "creationTimestamp"=>"2013-08-01T21:33:58.508-07:00",\r\n "zone"=>\r\n  "https://www.googleapis.com/compute/v1beta15/projects/redacted/zones/us-central1-a",\r\n "status"=>"READY",\r\n "name"=>"REDACTED",\r\n "sizeGb"=>"100",\r\n "sourceSnapshot"=>\r\n  "https://www.googleapis.com/compute/v1beta15/projects/REDACTED/global/snapshots/REDACTED",\r\n "sourceSnapshotId"=>"REDACTED",\r\n "selfLink"=>\r\n  "https://www.googleapis.com/compute/v1beta15/projects/redacted/zones/us-central1-a/disks/test-disk"\r\n}\r\n```\r\n\r\nBut, by the time control returns to my code, I have this object...\r\n\r\n```ruby\r\n<Fog::Compute::Google::Disk\r\n    name="test-disk",\r\n    kind=nil,\r\n    id=nil,\r\n    creation_timestamp=nil,\r\n    zone_name="us-central1-a",\r\n    status=nil,\r\n    description=nil,\r\n    size_gb=nil,\r\n    self_link=nil,\r\n    image_name=nil,\r\n   source_snapshot="https://www.googleapis.com/compute/v1beta15/projects/REDACTED/global/snapshots/test-snapshot"\r\n  >\r\n```'
2014,'','[AWS|ELB] policy model update\nAdd the ability to create and view non "stickiness" policies through the policy models.\r\n\r\n```ruby\r\nelb.policies.create(:id => "my-public-key-policy", :type_name => \'PublicKeyPolicyType\', :policy_attributes => {\'PublicKey\' => AWS::IAM::SERVER_CERT_PUBLIC_KEY})\r\nelb.policies.get("my-public-key-policy")\r\n=> <Fog::AWS::ELB::Policy\r\n     id="my-public-key-policy",\r\n     cookie=nil,\r\n     expiration=nil,\r\n     type_name=nil,\r\n     policy_attributes=nil\r\n    >\r\n```\r\n\r\nCurrently the `DescribeLoadBalancersResult` does not include any details about other policies, that would have to be fetched separately with a call to `DescribeLoadBalancerPolicies` for the elb in question. What are thoughts on the current state of this? Should the extra call be included for the model in the case where `OtherPolicies` are present on the elb?'
2013,'','[Rackspace] Added Transaction IDs to Exceptions\nThis PR adds transaction IDs to exceptions for compute, block storage, CDN, and storage services. The hope is that including these ids will make it easier to debug future issues.'
2012,'','[AWS|ELB] parser fix\nLots of little fixes for test failures I discovered when running with mocks disabled locally. I also tried to update the mocks to mirror AWS behavior as closely as possible.\r\n\r\nI added a `DEBUG_RESPONSE` environment variable to allow me to see the xml response for all requests. I tried using the `EXCON_DEBUG` env var at first but the body was always empty even when I saw content with tcpdump. My guess is that there may be a bug in excon around displaying an IO object that has already been read by the parser and has no more content to show, hence the empty body.'
2011,'',"Non-public S3 URL generation is slow\nI'm using Fog (1.14.0) with CarrierWave (0.9.0) to store user avatars on S3. It seems to be taking a long time to determine the avatar URL for a given user. Subsequent calls have a greatly reduced time. <a href='https://github.com/carrierwaveuploader/carrierwave/issues/261'>This issue</a> is talking about public files, but mine are not public.\r\n\r\n```\r\n#user.rb\r\nmount_uploader :avatar, ImageUploader\r\n```\r\n\r\n```\r\nCarrierWave.configure do |config|\r\n  config.fog_credentials = {\r\n    provider: 'AWS',\r\n    aws_access_key_id: ENV['AWS_ACCESS_KEY_ID'],\r\n    aws_secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']\r\n  }\r\n  config.fog_directory = ENV['AWS_S3_BUCKET_AVATAR']\r\n  config.fog_public = false\r\nend\r\n```\r\n```\r\nirb(main):002:0> Benchmark.measure { user.avatar_url }\r\n=>   0.500000   0.020000   0.520000 (  0.537884)\r\n\r\nirb(main):003:0> Benchmark.measure { user.avatar_url }\r\n=>   0.000000   0.000000   0.000000 (  0.001830)\r\n\r\nirb(main):004:0> Benchmark.measure { user.avatar_url }\r\n=>   0.000000   0.000000   0.000000 (  0.001454)\r\n\r\nirb(main):005:0> Benchmark.measure { user.avatar_url }\r\n=>   0.000000   0.000000   0.000000 (  0.000998)\r\n```"
2010,'','[glesys] added options to resuse ip and/or ipv6 and description\nAdding fog-suport for optional arguments in Glesys::Server#save to\r\nsupport\r\nhttps://github.com/GleSYS/API/wiki/functions_server#wiki-servercreate .'
2009,'icco','[google|compute] Add support for network and external_ip during server creation\n* Add support for an other network than default\r\n   ("default" network is still default network)\r\n * Can specify if creation or not of an external_ip\r\n   (External_ip is still created by default)\r\n\r\nThoughts ?'
2008,'','[AWS|ELB] proxy protocol support\nAWS recently [announced](http://aws.typepad.com/aws/2013/07/elastic-load-balancing-adds-support-for-proxy-protocol.html) support for the proxy protocol. These changes allow fog to provision an ELB with the proxy protocol.'
2007,'',"Google Compute server should accept public_key as well as public_key_path\n```public_key``` : for when the user has the contents of the key (so that fog doesn't make her deal with tempfiles)\r\n\r\n```public_key_path``` : for when there is a file (so that we dont make her deal with reading the file).\r\n\r\nFrom reading ```fog/compute/models/server.rb``` looks like these are all legit attributes\r\n```public_key```, ```public_key_path```, ```private_key```, ```private_key_path``` so we should accept both forms (correct me if I'm wrong).\r\n"
2006,'','[vsphere] Make mock data consistent across operations\nUse the the same list of vms for all calls, mimic other providers mocks\r\nrbvmomi returns hashes with string keys, not symbols\r\nMatch instance_uuid with id in list_virtual_machines as Real does\r\nBetter mock for vm_clone, returns a vm with new id and adds it to the list of running vms\r\nTest new_vm option'
2005,'','[rackspace|compute_v2] renaming keypairs to key_pairs \nThis PR renames keypairs to key_pairs to match the other compute providers.\r\n\r\n@bartvercammen Sorry I missed this in my review. I just wanted you to be aware in case you need to make a change on your end.'
2004,'','Fix Fog::Compute::Google::Flavor all method\n* list_machine_types takes one zone as argument'
2003,'icco','[google|compute] all method in Google::Compute::Servers should have filters argument\nI think this is a convention in all Compute providers.\r\n\r\nThoughts ?'
2002,'','Unable to list all domains on XenServer via LibVirt\n[bin]# ./fog\r\n[WARNING] Unsupported StormOnDemand service: network\r\n[WARNING] Unsupported StormOnDemand service: storage\r\n[WARNING] Unsupported StormOnDemand service: dns\r\n[WARNING] Unsupported StormOnDemand service: billing\r\n[WARNING] Unsupported StormOnDemand service: monitoring\r\n[WARNING] Unsupported StormOnDemand service: support\r\n[WARNING] Unsupported StormOnDemand service: account\r\n[WARNING] Unsupported StormOnDemand service: vpn\r\n  Welcome to fog interactive!\r\n  :default provides Libvirt and Openvz\r\n>> conn=Fog::Compute.new({:provider => "Libvirt", :libvirt_uri => "xenapi://192.168.110.14:443/?no_verify=1"})\r\n#<Fog::Compute::Libvirt::Real:23081120 @uri=#<Fog::Compute::LibvirtUtil::URI:0x00000002c05b00 @parsed_uri=#<URI::Generic:0x00000002c057b8 URL:xenapi://192.168.110.14:443/?no_verify=1>, @uri="xenapi://192.168.110.14:443/?no_verify=1"> @ip_command=nil @client=#<Libvirt::Connect:0x00000001a59cf8>>\r\n>> conn.servers.all\r\nLibvirt::RetrieveError: Call to virDomainAutostart failed: An error occurred, but the cause is unknown\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/lib/fog/libvirt/requests/compute/list_domains.rb:62:in `autostart?\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/lib/fog/libvirt/requests/compute/list_domains.rb:62:in `domain_to_attributes\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/lib/fog/libvirt/requests/compute/list_domains.rb:16:in `block in list_domains\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/lib/fog/libvirt/requests/compute/list_domains.rb:16:in `map\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/lib/fog/libvirt/requests/compute/list_domains.rb:16:in `list_domains\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/lib/fog/libvirt/models/compute/servers.rb:13:in `all\'\r\n        from (irb):2:in `<top (required)>\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/bin/fog:76:in `block in <top (required)>\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/bin/fog:76:in `catch\'\r\n        from /opt/rh/ruby193/root/usr/local/share/gems/gems/fog-1.14.0/bin/fog:76:in `<top (required)>\'\r\n        from ./fog:23:in `load\'\r\n        from ./fog:23:in `<main>\'\r\n>>\r\n'
2001,'','[AWS|ASG] parse ScalingPolicy MinAdjustmentStep\nFor some reason this attribute was missing from the parser. Proof that\r\nit exists:\r\n\r\nhttp://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_ScalingPolicy.html'
2000,'','[xenserver] Console model created\nBased on http://docs.vmd.citrix.com/XenServer/6.0.0/1.0/en_gb/api/?c=console'
1999,'','Fix #server so that it returns the right server instead of all servers\n'
1998,'','[AWS|ASG] filtering for ASG Scaling Activities\nAllow easy filtering of ASG Scaling Activities from attributes on collection initializer. Both of these forms work:\r\n\r\n```ruby\r\nFogWrap.auto_scaling_api.activities("AutoScalingGroupName" => "my-asg-name")\r\nFogWrap.auto_scaling_api.activities.all("AutoScalingGroupName" => "my-asg-name")\r\n```\r\n\r\nDidn\'t see any tests for the ASG activities for me to update :cry: '
1997,'','[vsphere] Raise NotFound exception when Datacenter or Template is not found\nMatch behavior with other providers'
1996,'','Add mock for dnsimple and fix tests for non mock mode\n'
1995,'',' put_object with a request_block can not be idempotent\nSee geemus/excon#235\r\nIf the request fails and is retried, it could then succeed but only upload an empty file.'
1994,'','Adding exception from net-ssh 2.6 that occurs during bootstrap as sshd is just starting up\n'
1993,'',"problem in rm command in keystone\nhello my friend.\r\nplease help me in keystone command:\r\n\r\nrm /var/lib/keystone/keystone.db' \r\nRm: cannot remove '/var/lib/keystone/keystone.db' : permission denied\r\nSudo rm /var/lib/keystone/keystone.db' \r\nRm: cannot remove '/var/lib/keystone/keystone.db' : no such file or directory\r\n\r\nthanks\r\n"
1992,'','add support for openstack network quota endpoints\n'
1991,'',"Ssh options\nThis branch is still a bit fresh. Let me know if this approach is acceptable or if you want more rework.\r\n\r\nI've been battling with Net::SSH for half an hour until I edited it locally to enable the verbose debugging."
1989,'','Changing the non-ascii dash in the url\nIt was breaking compilation for some jruby work.'
1988,'',"remove dependency on active_support's present? method\nAtmos file uses present? but Fog does not have an explicit dependency on ActiveSupport"
1987,'icco','[google] Add service level documentation and simple smoke tests.\nThis is a rough draft at adding some specifics about the Google section of Fog. It adds some simple smoke tests for compute and a little documentation for Google Cloud Storage and Google Compute Engine.'
1986,'','Trouble finding EC2 instance quota\nI was using fog version=1.1.1 for quite some while and am going through the process of upgrading to the latest version. I relied on the run_instances method for a `Fog::Computer::AWS` instance to throw a `Fog::Compute::AWS::Error` with a message that relayed the instance quota I had available for EC2. It seems that that is no longer the case in newer versions of fog. Anyone have any ideas as to how to get the EC2 instance quota currently?'
1985,'','problem in keystone \nhello my friend\r\nwhat is IP address of the host that is running the Keystone API?\r\nfor example in: \r\n$ export KEYSTONE_IP=10.230.7.2 # IP of your keystone API server\r\nwhere is this ip?\r\n\r\nthank you'
1984,'','[xenserver] Added support to get VM by uuid\nSometimes its really confused to get vm by name label, if you have both with same name you need to make a double check on uuid.\r\n\r\nUsing this get_by_uuid you can get the exactly object using its uuid'
1983,'','[Rackspace] Updated authentication tests\nUpdated authentication tests to ensure that the old constant style endpoints were properly passed.'
1982,'','[AWS|ASG] filtering for ASG Scaling Policies\nAllow easy filtering of ASG Scaling Policies from attributes on collection initializer. Both of these forms work:\r\n\r\n```ruby\r\nFogWrap.auto_scaling_api.policies("AutoScalingGroupName" => "my-asg-name")\r\nFogWrap.auto_scaling_api.policies.all("PolicyNames" => "my-policy-name")\r\n```\r\n\r\nDidn\'t see any tests for the ASG policies for me to update :cry: '
1981,'','Rackspace provider throwing ArgumentError in wait_for\n@krames @xplode\r\n\r\nError output example:\r\n\r\n```\r\n/usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-1.14.0/lib/fog/core/collection.rb:114:in `new\': Initialization parameters must be an attributes hash, got NilClass nil (ArgumentError)\r\n    from /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-1.14.0/lib/fog/rackspace/models/compute_v2/servers.rb:58:in `get\'\r\n    from /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-1.14.0/lib/fog/core/model.rb:40:in `reload\'\r\n    from /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-1.14.0/lib/fog/core/model.rb:65:in `block in wait_for\'\r\n    from /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-1.14.0/lib/fog/core/wait_for.rb:5:in `wait_for\'\r\n    from /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-1.14.0/lib/fog/core/model.rb:64:in `wait_for\'\r\n```\r\n\r\nSnippet of client code:\r\n\r\n```ruby\r\ncreate_params = {\r\n  \t:name => "#{options.name}",\r\n  :flavor_id => flavor.id,\r\n  :image_id =>  image.id,\r\n  :networks => [\'00000000-0000-0000-0000-000000000000\',\'11111111-1111-1111-1111-111111111111\',]\r\n  }\r\n  \r\n  # Add pool to server.create params\r\n  if options.pool\r\n  \tcreate_params[:metadata] = {\'RackConnectLBPool\' => options.pool}\r\n  end\r\n  \r\n  # create and bootstrap server\r\n  server = compute_service.servers.create(create_params)\r\n  \r\n  # Kick out password, just in case\r\n  puts "The #{server.username} password is #{server.password}\\n\\n"\r\n  \r\n  # Check every 5 seconds to see if server is in the active state (ready?). \r\n  server.wait_for(1200, 10) do\r\n    print "."\r\n    server.metadata.reload\r\n    built = ready? && !public_ip_address.empty? && server.metadata.size > 0\r\n    if built\r\n      rc_status = server.metadata.find {|metadataum| metadataum.key == \'rackconnect_automation_status\'}\r\n      built = rc_status.value == \'DEPLOYED\'\r\n    end\r\n    built\r\n  end\r\n  \r\n  puts "[DONE]\\n\\n"\r\n```\r\n\r\nThe stack trace points out the error occuring on the line `server.wait_for(1200, 10) do`'
1980,'',"exception: Initialization parameters must be an attributes hash, got NilClass nil\nUpgraded to fog 1.14 and am now getting the following exception when creating servers in rackspace:\r\n\r\n```\r\n[ERROR] server.rb:355: exception: Initialization parameters must be an attributes hash, got NilClass nil\r\n        /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.14.0/lib/fog/core/collection.rb:114:in `new'\r\n        /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.14.0/lib/fog/rackspace/models/compute_v2/servers.rb:58:in `get'\r\n        /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.14.0/lib/fog/core/model.rb:40:in `reload'\r\n        /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.14.0/lib/fog/core/model.rb:65:in `block in wait_for'\r\n        /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.14.0/lib/fog/core/wait_for.rb:5:in `wait_for'\r\n        /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.14.0/lib/fog/core/model.rb:64:in `wait_for'\r\n```"
1979,'','[openstack] Better missing argument check for a more informative error msg\nWhen the OpenStack API key is not defined by the Vagrant openstack provider,\r\nit is not null. We check for instance of String instead.'
1977,'',"Fog::HP::Storage with http_proxy\nIt appears that the Excon library is not obeying proxy settings or at least that is my assertion based on the error coming from my attempt to use a proxy with Fog::HP::Storage.  Please see below for more detail.\r\n\r\n\r\n.rvm/gems/ruby-1.9.3-p194/gems/excon-0.23.0/lib/excon/middlewares/expects.rb:10:in `response_call': Fog::Storage::HP::NotFound (Fog::Storage::HP::NotFound)\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/excon-0.23.0/lib/excon/connection.rb:353:in `response'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/excon-0.23.0/lib/excon/connection.rb:247:in `request'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.12.1/lib/fog/core/connection.rb:25:in `request'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.12.1/lib/fog/hp/storage.rb:291:in `request'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.12.1/lib/fog/hp/requests/storage/get_containers.rb:26:in `get_containers'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.12.1/lib/fog/hp/models/storage/directories.rb:13:in `all'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.12.1/lib/fog/core/collection.rb:141:in `lazy_load'\r\n\tfrom /Users/surma/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.12.1/lib/fog/core/collection.rb:22:in `each'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:217:in `seplist'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:338:in `block in pretty_print'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:217:in `block (2 levels) in group'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:243:in `nest'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:216:in `block in group'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:228:in `group_sub'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:215:in `group'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:337:in `pretty_print'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:154:in `block in pp'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:217:in `block (2 levels) in group'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:243:in `nest'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:216:in `block in group'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:228:in `group_sub'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/prettyprint.rb:215:in `group'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:154:in `pp'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:77:in `block in pp'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:121:in `guard_inspect_key'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:77:in `pp'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:60:in `block in pp'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:59:in `each'\r\n\tfrom /Users/surma/.rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/pp.rb:59:in `pp'\r\n\tfrom conn_hpcloud.rb:14:in `<main>'\r\n"
1976,'','Fog::Mock - random ip address generation\nIt looks like most providers have implemented their own (often similar) methods to generate dummy IPv4 and IPv6 addresses.  It also looks like most, if not all, of them sometimes return invalid addresses like "476.4.7.4" (the 476 is too high for a valid IP address).\r\n\r\nThis adds support for Fog::Mock.random_ip (with v4 vs v6 options) so providers don\'t need to implement their own using Fog::Mock.random_number.\r\n\r\nI did not include fixes in provider mocks to use the new method, but it looks like the bug exists in at least these providers:\r\nrackspace\r\naws\r\ncloudstack\r\necloud\r\nhp\r\nibm\r\ninternet_archive'
1975,'','Add a parameter to servers.all for rackspace v2 to make it the same as other providers\nThis is just to add a dud parameter to the method to make it possible to call `servers.all` on the `Fog::Compute` object the same way across the different providers.'
1974,'',"Must check for nil before checking for empty\nError message gems/fog-1.14.0/lib/fog/cloudstack/models/compute/servers.rb:26:in `get': undefined method `empty?' for nil:NilClass (NoMethodError)"
1973,'',"Fog::Collection violates Array contract; calamity ensues\nThis just bit me.\r\n\r\n    ids = [...] # A list of string ids I generated locally\r\n\r\n    s = Fog::Storage.new :provider => 'Rackspace', :rackspace_username => '...', :rackspace_api_key => '...'\r\n    d = s.directories.detect {|d| d.key == 'container_name' }\r\n\r\nThat directory contained about 3900 files. `ids` has 19 entries, all of which matched:\r\n\r\n    d.files.select {|f| ids.include?(f.key) }.length #=> 19\r\n\r\nThen I ran this command:\r\n\r\n    d.files.select {|f| ids.include?(f.key) }.each(&:destroy)\r\n\r\nIt seemed to be taking a bit long so I cancelled it and checked the bucket with `d.reload`. It looks like the `#select` was ignored and fog started deleting everything in the bucket.\r\n\r\nMy guess is that `#select` is mutating & returning the receiver instead of a copy, which is then somehow refreshed back to the unfiltered list on the next call.\r\n\r\nThis violates the implicit ruby array contract. Even more than a contract, in fact; an axiom: for `a.each(&:destroy)` to operate on an array other than `a` violates a fairly basic axiom of ruby. Basic enough that in this case, what should have been a trivial command in `irb` caused data loss.\r\n\r\nI tried writing some tests for `Fog::Collection`, since it doesn't seem to be unit tested. The tests showed that it behaves properly on its own. So did `Fog::Storage::Rackspace::Files` when I stubbed `#all` to return some test data, so I must have been stubbing too much. I stopped there because the codebase was making me emotional.\r\n\r\nSpeaking as a fog outsider, I think there are real coupling problems in this codebase, and it makes both testing and understanding infeasible. The specifics of talking to each provider, and the enumerable logic for backing an array with lazily loaded data, should be decoupled. That way they would be separately testable, and it would be a lot harder for problems like this to creep in.\r\n\r\nIf someone can advise me what path to take, I'd be happy to look again at speccing and then fixing this behaviour; being unfamiliar with fog, though, I can't see how to without either stubbing the world (so the test incorrectly passes) or having to actually hit the API.\r\n"
1972,'',"libvirt server model doesn't get vCPUs\nSimple one, really -- the libvirt provider doesn't specify the correct field, and so never gets the correct number of vCPUs out of libvirt, defaulting (always) to 1.  The patch is pretty simple:\r\n\r\n    --- libvirt/models/compute/server.rb.orig       2013-07-22 20:09:55.025437815 +1000\r\n    +++ libvirt/models/compute/server.rb    2013-07-22 20:08:44.217795988 +1000\r\n    @@ -480,7 +480,7 @@\r\n                 :max_memory_size => new_raw.info.max_mem,\r\n                 :cputime => new_raw.info.cpu_time,\r\n                 :memory_size => new_raw.info.memory,\r\n    -            :vcpus => new_raw.info.nr_virt_cpu,\r\n    +            :cpus => new_raw.info.nr_virt_cpu,\r\n                 :autostart => new_raw.autostart?,\r\n                 :os_type => new_raw.os_type,\r\n                 :xml => new_raw.xml_desc,\r\n"
1971,'','Better digitalocean support\nThis add better support for digitalocean, using the collection tests harness instead of custom tests, and adding bootstrapping to the Servers collection. This also adds support for a case in their api where you cannot operate on a droplet because it is locked, although they do not expose the lock via the api.'
1970,'','[aws|rds]: PubliclyAccessible is boolean.\nThe PubliclyAccessible attribute for the AWS::RDS::Server should be\r\nparsed as a boolean (similarly to MultiAZ).'
1969,'','Add VPC security groups to the RDS instances.\nAmazon splits credentials between DB Security and VPC Security Groups\r\nfor RDS instances. Fog currently does not parse the VPC security\r\ngroups. This patch adds that attribute to a Fog::AWS::RDS::Server.'
1968,'','Renamed Fog::AWS::SES::Real#verify_domain to #verify_domain_identity.\n* Match the AWS SES API.'
1967,'','[aws|storage] parse #complete_multipart_upload error\n`#complete_multipart_upload` may return `200 OK` with an error in the response body.\r\nThis adds `Code` and `Message` to the `response.body` if an error is returned.\r\n\r\n'
1966,'',"[rackspace] add keypair support\nadded Rackspace KeyPair support\r\n- create/list/delete/get keypair\r\n- only implemented for 'compute_v2'\r\n\r\nI'm new to Ruby and Fog, so any suggestions on that part are always welcome ;-)\r\n"
1964,'','Signature Does Not Match behind proxy & recent Excon\nWe are having troubles with recent versions of Fog & Excon while running behind a proxy. The following error is returned when trying to `get_object`:\r\n\r\n```xml\r\n<?xml version="1.0" encoding="UTF-8"?>\r\n<Error><Code>SignatureDoesNotMatch</Code><Message>The request signature we calculated does not match the signature you provided. Check your key and signing method.</Message><StringToSignBytes>47 45 54 0a 0a 0a 57 65 64 2c 20 31 37 20 4a 75 6c 20 32 30 31 33 20 32 31 3a 34 37 3a 34 32 20 2b 30 30 30 30 0a 2f 31 32 33 2e 6a 70 67</StringToSignBytes><RequestId>79CBAC67C2524EED</RequestId><HostId>atepgJntyqqBKSktjiSs10aKddNDNmoYZzx4n2dmbEkm1FbFBtBFo3VmPKSGLYKe</HostId><SignatureProvided>7Yv4A/95aiYnBARY0CCoMnmAtMY=</SignatureProvided><StringToSign>GET\r\n\r\n\r\nWed, 17 Jul 2013 21:47:42 +0000\r\n/123.jpg</StringToSign><AWSAccessKeyId>AKIAIFWJJSW7ZIAWT7AA</AWSAccessKeyId></Error>\r\n```\r\n\r\nI\'ve tried to debug this by printing string_to_sign in s3.signature method. And it indeed does not match the "StringToSign" from the above error.\r\n\r\n```ruby\r\n"GET\\n\\n\\nWed, 17 Jul 2013 22:38:42 +0000\\n/2f28552a-b95a-47c9-b1eb-44ec4be879bc/123.jpg" # actual\r\n"GET\\n\\n\\nWed, 17 Jul 2013 22:38:42 +0000\\n/123.jpg" # expected\r\n```\r\n\r\nRemoving `if params[:bucket_name]` condition from the method makes it work.\r\n\r\nNow, the strange things are:\r\n\r\n1. There is no error when http proxy isn\'t used.\r\n2. Excon 0.16.10 works, more recent - getting the error.\r\n\r\nI can reproduce it at our production server, and at my local machine. Here is the gist:\r\nhttps://gist.github.com/semaperepelitsa/6024403\r\n\r\nSteps:\r\n```sh\r\nruby proxy_server.rb # keep in separate terminal\r\ngem install fog -v 1.12.0; gem install fog -v 1.8.0; gem install excon -v 0.16.10\r\nhttps_proxy="https://localhost:8099" ruby fog_test.rb # error\r\nruby fog_test.rb # OK\r\nhttps_proxy="https://localhost:8099" ruby fog_test.rb stable # OK\r\n```\r\n\r\nThere are similar issues (#662) but they are said to be fixed.\r\n'
1963,'','[rackspace|storage] add methods for SLO support\nAdds `put_static_obj_manifest` and `delete_static_large_object` methods.\r\n\r\nRenames the current `put_object_manifest` method to better differentiate this from the new `put_static_obj_manifest` method. `put_object_manifest` has been retained for backward compatibility.'
1962,'','[rackspace|storage] add #delete_multiple_objects\n'
1961,'','[aws|sts] Add support for the AssumeRole STS method.  \nAlso enable the ability for the STS service to use IAM profiles to grab credentials off the EC2 instance, as is in place for the other Fog AWS services.'
1960,'icco','[google|compute] Destroy for disk.\nAdds the methods to destroy a disk and get the zone of a disk.\r\nAlso changed google/compute.rb to raise errors rather than throw them as is done in other providers in fog. This also makes the rescue I implemented in the last pull request actually work.'
1959,'','Joyent snapshot get does not handle error cases\nIn particular, I am getting this response from the API:\r\n```json\r\n{"code"=>"ResourceNotFound", "message"=>"Snapshot does not exist"}\r\n```\r\n\r\nFog gives an error about missing name.\r\n\r\nI think it would be relatively easy to catch these errors and raise a Fog::Compute::Joyent::Snapshot::NotFound error, but I cannot for the life of me figure out how to write a test for this in Shindo. I don\'t want to submit a pull request without a test, but I think it\'s going to take me a while to find a test that does something similar and reverse engineer it.'
1958,'','[openstack|storage] upload files using blocks\nI updated `put_object` to allow blocks so large files can be uploaded in an efficient manner similar to PR #1844.'
1957,'',"License missing from gemspec\nSome companies [will only use gems with a certain license](https://github.com/rubygems/rubygems.org/issues/363#issuecomment-5079786).\r\nThe canonical and easy way to check is [via the gemspec](http://docs.rubygems.org/read/chapter/20#license)\r\nvia e.g. \r\n\r\n    spec.license = 'MIT'\r\n    # or\r\n    spec.licenses = ['MIT', 'GPL-2']\r\n\r\nThere is even a [License Finder](https://github.com/pivotal/LicenseFinder) to help companies ensure all gems they use\r\nmeet their licensing needs. This tool depends on license information being available in the gemspec.\r\nIncluding a license in your gemspec is a good practice, in any case.\r\n\r\nHow did I find you?\r\n\r\nI'm using a script to collect stats on gems, originally looking for download data, but decided to collect licenses too,\r\nand make issues for missing ones as a public service :)\r\nhttps://gist.github.com/bf4/5952053#file-license_issue-rb-L13 So far it's going pretty well"
1956,'','Added tablet device to libvirt template to fix VNC and Mouse pointer\nAdded tablet device to default libvirt template to fix VNC and Mouse pointer'
1955,'','[fix] Corrected the service mocks for testing to respond with a 304 to values of If-Modified-Since that match Last-Modified\nThe HTTP spec suggests that clients supply the value of Last-Modified that they previously received from the server to If-Modified-Since. When comparing If-Modified-Since > Last-Modified, however, the Mock object would fail to return a 304 for such a case.'
1954,'',"[aws|rds] Use correct filters in RDS model snapshots 'all' method\nThere is a bug in the implementation of the 'all' method in the RDS model 'snapshots' for AWS.\r\n\r\nThe error shows up if one passes arguments to the 'each' method. The 'all' method does not properly pick up the filters, which results in an infinite loop if more than one page of results exists.\r\n\r\nThe 'each' method sets the :marker key on self.filters but the previous implementation used the parameter passed to the method, not self.filters."
1953,'',"Feature/vcloudng\nHi there!\r\n\r\nThis is a complete new implementation of vCloud director 1.5 from the ground up, i've called it **vcloudng** to avoid conflits with the current vcloud provider. It has great new features, like lazy load of collections to dramatically improve the performance. It handles vcloud tasks seamless so you don't have to worry about it. In addition of request, parsers and models, i've added a new layer called generators, which it takes care of generating a valid xml document from a ruby data structure. You can check out all the features and usage in the `documentation.md` file\r\n\r\nMy motivation to develop it came after using the current implementation of vcloud provider for a month, it fails erratically, models are broken so i had to use the requests directly, witch it made it quite cumbersome. It didn't make sense to write a layer on top of that to workaround the lack of consistency and error handling. Fixing it wasn't an option since i'd have to change the API to make it consistent.\r\n\r\nI haven't implemented any testing yet since i'm on a tight schedule, but i'm planning to make it in the following months.\r\n\r\nNework firewalling isn't implemented yet but i'll implement it in late August\r\n\r\nHope this new vcloud provider makes the life of people working with vmware vCloud Director technology easier.\r\n\r\nThanks,\r\n\r\nRodrigo Estebanez"
1952,'',"Prefix only sometimes used by AWS Storage models\nThe way these models use a prefix option seems very unexpected to me.\r\n\r\nI would've thought passing in a prefix separately to the key would set it as a default for future calls on the object. I want to be able to do a series of operations on a bunch of files under a shared prefix without constantly passing the prefix in to those calls or prepending it to the key name, but that doesn't seem possible.\r\n\r\nSo if I get a files object with:\r\n\r\n    f = Fog::Storage.new(aws_options).directories.\r\n      get(bucket_name, prefix: prefix).files\r\n\r\nthe one call that works as expected is:\r\n\r\n    f.count # => returns a count of only files under prefix/\r\n\r\nbut the following all ignore the passed in prefix:\r\n\r\n    f.get(filename) # not found, needs to be f.get(prefix + filename)\r\n    f.create(key: filename, ...) # puts it at the root of the bucket, needs to be f.create(key: prefix + filename, ...)\r\n    f.destroy(filename) # => not found, needs to be f.destroy(prefix + filename)\r\n\r\neven if I create the files object with:\r\n\r\n    f = Fog::Storage.new(aws_options).directories.\r\n      get(bucket_name, prefix: prefix).files.all(prefix: prefix)\r\n\r\nthe behaviour is the same.\r\n\r\nMy use case is an app that only ever accesses files under one prefix which is set in a configuration file. I want to create a directory or files object once, with the prefix configured, and have all future calls work within that prefix, instead of repeatedly having to pass it in or prepend it to the key.\r\n\r\nThanks."
1951,'','[aws|rds] implement describe_orderable_db_instance_options\nThis change provides access to the describe_orderable_db_instance_options request for AWS RDS, api version 2013-05-15.\r\n\r\nI will provide some tests once I have feedback on the ones written for https://github.com/fog/fog/pull/1949'
1950,'icco',"servers.boostrap not working correctly for Google Compute\nWhen calling ```bootstrap``` to start a new GCE server, this is the code that executes:\r\n\r\n```ruby\r\n  defaults { ... some default params ... }\r\n\r\n  server = create(defaults.merge(new_attributes)\r\n  server.wait_for { sshable? }\r\n```\r\n\r\nIn the ```create``` method, it does the following\r\n\r\n```ruby\r\n  object = new(attributes)\r\n  object.save\r\n  object\r\n```\r\n\r\nand within the ```save``` it makes a call to ```service.insert_server```\r\n\r\nNow, the problem here is that the ```new``` will return a Server object, that is not the complete representation of the remote server (it is only local). This is because that call returns the ```object``` (variable) which is _not_ updated with the response from the API call (because the server is still in the PENDING state --> which is an artifact of the non-RESTful way in which the GCE api behaves?).\r\n\r\nSo the the subsequent call to ``sshable?``` (in the wait_for loop) will never succeed, because trying to query whether the server is sshable? needs for its ```public_ip_address``` field to be set, which never gets set in this case, because of the code flow described above.\r\n\r\nThe fix for this would be to subsequently call ```reload``` on the server (till its public IP is populated, presumably when the server transitions out of PENDING), and then wait for the ```sshable?``` call to return true. Alternatively, we could query the operation id for the status of the operation, till the server is ready, and then call ```reload``` on the server.\r\n\r\nNote: IMHO, these are 'workarounds' to the quirkiness of the GCE API, which unlike the other APIs, does not immediately return a full representation of the vm (eg - on AWS, the RunInstances call returns the full representation of the server(s), therefore doesnt suffer from this problem)"
1949,'',"[aws|rds] implement describe_db_log_files/download_log_file_portion\nThis change provides access to the describe_db_log_files and download_log_file_portion requests for AWS RDS, api version 2013-05-15.\r\n\r\nThe log file content is added as a merged attribute (along with other attributes that determine if more log content is available). The download_log_file_portion API call uses the 'Marker' parameter in a slightly different way than other API calls. I think the approach of augmented the log_file model with extra attributes is the most natural way to handle working with the log file content, as opposed to introducing an additional model.\r\n\r\nI have attempted to include tests but I am not certain of the actions that would be taken against our AWS account so I have not run the suite. I wrote my own small script (not committed, of course) to verify that the implementation is working.\r\n\r\nI'd appreciate feedback on the tests (and the rest of it, naturally)."
1948,'','removing coveralls support for Ruby 1.9.2 in hopes of fixing #1921\nremoving coveralls support for Ruby 1.9.2 in hopes of fixing #1921\r\n\r\n@maxlinc is the appropriate way to disable coveralls for Ruby 1.9.2?'
1947,'',"[ibm] adding proper fixed secondary_ip support\nWith the newer version of the SmartCloud API, the format for secondary IP addresses has changed. It's much more annoying:\r\n\r\n```\r\nsecondary.ip.<number>\r\n[Optional] Specifies a static IP address ID to be associated with an instance, where <number> can be 0, 1, or 2. You can select only up to 3 secondary IP address IDs, such as secondary.ip.0=<your_ip_address_id>, secondary.ip.1=<your_ip_address_id>, secondary.ip.2=<your_ip_address_id>, where <your_ip_address_id> is the ID of the IP address.\r\nFor example:\r\n                                 secondary.ip.0=12345\r\n                                 secondary.ip.1=12346\r\n                                 secondary.ip.2=12347\r\n```\r\n\r\nI think I've done a decent job of making this work. It currently works for single entries as well as multiples. Not sure if test data is needed since the existing test data is a bit sparse. I can provide a santized mock entry if needed though."
1946,'icco',"[google|compute] Infer the 'image' URL correctly when inserting a server.\nWhen inserting (creating) a new server, using a private (project\r\nspecific) image, the code would infer the resource URI for the\r\nimage incorrectly, because it would try to find the image in the\r\ncurrent project using an incorrect method to access the name of\r\nthe project. This patch fixes the variable reference, and changes\r\nthe loop logic to try all known project names in the same fashion.\r\n\r\nRefs #1933"
1945,'','Disable ssl verify peer joyent\n'
1944,'',"How to get public url  without retrieving the whole file ?\nI want to something like \r\n```\r\nif file =  directory.files.head('resume.html')\r\n   puts file.public_url\r\nend\r\n\r\n```"
1943,'','Convert the raw_message for send_raw_email, just in case.\n* This allows others to directly send Mail::Message objects via\r\n  send_raw_email.'
1942,'','Add basic error handling for Fog::AWS::SES.\nDetect `MessageRejected` errors.'
1941,'','[rackspace] database instance hostname not getting mapped into Fog Model\nRetrieving the database instance details directly from the API contains the hostname:\r\n\r\n```console\r\ncurl -D - -H "X-Auth-Token: ***" https://ord.databases.api.rackspacecloud.com:443/v1.0/836354/instances/2a60f46a-761a-4623-bba5-3f5654ee4191   â¬ â­ â± â¼\r\nHTTP/1.1 200 OK\r\nContent-Type: application/json\r\nVia: 1.1 Repose (Repose/2.6.11)\r\nContent-Length: 786\r\nDate: Wed, 03 Jul 2013 19:02:47 GMT\r\nServer: Jetty(8.0.y.z-SNAPSHOT)\r\n\r\n{\r\n    "instance": {\r\n        "created": "2013-06-28T22:29:06", \r\n        "flavor": {\r\n            "id": "1", \r\n            "links": [\r\n                {\r\n                    "href": "https://ord.databases.api.rackspacecloud.com/v1.0/836354/flavors/1", \r\n                    "rel": "self"\r\n                }, \r\n                {\r\n                    "href": "https://ord.databases.api.rackspacecloud.com/flavors/1", \r\n                    "rel": "bookmark"\r\n                }\r\n            ]\r\n        }, \r\n        "hostname": "29f168e007f60e35761846dbf426c13205b30c45.rackspaceclouddb.com", \r\n        "id": "2a60f46a-761a-4623-bba5-3f5654ee4191", \r\n        "links": [\r\n            {\r\n                "href": "https://ord.databases.api.rackspacecloud.com/v1.0/836354/instances/2a60f46a-761a-4623-bba5-3f5654ee4191", \r\n                "rel": "self"\r\n            }, \r\n            {\r\n                "href": "https://ord.databases.api.rackspacecloud.com/instances/2a60f46a-761a-4623-bba5-3f5654ee4191", \r\n                "rel": "bookmark"\r\n            }\r\n        ], \r\n        "name": "dyspnoeal-ilex", \r\n        "status": "ACTIVE", \r\n        "updated": "2013-06-28T22:31:26", \r\n        "volume": {\r\n            "size": 1, \r\n            "used": 0.14134597778320312\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nThe same database instance viewed as a model:\r\n\r\n```console\r\n=>   <Fog::Rackspace::Databases::Instance\r\n    id="2a60f46a-761a-4623-bba5-3f5654ee4191",\r\n    name="dyspnoeal-ilex",\r\n    created=nil,\r\n    updated=nil, \r\n    state="ACTIVE",\r\n    hostname=nil, \r\n    links=[{"href"=>"https://ord.databases.api.rackspacecloud.com:443/v1.0/836354/instances/2a60f46a-761a-4623-bba5-3f5654ee4191", "rel"=>"self"}, {"href"=>"https://ord.databases.api.rackspacecloud.com:443/instances/2a60f46a-761a-4623-bba5-3f5654ee4191", "rel"=>"bookmark"}],\r\n    flavor_id="1",\r\n    volume_size=1\r\n```\r\n\r\nIt seems like it should contain the host name'
1940,'','Signature method requires x-amz-security-token header.\nBefore this change, when making requests to S3 on an instance using IAM role credentials I would receive that the signature was bad. While tracing the string_to_sign vs what AWS expected,  I found that this header was missing.'
1939,'','[rackspace] Reauthenticate and retry request when authentication token expires\nThis pull request is the result of a carrierwave bug report where the Rackspace provider in fog was throwing a HTTP 401 after a rails application had been running of over 24 hours. As a result of that bug, I created https://github.com/fog/fog/pull/1899.\r\n\r\nIt turns out that this issue is present in most of the Rackspace services. This pull request replaces PR #1899 with a much more comprehensive fix for the issue and refactors all of the services `request` methods to the `Fog::Rackspace::Service` class with the hope of a much more common handling of requests.\r\n'
1938,'','Increased IOPS limit to 4000.\nThe IOPS limit for EBS volumes has been increased to 4000.\r\n\r\nSee http://aws.typepad.com/aws/2013/05/provision-up-to-4k-iops-per-ebs-volume.html'
1937,'','Using filters for AWS Images does not work\nGood morning,\r\n\r\nI am trying to use the images#all method to return all the AMIs that are present in the AWS account.  However they do not seem to be working.\r\n\r\nIf I run the AWS tool from the command line:\r\n\r\n    ec2-describe-images -F owner-id=<ACCOUNT_ID>\r\n\r\nthen I see the 5 AMI images that I have in that account.\r\n\r\nHowever when I try to do the same thing with Fog I get nothing back:\r\n\r\n```ruby\r\ncloud = Fog::Compute.new({:provider => \'AWS\', :aws_access_key_id => "KEY", :aws_secret_access_key => "SECRET_KEY"})\r\n\r\nimages = cloud.images.all({\'owner-id\' => \'<ACCOUNT_ID>\'})\r\n```\r\n\r\nThe gives me:\r\n\r\n    <Fog::Compute::AWS::Images\r\n      filters={"owner-id"=>"<ACCOUNT_ID>"}\r\n      []\r\n    >\r\n\r\nWhich is obviously not right.  I then tried to add a Tag to my AMI to see if I could filter that way, but that gave the same result.\r\n\r\nThanks very much,\r\n\r\nRussell'
1936,'','Update OpenStack Mocks\nA handful of small tweaks for the OpenStack mocks. Mostly dealing with nil values in the mocks.'
1935,'','[aws] Update aws error handling\nRecent changes in one or more of fog/excon/AWS has resulted in less informative exceptions. The symptom is that the caller will receive an Excon::Errors::HTTPStatusError with a message, e.g., "Expected(200) <=> Actual(400 Bad Request)". The root cause is obscured and there are multiple reasons a 400 might be raised.\r\n\r\nThis pull request introduces a method which examines the HTTPStatusError raised by excon and extracts details used to raise an appropriate exception. It examines, in order, error.message and error.response.body for the details; the old implementation looked only at error.message.\r\n\r\nSome minor refactoring is included in the code that selects the exception to raise.\r\n\r\nThese changes have been made to:  auto_scaling, beanstalk, cloud_formation, compute, elasticache, elb, iam, rds, and sts.'
1934,'',"[openstack|image] Fix image reload\nInstead of returning the cached image in collection, get (or find_by_id) method\r\nshould refresh the image data. This will fix the reload method, as actually it\r\ndoesn't really reload the image details."
1933,'icco','Image URL being inferred incorrectly for Google Compute Engine instances\n**This only exists in 1.12 (see comment below for the behavior on master)**\r\n\r\nWhen creating an instance in GCE, the ```insert_server``` tries to check if the specified ```image_name``` exists in the project. It does so by making this call:\r\n\r\n```ruby\r\n  if get_image(image_name, @project).data[\'code\'] == 200\r\n```\r\n\r\nWhereas, ```get_image``` returns an ```Excon::Response``` (which doesnt have the ```\'code\'``` key. Instead, the check should be:\r\n\r\n```ruby\r\n  if get_image(image_name, @project).data[:status] == 200\r\n```\r\n\r\nWithout this, trying to spin up instances using a custom image will always fail (silently), because the image will never be found in the project, and fog will assume the image exists in the "global" pool, and proceed to send out the ```insert_server``` request using the broken image url.\r\n\r\n_The silent failure also points to another interesting "problem" here:_\r\n\r\n1. When creating an instance based off a custom image, fog defaults to using the global image pool to construct the URI for the image (as described above).\r\n2. This request is sent out on the wire, and \r\n   * the immediate response from GCE is always a ```:status=200, @data[\'status\'] = PENDING``` .\r\n   * At this point, the code returns a server object back to the caller (because its 200).\r\n   * On inspecting the "operations" section of the GCE console, I can see that it eventually transitions into an "INVALID_FIELD_VALUE: Invalid value for field \'resource.images\'", because the specified image does not exist in the global pool.\r\n   * So the cloud never actually spun up a server really.\r\n3. Now, as for the users code...\r\n   * If the (server creation) call was made using either a ```create``` and ```save```, then the users calls for ```ready?``` will always return false, and I dont know how else he/she is expected to know something went wrong (without querying for the operation)\r\n   * If this code path was executed via ```bootstrap``` , the call will block for a long time, and then fail due to the timeout (since ```ready?``` never returns true).\r\n\r\nThe former (3.a) case is where I was bitten.\r\n\r\n'
1932,'','Add RDS API version parameter option.\nRDS API has moved to 2013-05-15 and added additional methods and\r\nparameters to existing ones (such as NewDBInstanceIdentifier in\r\nModifyDBInstance). It makes sense to use the new API version, however\r\nit requires more testing and possibly implementing additional methods.\r\nThis commit allows the version to be passed when instantiating a fog\r\nobject, so that this can be done piece-meal, without blocking existing\r\nfog users.\r\n\r\nRefs: #1931'
1931,'','Support new RDS API: 2013-05-15\nCurrently Fog defaults to API 2012-09-17 for RDS. In 2013, Amazon added the ability to rename instances with the ModifyDBInstance API call (http://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html). It would be great to use that version, or as a stepping stone to allow the API version to be passed as a parameter when instantiating a Fog::AWS::RDS object (akin to what Fog::AWS::Compute already allows (https://github.com/fog/fog/pull/1134). I will submit a pull request to add the version parameter.'
1930,'icco','[google|compute] Add support for Disks and Micro Instances\nAdded Disks collection and Disk model to Google Cloud Compute and implemented a new insert server service method that allows all options for inserting a server to be used rather than just a subset. These changes were necessary to be able to create micro instances as a persistent disk must be manually specified in the micro instance request which was not possible before.'
1929,'','Parse the Message in AWS ErrorResponses\nI noticed that `response.data` does not contained the error information that would be parsed from the XML ErrorResponse. Perhaps there should be a common `Fog::AWS::Parser` which handles parsing error responses?'
1928,'','Add PubliclyAccessible option to RDS.\nThis flag allows you to specify that an RDS instance inside of a VPC should have a public endpoint. When a subnet group is specified, this value defaults to false.\r\n\r\nWe are using this to launch RDS instances inside a VPC that can be accessed by EC2 nodes created via Data Pipeline, which currently does not have the ability to create resources (EC2, EMR) inside of a VPC.'
1927,'','[cli] Changes `fog --version` short option to `-v`\nLooking at a number of similar Ruby based tools, Bundler, Rubygems, Pry\r\nand IRB all use lowercase v for the short option for `--version`\r\n\r\nRuby itself uses `-v` for verbose but without any further arguments\r\nprints the version and exits.'
1926,'','Added Fog::AWS::SES.verify_domain_identity.\n* http://docs.aws.amazon.com/ses/latest/APIReference/API_VerifyDomainIdentity.html\r\n* Added Fog::Parsers::AWS::SES::VerifyDomainIdentity.'
1925,'rubiojr',"Create Debian packages for Debian stable and the current Ubuntu LTS release\nI'd like to use this issue to document the whole process. Any input is greatly appreciated.\r\n\r\nThe idea is to maintain up2date deb packages for Fog users currently on LTS/stable releases still using Ruby 1.8.7.\r\n\r\nSee also #1878.\r\n\r\n\r\n\r\n"
1924,'','[xenserver|compute] Small fix for snapshot tests added in #1914\n'
1923,'','Storage with "use_iam_profile" fails to authenticate\nGiven an EC2 instance is launched with an iam instance profile, then Fog fails to authenticate against the S3 service.\r\n\r\nFog version 1.12.1\r\n\r\nCode: \r\n\r\n    connection=Fog::Storage::AWS.new({:use_iam_profile => true}) \r\n    p connection.directories.get("somebucket")\r\n\r\nReponse code: 403 Forbidden.\r\n\r\n    <Error><Code>SignatureDoesNotMatch</Code>\r\n    <Message>The request signature we calculated does not match the signature you provided. Check your key and signing method.</Message>\r\n    <StringToSignBytes>....</StringToSignBytes>\r\n    <StringToSign>GET\\n\\n\\nFri, 28 Jun 2013 14:41:44 +0000\\nx-amz-security-token:AVeryLongTokenThatMatchesMetaDataToken\\n/somebucket/</StringToSign>\r\n\r\n\r\n'
1922,'','OpenStack: create volumes from images, boot servers with block device mapping\nThis pull adds support for passing imageRef to volume creation to make volumes based on images, and then adds support for booting servers with those volumes attached.'
1921,'',"Coveralls is failing on some CI runs giving false results\nHi @maxlinc, \r\n\r\nSince integrating Coveralls into the CI run we've had a couple of buffer overflows kill Travis jobs so we get a failure whilst trying to send results.\r\n\r\nWorth noting failures are all on Ruby 1.9.2\r\n\r\n* https://travis-ci.org/fog/fog/jobs/8391737\r\n* https://travis-ci.org/fog/fog/jobs/8423779\r\n* https://travis-ci.org/fog/fog/jobs/8495553\r\n\r\n```\r\n[Coveralls] Submitting to https://coveralls.io/api/v1\r\n*** buffer overflow detected ***: /home/travis/.rvm/gems/ruby-1.9.2-p320/bin/shindont terminated\r\n```\r\n\r\nSee the build failures for exact details.\r\n\r\nNot sure if this is a known issue for @coveralls or @travis-ci \r\n\r\nAt the moment it is more of an annoyance but if it happens too frequently we may have to remove coveralls. Sure there's a joke in there somewhere.\r\n\r\nLinked to #1906 "
1920,'',"[rackspace|compute] adding parameter to save method \nI have added a non-used parameter to the Fog::Compute::Rackspace::Server so that it has the same method signature as Fog::Compute::Rackspace::Server. This should make it easier to write fog code that's common to both server versions."
1919,'','Passing the connection_options parameter to underlying Fog::Storage in Fog::RiakCS::Usage\nThis aids in scenarios where you want to pass settings that are contained in the `connection_options`, such as `proxy`.\r\n'
1918,'',"[rackspace] fixing broken tests\nThis pull request address several issues that occur when run against the live Rackspace Cloud.\r\n\r\nI have also increased the default fog timeout to 2000 seconds when running tests against a live cloud to address the brittleness of the Rackspace tests. I am receptive to hearing everyone's thoughts on this change."
1917,'','Optparse\nAdd option parsing to `bin/fog`.\r\n\r\n* Supports `-h`, `--help`\r\n* Supports `-V`, `--version`\r\n* Supports `-C`, `--credentials-path` for using alternate credentials file.'
1916,'',"Code coverage (cleanup based on PR comments)\nThis just does some cleanup based on comments in https://github.com/fog/fog/pull/1897.  It doesn't make any significant changes."
1914,'rubiojr','Added support for [xenserver] snapshot\nAdded support for snapshot on xenserver.. this is my first PR on fog, tried to keep the things as much similar on other parts of the code as I have studied..\r\n\r\nsorry if any mistake ;)'
1913,'','[xenserver] support for snapshots\nAny idea on supporting XenServer snapshots? thank you..'
1912,'','OpenStack Temp URL Support and AWS::File compatibility\nIn the context of enabling the Cloud Foundry Cloud Controller to use OpenStack Swift using the Fog HP storage provider an inconsistency in creating temporary file urls has been discovered.\r\n\r\nWhile Fog::Storage::AWS::File uses File#url to create a temporary url, Fog::Storage::HP::File uses File#temp_signed_url although semantically both methods are equal.\r\nThis pull requests adds a File#url method so that both File classes offer the same interface for creating temp urls.\r\n\r\nIn order to do that another change was needed:\r\nMany OpenStack users suggest the HP adapter to access OpenStack Swift as is it much more stable.\r\nBUT: the HP implementation of File#temp_signed_url is currently not OpenStack compatible.\r\nHP uses a different strategy to create signature urls avoiding the usage of a so called "account meta key" which has to be set for the Swift account for a regular OpenStack Swift.\r\n\r\nThis pull requests adds a simple logic:\r\nIt allows OpenStack users to use the HP adapter and pass "hp_account_meta_key" when creating a storage object.\r\nWhen hp_account_meta_key is set, the OpenStack signature url strategy is applied.\r\n\r\nWith this pull request the Cloud Foundry Cloud Controller will be able to use Fog seamlessly to use either AWS S3, HP or OpenStack Swift as a blob storage.\r\n\r\nMore than this all Fog users will benefit from the consistent API and OpenStack users will be able to use the HP provider\'s File#url method to create temp urls instead of implementing it separately.\r\n\r\n\r\n'
1911,'',"No (documented?) way to globally configure with environment variables\nWorking with Fog and Carrierwave in Rails 4 / Ruby 2.0 on Heroku -\r\n\r\nThe general intention, it seems, it to use a configuration file for the keys when you want to globally configure fog. But, because I want to keep my keys out of my repo, I need them as environment variables, so that doesn't work.\r\n\r\nPreviously, I've been doing:\r\n```ruby\r\nFog.credentials = {\r\n  :aws_access_key_id => ENV['AWS_ACCESS_KEY']\r\n}\r\n# later...\r\nFog::Storage[:aws].directories.get(ENV['AWS_BUCKET']).files.create({...})\r\n```\r\n\r\nbut this is a) not how you want me doing it and b) no longer working.\r\n\r\nIf I'm missing something, can you tell me, and add it to the docs? If I'm not, I would really like a way to do this."
1910,'tokengeek',"[Brightbox] Adds collaborator support\nUpdates Brightbox's fog provider to support collaborations in the API."
1909,'',"Allocate IP Address fails on Eucalyptus\nERROR: Allocate IP Address failed 400 Bad Request => Failed to bind the followin\r\ng fields:\\nDomain = standard\\n\r\n\r\nThe implementation of fog/aws/requests/compute/allocate_address.rb  is too strict for the domain parameter. the domain is forced to be standard even if a nil domain is passed. \r\nthe AWS API allocate address allows  for no domain to be passed (that internally to AWS defaults to standard0. So eucalyptus is a valid implementation that accepts the nil domain. (although they should also allow standard but they don't -)). \r\n\r\npassing  domain=standard to eucalyptus causes allocate_address  it to fail. \r\n\r\n\r\ndef allocate_address(domain='standard')\r\n          domain = domain == 'vpc' ? 'vpc' : 'standard'\r\n          request(\r\n            'Action'  => 'AllocateAddress',\r\n            'Domain'  => domain,\r\n            :parser   => Fog::Parsers::Compute::AWS::AllocateAddress.new\r\n          )\r\n        end \r\n\r\nshould \r\n\r\n def allocate_address(domain=nil)\r\n          domain = domain == 'vpc' ? 'vpc' : 'standard'  if domain != nil\r\n          request(\r\n            'Action'  => 'AllocateAddress',\r\n            'Domain'  => domain,\r\n            :parser   => Fog::Parsers::Compute::AWS::AllocateAddress.new\r\n          )\r\n        end\r\n \r\nthe mock portion should change as well \r\n\r\n def allocate_address(domain = nil)\r\n          domain = domain == 'vpc' ? 'vpc' : 'standard' if domain != nil"
1908,'','[vsphere] fix regex typo\nReported in Foreman: http://projects.theforeman.org/issues/2694'
1907,'','[rackspace|storage] Submit etags for file models\nUpdate file mode to submit etags if they are present.'
1906,'',"[google|compute] Upgrade GCE to v1beta15 and fix a bunch of bugs\nThis isn't quite ready to merge, but I wanna put it out there. \r\n\r\nTwo questions I have for @geemus and team:\r\n\r\n1) Right now I'm just printing out errors I'm getting in responses. What's the best way to deal with errors in fog?\r\n\r\n2) I've just been using p for debugging and the like, is there an official Fog logger? I haven't been able to find one (this might be the answer to 1)."
1905,'','Create separate Gemfile for Ruby 1.8.7\n* Allows users of Ruby 1.9 (and above) to use the latest version of `nokogiri`\r\n* Allows users of Ruby 1.8.7 to continue using `nokogiri` version 1.5\r\n* Creates a separate `Gemfile` for Ruby 1.8.7, where this project can specify stricter version constraint on other dependencies that may drop Ruby 1.8.7 support in future minor releases\r\n* Modifies the CI configuration to run tests against this new Gemfile on Ruby 1.8.7'
1904,'','Update excon dependency to version ~>0.25.0\nDoes exactly what it says on the tin.'
1903,'',"Adds documentation for CloudSigma\nThis adds documentation for CloudSigma. Could you also update the [Provider documentation](http://fog.io/about/provider_documentation.html) to point to this. Also this is a vendor provided library. We have also created an email address 'dev-support@cloudsigma.com' that can be added."
1902,'',"Am I cleaning up correctly?\n    connection = Fog::Storage.new({\r\n      :provider                 => 'AWS',\r\n      :aws_access_key_id        => AMAZON_ACCESS_KEY_ID,\r\n      :aws_secret_access_key    => AMAZON_SECRET_ACCESS_KEY\r\n    })\r\n\r\n    directory = connection.directories.create(\r\n      :key    => AMAZON_BUCKET_NAME,\r\n      :public => false\r\n    )\r\n\r\n    file = directory.files.get(path)\r\n\r\n    file.url(1.minutes.from_now)\r\n\r\n    # cleanup\r\n    directory.destroy\r\n\r\nSecond, why do I need to execute `directory.destroy` when I only want to fetch the expiring url of a file on S3?\r\n\r\n"
1901,'','[digitalocean] Rename do to docean in examples\nAvoids using a reserved word, and `docean` is also used elsewhere in\r\nthe getting started guide.'
1900,'',"Does your Gemspec and nokogiri 1.6 force fog 0.9.0\nWhen I did  `bundle update` fog was downgraded to 0.9.0 (and excon was also downgraded).  This seemed to have been caused by nokogiri upgrading to 1.6 and presumably 0.9.0 was the last fog gem to have a >=version for nokogiri making it the newest non-conflicting version.\r\n\r\nI'm not sure that this is what happened or what the correct resolution is but you might need to change your gemspec so that things don't go very odd when nokogiri is updated by another requirement.\r\n\r\nNote that in my case both fog and nokogiri were dependencies of other gems (asset_sync and rake respectively) rather than having been deliberately and consciously selected by me.  I only noticed the issue when I got errors with my Heroku deployment when it tried to use fog 0.9.0 to transfer the precompiled assests to Rackspace."
1899,'','[rackspace|cdn] updated to re-authenticate and retry request when auth token expires\nDevelopers are reporting receiving a HTTP 401 - Unauthorized using the Rackspace Cloud with carrierwave. This issue appears to be occurring because the CDN service is not re-authenticating after its authentication token expires.\r\n\r\nFor more information please refer to http://stackoverflow.com/questions/17139148/http-401-fogstoragerackspaceserviceerror/17149654#17149654\r\n\r\nNote, this pull request only addresses the CDN service. I am going to determine if this issue exists for other Rackspace services and if necessary open up a separate PR to address those.\r\n\r\n\r\n\r\n'
1898,'',"Path style for s3 endpoint\nDon't use the bucket and region logic when the endpoint is specified.\r\n\r\nPlease don't merge this PR yet, it is meant as a discussion for #1174"
1897,'','Code coverage\nhttps://github.com/fog/fog/pull/1893 again, but with a clean history.\r\n\r\nAdds SimpleCov and Coveralls.io reports.'
1896,'','[openvz] updates openvz exit code to check for openvz_connect_command \nUpdates openvz exit code to check for openvz_connect_command before attempting to run command in order prevent shindo from crashing when running live tests against a non-openvz cloud provider.'
1895,'','[rackspace|dns] Fix Pagination in DNS\nThis pull request addresses issue https://github.com/fog/fog/issues/1887 where the `each` method is not transparently requesting additional DNS pages.\r\n\r\n'
1894,'','Fix autoincrement when creating a flavor if private flavors exist.\nBefore, only public flavors were considered when finding the next free ID. That could lead to the case where the calculated ID was already taken which lead to a conflict. This happened whenever the user tried to create a private flavor via fog and then another (private OR public) flavor afterwards. Now, we also take private flavors into account, so the conflict cannot happen anymore.\r\n\r\nAs a side effect, it is now also possible to just return all private flavors, using the :is_public => false filter on the list_flavors_detail API call or the flavors collection.'
1893,'',"Code coverage with SimpleCov and Coveralls\nThis PR will add code coverage reports.  It will produce a SimpleCov report when you run locally (at coverage/index.html).  It should also hook Travis runs into [Coveralls](https://coveralls.io), which in turn will add comments to Pull Requests to indicate if coverage is increasing, decreasing or remaining the same.  (See [this example](https://github.com/lemurheavy/coveralls-ruby/pull/18)).\r\n\r\nIn case anyone is wondering, I'm not proposing there should be a code coverage target.  I agree with the Martin Fowler [post on test coverage](http://martinfowler.com/bliki/TestCoverage.html) which explains:\r\n\r\n>Test coverage is a useful tool for finding untested parts of a codebase. Test coverage is of little use as a numeric statement of how good your tests are."
1892,'','upgrade google compute engine api version\nCurrently, the v1beta14 version of google compute engine was deprecated.\r\nPlease upgrade to v1beta15.\r\nThanks.'
1891,'','Update excon dependency to version ~>0.24.0\nDoes exactly what it says on the tin.'
1890,'','Update nokogiri dependency to version ~>1.6.0\nDoes exactly what it says on the tin.'
1889,'','fix create_tenant Mock response description and name\nThe attributes hash keys are all symbols. Please reference:\r\nhttps://github.com/fog/fog/blob/master/lib/fog/core/attributes.rb#L20'
1888,'','Pagination on the rackspace DNS api?\nIf I call \r\n\r\nFog::DNS.new(RACKSPACE_CREDENTIALS).zones.map(&:domain).count\r\n=> 100\r\n\r\nWhereas I know I have 317 domains.\r\nI assume the rackspace API does pagination and your provider does not get all the results.\r\n\r\nI may have time to fix it myself soon,\r\nTom Hall'
1887,'','Pagination on the rackspace DNS api?\nIf I call \r\n\r\nFog::DNS.new(RACKSPACE_CREDENTIALS).zones.map(&:domain).count\r\n=> 100\r\n\r\nWhereas I know I have 317 domains.\r\nI assume the rackspace API does pagination and your provider does not get all the results.\r\n\r\nI may have time to fix it myself soon,\r\nTom Hall'
1886,'','Separate XML from Fog::Core::Connection\nThis is some work towards... #1878, #1253 and others.\r\n\r\nThis moves JSON and XML to the level alongside fog "core" so in future, when the code is split into gems, providers can rely on `fog-core` and `fog-json` without picking up XML requirements like Nokogiri.\r\n\r\nAlso added a deprecated form of `Fog::Connection` which should (I hope) function as currently - including SAX parsing of chunked responses - as well as a SAX parsing connection and a plain connection.\r\n\r\nThis is for initial review.\r\n\r\nI\'ve not been able to break the mental barrier to work on Shindo tests for it and unfortunately because we mock at the Service `#request` level, most of the code below that is not getting run.\r\n\r\nTests pass with mocks and against a testing instance of Brightbox\'s API so happy that the NON parsing path hasn\'t been affected.'
1885,'','[core] Removes unused getting of Constant\n'
1884,'',"OpenStack updates\nI found several issues with the `authenticate_v2` code that I felt needed to be addressed. I've also been attempting to reconcile the differences between all the services. I feel like there needs to be a `Fog::OpenStack::Service` class for all the duplicated initialization/authentication code. These commits bring these services closer to the point where this could be done, but there's still several items that need to be addressed.\r\n\r\nI wanted to post what I have so far to get some feedback. I've ordered these commits such that it should be easy to merge up to whichever commit you feel comfortable with. The last few commits obviously effect more than just OpenStack, but I thought I'd leave them here for the moment. \r\n"
1883,'','Excon::Errors::BadRequest when uploading big file to AWS\nHi,\r\n\r\nTrying to upload a big file (> 1 MiB) to AWS, which seems rather hard. I did look at #1731 and got some inspiration from there, however the suggested fix (to explicitly specify region was not enough for me).\r\n\r\nSmall files work great, no worries. It\'s only with bigger (= chunked) files that we run into problems.\r\n\r\nWithout specifying multipart_chunk_size, I get a boring "Connection reset by peer" in excon/connection.rb. When specifying a multipart_chunk_size which is low enough (in this case, 128 KiB seems to be the "magic number" - 256 KiB throws exceptions, 128 KiB works better), the upload progresses fine *until* it should be "ready" and mark the multipart as complete. Then it fails like this:\r\n\r\n```\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\n              response_call at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/excon-0.24.0/lib/excon/middlewares/expects.rb:6\r\n                   response at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/excon-0.24.0/lib/excon/connection.rb:353\r\n                    request at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/excon-0.24.0/lib/excon/connection.rb:247\r\n                    request at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/fog-1.11.1/lib/fog/core/connection.rb:21\r\n                    request at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/fog-1.11.1/lib/fog/aws/storage.rb:506\r\n  complete_multipart_upload at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/fog-1.11.1/lib/fog/aws/requests/storage/complete_multipart_upload.rb:33\r\n             multipart_save at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/fog-1.11.1/lib/fog/aws/models/storage/file.rb:278\r\n                       save at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/fog-1.11.1/lib/fog/aws/models/storage/file.rb:208\r\n                     create at /Users/plundberg/.rvm/gems/jruby-1.7.2/gems/fog-1.11.1/lib/fog/core/collection.rb:52\r\n                     (root) at spam.rb:19\r\n```\r\n\r\nI added some debugging code in expects.rb and got this (removed potentially sensitive info):\r\n\r\n``` xml\r\n<Error>\r\n<Code>EntityTooSmall</Code>\r\n<Message>Your proposed upload is smaller than the minimum allowed size</Message>\r\n<ETag>...</ETag>\r\n<MinSizeAllowed>5242880</MinSizeAllowed>\r\n<ProposedSize>131072</ProposedSize>\r\n<RequestId>...</RequestId><HostId>...</HostId>\r\n<PartNumber>1</PartNumber>\r\n</Error>\r\n```\r\n\r\nSo... does this mean that I cannot chunk the data in smaller chunk than 5 megs? :) Awkward, since that was my only way to get the file up at all...\r\n\r\nAny ideas? I\'m 100% sure that the region is correct (eu-west-1), I verified that with 3Hub.'
1882,'','uninitialized constant Fog::Storage::AWS::Directory prior to use\nFog::Storage::AWS::Directory is not included when `require \'fog\'`, but becomes available after (at least) a connection is attempted:\r\n\r\n```ruby\r\nrequire \'fog\'\r\n #=> true \r\nFog::Storage::AWS\r\n #=> Fog::Storage::AWS \r\nFog::Storage::AWS::Directory\r\n#=> NameError: uninitialized constant Fog::Storage::AWS::Directory\r\n#\tfrom (irb):3\r\n#\tfrom /Users/daqri202/.rvm/rubies/ruby-2.0.0-p0/bin/irb:16:in `<main>\'\r\nconfig = {\r\n     :provider => \'AWS\',\r\n     :aws_access_key_id => \'key\',\r\n     :aws_secret_access_key => \'secret\'\r\n}\r\n# => {:provider=>"AWS", :aws_access_key_id=>"key", :aws_secret_access_key=>"secret"} \r\n Fog::Storage.new(config).directories\r\n#=> Excon::Errors::Forbidden: Expected(200) <=> Actual(403 Forbidden)\r\n# ...\r\nFog::Storage::AWS::Directory\r\n#=> Fog::Storage::AWS::Directory\r\n```\r\n\r\nRuby 2, Fog 1.11.1'
1881,'','Fog AWS files.collect does not appear to get all files\nI have a bucket with many files in it, but `collect` does not appear to "progress to the next page" like `each`:\r\n\r\n    $ connection.files.collect{ ii += 1 }\r\n    $ ii\r\n    => 1000 \r\n\r\nSame bucket, with each:\r\n\r\n    $ connection.files.each{ ii += 1 }\r\n    $ ii\r\n    => 37567\r\n\r\nThis came up in writing a bucket duplication script, where I wanted to avoid duplicated existing files:\r\n\r\n    existing_files = to_bucket.files.collect{|f| f.key}\r\n    from_bucket.files.each do |f|\r\n      next if existing_files.include? f.key\r\n      ...\r\n    end'
1880,'','"Called \'load_file\' without the :safe option -- defaulting to safe mode."\nNewer Rubies force you to instantiate calls to YAML.load_file with the :safe option to avoid this warning.'
1879,'','Bug in configure_vm_cpus.rb and configure_vm_memory.rb results in 415 Unsupported Media Type error\nI believe that this is probably the same issue as: [[https://github.com/fog/fog/issues/1678]]\r\nfog-1.11.1 doesn\'t adhere to the vcloud api in some functions that configure the vm.  This results in a 415 Unsupported Media Type error when executing the server.save method.\r\n\r\nThese files are related:\r\n\r\nconfigure_vm_memory.rb \r\nerror in the code\r\n\r\n\u2028configure_vm_cpus.rb \r\nerror in the code\u2028\r\n\r\nconfigure_vm_disks.rb \r\nactually has correct code, but listed here as reference\r\n\r\nHere are the vmware api documents that I was viewing:\u2028[[http://pubs.vmware.com/vcd-51/index.jsp#com.vmware.vcloud.api.doc_51/GUID-E1BA999D-87FA-4E2C-B638-24A211AB8160.html]]\u2028[[http://pubs.vmware.com/vcd-51/index.jsp#com.vmware.vcloud.api.doc_51/GUID-472B5732-BAFE-4ECD-B77B-BE6287AABF58.html]]\r\n\r\n\r\nIn particular the \'Content-Type\' in the header is incorrect (an empty string) due to a bug in the code. I\'ve hacked the fog locally to get it to work, here\'s how our fix looks:\r\n          request(\r\n            :body     => body,\r\n            :expects  => 202,\r\n            :headers  => {\'Content-Type\' => \'application/vnd.vmware.vcloud.rasdItem+xml\' },  # ADDED BY IZ\r\n            #:headers  => {\'Content-Type\' => vm_data[:"vcloud_type"] }, COMMENTED OUT BY IZ\r\n            :method   => \'PUT\',\r\n            :uri      => "#{edit_uri}",\r\n            :parse    => true\r\n          )\r\n\r\nIn the following trace you can see that there is no :"vcloud_type" in the vm_data and that is how the Content-Type ends up as empty:\r\n\r\nvm_data key: <ns12_href>  value: <https://mycloud.us-east-01.greenhousedata.com/api/vApp/...etc.../virtualHardwareSection/cpu>\r\nvm_data key: <ns12_type>  value: <application/vnd.vmware.vcloud.rasdItem+xml>\r\nvm_data key: <rasd:AllocationUnits>  value: <hertz * 10^6>\r\nvm_data key: <rasd:Description>  value: <Number of Virtual CPUs>\r\nvm_data key: <rasd:ElementName>  value: <1 virtual CPU(s)>\r\nvm_data key: <rasd:InstanceID>  value: <4>\r\nvm_data key: <rasd:Reservation>  value: <0>\r\nvm_data key: <rasd:ResourceType>  value: <3>\r\nvm_data key: <rasd:VirtualQuantity>  value: <1>\r\nvm_data key: <rasd:Weight>  value: <0>\r\nvm_data key: <Link>  value: <{:rel=>"edit", :type=>"application/vnd.vmware.vcloud.rasdItem+xml", :href=>"https://mycloud.us-east-01.greenhousedata.com/api/vApp/...etcâ¦"}>\r\n'
1878,'','Nokogiri 1.6 onwards has dropped support for Ruby 1.8.7\nSo last month we decided to continue supporting Ruby 1.8.7 (see https://github.com/fog/fog/issues/1814) with the note to revisit when something happened to make us rethink things.\r\n\r\nWell https://github.com/fog/fog/pull/1877 has been sent which highlights that Nokogiri 1.6 has dropped support for Ruby 1.8.7 (https://github.com/sparklemotion/nokogiri/commit/7c5f3f6c444b73192abbcc19ef9e3c987cdf7ab0) making `1.5.10` the latest version with 1.8 support.\r\n\r\nSo that means we have to reconsider last months decision and consider any problems with distros with older and newer `libxml2` installs.\r\n\r\nMinimal work is documenting and setting the gemspec accordingly.\r\n\r\nOther options?\r\n\r\n* Making nokogiri optional\r\n\r\nDiscuss...'
1877,'','Ease the restriction on version of nokogiri\nWe want to be able to use Nokogiri 1.6.0 in a project that also requires Fog. This is because of a problem with earlier versions of Nokogiri and LibXML 2.9[1]. We ran all the Fog tests against Nokogiri 1.6.0 and everything passes.\r\n\r\nThe Fog README states that it should work with Ruby 1.8.7 and Ruby 1.9, but Nokogiri 1.6.0 will complain if you try to use it with anything less than Ruby 1.9.2. We appreciate that this might prevent this pull request making it back to master.\r\n\r\n[1] https://github.com/sparklemotion/nokogiri/issues/829'
1876,'','Add POST object restore operation\nSee http://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPOSTrestore.html\r\n\r\nThis would supercede #1297 and has some very basic test/mocks.'
1875,'','one more thing for rackspace LB timeout attribute\nFollowing on my other timeout change, this allows you to specify timeout in the initial LB creation attributes.\r\n\r\nThe test tried to set a timeout of 30 which was also the default value, so everything appeared to work. If you just apply the test change (to 60 sec) without the request change the test should fail.'
1874,'','[AWS | AutoScaling] Do not send Instances for update_auto_scaling_group\n(Avoids 413 Request Entity Too Large for ASGs with lots of instances)\r\n\r\nAWS does not require or expect Instances to be sent when updating the group: http://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_UpdateAutoScalingGroup.html'
1873,'tokengeek','[Brightbox] Expose expires_in value for the access token\n'
1872,'jedi4ever','[openvz] Fixes #1871 test helper callback\nThis moves the setting up of an `at_exit` callback from when the file\r\nis required to when the matching helper is used.\r\n\r\nThis prevents it failing on any run where OpenVZ is excluded.'
1871,'',"OpenVZ helper sets `at_exit` callback for all runs\nWhen you run non mocked tests and *openvz* tests are excluded a global callback is still triggered.\r\n\r\n```\r\nFOG_MOCK=false bundle exec shindo +meta -openvz\r\n... (shindo tests runs)\r\nvzlist -a -j\r\n/Users/paul/code/fog/lib/fog/openvz/compute.rb:165:in `vzlist': /Users/paul/.rubies/ree-1.8.7-2012.02/lib/ruby/1.8/open3.rb:73:in `exec': No such file or directory - vzlist -a -j   (Errno::ENOENT) (Fog::Errors::Error)\r\n... (stacktrace)\r\n\tfrom ./tests/openvz/helper.rb:32\r\n```\r\n\r\nReason being is that the callback is being setup when `tests/openvz/helper.rb` is required (all runs) even when it is never needed (because `openvz_fog_test_server` is never used).\r\n"
1870,'','[AWS | Compute] Added copy_image request with parser, mocks and tests.\nAdded copy_image request with parser, mocks and tests.'
1869,'','[AWS | Compute] Added copy_image request with parser, mocks and tests.\nAdded copy_image request with parser, mocks and tests.'
1868,'seanhandley','This withstands naming/renaming issues.\nFollows up https://github.com/fog/fog/pull/1867\r\n\r\nand\r\n\r\nhttps://github.com/fog/fog/pull/1867#discussion_r4588518'
1867,'seanhandley','Fix issue 1414\nSee #1414'
1866,'rubiojr',"Fog Xenserver Net::ReadTimeout on certain actions like power_off\nHi, \r\n\r\nI'm using fog (1.11.1) as part of a script to spin up - and power control  vms on Citrix Xenserver. So far this looks really great except I receive timeouts on shutting down a vm for example. \r\n\r\nI cannot find a way to configure this timeout. It looks like this is set to 30 seconds somewhere. Shutting down a vm may take longer, for me it's even fine if it takes 300 seconds at least allow me to set this somewhere. This does not happen on every request, only on slower hosts or vms that are slow on shutdown sequence. \r\n\r\nThis is part of the code to setup a connection \r\n\r\n          @connection = Fog::Compute.new({\r\n                                             :provider => 'XenServer',\r\n                                             :xenserver_url => @host,\r\n                                             :xenserver_username => @user,\r\n                                             :xenserver_password => @pass\r\n                                         })\r\n\r\nActual statement for shutting down the vm is vm.stop \r\n\r\noutput: \r\n\r\n```\r\n/usr/local/rvm/gems/ruby-2.0.0-p0/gems/fog-1.11.1/lib/fog/xenserver.rb:41:in `eval': Net::ReadTimeout (Net::ReadTimeout)\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/protocol.rb:152:in `rbuf_fill'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/protocol.rb:134:in `readuntil'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/protocol.rb:144:in `readline'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http/response.rb:39:in `read_status_line'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http/response.rb:28:in `read_new'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http.rb:1405:in `block in transport_request'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http.rb:1402:in `catch'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http.rb:1402:in `transport_request'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http.rb:1375:in `request'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/net/http.rb:1321:in `request_post'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/xmlrpc/client.rb:477:in `do_rpc'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/xmlrpc/client.rb:281:in `call2'\r\n\tfrom /usr/local/rvm/rubies/ruby-2.0.0-p0/lib/ruby/2.0.0/xmlrpc/client.rb:262:in `call'\r\n\tfrom (eval):1:in `request'\r\n\tfrom /usr/local/rvm/gems/ruby-2.0.0-p0/gems/fog-1.11.1/lib/fog/xenserver.rb:41:in `eval'\r\n\tfrom /usr/local/rvm/gems/ruby-2.0.0-p0/gems/fog-1.11.1/lib/fog/xenserver.rb:41:in `request'\r\n\tfrom /usr/local/rvm/gems/ruby-2.0.0-p0/gems/fog-1.11.1/lib/fog/xenserver/requests/compute/shutdown_server.rb:8:in `shutdown_server'\r\n\tfrom /usr/local/rvm/gems/ruby-2.0.0-p0/gems/fog-1.11.1/lib/fog/xenserver/models/compute/server.rb:184:in `stop'\r\n\tfrom /usr/local/rvm/gems/ruby-2.0.0-p0/gems/xenfoo-0.0.1/lib/xenfoo/action.rb:63:in `poweroff_vm'\r\n```\r\n\r\nTo me it seems Fog is using xmlrpc over ruby-net to setup the connection to the host. Where can I tweak some values? Any help is really appreciated. \r\n "
1865,'','Issue creating Ephemeral Drives in EC2 VPC\nI am running fog (1.11.1)\r\n\r\nknife-ec2 (0.6.4)\r\n\r\nI modified ec2_server_create.rb and added the below which now occupies lines 241 and 242\r\n\r\n238         # For VPC EIP assignment we need the allocation ID so fetch full EIP details\r\n239         elastic_ip = connection.addresses.detect{|addr| addr if addr.public_ip == requested_elastic_ip}\r\n240 \r\n241         puts "DEBUG #{create_server_def}"\r\n242         exit\r\n243         @server = connection.servers.create(create_server_def)\r\n\r\nI also added\r\n\r\n487         (config[:ephemeral] || []).each_with_index do |device_name, i|\r\n488           puts "DEBUG #{device_name} - #{i}"\r\n489           server_def[:block_device_mapping] = (server_def[:block_device_mapping] || []) << {\'VirtualName\' => "ephemeral#{i}", \'DeviceName\' => device_name}\r\n490         end\r\n\r\nI ran my knife ec2 server create command and I got the below for the create_server_def\r\n\r\nDEBUG /dev/xvdb - 0\r\nDEBUG /dev/xvdc - 1\r\nDEBUG /dev/xvdd - 2\r\nDEBUG /dev/xvde - 3\r\nDEBUG {:image_id=>"ami-8baa73e2", :groups=>nil, :security_group_ids=>["sg-1", "sg-2", "sg-3", "sg-4"], :flavor_id=>"m1.large", :key_name=>"OUR-KEY", :availability_zone=>"us-east-1c", :subnet_id=>"subnet-2e281d47", :private_ip_address=>"OUR_IP",, :ebs_optimized=>"false", :block_device_mapping=>[{"VirtualName"=>"ephemeral0", "DeviceName"=>"/dev/xvdb"}, {"VirtualName"=>"ephemeral1", "DeviceName"=>"/dev/xvdc"}, {"VirtualName"=>"ephemeral2", "DeviceName"=>"/dev/xvdd"}, {"VirtualName"=>"ephemeral3", "DeviceName"=>"/dev/xvde"}]}\r\n\r\nI ran pry and did the following step by step below:\r\n\r\nrequire \'fog\'\r\n\r\nconnection = Fog::Compute.new(\r\n\t\t:provider\t=> "AWS",\r\n\t\t:aws_access_key_id\t=> "#{ENV[\'AWS_ACCESS_KEY_ID\']}",\r\n\t\t:aws_secret_access_key => "#{ENV[\'AWS_SECRET_ACCESS_KEY\']}"\r\n\t\t)\r\n\r\ncreate_server_def = {:image_id=>"ami-8baa73e2", :groups=>nil, :security_group_ids=>["sg-1", "sg-2", "sg-3", "sg-4"], :flavor_id=>"m1.large", :key_name=>"OUR-KEY", :availability_zone=>"us-east-1c", :subnet_id=>"subnet-2e281d47", :private_ip_address=>"OUR_IP",, :ebs_optimized=>"false", :block_device_mapping=>[{"VirtualName"=>"ephemeral0", "DeviceName"=>"/dev/xvdb"}, {"VirtualName"=>"ephemeral1", "DeviceName"=>"/dev/xvdc"}, {"VirtualName"=>"ephemeral2", "DeviceName"=>"/dev/xvdd"}, {"VirtualName"=>"ephemeral3", "DeviceName"=>"/dev/xvde"}]}\r\n\r\n@server = connection.servers.create(create_server_def)\r\n\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\nfrom /opt/chef/embedded/lib/ruby/gems/1.9.1/gems/excon-0.22.1/lib/excon/middlewares/expects.rb:10:in `response_call\''
1864,'','[rackspace|compute] removing erronious note on setup method\n'
1863,'',"debug excon errors in tests\n@geemus For the next fog/excon release.\r\nExcon doesn't check defaults for invalid keys, so this won't log any warnings before then."
1862,'','OpenStack Orchestration\nPartial support for OpenStack\'s "heat" component which allows (among other things) creation of multiple VMs in a single step using a JSON-based template language. Implemented so far is CRUD for the "stack" model, which handles creation and deletion of VM groups. More things might follow later.'
1861,'',"Can't resize AWS autoscaling group\nI have an auto-scaling group defined under my AWS account, and I am trying to resize it.\r\nI tried the following operations inside the fog command prompt, but they have no effect:\r\n\r\n    >> as.groups[0].min_size\r\n    2\r\n    >> as.groups[0].min_size=1\r\n    1\r\n    >> as.groups[0].min_size\r\n    2\r\n\r\nAm I missing something?"
1860,'',"[stormondemand] Add support for all Storm On Demand APIs\nThese commits add supports for all Storm On Demand APIs. I also added services like Monitoring, Account, Billing and Support to category the APIs. There's a README in lib/fog/storm_on_demand/ directory for basic usage of the new APIs. "
1859,'','Avoid AWS Throttling on RDS Snapshots\nThe method Fog::AWS::RDS::Snapshots#each overrides Enumerable#each, which can cause a large number of requests to AWS if, e.g., a call to #all is chained with a call to map.\r\n\r\nThis change renames the #each method to #each_page.'
1858,'','Vcloud/add metadata and customizationScript\nHi,\r\n\r\nThis PR adds two features to the vcloud provider\r\n\r\nyou can create, list and destroy Metadata (called tags in AWS) for servers(VMs) \r\nYou can pass a customizationScript (called userdata in AWS) to a VM so it can be bootstrapped.\r\n\r\nThanks,\r\n\r\nRodrigo Estebanez'
1857,'','Support Azure compute, for its per-minute billing deliciousness\nhttp://weblogs.asp.net/scottgu/archive/2013/06/03/windows-azure-announcing-new-dev-test-offering-biztalk-services-ssl-support-with-web-sites-ad-improvements-per-minute-billing.aspx'
1856,'','[openstack|storage] allow headers to be specified for object manifest\nAllows additional headers to be set, as well as overriding the default `X-Object-Manifest` header.\r\n\r\nThese are the same changes made to `Storage::Rackspace` in #1800 and #1855, and replaces PR #1802.\r\n\r\nNote: Someone with a `Storage::OpenStack` compatible account needs to verify these tests pass.'
1855,'','[rackspace|storage] allow headers to be specified for object manifest\nUpdates changes recently committed in #1800 to allow additional headers to be set, as well as overriding the default `X-Object-Manifest` header.'
1854,'kevinykchan',"[joyent|compute] support for http-signature-auth using ssh-agent\nThis PR enables authenticating against Joyent's API using ssh-agent, this eliminates the need to enter a passphrase every time when making API requests."
1853,'',"Add joyent API version and network support\nAdding support for listing networks in the Joyent Cloud.\r\n:joyent_version was defined in a way that it would always\r\nfall back to the default '~6.5'. Creating servers with\r\na particular network requires setting :joyent_version to '~7.0'\r\nor greater."
1852,'','[rackspace|storage] fixing large upload example and documentation\nFixing issue in large file upload example mentioned by @burns.\r\n\r\nhttps://github.com/fog/fog/pull/1844#issuecomment-18727996'
1851,'','Added AWS IAM iam.roles support\nComplete with test.\r\nFixes: https://github.com/fog/fog/issues/1850'
1850,'',"AWS IAM iam.roles collection support\nHi,\r\n\r\nThe project I work on requires me to work with IAM roles. fog does not support iam.roles collection and I've decided to add it. Here's what I hacked around:\r\n\r\nhttps://github.com/radekg/fog/commit/83a4cd984029b80f9210c33caecc041d7a526934\r\n\r\nIf I implement tests, would you be willing to pull that in?\r\nGreat project BTW!"
1849,'','[Rackspace] add proxy support for Auth 2.0\nAuth 2.0 was not passing the connection_options hash onto the identity service consequently users were unable to use proxies with Auth 2.0. This pull request addresses that issue. '
1848,'','Fog Storage - Common Fog error class for NotFound errors\nIn the context of Fog storage providers deleting a file such as:\r\n\r\n    dir.files.destroy(key)\r\n\r\nThe issue is:\r\nSome providers throw NotFound errors, some don\'t.\r\n\r\nHow to catch all possible not found errors?\r\nIt\'s practically impossible as they do not share a common superclass.\r\n\r\nYou might catch a standard error, see whether the class is a "NotFound" error by name but ... this is not really desirable.\r\nIn the end a provider specific NotFound class does not add any value.\r\n\r\nSo wouldn\'t it be easier to introduce a class\r\n\r\nFog::Errors::NotFound < Fog::Errors::Error\r\n\r\nAll providers could throw it.\r\n\r\nSo two things should be done:\r\n\r\n1. Consistently either throw or not throw NotFound errors across all providers\r\n2. If throwing NotFound errors, throw Fog::Errors::NotFound'
1847,'','Fog Storage - Common Fog error class for NotFound errors\nIn the context of Fog storage providers deleting a file such as:\r\n\r\n    dir.files.destroy(key)\r\n\r\nThe issue is:\r\nSome providers throw NotFound errors, some don\'t.\r\n\r\nHow to catch all possible not found errors?\r\nIt\'s practically impossible as they do not share a common superclass.\r\n\r\nYou might catch a standard error, see whether the class is a "NotFound" error by name but ... this is not really desirable.\r\nIn the end a provider specific NotFound class does not add any value.\r\n\r\nSo wouldn\'t it be easier to introduce a class \r\n\r\nFog::Errors::NotFound < Fog::Errors::Error\r\n\r\nAll providers could throw it.\r\n\r\nSo two things should be done:\r\n\r\n1. Consistently either throw or not throw NotFound errors across all providers\r\n2. If throwing NotFound errors, throw Fog::Errors::NotFound'
1846,'','Add API calls to manage flavor access across tenants\nThis commit adds the three API calls\r\n\r\n```\r\nadd_flavor_access\r\nremove_flavor_access\r\nlist_tenants_with_flavor_access\r\n```\r\n\r\nwhich allow to manage access rights of flavors in tenants.'
1845,'','Pass on filters to volume endpoint\nThis is mainly to allow admin to get volumes from all tenants. It also applies only to the cinder endpoint.'
1844,'','[rackspace|storage] Large Object Upload Support\nI updated `put_object` to allow blocks so large files can be uploaded in an efficient manner. This pull request also includes an accompanying example and documentation.\r\n\r\n'
1843,'',"Support filters in images collection\nThis commit adds support to add filters to the images collection. This makes it possible to write requests like (assuming compute is a `Fog::Compute` instance)\r\n\r\n```ruby\r\ncompute.images.all(:type => 'BASE', :status => 'SAVING')\r\n```\r\n"
1842,'','[openvz|compute] Initial commit\nThis implements an openvz provider. This is a driver similar to vmfusion & virtualbox.\r\n\r\nIt includes:\r\n-  a documentation : https://github.com/jedi4ever/fog/tree/openvz-provider/lib/fog/openvz\r\n- a basic set of tests for the lifecycle\r\n\r\nMerge at your leasure - \r\nPing @fnichol , @skottler'
1841,'','quote data in regex\nPeople can choose fancy names for vmware objects (e.g. "Datacenter V++"). Make sure that such input doesn\'t break the regex.'
1840,'',"Exception thrown when using Rails 4.0.0.rc1\nI have been using Fog (1.11.1) in a Rails 3.2.13 app for a few months. While testing a new branch of the app in Rails 4.0.0.rc1, I am receiving the following exception:\r\n\r\nExcon::Errors::Forbidden: Expected(200) <=> Actual(403 Forbidden)\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/expects.rb:6:in `response_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:355:in `response'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:249:in `request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/idempotent.rb:12:in `error_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:262:in `rescue in request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:222:in `request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/idempotent.rb:12:in `error_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:262:in `rescue in request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:222:in `request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/idempotent.rb:12:in `error_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:262:in `rescue in request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/gems/excon-0.22.1/lib/excon/connection.rb:222:in `request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/bundler/gems/fog-f6dc35bf069d/lib/fog/core/connection.rb:21:in `request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/bundler/gems/fog-f6dc35bf069d/lib/fog/aws/storage.rb:504:in `request'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/bundler/gems/fog-f6dc35bf069d/lib/fog/aws/requests/storage/get_service.rb:22:in `get_service'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/bundler/gems/fog-f6dc35bf069d/lib/fog/aws/models/storage/directories.rb:13:in `all'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/bundler/gems/fog-f6dc35bf069d/lib/fog/core/collection.rb:141:in `lazy_load'\r\n\tfrom /home/nate/.rvm/gems/ruby-2.0.0-p195/bundler/gems/fog-f6dc35bf069d/lib/fog/core/collection.rb:15:in `each'\r\n\r\n\r\nThe code that triggers the exception is here:\r\n  def find_bucket\r\n    @connection.directories.each do |bucket|\r\n      return bucket if bucket.key == @bucket_name\r\n    end\r\n  end\r\n\r\nAgain, this works in 3.2.13 but is now not working. I've searched around and I haven't found any other recent mention to this exception being thrown. Help would be appreciated. "
1838,'','Friendly exceptions for EC2 errors\nPlease take a look at https://github.com/kickstarter/build-ubuntu-ami/issues/12 where I created an issue about 400 bad requests in EC2 and the lack of error messages / friendly exceptions in fog.'
1837,'','Fixed typo\nAdded a missing \'i\' to change "Create Drectory" to "Create Directory".'
1836,'','Chdir in a block to dry up all method\nWhilst testing out Fog with the `:local` provider, I kept having a problem with FakeFS. This change fixes compatibility with it but more importantly the exception raised when multiple threads access the same block is most likely the desired behaviour. Thoughts?'
1835,'','Non-Amazon S3 Endpoints support\nLuncloud is a cloud provider with a storage API that is S3 compliant. However, their endpoints are different than the amazon ones.\r\n\r\nHow hard it would be to be able to make requests to the Lunacloud endpoints using the AWS provider class?'
1834,'','Update OpenStack Volume service with latest API specs\nUpdate OpenStack Volume service:\r\n* Update Volume models and requests\r\n* Add Volume tests\r\n* Add Volume Types models, requests and tests\r\n* Add Snapshots models, requests and tests\r\n* Add Backups models, requests and tests\r\n* Add Extensions, Limits and Hosts requests and tests\r\n* Add openstack_region to service\r\n* Change default endpoint_type to publicURL'
1833,'',"Include the ResourceRecordSetCount for AWS's DNS Service\n"
1832,'','Fog error response handling broken\nThere are some places in the fog code base where it catches Excon exceptions and then looks at the error message to branch behavior, such as here:\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/models/storage/files.rb#L72\r\n\r\nSince excon 0.22.0, these error values are not part of the exception message.  They need to be retrieved from the response object attached to the exception.'
1831,'','Fixes security group handling for spot instances launched into an EC2 VPC\nSimply one line modification to fix security groups for VPC spot instances (which must use LaunchSpecification.SecurityGroupId instead of LaunchSpecification.SecurityGroup).'
1830,'','[rackspace|lb] Add support for timeout attribute\nI needed support for this attribute. Per the API docs it is not included in individual LB responses and the "detail" listing but not the regular listing. Added it to relevant tests.\r\n\r\nThis is pretty trivial and I can merge if no one has any issues but since I haven\'t touched Fog in a while I figure it\'d be good to let someone look over it.'
1829,'','AWS S3 Put appears to hang on large file (socket contention?)\nI\'m attempting to do an upload of a 79 MB file to S3 using fog. However, when I run the script, it hangs and I have to kill it.\r\n\r\nHere\'s the script:\r\n\r\n    require \'rubygems\'\r\n    require \'fog\'\r\n\r\n    storage = Fog::Storage.new({\r\n      :aws_access_key_id => "foo",\r\n      :aws_secret_access_key => "bar",\r\n      :provider => "AWS"\r\n    })\r\n\r\n    dir = storage.directories.new(key: "bucket")\r\n    dir.files.create(\r\n      key: \'5130.tar.enc\',\r\n      body: File.read("/Users/noah/Backup/.tmp/5130.tar.enc")\r\n    )\r\n\r\n\r\nHere\'s the backtrace:\r\n\r\n    /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/excon-0.9.6/lib/excon/socket.rb:116:in `select\': Interrupt\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/excon-0.9.6/lib/excon/socket.rb:116:in `rescue in write\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/excon-0.9.6/lib/excon/socket.rb:110:in `write\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/excon-0.9.6/lib/excon/connection.rb:203:in `request_kernel\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/excon-0.9.6/lib/excon/connection.rb:86:in `request\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/fog-1.1.2/lib/fog/core/connection.rb:20:in `request\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/fog-1.1.2/lib/fog/aws/storage.rb:381:in `request\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/fog-1.1.2/lib/fog/aws/requests/storage/put_object.rb:43:in `put_object\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/fog-1.1.2/lib/fog/aws/models/storage/file.rb:119:in `save\'\r\n    from /Users/noah/.rbenv/versions/1.9.3-p286/lib/ruby/gems/1.9.1/gems/fog-1.1.2/lib/fog/core/collection.rb:50:in `create\'\r\n\r\nAs you can see the stacktrace leads back to excon. So I looked into excon a bit and saw this:\r\n\r\nhttps://github.com/geemus/excon/pull/87\r\n\r\nPerhaps coincidental, but it seems suspiciously similar to the behavior I\'m seeing, though that commit was made a year ago, merged and supposedly resolved.\r\n\r\nWas there perhaps a regression since?'
1828,'',"[openstack|image] Define get method for images\nUse common `get` method to get image information, This should fix the `reload` method that is not working right now (because there's no get method).\r\n\r\nTo not break existing clients, I defined the `get` method as an alias for `find_by_id`."
1827,'',"[AWS] adds attributes to instances, and fixes instance tests.\n[AWS] adds 'hypervisor', 'lifecycle', 'requester_id', 'source_dest_check...', 'spot_instance_request_id', 'virtualization_type' attributes to instances, also fixes instance tests to work in non-mocking mode"
1826,'','[openstack|compute] Add mock method to list_address_pools\n'
1824,'','[openstack|network] Add support for OpenStack Networking LBaaS extension\nAdd support for OpenStack Networking [Load Balancer as a Service (LBaaS)](http://docs.openstack.org/api/openstack-network/2.0/content/lbaas_ext.html) extension:\r\n* Load balancing pools\r\n* Load balancing members\r\n* Load balancing health monitors\r\n* Load balancing VIPs'
1823,'','[Rackspace|Storage] last_modified= work around\nThis pull request addresses issue #1809 where `get_container` request method returns a last_modified timestamp similar to the following `2013-05-09T22:20:59.287990`.\r\n\r\nRuby assumes this date is in the local time zone (which is the appropriate behavior according to iso 8601), however, cloud files (swift) is returning the date in UTC.\r\n\r\nhttps://github.com/openstack/swift/blob/master/swift/container/server.py#L398-L399\r\n\r\nAn initial fix was proposed in PR #1811 by @neojin. The hope is that this PR is a little more robust.'
1822,'','[joyent|compute] list_machines unnecessarily fetches tags for each machine\nIt is fetching tags for each machine even though tags are already included as part of the /my/machines response.'
1821,'',"AWS S3 Invalid signature when using response-content-disposition=attachment with filename\nHi.  To request an S3 object as an attachment with a specific name (different from the object name), you'd use\r\n\r\n    file.url(expiry, query: {'response-content-disposition' => 'attachment; filename=foo.txt'})\r\n\r\nThis worked in 1.10 but in 1.11.1 it gets a SignatureDoesNotMatch error.  \r\n\r\nThe problem is that in 1.11.1, the signature() method is CGI encoding the query parameter values into the signature string, but AWS seems to expect the signature string to match the non-encoded values.  \r\n\r\nThis pull request is a quick edit to remove the encoding from the signature string."
1820,'','Used publicURL as default endpoint type for OpenStack network\n'
1819,'','Unable to retrieve DNS entries with names starting with "pu" from route53\nI know this looks crazy, but any record that I create with a name starting with "pu" does not show up via Fog::DNS::AWS::Zone.records.\r\n\r\nTo reproduce:\r\n1. Create a DNS entry named "pu1.myzone.com" in the route53 UI.\r\n2. Run Fog::DNS::AWS::Zone.records\r\n3. Notice that the zone is not there.\r\n\r\nI originally noticed this manifesting because I was creating puppet servers and naming them "puppet.myzone.com". I narrowed it down by creating records from "puppet1.myzone.com" --> "p1.myzone.com". pu1.myzone.com did not show up, but p1.myzone.com did.'
1818,'tokengeek','[Brightbox] Updates to delete requests and doc fixes\nWe renamed our API docs to use "delete" rather than "destroy". This renames the files and methods whilst keeping "destroy" variants in place.\r\n\r\nAlso fixes many yardoc errors across the generated docs for requests.'
1817,'','Avoids Fog::Compute::Joyent::Real#decode_time_attrs raising an exception...\n... when an empty string is returned as created or updated property\r\n\r\nI tried creating a machine with fog v1.11.1 and an exception ocurred:\r\n<pre>\r\ncloud_server = fog.create_machine(:name => \'joyent-test\', :package => "Small 1GB", :dataset => "71101322-43a5-11e1-8f01-cf2a3031a7f4")\r\nArgumentError: no time information in ""\r\n\tfrom /Users/pbanos/.rvm/rubies/ruby-1.9.3-p327/lib/ruby/1.9.1/time.rb:267:in `parse\'\r\n\tfrom /Users/pbanos/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.11.1/lib/fog/joyent/compute.rb:202:in `decode_time_attrs\'\r\n\tfrom /Users/pbanos/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.11.1/lib/fog/joyent/compute.rb:171:in `json_decode\'\r\n\tfrom /Users/pbanos/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.11.1/lib/fog/joyent/compute.rb:159:in `request\'\r\n\tfrom /Users/pbanos/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.11.1/lib/fog/joyent/requests/compute/create_machine.rb:10:in `create_machine\'\r\n</pre>\r\n\r\nIt seems Joyent API may now return these fields set to an empty string instead of nil, so that Time.parse will raise the observed ArgumentError.\r\n\r\nI modified Fog::Compute::Joyent::Real#decode_time_attrs so that it does not try to parse times on empty strings\r\n'
1816,'','Added support for OpenStack region for network service\n'
1815,'','Remove warning when using a period in an S3 bucket name.\nThis removes a warning that is outputed by Fog when a S3 bucket name\r\ncontains a period. This resulted in excessive logging of a condition when\r\nusing Fog to push to a S3 bucket configured to serve a web site. See\r\nfredjean/middleman-s3_sync#10 to see the issue that triggered this commit.'
1814,'','Plan for Ruby 1.8.7 End of Life\nWith Ruby 1.8.7 coming up to being unsupported, it\'s probably time to plan for Fog to run a maintenance version that works on 1.8.7 and then allow new Fog code to drop support for 1.8.7\r\n\r\nDropping 1.8.7 support was raised before when we discussed the roadmap (https://github.com/fog/fog/issues/1250) but at the time there wasn\'t much reason to.\r\n\r\nNow that 1.8.7 is actually unsupported from June 2013 I think we should revisit our decision.\r\n\r\nThis will have knock-on stuff such as setting `required_ruby_version` in `gemspec` and ensuring our Travis settings are up to date.\r\n\r\nNot sure if we want to start taking some action on the roadmap and make this change around a "Fog 2.0" banner.\r\n\r\nPersonally I don\'t mind but I am aware Fog is carrying a lot of baggage from so many providers, keeping support for unsupported versions of Ruby adds even more work for people.\r\n\r\nThoughts?'
1813,'','Support RSpec 2.x\nHi,\r\n\r\nsince running RSpec 2.x works just fine for the test suite, I am proposing to allow both 1.x and 2.x versions for running tests. This makes it much easier to automate test runs in the environments like Fedora, where the old RSpec is long time gone.\r\n\r\nPlease accept. Thanks.'
1812,'',"[Zerigo|DNS] Remove default 3600 TTL\nZerigo records and zones were setting a TTL of 3600 on the model if no\r\nTTL was set in the response. On first glance this seems like A Good\r\nThing - yes we want a default TTL! However, it masks the fact that a\r\nrecord might have no TTL set on it and is using the default TTL from the\r\nzone. If you're trying to use the model to determine if the TTL is set\r\nto some value (say 3600), but the value defaults to 3600 if it isn't\r\nset, then you have no way of knowing if it's right or not.\r\n\r\nThis change forces you to set a TTL if you're performing an operation\r\nthat requires one (#save)."
1811,'',"Force UTC last_modified time on rackspace cloudfiles get_container\nRe: issue #1809\r\n\r\nThis is probably not the ideal fix but it will at least show the problem:\r\n\r\nFrom the Rackspace cloudfiles API, get_container returns last_modified values like this:\r\n\r\n`2013-05-09T22:20:59.287990`\r\n\r\nWhen doing a `Time.parse` on this value, it is returning the wrong value because it is adding an offset equal to your local time zone. However, the rackspace time is UTC. \r\n\r\nI 'fixed' this by force adding a 'Z' at the end of the last_modified time, which correctly parses the time as UTC."
1810,'','Fix "cache_controle" typo in docs\n'
1809,'','Rackspace cloudfiles file.last_modified different than files.last_modified\nI believe there is an issue with the Fog::Time class when converting times from rackspace cloudfiles.\r\n\r\nex)\r\n````\r\n#Using the underlying service:\r\n\r\nfog.get_object("test_container", "IELCD004U4V1_S/15 Track 15.mp3")\r\n\r\n#results in:\r\n\r\n<Excon::Response:0x007f8a4b1bd730 \r\n@data={:body=>"--removed--", \r\n@headers={"Content-Length"=>"1487139", "Accept-Ranges"=>"bytes", "Last-Modified"=>"Thu, 09 May 2013 22:20:59 GMT", "Etag"=>"0b4443434f4921840d914a1e54216996", "X-Timestamp"=>"1368138059.28799", "Content-Type"=>"audio/mpeg", "X-Trans-Id"=>"tx94ed3d4846ef4aac8a43bf29790e301f", "Date"=>"Thu, 09 May 2013 22:51:57 GMT"}, \r\n@status=200, \r\n@remote_ip="--removed--">\r\n\r\n#The last modified time is: Thu, 09 May 2013 22:20:59 GMT\r\n\r\n\r\n\r\n#Getting just the file directly using the model:\r\n\r\nfog.directories.get("test_container").files.get("IELCD004U4V1_S/15 Track 15.mp3")\r\n\r\n#results in:\r\n\r\n<Fog::Storage::Rackspace::File\r\n    key="IELCD004U4V1_S/15 Track 15.mp3",\r\n    content_length=1487139,\r\n    content_type="audio/mpeg",\r\n    content_disposition=nil,\r\n    etag="0b4443434f4921840d914a1e54216996",\r\n    last_modified=2013-05-09 15:20:59 -0700,\r\n    access_control_allow_origin=nil,\r\n    origin=nil\r\n  >\r\n\r\n#The last modified time is: 2013-05-09 15:20:59 -0700\r\n````\r\n\r\n\r\nThese two methods above produce the correct last modified time. However, using the files method does not:\r\n\r\n\r\n````\r\nf.directories.get("test_container").files.last\r\n\r\n<Fog::Storage::Rackspace::File\r\n    key="IELCD004U4V1_S/15 Track 15.mp3",\r\n    content_length=1487139,\r\n    content_type="audio/mpeg",\r\n    content_disposition=nil,\r\n    etag="0b4443434f4921840d914a1e54216996",\r\n    last_modified=2013-05-09 22:20:59 -0700,\r\n    access_control_allow_origin=nil,\r\n    origin=nil\r\n  >\r\n````\r\n\r\nThe last modified time jumps 7 hours ahead, equal to its offset.\r\n'
1808,'','Include all snapshots in Fog::AWS::RDS::Snapshots#all\nThis fixes a problem retrieving a list of all RDS snapshots - only the first page of results was returned.\r\n\r\nThe change is to iterate through all pages of results using the returned marker.\r\n\r\nThis means a call to Snapshots#all may result in many downstream API calls, but is necessary to obtain a full list.'
1807,'','[Zerigo|DNS] Support pagination on Zerigo DNS zones\nFor Zerigo accounts with more than 100 domains, the previous zones.all\r\nmethod was unable to get to records beyond 100. This adds pagination per\r\nthe Zerigo API doc with `:per_page` and `:page` parameters. You can then use\r\ncount_zones to get the total zone count, divide by your `:per_page`, and\r\niterate over all pages to fetch all your zones.\r\n\r\nhttps://www.zerigo.com/docs/apis/dns/1.1/zones/index'
1805,'','CloudStack: fails when there are no VMs in default view for user\nThe following code will fail if there are no VMs in the user\'s cloudstack default view (.first of a nil object)\r\n```ruby\r\nrequire \'rubygems\'\r\nrequire \'fog\'\r\n\r\nservice = Fog::Compute[:cloudstack]\r\nputs service.list_virtual_machines["listvirtualmachinesresponse"]["virtualmachine"].first\r\n```'
1804,'kevinykchan','joyent server resize -- server resize appears successful even if API call fails\nThis addresses an issue reported at kevinykchan/knife-joyent#39'
1803,'','Add :id attribute to libvirt nic model\nMy cutting edge version of libvirt (1.0.4 Archlinux) seems to reply with  :id for NICs, causing the nic model to break.'
1802,'',"[openstack|storage] add large object container and prefix options\nThese are the same changes that were made to `Storage::Rackspace` in b1e373520b621b4c002f30b556cb83d774600803 (#1800).\r\n\r\nI don't have an account I can run these test against, since apparently you can't use the OpenStack storage with Rackspace. So, someone do please run them :)"
1801,'','Revert "Updated gem spec to require json rather than multi_json"\nThis reverts commits: 66638b25d76a5eb737c9a41ed9b4847841549d50, 3f0314dbd1972051e0f705e8f83813e7e2305e46, and 18ce4b7eca41ea75d45564466e4d44076128981e.\r\n\r\nSince `google-api-client` was added as a dependency in afa9b025e9a1c474882f9e6a7a7285debddb4d7e, `multi_json` is a de facto dependency of `fog`, so this is a needless layer. If #1034 is still an issue, I\'d be happy to ship a version of `multi_json` that requires `rubygems >= 1.3.5`.'
1800,'','[rackspace|storage] add large object container and prefix options\nWhen storing an OpenStack Large Object, the object is split into segments which share the same\r\nprefix and are suffixed such that they will sort in the order they should be concatenated back\r\ntogether. `#put_object` is used to upload each segment, then `#put_object_manifest` is used to store\r\na manifest object with a `X-Object-Manifest` header that contains the prefix used for the segments.\r\n\r\n`#put_object_manifest(container, object)` stores the manifest as `container/object` and uses this\r\nsame name for `X-Object-Manifest`. There is no way to specify a separate segment prefix.\r\n\r\nBeing able to use a name for the manifest object that\'s different from the prefix used by the\r\nsegments would make the manifest file easier to identify within the container. Also, while all\r\nsegments must be in the same container, the manifest file may be in a different container.\r\n\r\nBeing the same as the segments\' prefix also creates a problem when you want to use the `Etag`\r\nreturned by a `#head_object` for the manifest object. This `Etag` is a MD5 hexdigest of the\r\nconcatenated `Etag`s for all the segments for the manifest.\r\n\r\n```rb\r\netags = []\r\nprefix = File.basename(large_file)\r\nFile.open(large_file, \'r\') do |file|\r\n  while data = file.read(chunk_size)\r\n    etags << Digest::MD5.hexdigest(data)\r\n    suffix = etags.size.to_s.rjust(5, \'0\')\r\n    connection.put_object(container, "#{ prefix }-#{ suffix }", data, { \'Etag\' => etags.last })\r\n  end\r\n  connection.put_object_manifest(container, prefix)\r\nend\r\n\r\n# etags => ["82d82ca1dbf1deb04f433fc213a57638", "0b7af2259525d8101f313fa6244ef97b"]\r\nexpected = Digest::MD5.hexdigest(etags.join) # => "7447e423f30e20a83ccb0882b90e1405"\r\n\r\n# I don\'t know why this is returned with quotes, but it is.\r\nactual = connection.head_object(container, prefix).headers[\'Etag\'].gsub(\'"\',\'\')\r\n```\r\n\r\nYou would expect `actual` to equal `expected`.\r\nHowever, `actual` here is `f74ae5c6ab8115a9ed993c963dc67531`.\r\n\r\nSince the manifest object\'s path is the same as the prefix for the segments, OpenStack sees the\r\nmanifest object as the first segment. So to compute the correct `expected` value, you must prepend\r\nthe manifest object\'s `Etag`:\r\n\r\n```rb\r\netags.unshift "d41d8cd98f00b204e9800998ecf8427e" # => Digest::MD5.hexdigest(\'\')\r\nexpected = Digest::MD5.hexdigest(etags.join) # => "f74ae5c6ab8115a9ed993c963dc67531"\r\n```\r\n\r\nThis pull request gives you the option to create a manifest object with a name that will not match\r\nthe segments\' prefix and avoid this work-around.\r\n\r\n```rb\r\nconnection.put_object_manifest(container, \'large_object\', \'segments_prefix\' => \'large_object-\')\r\n```\r\n\r\nYou may also create the manifest file in a separate container, in which case it doesn\'t matter if\r\nthe manifest name and the segments\' prefix is the same or not.\r\n\r\n```rb\r\nconnection.put_object_manifest(\'container_a\', \'large_object\', \'segments_container\' => \'container_b\')\r\n```\r\n'
1799,'','[vSphere] fixed bug that datastores in subfolders would not be found.\nWith the current vSphere implementations datastores located in subfolders would not be found. The pullrequest should fix the problem.'
1798,'','AWS Cloudformation list_stacks and list_stack_resources API support\nAdding support for list_stacks and list_stack_resources. Amazon documentation below:\r\n\r\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_ListStacks.html\r\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_ListStackResources.html'
1797,'','Load google/api_client late to avoid dep.\n    Updates the google/compute.rb module so that it requires the\r\n    \'google/api_client\' dependency late. This avoids having to\r\n    require (and install) proprietary google client API code\r\n    to use Fog for other providers. (previously, even when using\r\n    AWS I\'d still have to install google-client-api)\r\n    \r\n    ---\r\n    \r\n    I understand code reuse is important but I think the fact that\r\n    we recently added google-api-client as a top level dependency\r\n    sets a bad precedent and perhaps highlights the need to move further\r\n    towards "fog modules" for each provider to avoid these types of\r\n    situations.'
1796,'',"Cloudformation cfn-list-stacks & cfn-list-stack-resources\nIt doesn't appear as though Fog does not supports cfn-list-stacks & cfn-list-stack-resources API calls. e.g.\r\n\r\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/list-stacks.html\r\n\r\nI'm happy to add the support, but thought I'd check first if this was already WIP.\r\n"
1795,'','OS: Fix revert_resize_server method name.\nFixes an issue where calling revert_resize on the OpenStack Server\r\nobject would fail with a method name error.\r\n\r\n----\r\n\r\nUpdates the revert_resize_server request methods to match the filename.\r\nThis also makes it match the method name we call in the\r\ncompute/server.rb module (revert_resize_server instead of\r\nrevert_resized_server).\r\n\r\nAdds a test case which should guard against the above issue.'
1793,'tokengeek','[Brightbox] Updates image selector for name format\nBrightbox is now moving to using the default Ubuntu Cloud Images\r\n(http://cloud-images.ubuntu.com/) where we are also using the naming\r\nconvention used there.\r\n\r\nSo the image selector has been updated to select the latest version of\r\nUbuntu (i386, official Brightbox) image if no image is specified with\r\nthe new format.'
1792,'tokengeek','[Brightbox] Updates image selector for name format\nBrightbox is now moving to using the default Ubuntu Cloud Images\r\n(http://cloud-images.ubuntu.com/) where we are also using the naming\r\nconvention used there.\r\n\r\nSo the image selector has been updated to select the latest version of\r\nUbuntu (i386, official Brightbox) image if no image is specified with\r\nthe new format.'
1790,'','Added missing attribute in floating_ip model\n'
1789,'','issue #1275 remove specs & converted YARD format\n'
1788,'','Fix typo in method name for DynamoDB::Mock#setup_credentials\nThis was mistyped as "setup_credientials"'
1787,'','[aws|glacier] Host header requires port for signaturev4\nAccording to the 403 `InvalidSignatureException` error message returned from AWS, the host header in the hashed canonical request must include the port. \r\n\r\n```diff\r\ndiff --git a/lib/fog/aws/glacier.rb b/lib/fog/aws/glacier.rb\r\nindex f28712d..f9c3e30 100644\r\n--- a/lib/fog/aws/glacier.rb\r\n+++ b/lib/fog/aws/glacier.rb\r\n@@ -155,7 +155,7 @@ module Fog\r\n           params[:headers][\'Date\'] = date.to_date_header\r\n           params[:headers][\'x-amz-date\'] = date.to_iso8601_basic\r\n \r\n-          params[:headers][\'Host\'] = @host\r\n+          params[:headers][\'Host\'] = "#{@host}:#{@port}"\r\n           params[:headers][\'x-amz-glacier-version\'] = @version\r\n           params[:headers][\'x-amz-security-token\'] = @aws_session_token if @aws_session_token\r\n           params[:headers][\'Authorization\'] = @signer.sign params, date\r\n```\r\n\r\nWith this patch I was able to successfully upload.'
1786,'','Gaurd error of parsing non-JSON response\n'
1785,'','Support authenticating with DNSimple using an API token\nCurrently Fog requires an email and a password to authenticate with DNSimple. However, the [DNSimple API](http://developer.dnsimple.com/domains/) allows authentication using the `X-DNSimple-Token: <email>:<token>` header, where token is a random 20 character alpha-numeric string.'
1784,'','Add real option parsing to the fog util\n`fog` should respond to `--help`, `--version`, `--fogrc` and other useful options.'
1783,'',"[aws|dns] Excon::Errors::SocketError: SSL_write:: bad write retry (OpenSSL::SSL::SSLError)\nHi,\r\nI get `Excon::Errors::SocketError: SSL_write:: bad write retry (OpenSSL::SSL::SSLError)` when trying to access my AWS dns zones.\r\nAny idea what might cause this?\r\n\r\nProblem is, I can't reproduce it well. I get the error during chef runs, where I call fog from within a cookbook.\r\nHowever, if I execute the same code in irb, everything works perfectly fine.\r\n\r\nThe offending code snippet is [here](https://github.com/promisedlandt/cookbook-amazon_dns/blob/master/providers/zone.rb#L9), the connection is defined [here](https://github.com/promisedlandt/cookbook-amazon_dns/blob/master/libraries/amazon_dns.rb#L11).\r\n\r\nFull stack trace [here](https://gist.github.com/promisedlandt/5479340).\r\n\r\nI'm guessing there's some timing problems involved, like the connection being opened and timing out, but usually when you try to execute anything on a stale connection, you get EOFError, so I'm stumped.\r\n\r\nFurther information:\r\nruby 1.9.3p286\r\nfog 1.10.1\r\nexcon 0.20.1\r\n\r\nHappens on Ubuntu 12.04, 13.04, Debian 6.0.5, 6.0.6\r\n"
1782,'','Added support for OpenStack region for network\n'
1781,'',"add life_cycle attribute (instanceLifecycle) to EC2 instance\nadd life_cycle attribute (instanceLifecycle), useful to figure\r\nout if an EC2 instance is a 'normal' or 'spot' instance."
1780,'',"Fix bluebox's Server#public_ip_address\nThis should be returning a String not a Hash."
1779,'','[aws|iam| user: add created_at attribute\n'
1778,'','Getting The following keys are invalid: :url message\nI am using fog 1.6.0 and using following:\r\nstorage = Fog::Storage.new( :provider => \'AWS\',\r\n                                  :aws_access_key_id => access_key,\r\n                                  :aws_secret_access_key => secret key)\r\n storage.directories is returning "The following keys are invalid: :url".I was getting correct result tomorrow,but it is not working today.\r\n\r\nDid you make any change in this version?Please provide your solution for it.'
1777,'',"Rackspace DNS record creation throws Fog::Rackspace::Errors::BadRequest error.\nI could be missing something obvious here but creating a DNS record w/ Rackspace seems to always throws a Fog::Rackspace::Errors::BadRequest error.  Here's an example:\r\n\r\n```ruby\r\n@dns = Fog::DNS.new(:provider => 'rackspace', :rackspace_api_key => '...', :rackspace_username => '...')\r\nzone = @dns.zones.create(:email => 'test@example.com', :domain => 'my-test-domain.com')\r\nrecord = zone.records.create(:name => 'foo', :value => '4.2.2.1', :type => 'A', :ttl => 3600)\r\n```\r\n\r\nI've played with different optional params for the record, and also tried adding :rackspace_auth_url to the DNS constructor params but it always errors out on the record creation.  Here's the backtrace:\r\n\r\n```\r\nFog::Rackspace::Errors::BadRequest: [HTTP 400] Fog::Rackspace::Errors::BadRequest\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/excon-0.20.1/lib/excon/middlewares/expects.rb:10:in `response_call'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/excon-0.20.1/lib/excon/connection.rb:332:in `response'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/excon-0.20.1/lib/excon/connection.rb:226:in `request'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/fog-1.10.1/lib/fog/core/connection.rb:21:in `request'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/fog-1.10.1/lib/fog/rackspace/dns.rb:113:in `request'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/fog-1.10.1/lib/fog/rackspace/requests/dns/add_records.rb:32:in `add_records'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/fog-1.10.1/lib/fog/rackspace/models/dns/record.rb:62:in `create'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/fog-1.10.1/lib/fog/rackspace/models/dns/record.rb:39:in `save'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/fog-1.10.1/lib/fog/core/collection.rb:52:in `create'\r\n\tfrom (irb):103\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/railties-3.2.12/lib/rails/commands/console.rb:47:in `start'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/railties-3.2.12/lib/rails/commands/console.rb:8:in `start'\r\n\tfrom /Users/brian/.rvm/gems/ruby-1.9.3-p0@rails-3.2.12/gems/railties-3.2.12/lib/rails/commands.rb:41:in `<top (required)>'\r\n\tfrom script/rails:6:in `require'\r\n\tfrom script/rails:6:in `<main>'\r\n```\r\n\r\nAny help or guidance would be greatly appreciated.  If I can isolate what is throwing the error I can make a pull request for the fix."
1776,'','S3 Content Disposition header\nI switched from aws-sdk to fog just yesterday and it works great. Now I\'m trying to generate a temporary URL for a file on Amazon S3 that has the "Content-Disposition" header set to "attachment", such that the client\'s browser downloads the file and does not try to open it directly in the browser.\r\n\r\nWith aws-sdk it worked like this:\r\n\r\n    aws_obj = bucket.objects["somefile"]\r\n    aws_obj.url_for :read, expires: 60, response_content_disposition: "attachment"\r\n\r\nHow can I accomplish the same task using fog? I tried it like this, but the header is not set properly:\r\n\r\n    file = directory.files.head("somefile")\r\n    file.url(60.seconds.from_now, response_content_disposition: "attachment")'
1775,'',"[vSphere] Refactor and extend network interface methods (similar to the ovirt Implementation)\nThis is the changes discussed with Ohad the other day.\r\nThe extend the functionality of vSphere to add/destroy/update the interfaces.\r\nAlso a better way to retrieve interfaces was added (interfaces.get).\r\n\r\nChanges:\r\n* added methods to add, remove and update interfaces for vSphere\r\n* added missing method to retrieve the interface\r\n* added existing attribute key to interface (required for modifying, deleting interfaces)\r\n* alias interface's mac to id\r\n"
1774,'','Fix non-circular-require warnings\nThis fixes miscellaneous warnings in fog including unused variables,\r\nindentation mismatch and one warning for a duplicated attr_reader.'
1772,'','[Vsphere] Assign service to clone_result before new instance of vm\nThe previous code had the following error when cloning a vm on Vsphere:\r\n\r\n```\r\n~/fog-1.10.1/lib/fog/vsphere/models/compute/server.rb:122:in `clone\': undefin\r\ned method `service=\' for #<Fog::Compute::Vsphere::Server> (NoMethodError)\r\n```\r\n\r\nI fixed it by assigning the service before creating the new instance of "new_vm".\r\n\r\nCan anyone review it? Thanks!'
1771,'','[cloudstack] add disk offering model\n'
1770,'','[vsphere] Use find_raw_datacenter instead of get_raw_datacenter\nfind_raw_datacenter uses the cache of datacenters in list_datacenters, speeding it up. Calls get_raw_datacenter if not cached'
1769,'','[vsphere] Use Fog.mock? as the other providers\nSpecs can set Fog.mock! without setting the env var'
1768,'','[cloudstack] fix snapshot tests\n'
1767,'','[rackspace] removing duplicate line caused by bad merge\n'
1766,'','[rackspace|compute_v2] Fixed issue adding networks to new servers\nThis pull request is an attempt to address adding networks to servers during creation.\r\n\r\nBoth pull request https://github.com/fog/fog/pull/1761 and pull request https://github.com/fog/fog/pull/1578 have attempted to fix this by the adding  a `networks` attribute. @bradgignac has suggested against this approach because the attribute would only be used during the creation process and it would always return `nil` if user would call `server.networks`.\r\n\r\n This pull request takes the approach of accessing networks using the `attributes` hash as mentioned in https://github.com/fog/fog/pull/1578.'
1765,'','[Internet archive] fix head request bug\nI made a mistake cleaning up the head request; it does not need to send any kind of query for IA.'
1764,'','[VSphere] Removed hard coded dependency to the Datacenters root path. \nRemoved hard coded dependency to the Datacenters root path. It should now even work with other localizations.'
1763,'','[VSphere] Added VMware customvalue and customfields to read the annotatitions for each VM\nThis Patch adds the functionality to the VSphere implementation to query for the annotations given for each virtual machine.'
1761,'','Rackspace Provide networks attribute to allow create via collection to enable networks\nThis allows for usage like:\r\n\r\n```ruby\r\nserver = connection.servers.create(\r\n  :name => _name,\r\n  :image_id => _image_id,\r\n  :flavor_id => _flavor_id,\r\n  :metadata => _metadata,\r\n  :networks => _networks\r\n)\r\n```'
1760,'',"[Rackspace] Not Found Exceptions\nThis pull request is an effort to address issue #1739 where some users are finding that the new auth 2.0 implementation defaults them to the dfw region whereas the previous auth 1.0 defaulted some users to the ord region. This pull request updates the NotFound exception to include the region to make it easier to spot the problem.\r\n\r\nIn implementing this, I found out that the Rackspace provider was inconsistently namespacing NotFound exceptions. Some were using Fog::Rackspace::Errors::NotFound other were using Fog::Rackspace::Service::NotFound and still others were using Fog::Service::Rackspace::NotFound.\r\n\r\nBased on my conversation with @geemus, I decided to redo all NotFound exceptions to use Fog::Service::Rackspace::NotFound. I couldn't find anyway to make this backwards compatible with the NotFound exception being created when each service inherits from Fog::Service.\r\n\r\nLet me know if this is going to pose a big issue and I will re-implement this.\r\n\r\nException discussion:\r\nhttps://groups.google.com/forum/?fromgroups=#!topic/ruby-fog/NKbZwEijf9w\r\n\r\nNotFound class is created when Fog::Core is inherited:\r\nhttps://github.com/fog/fog/blob/master/lib/fog/core/service.rb#L39"
1759,'','[cloudstack] fix image password_enabled field alias\n'
1758,'','Wait for volume to be available before attaching\nWe ran into a case in one of our AWS availability zones where new volumes are not ready to be attached for a few seconds after creation.  Attempting to attach the volumes while they are in "creating" state fails.'
1757,'','Changes the path only if subdomain is not @host\nsee https://github.com/fog/fog/issues/1631#issuecomment-16396992'
1756,'',"Please add #original_filename\nI tried to use fog today, but got this error:\r\n```\r\nNoMethodError: undefined method `original_filename' for #<CarrierWave::Storage::Fog::File:0xab4134c>\r\n```\r\n\r\nAfter looking around a bit, I'm not the only one with this problem (https://github.com/gzigzigzeo/carrierwave-meta/issues/4).\r\n\r\nWould you please add a original_filename method?  possibly like the one described in the link above:\r\n```\r\ndef original_filename\r\n  ::File.basename(path)\r\nend\r\n```\r\nby @clemens"
1755,'','[vsphere|compute] Add support for Annotations\n'
1754,'','[cloudstack] servers collection, add attributes to :all method\ntiny improvement'
1753,'','[Rackspace | ComputeV2] Add calls to enter and exit rescue mode\nSmall patch to implement the call to enter rescue mode for Rackspace Compute V2 servers.'
1752,'','[openstack|volume] Added quota requests for Cinder\nWhen using Cinder, updating quotas related to volumes are now done through Cinder and not Nova. Updating volumes and gigabytes quotas through nova would result in this error:\r\n\r\n{"badRequest": {"message": "Bad key(s) gigabytes,volumes in quota_set", "code": 400}}'
1751,'',"[cloudstack] compute login, authentication adapter\nRight now we have hardcoded `'password' => Digest::MD5.hexdigest(password)` https://github.com/fog/fog/blob/master/lib/fog/cloudstack/compute.rb#L161 md5 for password. It works for default md5 adapter, but cloud settings can be changed..\r\n\r\nBTW ,In a short time cloudstack default adapter will be changed to SHA256Salt https://reviews.apache.org/r/10039/diff/\r\n\r\nWe should create own auth adapters and add adapter option."
1750,'','[cloudstack] Add list os types and list disk offerings mocks\n'
1749,'','[openstack|metering] Added metering service for Ceilometer\n'
1748,'','Fog::Model#wait_for: eliminate inner retry loop\nAWS frequently takes more than 3 seconds for an instance to appear.\r\nRather than having the overlapping timeouts for reload and\r\ninstance_eval, simply make them both occur with the same timeout.\r\n\r\n + Prevents spurious failures when waiting for AMI\r\n + Easier to follow flow\r\n\r\nRefs https://github.com/fog/fog/issues/1692'
1747,'','[Vsphere] delete VMs of which config is NULL\nWhen VMs is in creation or destroy, the config field of VM is nil. So they need to be filtered out as well.'
1745,'',"@in_common_prefixes not initialized\nRunning multiple threads under jruby, I am seeing this warning a lot:\r\n\r\n/home/deploy/jruby-1.7.3/lib/ruby/gems/shared/bundler/gems/fog-017ce23a256b/lib/fog/aws/parsers/storage/get_bucket.rb:46 warning: instance variable @in_common_prefixes not initialized\r\n\r\nI will investigate further when I have more time, but for now I'm reporting it as a reminder."
1744,'','Added pointers to provider specific documentation to README.md\nI added a note to the README.md pointing the the provider specific resources on fog.io so this information would be easier to find.'
1743,'',"[AWS|storage] access cleanup\nA couple of patches for AWS's storage. Mainly, S3 bucket names with dots don't work really well with SSL because the certificates only cover of DNS level.\r\n\r\nIt's still a bit early to merge. I had essentially the same on an older branch and just rebased today. I'm going to test it a bit more but thought I might already start the conversation."
1742,'','[vsphere|compute] fix incorrect filters.merge in networks model\nwhen requesting a list of networks options { :datacenter } was being ignored due to filters{} being merged in the wrong direction.\r\n\r\n@jeffmccune thanks for your help with these.\r\n'
1740,'',"[vsphere|compute] cleanup merge conflicts with clone method\n@mingjin's PR and my PR clashed and we ended up with `virtual_machine_config_spec` being set twice.\r\n@jeffmccune  this just cleans it up.\r\n\r\nI missed his waiting PR before sending my own. I will try better to not duplicate effort next time.\r\n"
1739,'',"Fog::Storage::Rackspace::NotFound on 1.10.1\nI can't upload to Rackspace after upgrading to version 1.10.1.\r\n\r\nEverything works fine on 1.10.0"
1738,'','Fix CHANGELOG fog version for digitalocean, xenserver and openstack\nJumped the gun too fast yesterday and used Fog version 1.11.0 instead of 1.10.1'
1736,'','S3 Read with Progress Callback Fails\nI am trying to download a large (>500mb) file from s3 with fog. I would like to check on progress, but the callback block function doesn\'t seem to work.\r\n\r\nI\'m using:\r\n\r\n```\r\nconnction = Fog::Storage.new(\r\n  provider: \'AWS\',\r\n  aws_access_key_id: key_id,\r\n  aws_secret_access_key: secret_key,\r\n  region: \'eu-west-1\',\r\n)\r\n\r\nconnection.get_object(bucket, obj_key) do |chunk, remaining, total|\r\n  p "Writing file: #{remaining} / #{total} remaining"\r\nend\r\n```\r\n\r\nAnd it seems to do the entire process multiple times, almost downloading all the data but when there\'s one megabyte left, it starts downloading all over again.\r\n\r\nAfter roughly 4 loops it raises the error:\r\n\r\n```\r\nnegative argument (ArgumentError) (Excon::Errors::SocketError)\r\n\tfrom script/pull-db.rb:186:in `block (2 levels) in <main>\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/excon-0.16.10/lib/excon/response.rb:49:in `call\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/excon-0.16.10/lib/excon/response.rb:49:in `parse\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/excon-0.16.10/lib/excon/connection.rb:275:in `request_kernel\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/excon-0.16.10/lib/excon/connection.rb:103:in `request\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/core/connection.rb:21:in `request\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/aws/storage.rb:401:in `request\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/aws/requests/storage/get_object.rb:58:in `get_object\'\r\n\tfrom script/pull-db.rb:183:in `block in <main>\'\r\n\tfrom /Users/peh10/.rbenv/versions/1.9.3-p374/lib/ruby/1.9.1/tempfile.rb:320:in `open\'\r\n\tfrom script/pull-db.rb:182:in `<main>\'\r\n```\r\n\r\n`connection.get_object(bucket, obj_key)` seems to work fine on it\'s own, it just breaks when the block is added.'
1735,'','[openstack|network] added network/subnet/router related example\nRelated to #1603'
1734,'','ChangeLogs Update\n* Added some missing ChangeLogs for Dreamhost, OpenStack and DigitalOcean\r\n* Updated XenServer ChangeLog'
1733,'','Build Rackspace Provider on Openstack\nAll Rackspace services that are built on top of OpenStack should also be built on the Fog OpenStack provider. This has been brought up and dropped several times in the past. However, I believe we have buy in from all of the major Rackspace contributors and @dprince. This issue can serve as an idea board for how to move toward that goal.\r\n\r\n/cc @dprince @brianhartsock @krames '
1732,'',"[vsphere] allow setting ram and num of cpu when cloning\nbuilds a `virtual_machine_config_spec` with memoryMB + numCPUs when cloning if they are passed in as options.\r\n\r\neg:\r\n\r\n``` ruby\r\n#!/usr/bin/env ruby\r\n\r\nrequire 'fog'\r\nrequire 'pp'\r\n\r\nconnection = Fog::Compute[:vsphere]\r\n\r\noptions = { \r\n  'datacenter'          => 'syd07',\r\n  'dest_folder'         => 'foo',\r\n  'template_path'       => 'templates/ubuntu-precise-amd64',\r\n  'name'                => 'bar-web-11',\r\n  'resource_pool'       => ['cluster1','resource pool 2'],\r\n  'memoryMB'            => '8192',\r\n  'numCPUs'             => 4,\r\n  'power_on'            => true,\r\n  'wait'                => true\r\n}\r\n\r\nnew_vm=connection.vm_clone(req_options)\r\npp new_vm\r\n\r\n```"
1731,'','Excon::Errors::SocketError: Broken pipe (Errno::EPIPE) - while uploading more than 1MB file\nwhile uploading more than 1MB file. Even same error after gave region value.\r\n\r\nplz suggest upload large file to S3\r\n\r\ngem details \r\n excon-0.20.1\r\n formatador-0.2.4\r\n net-ssh-2.6.6\r\n net-scp-1.1.0\r\n nokogiri-1.5.9\r\nruby-hmac-0.4.0\r\n fog-1.10.0\r\n\r\nHere code\r\n\r\n> connection = Fog::Storage.new({:provider => \'AWS\', :aws_access_key_id => \'my key \', :aws_secret_access_key =>\'my key\'})\r\n> directory = connection.directories.get(\'git-44\')\r\n> a=directory.files.create(:key =>"288.pdf",:body =>File.open(\'/Users/hide/Downloads/Folx/rails_testing.pdf\'),:public => true)\r\n\r\n Excon::Errors::SocketError: Broken pipe (Errno::EPIPE)\r\n  \tfrom /usr/local/rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/openssl/buffering.rb:375:in `syswrite_nonblock\'\r\n\tfrom /usr/local/rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/openssl/buffering.rb:375:in `write_nonblock\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/socket.rb:156:in `write\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/ssl_socket.rb:82:in `write\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:167:in `request_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/mock.rb:79:in `request_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/instrumentor.rb:22:in `request_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:223:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:239:in `rescue in request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:200:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:239:in `rescue in request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:200:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/idempotent.rb:12:in `error_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/middlewares/base.rb:10:in `error_call\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:239:in `rescue in request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/excon-0.20.1/lib/excon/connection.rb:200:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/fog-1.10.0/lib/fog/core/connection.rb:21:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/fog-1.10.0/lib/fog/aws/storage.rb:401:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/fog-1.10.0/lib/fog/aws/requests/storage/put_object.rb:40:in `put_object\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/fog-1.10.0/lib/fog/aws/models/storage/file.rb:212:in `save\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p194/gems/fog-1.10.0/lib/fog/core/collection.rb:52:in `create\'\r\n'
1730,'','[Core] Updated Fog::JSON to use JSON gem by default\nThis revisits pull request https://github.com/fog/fog/pull/1034.\r\n\r\nI have updated all references from MultiJson to Fog::JSON. Fog::JSON will attempt to use MultiJson by default and fall back to JSON if necessary. (As suggested by @geemus in  https://github.com/fog/fog/pull/1034)\r\n\r\nIn order to do this, I had to update the gemspec to require JSON rather than MultiJSON. I also added MultiJSON to the gemfile to aid with development.'
1729,'','[openstack|storage] Added storage example to set the account quota\nSee also #1632'
1728,'',"[digitalocean] Check to see if digitalocean_api_key exists before running exit code\nWhen running a tests without mocking I get the following exception:\r\n\r\n/Users/kyle.rames/Projects/fog/lib/fog/core/service.rb:208:in `validate_options': Missing required arguments: digitalocean_api_key, digitalocean_client_id (ArgumentError)\r\n\tfrom /Users/kyle.rames/Projects/fog/lib/fog/core/service.rb:58:in `new'\r\n\tfrom /Users/kyle.rames/Projects/fog/lib/fog/compute.rb:44:in `new'\r\n\tfrom /Users/kyle.rames/Projects/fog/lib/fog/compute.rb:5:in `[]'\r\n\tfrom tests/digitalocean/helper.rb:4:in `service'\r\n\tfrom tests/digitalocean/helper.rb:36:in `block in <top (required)>'\r\n\r\nThis pull request checks to see if we are mocking and if a digitalocean_api_key before attempting to delete servers."
1727,'','[AWS]412 Precondition Failed\nuse fog to connect Eucalyptus,i have two interface errors:412 Precondition Failed\r\n\r\nAWS.security_groups.get("default")\r\nAWS.volumes.get(\'vol-BF803A6A\')\r\n\r\n412 Precondition Failed</Code><Message>Failed to bind the following fields:\\nFilter.1.Name = group-name\\nFilter.1.Value.1 = test\\n</Message></Error></Errors><RequestID>Failed to bind the following fields:\\nFilter.1.Name = group-name\\nFilter.1.Value.1 = test\\n</RequestID></Response>", :headers=>{"Content-Type"=>"text/plain; charset=UTF-8"}, :status=>412, :remote_ip=>"110.68.19.0"}, @body="<?xml version=\\"1.0\\"?><Response><Errors><Error><Code>412 Precondition Failed => Failed to bind the following fields:\\nFilter.1.Name = group-name\\nFilter.1.Value.1 = test\\n\r\n\r\n\r\nhelp me,thx very much.'
1726,'',"restore ability to load fog from source without bundler\nfrom discussion on e5c438a20661d7d71b5e583edf7cbadabab6d43b (@krames @geemus)\r\n\r\nThis should restore the ability to load fog from source without bundler. It does not add support for requiring individual fog providers by source without bundler, since that would require adding this load path hack to each provider's file. Let me know if I should do that?\r\n"
1725,'','Fix S3 directory location infinite loop\nFixes #1722'
1724,'','[aws] Handle the "phantom" security group that exists for elbs\nAws creates a security group for elbs outside the scope of managable security groups.  Added Mock support for that'
1723,'',"[VSphere] Improve performance of Fetching all VMs\n``` ruby\r\n#before\r\nBenchmark.realtime{ Fog::Compute[:vsphere].servers(datacenter: 'supernap').all} # => 118.993048\r\n\r\n#after (so far)\r\nBenchmark.realtime{ Fog::Compute[:vsphere].servers(datacenter: 'supernap').all} # => 83.332368\r\n```\r\n\r\nAchieved by requesting all properties  for the entier VM view"
1722,'','Setting S3 directory location results in infinite loop\nThis happens because location= is defined and calls merge_attributes, which calls location= again.\r\n\r\nThis is an easy fix, and I\'ve done it here:\r\nhttps://github.com/promisedlandt/fog/blob/s3locationfix/lib/fog/aws/models/storage/directory.rb#L46\r\n\r\nSadly, since my other pull request is open and I did everything in master, not a branch, I can\'t easily submit a pull request for this issue.\r\n\r\n````\r\n>> dir = connection.directories.new :key => "#{ Time.now.to_i }.example.com"\r\n  <Fog::Storage::AWS::Directory\r\n    key="1364620135.example.com",\r\n    creation_date=nil\r\n  >\r\n>> dir.location = "eu-west-1"\r\nSystemStackError: stack level too deep\r\n        from /usr/local/rvm/rubies/ruby-1.9.3-p194/lib/ruby/1.9.1/irb/workspace.rb:80\r\nMaybe IRB bug!\r\n````'
1721,'','AWS VPC Network ACL Support\nFeature Request: CreateNetworkAcl, CreateNetworkAclEntry, DeleteNetworkAcl, DeleteNetworkAclEntry, DescribeNetworkAcls, ReplaceNetworkAclAssociation, ReplaceNetworkAclEntry in AWS Compute'
1720,'','AWS VPC Route Table Support\nFeature request: CreateRouteTable, DeleteRouteTable, DescribeRouteTable in AWS Compute'
1719,'','SECURITY PROBLEM: Need to change excon dependency to version 0.20.0 or later in published gem on rubygems.org\nPlease change the current excon dependency to version 0.20.0 or later in the published gem on rubygems.org. There is a pretty serious security problem that needs to be addressed. I see the latest code has been updated. Looks like it just needs to be published to rubygems.org.\r\n\r\nExcon versions prior to 0.20.0 have a security problem that allowed passwords to be shown in plain text in exceptions raised from excon.\r\n\r\nIt appears that the current version of fog on rubygems.org is depending on excon version 0.14.\r\n\r\nA fix for this on rubygems would be greatly appreciated.\r\n\r\nJon Marinello\r\nhttp://www.rightscale.com/'
1718,'','[Rackspace] Revising Getting Started Documents\nI added a bootstrap and ssh section to the compute document and revised the getting started page.'
1717,'','[rackspace] updated examples to use Chicago data center\nUpdated examples to use Chicago data center; updated error message to indicate we were using the Chicago data center.\r\n'
1716,'',"Require individual providers\nfrom discussion in #1695\r\n\r\nThis clarifies the loading plan for Fog in a way that makes it obvious that each provider should be independent. I can't think of a way to strictly enforce it, but I've verified that each provider requires cleanly by itself and fixed a couple that weren't properly using ```require fog/core```.\r\n\r\nMost providers could already be required separately, and the included ```benchs/load_times.rb``` shows the benefit:\r\n```\r\n$ git checkout require_individual_providers\r\n$ ruby benchs/load_times.rb \r\nrequire fog:\r\n0.6303\r\n\r\nrequire fog/aws:\r\n0.4830\r\n```\r\n\r\nfor sanity:\r\n```\r\n$ git checkout master\r\n$ git checkout benchs/load_times.rb -- require_individual_providers\r\n$ ruby benchs/load_times.rb \r\nrequire fog:\r\n0.6233\r\n\r\nrequire fog/aws:\r\n0.4827\r\n```"
1715,'','[cloudstack] add update methods for collections\nadded `update` method for server, `update_template` request, `update` method for image'
1714,'','Retrieving files from cloud store with atmos\nI had an issue to get around where files upload to a ninefold cloud store using fog. The file name contained square brackets. What I found was when the path was passed to fog the URI was not able to be built to retrieve the file.\r\n\r\nMy work around was to add the following to lib/fog/atmos/models/storage/file.rb\r\n\r\nsafe_key = key.gsub(/[\\[]/,\'%5B\').gsub(/[\\]]/,\'%5D\')\r\n\r\nThen\r\n\r\nuri = URI::HTTPS.build(:scheme => Fog::Storage::Ninefold::STORAGE_SCHEME, :host => Fog::Storage::Ninefold::STORAGE_HOST, :port => Fog::Storage::Ninefold::STORAGE_PORT.to_i, :path => "/rest/namespace/#{directory.key}#{safe_key}" )\r\n\r\nA bit hacky but fixed my immediate issue. Thought it might be worth taking a look.'
1713,'',"hidden requires and thread safety\nOne of the patterns Fog uses to avoid loading unused code is a network of hidden requires inside methods. As an example: a service's collections, models, and requests are not required until the service is instantiated for the first time (```setup_requirements```).\r\n\r\nMy understanding is that this can cause problems in multi-threaded environments as well as add some performance overhead in forking environments like Resque.\r\n\r\nOnce Fog supports the ability to load only a few specific providers and services (#1695), then many of these hidden requires may be unnecessary optimizations and can be removed.\r\n\r\nI'm willing to tackle some of the work in a pull request if this is the right direction for Fog to go."
1712,'',"Separable requires\nfrom discussion in #1695\r\n\r\nThe goal of this pull request is to allow a developer to require all of fog, a single provider, or a single service from a single provider.\r\n\r\nSo far I've only refactored AWS for proof of concept."
1711,'rubiojr','Added service_catalog method to OpenStack::Identity\nThe serviceCatalog hash is returned during authentication.  This holds important information on service endpoints and available regions and it is useful to be able to view all information.'
1710,'','Updated DescribeReservedInstancesOfferings to take in filters as request parameters\nAWS API changes to this action appear to no longer support the indexed filters'
1709,'',"DNS - Getting a record from a route53 zone with thousands of records\nI am trying to use fog to work with Amazon Route-53.  I have run into a situation where my zone has 1000's of records and I am trying to get hold of a record from that zone. \r\n\r\n$record = $zone.records.find{|r| r.name == @record_name }  returns when the @record_name starts with 'a' but when I use a record_name starts with 'b' this wont return even though a record with the name exists.  I bet it has got to do with number of records and not necessarily the alphabets.\r\n\r\n$zone.records.get doesn't seem to support a way to get it using the name. It seems too want to give it the id. "
1708,'','[Rackspace] Add exception information to API docs\nThis pull request adds exception information to API docs as well as a few formatting tweaks.'
1707,'','[cloudstack] add create_template request, fix saving image(template)\nAdded `create_template` request ->  fixed saving `image`(template)'
1706,'',"DescribeReservedInstancesOfferings does not work properly with filters after 1.8.0\nAWS has made a couple of updates to their DescribeReservedInstancesOfferings API request since the release of fog 1.8.0.  I'm unsure of the exact cause, I just know that the same filters that work in 1.8.0 do not work in 1.9.0, or 1.10.0.  There are no errors, just an empty array."
1705,'rubiojr','[openstack|compute] Add volume attachment methods\nAdded new methods to server:\r\n\r\n- Attach volume to a server\r\n- Detach volume from a server\r\n- Retrieve volumes attached to a server\r\n\r\nAdded volume tests.'
1704,'','Cloudfront distribution creation issue with trusted signers\nHi,\r\n I am using Fog 1.9.0 to create a CloudFront streaming distribution. If I don\'t specify TrustedSigners, a streaming distribution post request results in the creation of a streaming distribution.\r\nHowever if I add TrustedSigners a 400 (Bad Request) is returned.\r\n  From the Fog documentation, TrustedSigners is an array:\r\n \'TrustedSigners\'<~Array> - Optional grant of rights to up to 5 aws accounts to generate signed URLs for private content, elements are either \'Self\' for your own account or an AWS Account Number\r\n  I use it in the following manner:\r\n\r\n---------------------------------------------------------------------------------------------------------------------\r\nrequire \'fog\'\r\n\r\nconn = Fog::CDN.new(\r\n                      :provider              => \'AWS\',\r\n                      :aws_access_key_id     => \'xyz\',\r\n                      :aws_secret_access_key => \'abcd\'\r\n                    ) \r\np = {"Enabled"=>true, "S3Origin"=>{"DNSName"=>"simple-test.s3.amazonaws.com", "OriginAccessIdentity"=>"origin-access-identity/cloudfront/E3QU39FOKP0LeP"}, "TrustedSigners"=>[\'self\']}\r\nresp = conn.post_streaming_distribution(p)\r\nputs resp.body\r\nputs resp.headers\r\n-----------------------------------------------------------------------------------------------------------------------\r\n\r\nI get the following error:\r\n\r\n-----------------------------------------------------------------------------------------------------------------------\r\n `request_kernel\': Expected(201) <=> Actual(400 Bad Request) (Excon::Errors::BadRequest)\r\n  request => {:connect_timeout=>60, :headers=>{"User-Agent"=>"fog/1.9.0", "Content-Type"=>"text/xml", "Date"=>"Mon, 11 Mar 2013 02:14:39 +0000", "Authorization"=>"AWS AH525I3MBWA:TVqcaXNNQ1NCbWAvSRYh75lQLoo=", "Host"=>"cloudfront.amazonaws.com:443", "Content-Length"=>419}, :instrumentor_name=>"excon", :mock=>false, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/usr/local/lib/ruby/gems/1.9.1/gems/excon-0.14.3/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"cloudfront.amazonaws.com", :path=>"/2010-11-01//streaming-distribution", :port=>"443", :query=>nil, :scheme=>"https", :body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?><StreamingDistributionConfig xmlns=\\"http://cloudfront.amazonaws.com/doc/2010-11-01/\\"><Enabled>true</Enabled><S3Origin><DNSName>test.s3.amazonaws.com</DNSName><OriginAccessIdentity>origin-access-identity/cloudfront/E3QU39FOKP0LeP</OriginAccessIdentity></S3Origin><TrustedSigners>self</TrustedSigners><CallerReference>1362986179</CallerReference></StreamingDistributionConfig>", :expects=>201, :idempotent=>true, :method=>"POST", :response_block=>#<Proc:0x9fba80c@/usr/local/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/core/connection.rb:17 (lambda)>}\r\n  response => #<Excon::Response:0x9fae4a8 @body="<?xml version=\\"1.0\\"?>\\n<ErrorResponse xmlns=\\"http://cloudfront.amazonaws.com/doc/2010-11-01/\\"><Error><Type>Sender</Type><Code>MalformedInput</Code><Message>Unexpected complex element termination</Message></Error><RequestId>72593a20-89f1-11e2-abb8-3518185a092c</RequestId></ErrorResponse>", @headers={"x-amzn-RequestId"=>"72593a20-89f1-11e2-abb8-3518185a092c", "Content-Type"=>"text/xml", "Content-Length"=>"286", "Date"=>"Mon, 11 Mar 2013 02:14:47 GMT"}, @status=400>\r\n-----------------------------------------------------------------------------------------------------------------------\r\n\r\nThe creation of the TrustedSigners in the request body doesn\'t seem to be what Amazon is expecting:\r\nIf I see the latest AWS documentation (http://docs.aws.amazon.com/AmazonCloudFront/latest/APIReference/CreateStreamingDistribution.html),  AWS is expecting TrustedSigners in the following format:\r\n\r\n\\<TrustedSigners\\>\r\n      \\<Quantity\\>3\\<\\/Quantity\\>\r\n      \\<Items\\>\r\n         \\<AwsAccountNumber\\>self\\<\\/AwsAccountNumber\\>\r\n         \\<AwsAccountNumber\\>111122223333\\<\\/AwsAccountNumber\\>\r\n         \\<AwsAccountNumber\\>444455556666\\<\\/AwsAccountNumber\\>\r\n      \\<\\/Items\\>\r\n   \\<\\/TrustedSigners\\>\r\nand not \\<TrustedSigners\\>self\\<\\/TrustedSigners\\> that Fog is sending out in its body.\r\n\r\nRegards,\r\nRoshan\r\n\r\n'
1703,'','[cloudstack] add register template(image)\nOk, this PR added wrapper for register_template request.'
1702,'','libvirt (libvirt ffi?)\nwhat / where does this come from '
1701,'','[openstack|network] mock fixes in some OpenStack Network requests\nUpdated mocks in some network request fixing some issues and keeping\r\nthe mocking style used in other requests.\r\n\r\nSee also the comments in #1697'
1700,'','Xenserver network additions\nCreating/destroying VLANs and Networks with required tests and a new example.'
1699,'rubiojr',"[openstack] Retrieve supported API version for Image & Network services\nSome environments don't set the API version for endpoints in service catalog (as a default glance or quantum endpoint in a devstack env), so if you try to use Fog::Image of Fog::Network it'll fail with a 300 (Multiple Choices) error. Also, Fog doesn't support some latest API versions (i.e. glance v2).\r\n\r\nInstead of failing, Fog will now check if the service catalog returns an API version and if it is supported by Fog. If not, it'll try to retrieve the supported API endpoint.\r\n"
1698,'','[cloudstack] add snapshot model\nAdded snapshot model, snapshots collection and `create_snapshot` mock.'
1697,'','[rackspace|compute_v2] Ready Exception\nI added specific exception for invalid states in order to make it easier to rescue. I opted to subclass it from RuntimeError for backwards compatibility. '
1696,'','[Rackspace|BlockStorage]\nThis pull request adds API documentation to Rackspace Block Storage.'
1695,'',"fog force loads all providers\nWhile benchmarking my application's startup time, I found that requiring Fog costs ~0.6s. A significant portion of that is spent loading providers and services that we don't use.\r\n\r\n```\r\n0.5931  fog\r\n  0.3629  lib/fog/providers\r\n    0.0886  lib/fog/providers/aws\r\n      0.0025  aws/cdn\r\n      0.0040  aws/compute\r\n      0.0798  aws/etc\r\n      0.0864  (sum)\r\n    0.2742  others\r\n    0.3629  (sum)\r\n```\r\n\r\nIf we could avoid loading all of the providers and aws services that we don't need, we would save about 0.35s every time we boot our environment.\r\n\r\nBefore I begin work on a pull request, I'd like to ask if there are any specific considerations to keep in mind? This may be familiar ground to someone."
1694,'',"beanstalk parser error\nExcon::Errors::SocketError: undefined method `<<' for {}:Hash (NoMethodError)\r\n\r\nThere is a method in lib/fog/aws/parsers/beanstalk/parser.rb\r\n```ruby\r\ndef start_element(name, attrs = [])\r\n            super\r\n            if name == 'member'\r\n              if @parse_stack.last[:type] == :object\r\n                @parse_stack.last[:value] << {} # Push any empty object\r\n              end\r\n            end\r\nend\r\n```\r\n\r\nWhen the element is member and the type is object it pushes an empty object onto the previous value. Something changed and the previous value is sometimes an empty hash causing an error. I havent had time to figure out how these parsers work but by just skipping pushing the empty object if the last[:value] is an empty object seems to work."
1693,'','Remove the OpenStack API cache busting.\nNot sure why this was ever here, and I cannot find a reason to continuously bust\r\nthe Nova request caching in the wsgi request handler. It does not help\r\nperformance, and makes attempts at ANY caching of responses of a Fog request\r\nannoying.'
1692,'','Short timeout results in Fog::Compute::AWS::Server #{ami_id} went away. (Fog::Errors::Error)\nFog::Model#wait_for requires that a reload succeed within 3 tries.  I have seen this fail numerous times.\r\n\r\nI patched it to remove the "reload" loop and keep retrying for the full duration of Fog.timeout.    This has solved the problem for my use, but it eliminates the "Reload failed ... went away." error which, while perhaps misleading, may be needed by someone.\r\n\r\nHere\'s my patch: https://github.com/chris-maginatics/fog/commit/07ce84f9907213c0b30f3eef7bf701ea564057d4\r\n'
1691,'','[Rackspace|BlockStorage] Adding Block Storage Examples\nAdding Block Storage Examples'
1690,'','[Rackspace] Adding Cloud Block Storage Getting started doc\n Adding Cloud Block Storage Getting started doc along with various getting started document tweaks.'
1689,'',"Fix for AWS error message regex not matching `Code` correctly\nThe regular expression `<Code>(.*)<\\/Code>(?:.*<Message>(.*)<\\/Message>)` isn't matching the `Code` portion correctly in the error handling of `_request` methods of the various AWS classes.\r\n\r\nAs a consequence, the incorrect exception is raised from these methods. For example, the `get` method for users should return `nil` for a non-existent user, but instead `Fog::AWS::IAM::Error` is raised.\r\n\r\n```ruby\r\niam = Fog::AWS::IAM.new({:provider => 'AWS', :aws_access_key_id => ACCESS_KEY_ID, :aws_secret_access_key => SECRET_ACCESS_KEY})\r\nuser = iam.users.get('non_existent_user')\r\nuser.should be_nil\r\n```\r\n\r\nI've looked at what has changed in Fog, excon and the AWS SDK to see why the regex used to work, but am unable to figure it out.\r\n\r\nHowever, by changing to regex to match `(?:.*<Code>(.*)<\\/Code>)(?:.*<Message>(.*)<\\/Message>)` the error handling logic in [Fog::AWS:IAM::Real#_request](https://github.com/fog/fog/blob/master/lib/fog/aws/iam.rb#L197) works as expected.\r\n"
1688,'',"AWS error message regex not matching `Code` correctly\nThe regular expression `<Code>(.*)<\\/Code>(?:.*<Message>(.*)<\\/Message>)?` isn't matching the `Code` portion correctly in the error handling of `_request` methods of the various AWS classes.\r\n\r\nAs a consequence, the incorrect exception is raised from these methods. For example, the `get` method for users should return `nil` for a non-existent user, but instead `Fog::AWS::IAM::Error` is raised.\r\n\r\n```ruby\r\niam = Fog::AWS::IAM.new({:provider => 'AWS', :aws_access_key_id => ACCESS_KEY_ID, :aws_secret_access_key => SECRET_ACCESS_KEY})\r\nuser = iam.users.get('non_existent_user')\r\nuser.should be_nil\r\n```\r\n\r\nI've looked at what has changed in Fog, excon and the AWS SDK to see why the regex used to work, but am unable to figure it out.\r\n\r\nHowever, by changing to regex to match `(?:.*<Code>(.*)<\\/Code>)(?:.*<Message>(.*)<\\/Message>)?` the error handling logic in [Fog::AWS:IAM::Real#_request](https://github.com/fog/fog/blob/master/lib/fog/aws/iam.rb#L197) works as expected.\r\n"
1687,'',"[storm_on_demand] API v1 changes, fix some namespace-related bugs\nAdd more underscores to 'stormondemand' to become 'storm_on_demand' where needed. Complete and fix servers and load balancers for version 1 of the Storm On Demand API."
1686,'','Add support for AWS bucket website redirects\nS3 buckets can redirect all requests to another host name (useful for static website hosting).\r\nSince I could not find support for this in Fog, I added it.\r\n\r\nTo use, add :redirect_to => REDIRECT_TARGET to options hash for\r\nput_bucket_website, e.g.: `connection.put_bucket_website("www.example.com", nil, :redirect_to => "example.com")`\r\n\r\nTo my eternal shame I have to confess that I have no idea how to write a spec for this, and looking at the existing put_bucket_website didn\'t help me any.'
1685,'','[vsphere] add list_templates function\nthis commit it to add list_templates function for vsphere'
1684,'','[openstack|network] Fix #connection deprecation replacing it with #service\n'
1683,'','[openstack|network] remove superfluous Router model attributes\nSee https://github.com/fog/fog/pull/1603#issuecomment-15136440'
1682,'','[core] Updated to make ssh timeout user configurable.\nUpdated to make ssh timeout user configurable. This should address issue https://github.com/fog/fog/issues/1681.\r\n\r\n@geemus Can you take a look at this?'
1681,'krames','SSH timeout not configurable\nIt looks to me like I might have hardcoded that value to 30. \r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/core/ssh.rb#L49\r\n\r\nLine 49 should have been:\r\n\r\noptions[:timeout] ||= 30\r\n\r\nNot \r\n\r\noptions[:timeout] = 30\r\n\r\n\r\nLet me submit a fix for that, which should go out in the next release. \r\n\r\nIn the meantime, here is a patch to fix the issue.\r\n\r\nhttps://gist.github.com/krames/5204730\r\n\r\nhttps://groups.google.com/forum/?fromgroups=#!topic/ruby-fog/x_p-QNOBnJ8'
1680,'','[VMWare] Fixed broken support for obj_ids with spaces.\nMight cure the illness reported in issue https://github.com/fog/fog/issues/1671.'
1679,'',"Rackspace Node Model - variable collection does not contain instance of load balancer\nThe following error is observed while trying to create a new node:\r\n\r\n<pre>\r\n/gems/fog-1.10.0/lib/fog/rackspace/models/load_balancers/node.rb:41:in `create': undefined method `id' for nil:NilClass (NoMethodError)\r\n/gems/fog-1.10.0/lib/fog/rackspace/models/load_balancers/node.rb:26:in `save'\r\n</pre>\r\n\r\nI've attached code that replaces collection.load_balancer with @attribute[:load_balancer] which seems to fix the problem, but I'm not sure if this is the best method."
1678,'','[vcloud|compute] 415 Unsupported Media Type when running server.save method\nAfter updating my libraries on a new development box, I am running into this problem.  fog code and calling code is the same between the machines.  I\'m suspecting there\'s an issue/difference with one of the required libraries.  In this case, I was trying to update the CPU count and save the server object.  Updating memory and network also fail.\r\n\r\n`(eval):523: Expected(202) <=> Actual(415 Unsupported Media Type)\r\n  request => {:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"User-Agent"=>"fog/1.10.0", "Content-Type"=>nil, "Accept"=>"application/*+xml;version=1.5", "Cookie"=>"vcloud-token=XXX=; Secure; Path=/", "Host"=>"mycloud.us-west-01.greenhousedata.com:443", "Content-Length"=>1433}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/usr/local/ruby/lib/ruby/gems/1.9.1/gems/excon-0.20.1/data/cacert.pem", :ssl_verify_peer=>true, :uri_parser=>URI, :write_timeout=>60, :host=>"mycloud.us-west-01.greenhousedata.com", :path=>"/api/vApp/vm-XXX/virtualHardwareSection/memory", :port=>"443", :query=>nil, :scheme=>"https", :user=>nil, :password=>nil, :family=>0, :body=>"          <Item xmlns=\\"http://www.vmware.com/vcloud/v1.5\\" xmlns:rasd=\\"http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_ResourceAllocationSettingData\\" xmlns:vcloud=\\"http://www.vmware.com/vcloud/v1.5\\" vcloud:href=\\"https://mycloud.us-west-01.greenhousedata.com/api/vApp/vm-XXX/virtualHardwareSection/memory\\" vcloud:type=\\"application/vnd.vmware.vcloud.rasdItem+xml\\" xmlns:xsi=\\"http://www.w3.org/2001/XMLSchema-instance\\" xsi:schemaLocation=\\"http://www.vmware.com/vcloud/v1.5 http://mycloud.us-west-01.greenhousedata.com/api/v1.5/schema/master.xsd http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2/CIM_ResourceAllocationSettingData http://schemas.dmtf.org/wbem/wscim/1/cim-schema/2.22.0/CIM_ResourceAllocationSettingData.xsd\\">\\n            <rasd:AllocationUnits>byte * 2^20</rasd:AllocationUnits>\\n            <rasd:Description>Memory Size</rasd:Description>\\n            <rasd:ElementName> MB of memory</rasd:ElementName>\\n            <rasd:InstanceID>5</rasd:InstanceID>\\n            <rasd:Reservation>0</rasd:Reservation>\\n            <rasd:ResourceType>4</rasd:ResourceType>\\n            <rasd:VirtualQuantity></rasd:VirtualQuantity>\\n            <rasd:Weight>0</rasd:Weight>\\n            <Link rel=\\"edit\\" type=\\"application/vnd.vmware.vcloud.rasdItem+xml\\" href=\\"https://mycloud.us-west-01.greenhousedata.com/api/vApp/vm-XXX/virtualHardwareSection/memory\\"/>\\n        </Item>\\n", :expects=>202, :method=>"PUT", :retries_remaining=>4}\r\n  response => #<Excon::Response:0x007f36080b4768 @data={:body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error xmlns=\\"http://www.vmware.com/vcloud/v1.5\\" minorErrorCode=\\"UNSUPPORTED_MEDIA_TYPE\\" message=\\"Unsupported Media Type\\" majorErrorCode=\\"415\\" xmlns:xsi=\\"http://www.w3.org/2001/XMLSchema-instance\\" xsi:schemaLocation=\\"http://www.vmware.com/vcloud/v1.5 http://mycloud.us-west-01.greenhousedata.com/api/v1.5/schema/master.xsd\\"></Error>\\n", :headers=>{"Date"=>"Wed, 20 Mar 2013 01:03:21 GMT, Wed, 20 Mar 2013 01:03:21 GMT", "Content-Type"=>"application/vnd.vmware.vcloud.error+xml;version=1.5", "Content-Length"=>"372"}, :status=>415, :remote_ip=>"173.242.18.150"}, @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error xmlns=\\"http://www.vmware.com/vcloud/v1.5\\" minorErrorCode=\\"UNSUPPORTED_MEDIA_TYPE\\" message=\\"Unsupported Media Type\\" majorErrorCode=\\"415\\" xmlns:xsi=\\"http://www.w3.org/2001/XMLSchema-instance\\" xsi:schemaLocation=\\"http://www.vmware.com/vcloud/v1.5 http://mycloud.us-west-01.greenhousedata.com/api/v1.5/schema/master.xsd\\"></Error>\\n", @headers={"Date"=>"Wed, 20 Mar 2013 01:03:21 GMT, Wed, 20 Mar 2013 01:03:21 GMT", "Content-Type"=>"application/vnd.vmware.vcloud.error+xml;version=1.5", "Content-Length"=>"372"}, @status=415, @remote_ip="173.242.18.150">`\r\n\r\nGems installed on new dev box:\r\n`Successfully installed builder-3.2.0\r\nSuccessfully installed excon-0.20.1\r\nSuccessfully installed formatador-0.2.4\r\nSuccessfully installed multi_json-1.7.1\r\nSuccessfully installed mime-types-1.21\r\nSuccessfully installed net-scp-1.1.0\r\nSuccessfully installed nokogiri-1.5.8\r\nSuccessfully installed ruby-hmac-0.4.0\r\nSuccessfully installed fog-1.10.0\r\n9 gems installed`\r\n\r\nGem versions on old box:\r\n`builder-3.1.4\r\nexcon-0.16.10\r\nformatador-0.2.4\r\nmulti_json-1.5.0\r\nmime-types-1.20.1\r\nnet-scp-1.1.0\r\nnokogiri-1.5.6\r\nruby-hmac-0.4.0\r\nfog-1.10.0`\r\n\r\nI will see if I can update gems one at a time to isolate the issue.\r\nIs there a simple way to get the HTML queries to compare success vs failure?'
1677,'','[aws] mock update_server_certificate\nimplement ```Fog::AWS::IAM::Mock#update_server_certificate```'
1676,'','[libvirt|compute] handle missing <system> tag in libvirt node info\nFixes #1652: libvirt provider requires a field that libvirt specifies as\r\noptional'
1675,'',"Feature request: Fog::*::Server#recognizes, #requires, #readonly\nFor automatic discovery it would be helpful if Service-attributes could be exposed as *required* (read/write), *optional* (read/write) and *read-only*. Currently the services only expose a list of all attributes (`Fog::AWS::Server.attributes`) without the type of the individual attributes.\r\n\r\nE.g. it would be nice if we had something like `Fog::AWS::Server.recognizes`, `Fog::AWS::Server.requires`, `Fog::AWS::Server.readonly` - akin to `Fog::AWS.requires` and `Fog::AWS.recognizes`.\r\n\r\n(or, if there's already a way to determine the attribute-types through reflection, I'd appreciate a pointer)"
1674,'','[Rackspace] update other services to use Auth 2.0\nI have updated the rest of the services to use Auth 2.0. I have also updated all of the auth tests to make a simple call to the service endpoint to ensure we populated a valid endpoint.'
1673,'','[vsphere] fix bug where servers.all was ignoring filters due to hash merging in the wrong direction\npassing a filters hash to connection.servers.all was being ignored due to the hash merge happening in the wrong direction.\r\nAfter the merge :folders, :datacenters etc was empty.\r\n\r\nThis swaps the merge around and is now working as I would expect.\r\nThanks @ohadlevy confirming my thoughts on this.\r\n\r\n\r\n'
1672,'','Fix inconsistencies, enable discovery\nHi,\r\n\r\nI\'m using the following code to circumvent the dynamic class loader and auto-discover all available Server-models;\r\n\r\n```ruby\r\n#!/usr/bin/env ruby\r\n\r\nrequire \'fog\'\r\n\r\nFog::Compute.constants.each do |c|\r\n  provider_class = Fog::Compute.const_get(c)\r\n  name = provider_class.name.split(\'::\')[-1]\r\n  rq_path = "fog/#{name.downcase}/models/compute/server"\r\n  begin\r\n    require rq_path\r\n    server_class = provider_class.const_get(\'Server\')\r\n    puts "#{name} OK, #{server_class.attributes.length} attributes"\r\n  rescue LoadError\r\n    puts "** #{name} not found in #{rq_path}"\r\n  end\r\nend\r\n```\r\n\r\nIf you run this code-snippet you will get output like this:\r\n\r\n```\r\nAWS OK, 34 attributes\r\nBluebox OK, 12 attributes\r\nBrightbox OK, 22 attributes\r\nCloudstack OK, 32 attributes\r\nClodo OK, 31 attributes\r\nDigitalOcean OK, 8 attributes\r\nEcloud OK, 13 attributes\r\nGlesys OK, 19 attributes\r\n** GoGrid not found in fog/gogrid/models/compute/server\r\nHP OK, 23 attributes\r\nIBM OK, 21 attributes\r\nJoyent OK, 11 attributes\r\n** LibvirtUtil not found in fog/libvirtutil/models/compute/server\r\nLibvirt OK, 18 attributes\r\nLinode OK, 3 attributes\r\n** BareMetalCloud not found in fog/baremetalcloud/models/compute/server\r\nNinefold OK, 46 attributes\r\nRackspace OK, 10 attributes\r\n** RackspaceV2 not found in fog/rackspacev2/models/compute/server\r\nOpenStack OK, 29 attributes\r\nOvirt OK, 18 attributes\r\nServerlove OK, 18 attributes\r\n** StormOnDemand not found in fog/stormondemand/models/compute/server\r\n** VirtualBox not found in fog/virtualbox/models/compute/server\r\nVmfusion OK, 5 attributes\r\nVsphere OK, 25 attributes\r\nVoxel OK, 7 attributes\r\nXenServer OK, 38 attributes\r\n```\r\n\r\nAs you can see some models can not be discovered because of path inconsistencies. E.g. `fog/gogrid/models/compute/server.rb` is not found, instead the model is declared in `fog/go_grid/models/compute/server.rb`\r\n\r\nIt would be great if these inconsistencies could either be fixed, or a more formalized discovery-mechanism could be implemented.\r\n\r\nThis kind of discovery is critical in order to use Fog as a normalizing layer across multiple cloud-providers.'
1671,'','Fog fails to parse vSphere network name that includes whitespace\nRunning foreman with fog on CentOS 6.4. I added an ESXi 5.1 server as a compute resource. When I attempted to add a new host via foreman, I received the following error in /var/log/foreman/production.log while in debug mode:\r\n\r\nhttps://gist.github.com/anonymous/4f0bac177f800775dc23\r\n\r\nAfter troubleshooting with ohadlevy on IRC we discovered that changing the name of the Virtual Machine Port Group from "VM Network" to "VMNetwork" resolved the issue.'
1670,'','[rackspace|compute_v2] Use endpoint from service catalog rather than constants\nUpdated compute_v2 to get the appropriate endpoint from the service catalog when an endpoint is specified via :rackspace_endpoint with one of the known constants (DFW_ENDPOINT, ORD_ENDPOINT, LON_ENDPOINT).\r\n\r\nI also updated compute examples to use rackspace region rather than the constants.'
1669,'','[openstack|compute] Allow booting a VM with NICs (net_id, port_id, fixed_ip)\nQuantum extension allows to [boot a VM attaching NICs](http://docs.openstack.org/folsom/openstack-network/admin/content/advanced_vm.html), specifying a net-id or a port-id, and optional a (v4) fixed_ip.'
1668,'','[openstack|compute] "undefined method `+\' for nil:NilClass" when creating flavor and the flavor list is empty\nI\'ve run into the following issue when creating a flavor and the flavor list is empty:\r\n\r\n```\r\nundefined method `+\' for nil:NilClass\r\n/home/rubiojr/.rbenv/versions/2.0.0-p0/lib/ruby/gems/2.0.0/gems/fog-1.10.0/lib/fog/openstack/requests/compute/create_flavor.rb:21:in `create_flavor\'\r\n```\r\n\r\nThe culprit seems to be in https://github.com/fog/fog/blob/master/lib/fog/openstack/requests/compute/create_flavor.rb#L21\r\n\r\nMy first thought was to add 0 to the flavor_id array if it\'s empty:\r\n\r\n```\r\n          # The list of flavors may be empty, add at least one flavor_id\r\n          # if that\'s the case\r\n          flavor_ids << 0 if flavor_ids.empty?\r\n```\r\n\r\nBut I think it\'s not a good idea since the flavor_id 1 could be there but hidden, if the flavor has been \'deleted\'. See https://bugs.launchpad.net/horizon/+bug/1057799/comments/6\r\n\r\nAlso, we\'re doing an additional request (list_flavors_detail) when creating a flavor and I wonder if this is, perhaps, doing too much.\r\n\r\nHaving a closer look at the database (nova.instance_types table), If the flavor_id isn\'t specified, a UUID for the flavorid column is auto-generated apparently.\r\n\r\nSo the question is, are we OK letting the platform decide the flavorid if it wasn\'t provided and remove that extra request?\r\n\r\nThe request would look something like:\r\n\r\n```ruby\r\n        def create_flavor(attributes)\r\n          data = {\r\n            \'flavor\' => {\r\n              \'name\' => attributes[:name],\r\n              \'ram\' => attributes[:ram],\r\n              \'vcpus\' => attributes[:vcpus],\r\n              \'disk\' => attributes[:disk],\r\n              \'swap\' => attributes[:swap],\r\n              \'OS-FLV-EXT-DATA:ephemeral\' => attributes[:ephemeral],\r\n              \'os-flavor-access:is_public\' => attributes[:is_public],\r\n              \'rxtx_factor\' => attributes[:rxtx_factor]\r\n            }\r\n          }\r\n\r\n          data[\'flavor\'][\'id\'] = attributes[:flavor_id] if attributes[:flavor_id]\r\n\r\n          request(\r\n            :body => MultiJson.encode(data),\r\n            :expects => 200,\r\n            :method => \'POST\',\r\n            :path => \'flavors\'\r\n          )\r\n        end\r\n```\r\n\r\nThis changes behavior however and I\'m not sure how previous OpenStack versions would behave.\r\n\r\n@dprince?'
1667,'','Merge hpfog 0.0.20 release\nPush changes upstream for HP provider to sync with hpfog release 0.0.20 '
1666,'rubiojr',"Openstack legacy authentication\nMy cloud provider only supports the legacy v1.0 style auth. The method exists in /lib/fog/openstack.rb as authenticate_v1, but /lib/fog/openstack/storage.rb only uses authenticate_v2 within it's authenticate method. Could it be possible to create an option to choose the v1.0 style auth method?"
1665,'',"bug in openstack.rb\n```ruby\r\n#/lib/fog/openstack.rb\r\n\r\n    # legacy v1.0 style auth\r\n    def self.authenticate_v1(options, connection_options = {})\r\n      uri = options[:openstack_auth_uri]\r\n      connection = Fog::Connection.new(uri.to_s, false, connection_options)\r\n      @openstack_api_key  = options[:openstack_api_key]\r\n      @openstack_username = options[:openstack_username]\r\n\r\n      response = connection.request({\r\n        :expects  => [200, 204],\r\n        :headers  => {\r\n          'X-Auth-Key'  => @openstack_api_key,\r\n          'X-Auth-User' => @openstack_username\r\n        },\r\n        :host     => uri.host,\r\n        :method   => 'GET',\r\n        :path     =>  (uri.path and not uri.path.empty?) ? uri.path : 'v1.0'\r\n      })\r\n\r\n      return {\r\n        :token => response.headers['X-Auth-Token'],\r\n        :server_management_url => response.headers['X-Server-Management-Url'],\r\n        :identity_public_endpoint => response.headers['X-Keystone']\r\n      }\r\n    end\r\n```\r\nShouldn't the X-Server-Management-Url be X-Storage-Url?"
1664,'',"[openstack|identity] moved identity example to the examples directory\nIt seems that we're standardizing on adding examples to the examples\r\ndirectory so move previous identity example to this directory."
1663,'','[openstack|glance] Added image service example\nDownload CirrOS 0.3.0 image from launchpad (~6.5MB) to /tmp\r\nand upload it to Glance (the OpenStack Image Service).'
1662,'','Allow passing Content-Disposition header when saving file into Rackspace cloud\n'
1661,'','Enumerable fixes\nChanges as discussed in https://github.com/fog/fog/commit/989acc71baddbe4197816d755bb36c72c582acae\r\nPlus a fix for a bug I discovered with the new tests.'
1660,'','Remove unnecessary print statement\n'
1659,'','Excon::Errors::SocketError Broken pipe (Errno::EPIPE)\nWhen I try to upload an image with carrierwave/fog, I\'m getting\r\n\r\n```\r\nExcon::Errors::SocketError in PhotosController#create\r\nBroken pipe (Errno::EPIPE)\r\n```\r\n\r\nuploading just to the filesystem works, the problem is just when using S3. Here\'s my config\r\n\r\n```ruby\r\nCarrierWave.configure do |config|\r\n  config.fog_credentials = {\r\n    :provider               => "AWS",\r\n    :aws_access_key_id      => ENV["AWS_KEY"],\r\n    :aws_secret_access_key  => ENV["AWS_SECRET"],\r\n    :host                   => "s3.amazonaws.com",\r\n    :endpoint               => "https://s3.amazonaws.com",\r\n    :region                 => \'eu-west-1\'\r\n  }\r\n  config.fog_directory  = \'foo\'\r\n  config.fog_public     = true\r\n  config.fog_attributes = {\'Cache-Control\'=>\'max-age=315576000\'}\r\nend\r\n```\r\n\r\nThere\'s nothing special going on in the controller\r\n\r\n```ruby\r\nclass PhotosController < ApplicationController\r\n\r\n  def create\r\n    photo = Photo.create!(params[:photo])\r\n    redirect_to photo.activity\r\n  end\r\n\r\nend\r\n```\r\n\r\n## [Here\'s a full stacktrace](https://gist.github.com/shosanna/3f8e61f429613b0ad673)'
1658,'','Forcing good version of Excon\nThe old gemspec allow a buggy version of Excon (0.19.2) and fog may not work properly.'
1657,'','[rackspace] fixing constant already defined error\n[rackspace] fixing constant already defined error for Fog::Rackspace::UK_AUTH_ENDPOINT and Fog::Rackspace::US_AUTH_ENDPOINT'
1656,'','Add block handlers for SCP\nThis allows to use a block to handle scp data callbacks, so you can do something like this:\r\n\r\n```ruby\r\nserver.scp(local_path, remote_path) do |ch, name, sent, total|\r\n   # use data here\r\nend\r\n```'
1655,'',"Stop hardcoding the server's ssh port.\nBecause people might want to run ssh in a different port."
1654,'','[Vcloud] Server reset instance vars after save\nNew networking support needs to reset the stored update value after a save is completed'
1653,'','[Rackspace] Updating Getting Started Docs\n'
1652,'',"libvirt provider requires a field that libvirt specifies as optional\nFollowing this [foreman issue](http://projects.theforeman.org/issues/2292) we dug deeper and found that the issue lies in Fog.\r\n\r\nFog (seems to) depend on libvirt to return `<system>`, libvirt however will not return that section if it cannot get any of it's items."
1651,'','[Rackspace|Storage] Getting started Docs for Cloud Files\nThis pull request contains the getting started documentation for Rackspace Cloud Files.'
1650,'','[Rackspace|Storage] API documentation\nAdded YARD documentation for the Rackspace Storage service.'
1649,'','reformatted AWS CDN and CloudFormating to YARD docs\nChanged docs content form RDoc to YARD.\r\n\r\nComments and any input welcome!'
1648,'','add list_images_detail request to rackspace compute_v2 (openstack) support\n add support for the list_images_detail openstack command in rackspace. This help get more info about an image. It is consistent with other openstack implementations like hp.'
1647,'',"Fog #1620\nGuarding around a few possibilities of nil that I discovered while trying to mock up address association in a VPC.  The relevant issue is:\r\n\r\n[#1620](https://github.com/fog/fog/issues/1620)\r\n\r\nI'm not sure how valid the response will be after this. If this makes things worse, feel free to disregard.  I should probably fire up a test environment in AWS to gather enough test cases and response to further flush out this mock."
1646,'',"Changed GoogleAccessKeyId to GoogleAccessId\nI struggled with this for four hours today. Finally found this:\r\nhttps://groups.google.com/forum/?fromgroups=#!topic/gs-discussion/iahTA7C2nmE\r\n\r\nwhich led me to this:\r\nhttps://developers.google.com/storage/docs/accesscontrol#Signed-URLs\r\n\r\nTested that it works, but don't want to do gsubs for this in every URL generated by Carrierwave + fog in my app."
1645,'',"Add support for working with ovirt quotas\nRHEV 3.1 includes quota support. WIth these enabled Foreman can't properly provision virtual machines."
1644,'','Add Riak CS provider in Fog.\nThis PR adds support for the upcoming release of Riak CS 1.3 to fog.\r\n\r\nPlease let me know if you have any questions.  I will maintain this moving forward to keep it feature compatible will all future Riak CS releases.\r\n\r\n@geemus '
1643,'','Further fixes and enhancements to vCloud \n'
1642,'',"enabled to select the net-id of quantum when you boot the instance.\nI enabled to select the net-id of quantum when you boot instances.\r\n\r\n<http://docs.openstack.org/api/openstack-compute/2/content/CreateServers.html>\r\n\r\nThis OpenStack API Guide does not contain about booting with net-id of quantum. \r\nSo I checked API by executing the 'nova boot --nic' command. \r\n\r\nand This patch also enabled to select 'v4-fixed-ip' and 'port-id'.\r\n\r\nI did test with mock and real OpenStack router of folsom (2012.2.1) release.\r\n\r\nIf you boot with fog like this, you can select the net-id.\r\n\r\n    @compute.create_server('fogtest05', image_id, flavor_id, {'net_id' => uuid, 'v4_fixed_ip' => ip, 'port_id' => port})\r\n\r\nor\r\n\r\n    @compute.create_server('fogtest05', image_id, flavor_id, {'net_id' => uuid})\r\n\r\nBest Regards from Tokyo. :D "
1641,'',"enabled to select the net-id of quantum when you boot the instance.\nI enabled to select the net-id of quantum when you boot instances.\r\n\r\n<http://docs.openstack.org/api/openstack-compute/2/content/CreateServers.html>\r\n\r\nThis OpenStack API Guide does not contain about booting with net-id of quantum. \r\nSo I checked API by executing the 'nova boot --nic' command. \r\n\r\nand This patch also enabled to select 'v4-fixed-ip' and 'port-id'.\r\n\r\nI did test with mock and real openstack router of folsom (2012.2.1) release.\r\n\r\nBest regards from Tokyo. :D "
1640,'',"Add Vcloud support back to Fog::Compute\nVcloud does not work with the new cleanup code for generic provider compute support from commit eb0545b7241c61248428c1cda96f7143a83ceaa3.\r\nWould return:\r\n````NameError: uninitialized constant Fog::Compute::Vcloud\r\n\tfrom /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.10.0/lib/fog/compute.rb:41:in `const_get'\r\n\tfrom /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.10.0/lib/fog/compute.rb:41:in `new'````"
1639,'','Clarified Documentation\n"Number of seconds before x" seems to imply a relative value, but the API actually expects seconds since epoch...'
1638,'','Excon::Errors::BadRequest with fog on get/put file to s3\nDont know whats happening but since some of the latest fog relases(i had to do the update bcs of net-scp yankin) i am getting errors i never had. might be fog, might be excon, or even amazon ?? So maybe it helps putting it here.\r\ni did get some errors where downloaded files had an empty body and got the following when uploading a file.\r\n\r\n\r\n    Excon::Errors::BadRequest in /\r\n    "Expected(200) <=> Actual(400 Bad Request)\\n \r\n    request => {:chunk_size=>1048576, :connect_timeout=>60, :headers=>{\\"User-Agent\\"=>\\"fog/1.9.0\\", \\"Content-Length\\"=>42946, \\"Content-Type\\"=>\\"application/pdf\\", \\"x-amz-acl\\"=>\\"private\\", \\"Content-Disposition\\"=>\\"attachment; filename=\\\\\\"some-name.pdf\\\\\\"\\", \\"Date\\"=>\\"Wed, 06 Mar 2013 20:49:47 +0000\\", \\"Authorization\\"=>\\"REDACTED\\", \\"Host\\"=>\\"mybucket.s3.amazonaws.com:443\\"}, :idempotent=>true, \r\n    :instrumentor_name=>\\"excon\\", \r\n    :middlewares=>[Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], \r\n    :mock=>false, :nonblock=>true, \r\n    :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>\\"/srv/www/salesking/shared/bundle/ruby/1.9.1/gems/excon-0.19.5/data/cacert.pem\\", \r\n    :ssl_verify_peer=>true, \r\n    :uri_parser=>URI, \r\n    :write_timeout=>60, \r\n    :host=>\\"myhost.s3.amazonaws.com\\", \r\n    :path=>\\"/cxGXI-4ayr36GbxPJQHgBF%2Fassets%2FDocument%2F130306-some-filename.pdf\\", \r\n    :port=>\\"443\\", \r\n    :query=>nil, \r\n    :scheme=>\\"https\\", \r\n    :user=>nil, \r\n    :password=>nil, \r\n    :family=>0, \r\n    :body=>\\"%PDF-1.7\\\\ ... som more content\r\n\r\n    Backtrace\r\n\r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/expects.rb:10:in `response_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:325:in `response\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:230:in `request\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/idempotent.rb:11:in `error_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/base.rb:10:in `error_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:243:in `rescue in request\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:204:in `request\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/idempotent.rb:11:in `error_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/base.rb:10:in `error_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:243:in `rescue in request\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:204:in `request\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/idempotent.rb:11:in `error_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/middlewares/base.rb:10:in `error_call\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:243:in `rescue in request\' \r\n    ..shared/bundle/ruby/1.9.1/gems/excon-0.19.5/lib/excon/connection.rb:204:in `request\' \r\n    ..shared/bundle/ruby/1.9.1/bundler/gems/fog-c3dac20b6d01/lib/fog/core/connection.rb:21:in `request\' \r\n    ..shared/bundle/ruby/1.9.1/bundler/gems/fog-c3dac20b6d01/lib/fog/aws/storage.rb:401:in `request\' \r\n    ..shared/bundle/ruby/1.9.1/bundler/gems/fog-c3dac20b6d01/lib/fog/aws/requests/storage/put_object.rb:40:in `put_object\' \r\n    ..shared/bundle/ruby/1.9.1/bundler/gems/fog-c3dac20b6d01/lib/fog/aws/models/storage/file.rb:212:in `save\' \r\n    ..shared/bundle/ruby/1.9.1/bundler/gems/fog-c3dac20b6d01/lib/fog/core/collection.rb:52:in `create\' \r\n'
1637,'','[Rackspace|block storage] Support optional `snapshot_id` key when creating volumes\nUsage of snapshot_id is already present in mock, but not within real method.'
1636,'','Add backup to users page\nOn the list of users:\r\nhttp://fog.io/about/users.html\r\n\r\nCan you add backup?\r\nhttps://github.com/meskyanichi/backup\r\n\r\nRight now it uses Rackspace storage, but with the release of Fog 1.10 I am extending it to use any OpenStack storage.'
1635,'','sshable should accept the same options as ssh\nThis way one can check sshable?(password: password) '
1634,'','[Internet Archive] handle IA specific headers\nMaking this more specific to IA:\r\n\r\nSupport x-amz-* and x-archive-* headers\r\n\r\nSpecify standard x-archive-meta-* headers\r\n\r\nHandle multiple headers, e.g.:\r\n* x-archive-meta01-collection:foo\r\n* x-archive-meta01-collection:bar\r\n\r\nAdditional attributes for files, specific to IA headers:\r\n* :auto_make_bucket\r\n* :cascade_delete\r\n* :ignore_preexisting_bucket\r\n* :interactive_priority\r\n* :keep_old_version\r\n* :queue_derive\r\n* :size_hint\r\n'
1633,'',"First attempt at an S3 path_style flag\nAs discussed: https://github.com/fog/fog/issues/1631\r\n\r\nThe good news: This patch solves my issue.\r\nThe bad news: The fix completely depends on the - previously existing - side effects of Storage#signature on the params hash. So it fails during testing, since the method is then mocked. A 'proper' fix would probably involve removing all side-effects on the params[:path], injecting the setting during file/directory model creation and depending on their #url methods completely. Let me know what you think."
1632,'','[openstack|storage] Added support to impersonate other accounts\nThe patch would allow to impersonate other accounts if you have\r\nan admin role:\r\n\r\n     require \'fog\'\r\n     require \'pp\'\r\n\r\n     auth_url = \'https://identity.test.lan/v2.0/tokens\'\r\n     user = \'admin@test.lan\'\r\n     password = \'secret\'\r\n\r\n     id = Fog::Identity.new :provider => \'OpenStack\',\r\n                            :openstack_auth_url => auth_url,\r\n                            :openstack_username => user,\r\n                            :openstack_api_key  => password\r\n\r\n     st = Fog::Storage.new :provider => \'OpenStack\',\r\n                           :openstack_auth_url => auth_url,\r\n                           :openstack_username => user,\r\n                           :openstack_api_key  => password\r\n\r\n     id.tenants.each do |t|\r\n       puts "Changing account to #{t.name}"\r\n       st.change_account "AUTH_#{t.id}"\r\n       # list account containers\r\n       pp st.directories\r\n       # We could also head the account and get usage information\r\n       pp st.request :method => \'HEAD\'\r\n     end'
1631,'','Ability to force path-style bucket requests\nI would like to be able to force path-style bucket requests, instead of subdomain-style calls. So "host/bucket_name/object", instead of "bucket_name.host/object". Currently, this only happens when the bucket is not a valid dns name and produces a warning.\r\n\r\nSince I connect to our own S3-compatible storage, it\'s tricky to configure SSL for random subdomains and also requires a reboot of said storage.\r\n\r\nMy proposal is to use something like params[:path_style] to force path-style requests. If you like I could provide a pull request.'
1630,'',"[openstack|image] Retrieve glance version if not set\nSome environments (as a default devstack env) don't set the version for glance endpoints in service catalog, so if you try to use Fog::Image, it'll fail with a 300 (Multiple Choices) error. \r\n\r\nInstead of failing, if glance endpoint doesn't have version in path, fetch glance for current glance version. It uses same pattern as [openstack network](https://github.com/fog/fog/blob/master/lib/fog/openstack/network.rb#L215)"
1629,'',"[openstack|image] Check for glance version (fog only supports v1)\nCheck if version returned by service catalog is supported, as Fog only suports glance version v1 (or v1.1). I'm working on v2 support.\r\n\r\nSame behaviour as [openstack compute](https://github.com/fog/fog/blob/master/lib/fog/openstack/compute.rb#L406)"
1628,'','[openstack|network] Add endpoint_type option\nLet users set what endpoint type to use when connecting to OpenStack Network service. Default is "adminURL".'
1627,'','add Bluebox Blocks Load Balancer API\nThis adds all of the endpoints of the Bluebox BLB API. At this point, all of the tests for this pass but two, one due a bug in our API, one that I can\'t figure out as the array of hashes seems to be defined correctly.\r\n\r\nhttps://github.com/jyotty/fog/blob/bluebox-lb/tests/bluebox/requests/blb/lb_tests.rb#L41-L43\r\n\r\n`[{"text"=>"Service â¦ was updated successfully.\\n"}, {"status"=>"ok"}] does not match [{"text"=>String}, {"status"=>String}]`'
1626,'',"[virtualbox] Removed VirtualBox since it has many problems and the gem it's based on is no longer maintained.\nThis should be pretty straightforward.  I just want a second set of eyes to make sure I didn't do anything silly."
1625,'','Typo in instantiate_vapp_template.rb\nRemove typo in instantiate_vapp_template()'
1624,'','[openstack|compute] images collection should not return nil for #all\nFog::Compute[:openstack].images.all returns nil without the patch.\r\nThe patch should bring the images collection behaviour in-line with\r\nother collections I think.\r\n\r\nThe added test should expose the issue.'
1623,'','[openstack|identity] user model tests fixes\n- update_tenant expects a tenant model or a tenant_id\r\n- update_enabled expects a boolean\r\n- role created while testing needs cleanup'
1621,'',"Remove VirtualBox support\nI realize this may be a contentious proposal, but I attempted to use VirtualBox today and ran into FFI problems on both JRuby 1.7.3 and MRI 2.0.0-p0.  I'm not sure which rubies are supposed to work, but the provider is based on the 'virtualbox' gem, which the author has abandoned.  Given the upstream gem is no longer maintained, I don't see much how we can fix any issues we encounter."
1620,'',"error in Fog::Compute::AWS.Mock#associate_address?\nI apologize in advance if this is not the correct forum to ask this question.\r\n\r\nI'm attempting to mock up calls to associate_address in some tests that I'm writing, and am receiving errors.  I haven't been working with Ruby very long, but did attempt to trace through this with little luck.\r\n\r\nI've linked the output at https://gist.github.com/jessedavis/5077890.\r\n\r\nThank you in advance."
1619,'',"OpenStack: base64 encode personality in rebuild\nUpdates the rebuild_server action so that it base64's the personality\r\njust like we do in create_server."
1618,'','[Rackspace] Fixed Other Service endpoints and added accept headers\nI separated the Database fix from the rest of the header changes as the database service does not currently work and I wanted to get the fix in the next version of Fog.\r\n\r\nThis pull request adds the Accept headers to the rest of the services and I wanted to get a second set of eyes on this before I accept it.\r\n\r\nhttps://github.com/fog/fog/pull/1615'
1617,'','[rackspace|database] remove extraneous colon from accept header\nremove extraneous colon from accept header'
1616,'',"Switch gem source to https://rubygems.org\nHopefully won't harm."
1615,'','[rackspace] Fixed DB Service endpoints and added accept headers\nThis pull request fixes an issue with Rackspace Database service. \r\n\r\nThe hard coded endpoints contained an extraneous trailing slash that was causing a user to experience a 401 unauthorized error for all database requests.\r\n\r\nAfter fixing the endpoint, I was getting a python stack trace in the response body. I tracked this down to a lack of an Accept header. I believe this issue might impact more than just the database service.\r\n\r\nI have added accept headers to all of the rackspace services as well.'
1614,'',"Fix openstack mock methods\nSeveral OpenStack mock methods signatures didn't match the non-mocked methods."
1613,'','Test file acl\nHi guys,\r\nHow do you use fog to test S3 file ACL?\r\n\r\nI have a bunch of tests that tests files upload and I would like to test the acl without having to mock everything:\r\n\r\nit "should upload a file with private acl" do\r\n  Fog.mock!\r\n  Fog::Storage[:aws].directories.create(key: \'my-dir\')\r\n\r\n  schedule_task_upload(file => \'my-file\', directory => \'my-dir\', private => true)\r\n\r\n  Fog::Storage[:aws].directories.get(\'my-dir\').files.get(\'my-file\').acl.should == :private\r\nend\r\n\r\nI didn\'t find any obvious way to test that. Any suggestions?\r\n\r\nThanks,\r\nVivien'
1612,'','How to test file acls\nHi guys,\r\nHow do you guys use fog to test S3 file ACL.\r\n\r\nI have a bunch of tests that tests files upload and I would like to test the acl without having to mock everything:\r\n\r\nit "should upload a file with private acl" do\r\nFog::Storage[:aws].directories.create(key: \'my_bucket_name\')\r\n  schedule_task_upload(file => \'my-file\', directory => \'my-dir\', private => true)\r\n  Fog::Storage[:aws].directories.get(\'my-dir\').files.get(\'my-file\').acl.should == :private\r\nend\r\n\r\n\r\nis there any way to do it like this\r\n\r\n\r\n'
1611,'','[Rackspace|Storage] Adding Cloud Files examples\nAdding Cloud File examples. Removed superfluous readme in ComputeV2 examples.'
1610,'','[rackspace|storage] Added ability to determine prefixes from Class Objects\n[rackspace|storage] added the ability to determine meta prefixes from Class objects as well as Fog object. This addresses issue in Files#get method.'
1609,'','[Rackspace|Compute_v2] Improving tests\ncompute_v2 tests were failing because the flavor used in the tests was too small for the image selected. I updated the tests to use the an Ubuntu image in hopes of making the tests less brittle.'
1608,'','Use strict_encode64 \nThe current way of generating the base64 encoding of the credentials breaks for very large org names due to this:\r\nhttp://stackoverflow.com/questions/2620975/strange-n-in-base64-encoded-string-in-ruby\r\n\r\nUse strict_encode64 instead.'
1607,'','allow specifying an AZ when creating an AWS VPC Subnet\nThis change allows the creation of new AWS VPC subnets with a specified availability_zone. Previously, the optional parameter to create_subnet was not passed - so the API would pick an AZ on its own.'
1606,'','[openstack|volume] Added missing service declaration\n- Fixes regresion probably caused by eb0545b\r\n- Added minimal test to catch the issue\r\n- Fixes #1605'
1605,'','OpenStack Volume service broken in master\nI believe the changes in eb0545b to lib/fog/volume.rb caused the regresion. Originally reported by @pperezrubio. 1.9.0 seems to be fine.\r\n\r\nInvestigating.'
1604,'',"Extended Fog::Storage::AWS::Files files method\nThis method now accepts an hash of options that is fed to the Fog::Storage::AWS::Files constructor.\r\n\r\nIt's useful to filter the files that are returned prior to actually getting all the files.\r\n\r\nExample:\r\n\r\n```ruby\r\nFog::Storage::AWS::Directory.files(\r\n  :directory => some_bucket, \r\n  :service => some_bucket.service, \r\n  :prefix => 'this/is/some/key/prefix'\r\n)\r\n```"
1603,'','@Rubiojr and  @jedipunkz enabled to operate routers with openstack.\n@Rubiojr and I enabled to operate routers with openstack.\r\n\r\nhttps://github.com/fog/fog/pull/1586\r\n\r\nWe collaborate to build a patch which enable to operate routers with openstack.\r\n\r\nThis code was tested by @Rubiojr and I with OpenStack Folsom and Grizzly release versions. and I tested by mock, too. \r\n\r\nPerhaps, some fails will occure with tests/openstack/requests/network/router_tests.rb. If that is not good, please remove this file. all of other mock tests are ok.\r\n\r\nRegards.'
1602,'',"excon ~> 0.18 â ArgumentError The following keys are invalid: :url\nAfter upgrading `excon` dependency up to 0.18.5 I've faced an error raised by `excon`:\r\n`ArgumentError The following keys are invalid: :url`, raised from https://github.com/fog/fog/blob/v1.9.0/lib/fog/aws/requests/storage/get_service.rb#L22. And it's really true: in https://github.com/geemus/excon/commit/7bf575bade354b12962572e296ad65e53b1713e4 @geemus created `VALID_CONNECTION_KEYS` constant that doesn't include `:url` key. I think, that's the problem.\r\n\r\nAlso, I've noticed that passing a block to `excon`'s request is depercated https://github.com/geemus/excon/blob/v0.18.5/lib/excon/connection.rb#L222, and `fog` uses it too https://github.com/fog/fog/blob/master/lib/fog/core/connection.rb#L21, but I am not sure that it's a problem.\r\n\r\nJust letting you now. I have no problems with fixing on `excon '~> 0.17.0'` now. \r\n\r\nThanks! "
1601,'','Remove :url param from aws get_service request\nAs of geemus/excon@cb6b273 Excon validates params for ```request``` method.\r\nHowever, array of valid params doesnât include ```url``` param, which ends up with ```ArgumentError: The following keys are invalid: :url``` exception.\r\nI removed that param from ```get_service``` method, and everything seems to be OK, however, Iâm not sure if this is not exconâs bug, and I shouldnât add ```:url``` to ```VALID_CONNECTION_KEYS``` array â if so, just let me know.'
1600,'','[openstack|compute] ensures we clear ipaddresses cache upload reload\n'
1599,'','[rackspace|compute_v2] fixing bootstrap example\nfixing bootstrap example'
1598,'','[openstack|network] create_network provider extensions\nImplements (optional) provider extensions when creating networks.\r\n\r\nSee:\r\n\r\nhttp://docs.openstack.org/trunk/openstack-network/admin/content/provider_attributes.html\r\n\r\nComplements #1581 (Added missing Network model attributes)'
1597,'','OpenStack Compute: Fix server model metadata\nUpdates the OpenStack compute server model so that it stores/handles\r\nmetadata correctly on Server create again.\r\n\r\nThis was a regression from 21499d8 (and should properly handle the\r\nconcern there too).\r\n\r\nIncludes an update to the test that fails without these fixes.'
1596,'',"Getting undefined method `headers' for #<Hash:0xb6d88e0> when uploading to AWS\nI am getting the following error when using fog with asset_sync.\r\nI have logged the issue here as well: https://github.com/rumblelabs/asset_sync/issues/160\r\nApologies for the duplication, not sure where this is best placed.\r\nThe problem also looks like it relates to: https://github.com/rumblelabs/asset_sync/issues/158\r\n but there isn't much information in that ticket.\r\n\r\nundefined method `headers' for #<Hash:0xb740170>\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/fog-1.9.0/lib/fog/aws/storage.rb:403:in `rescue in request'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/fog-1.9.0/lib/fog/aws/storage.rb:400:in `request'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/fog-1.9.0/lib/fog/aws/requests/storage/get_bucket.rb:52:in `get_bucket'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/fog-1.9.0/lib/fog/aws/models/storage/directories.rb:24:in `get'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/asset_sync-0.5.4/lib/asset_sync/storage.rb:18:in `bucket'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/asset_sync-0.5.4/lib/asset_sync/storage.rb:77:in `get_remote_files'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/asset_sync-0.5.4/lib/asset_sync/storage.rb:163:in `upload_files'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/asset_sync-0.5.4/lib/asset_sync/storage.rb:177:in `sync'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/asset_sync-0.5.4/lib/asset_sync/asset_sync.rb:35:in `sync'\r\n/var/lib/jenkins/.rvm/gems/ruby-1.9.3-p392/gems/asset_sync-0.5.4/lib/tasks/asset_sync.rake:3:in `block in <top (required)>'\r\nTasks: TOP => assets:precompile:nondigest"
1595,'','[rackspace|storage] removing type conversion for metadata\nRemoving type conversion for metadata per https://github.com/fog/fog/pull/1587/files#r3137143'
1594,'','[openstack|compute] adds methods to retireve floating & fixed ip addresses\n\r\nthis also refactors the public/private_ip_address methods'
1593,'','Added provider for CloudSigma\nHi,\r\n\r\nI created a provider for CloudSigma. Currently only the basic functionality is covered with tests (CRUD for volumes and servers, and attaching networks to servers).\r\n\r\nI can provide some free resources for testing against real infrastructure. The tests will also work with the resources available from a trial account. Accounts can be created at https://lvs.cloudsigma.com/ui/ (I am mentioning it because there is also a legacy system, and the provider is for the new system).\r\n\r\nAny feedback will be appreciated.'
1592,'','Follow 307 redirection from response even if response is a Hash\nHello,\r\n\r\nThis commit fixes a regression on #27.\r\n\r\nFrom what I understand it seems that at some point the logic catching the 307 was moved to `Excon::Errors::TemporaryRedirect`. This is good, but it seems that since then `error.response` is not behaving as expected.\r\n\r\nIf we go `error.response.headers[\'Location\']` it breaks with:\r\n\r\n    NoMethodError: undefined method `headers\' for #<Hash:0x007fac3ba55c28>\r\n\r\nInspecting the `error.response` object:\r\n\r\n``` ruby\r\nresponse => \r\n{:body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n\r\n<Error>\r\n  <Code>TemporaryRedirect</Code>\r\n  <Message>Please re-send this request to the specified temporary endpoint. Continue to use the original request endpoint for future requests.</Message>\r\n  <RequestId>659**********5D8</RequestId>\r\n  <Bucket>**********-dev</Bucket>\r\n  <HostId>RRfN**********RWE</HostId>\r\n  <Endpoint>**********-dev.s3-external-3.amazonaws.com</Endpoint>\r\n</Error>",\r\n:headers=> {\r\n  "x-amz-request-id"=>"659**********45D8",\r\n  "x-amz-id-2"=>"RRfN**********bwRWE",\r\n  "Location"=>"https://**********-dev.s3-external-3.amazonaws.com/?prefix=assets",\r\n  "Content-Type"=>"application/xml", \r\n  "Transfer-Encoding"=>"chunked", \r\n  "Date"=>"Mon, 25 Feb 2013 09:31:32 GMT", "Server"=>"AmazonS3"\r\n}, :status=>307, :remote_ip=>"**********"}>\r\n```\r\n\r\nMy fix makes sure that it will handle correctly the response if it\'s a hash while still working if we have an Excon response object instead to avoid problems for users with various versions of Excon.\r\n\r\nThis fixes my issue and I doubt it\'ll break any logic.\r\n\r\nLet me know if you need more information in order to merge this.\r\n\r\nThanks for the gem!\r\nmarc- \r\n'
1591,'',"[ovirt] fix issues with oVirt 3.1 API.\nIn version 3.1 of oVirt API there is a change in the meaning of the virtual machine (VM) status. When creating a VM in versions prior to 3.1, it used to be in status 'image-locked' until the virtual disks where ready. In version 3.1 a change in the API was introduced, the VM status no longer represent the status of the VM and it's disks, from this version, in order to know that a VM is ready for launch, we need to loop through the disks checking the state of each one.\r\nThis patch fix the oVirt launch logic, it is backward compatible with previous oVirt versions."
1590,'',"[Vcloud|compute] Unable to get customization options in validate_instantiate_vapp_template_options\nWhen trying to create a VMWare Vcloud server, I ran into an error:\r\nRuntimeError: Unable to get customization options for https://mycloud.us-west-01.greenhousedata.com/api/catalogItem/32bd6f97-c990-413b-9e93-755de678f351\r\n\tfrom /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/vcloud/requests/compute/instantiate_vapp_template.rb:30:in `rescue in validate_instantiate_vapp_template_options'\r\n\tfrom /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/vcloud/requests/compute/instantiate_vapp_template.rb:27:in `validate_instantiate_vapp_template_options'\r\n\tfrom /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/vcloud/requests/compute/instantiate_vapp_template.rb:69:in `instantiate_vapp_template'\r\n\tfrom /usr/local/ruby/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/vcloud/models/compute/servers.rb:30:in `create'\r\n\tfrom (irb):85\r\n\tfrom /usr/local/ruby/bin/irb:18:in `<main>'\r\n\r\nInvestigating the code, I see the line causing the error is:\r\nget_vapp_template(options[:template_uri]).body[:Children][:Vm][:GuestCustomizationSection]\r\n\r\nIt looks like on the Vcloud I am connected to, the results from get_vapp_template(options[:template_uri]).body[:Children][:Vm] is a one-element array, instead of a hash.  I am using API v1.5."
1589,'','[hp/openstack|compute] remove erroneous block argument to get_object; fi...\nFixes https://github.com/fog/fog/issues/1588 for HP and OpenStack.'
1588,'',"Regression Fetching Objects w/ Rackspace Storage Service - Fog 1.9.0, Excon 0.18.5.\nHere's the backtrace:\r\n\r\n    ArgumentError: The following keys are invalid: :block\r\n      excon-0.18.5/lib/excon/connection.rb:31:in `assert_valid_keys_for_argument!'\r\n      excon-0.18.5/lib/excon/connection.rb:211:in `request'\r\n      fog-1.9.0/lib/fog/core/connection.rb:21:in `request'\r\n      fog-1.9.0/lib/fog/rackspace/storage.rb:107:in `request'\r\n      fog-1.9.0/lib/fog/rackspace/requests/storage/get_object.rb:24:in `get_object'\r\n      fog-1.9.0/lib/fog/rackspace/models/storage/files.rb:57:in `get'\r\n"
1587,'','[rackspace|storage]  decoding strings in Metadata.from_headers.\nAddressed issue where Fog::Rackspace::Metadata.from_headers throws a MultiJson::LoadError exception when encountering a string.'
1586,'','I made code which can operate OpenStack quantum router.\nHi,\r\n\r\nI made code which can operate OpenStack quantum router. CRUD is...\r\n\r\n    # Router CRUD\r\n    request :list_routers\r\n    request :create_router\r\n    request :delete_router\r\n    request :get_router\r\n    request :update_router\r\n    request :add_router_interface\r\n    request :remove_router_interface\r\n\r\nI tested by mock and real openstack quantum router.\r\n\r\nBest Regards from Tokyo.'
1585,'',"joyent resize smartmachine incorrect class type\nWhen doing a resize on Fog master the following error message appears. . \r\n\r\nNoMethodError: undefined method `resize_machine' for #<Fog::Compute::Joyent::Real:0x000000015b86b8>\r\n        from /home/angus/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.9.0/lib/fog/joyent/models/compute/server.rb:56:in `resize'\r\n        from (irb):6\r\n        from /home/angus/.rvm/rubies/ruby-1.9.3-p194/bin/irb:16:in `<main>'\r\n\r\nIt appears that the service needs to be 'cast' as Real.  I've also ensured that there is consistancy by the library method resize that requires a 'flavor' passes the 'package' (string) to the request library.  \r\n"
1584,'',"[openstack|network] Openstack Router Layer-3 Networking Extension\nWork in Progress, not to be merged\r\n---------------------------------------------------\r\n\r\nSee http://docs.openstack.org/api/openstack-network/2.0/content/router_ext.html\r\n\r\nBasic functionality is there, with working tests.\r\nWe're testing this stuff against OpenStack Grizzly, but this should be available in Folsom too I believe (unconfirmed).\r\n\r\nMissing stuff so far, to be done before merging:\r\n\r\n- [ ] Proper mocking all around.\r\n- [ ] Proper documentation.\r\n- [ ] More tests.\r\n- [ ] create_network request may need to be updated to support some Router functionality.\r\n\r\nI'd love to get some peer review before merging this stuff if possible, since I've been barely exposed to this stuff.\r\n"
1583,'',"[Rackspace] Updated compute_v2, storage, and cdn services to support auth 2.0\nI updated compute_v2, storage, and cdn services to do authorization using the Identity service by default. (The identification service uses auth 2.0 endpoints) Services will fallback to the old  legacy authentication system if supplied with an old 1.0/1.1 authorization endpoint via the `:rackspace_auth_url` parameter.\r\n\r\nI have added a ServiceCatalog model to the Identify service. This model is populated when a user uses `Identify#authenticate`. The service catalog is returned by `Identify#service_catalog`.\r\n\r\nRegions should now be selected by using the `:rackspace_region` parameter along with the value of `:dfw`, `:ord`. `:lon`. (Note these values are generated off of the service catalog returned from the auth 2.0 request.) A deprecation warning will appear if user specifies compute_v2 region using `:rackspace_endpoint` along with one of the following constants: `DFW_ENDPOINT`, `ORD_ENDPOINT`, `LON_ENDPOINT`. \r\n\r\nUser's are able to manually select endpoints by using one of the following values: `:rackspace_storage_url`, `rackspace_cdn_url`, and `:rackspace_compute_url`. A deprecation warning is displayed if user specifies compute_v2 endpoint using `rackspace_endpoint`. (This was in attempt to standardize how you specify endpoints for each service.)"
1582,'','[vSphere:] Implementation of Query for Guesttype and NICTypes\nThis pull request is a concept to implement a concept to query for guest types (fog: servertypes) and nic types (fog: interfacetypes).\r\n\r\nExample on how to call:\r\n\r\ncompute.datacenters.first.servertypes.map{ | servertype | servertype.id }\r\n=> ["windows8Server64Guest", "windows7Server64Guest", "winLonghorn64Guest", "winLonghornGuest", "winNetEnterprise64Guest", "winNetEnterpriseGuest", "winNetDatacenter64Guest", "winNetDatacenterGuest", "winNetStandard64Guest", "winNetStandardGuest", "winNetWebGuest", "winNetBusinessGuest", "windows8_64Guest", "windows8Guest", "windows7_64Guest", "windows7Guest", "winVista64Guest", "winVistaGuest", "winXPPro64Guest", "winXPProGuest", "win2000AdvServGuest", "win2000ServGuest", "win2000ProGuest", "winNTGuest", "win98Guest", "win95Guest", "win31Guest", "dosGuest", "rhel6_64Guest", "rhel6Guest", "rhel5_64Guest", "rhel5Guest", "rhel4_64Guest", "rhel4Guest", "rhel3_64Guest", "rhel3Guest", "rhel2Guest", "sles11_64Guest", "sles11Guest", "sles10_64Guest", "sles10Guest", "sles64Guest", "slesGuest", "centos64Guest", "centosGuest", "debian6_64Guest", "debian6Guest", "debian5_64Guest", "debian5Guest", "debian4_64Guest", "debian4Guest", "asianux4_64Guest", "asianux4Guest", "asianux3_64Guest", "asianux3Guest", "oesGuest", "oracleLinux64Guest", "oracleLinuxGuest", "ubuntu64Guest", "ubuntuGuest", "other26xLinux64Guest", "other26xLinuxGuest", "other24xLinux64Guest", "other24xLinuxGuest", "otherLinux64Guest", "otherLinuxGuest", "darwin11_64Guest", "darwin11Guest", "darwin10_64Guest", "darwin10Guest", "darwin64Guest", "darwinGuest", "freebsd64Guest", "freebsdGuest", "os2Guest", "netware6Guest", "netware5Guest", "solaris11_64Guest", "solaris10_64Guest", "solaris10Guest", "solaris9Guest", "solaris8Guest", "openServer6Guest", "openServer5Guest", "unixWare7Guest", "eComStation2Guest", "eComStationGuest", "otherGuest64", "otherGuest", "vmkernel5Guest", "vmkernelGuest"]\r\n\r\nFor specific nictypes:\r\ncompute.datacenters.first.servertypes.get("debian6Guest").interfacetypes\r\n=>   <Fog::Compute::Vsphere::Interfacetypes\r\n    [\r\n      <Fog::Compute::Vsphere::Interfacetype\r\n        id="VirtualE1000",\r\n        name="VirtualE1000",\r\n        datacenter="axref200",\r\n        servertype="debian6Guest"\r\n      >,\r\n      <Fog::Compute::Vsphere::Interfacetype\r\n        id="VirtualVmxnet3",\r\n        name="VirtualVmxnet3",\r\n        datacenter="axref200",\r\n        servertype="debian6Guest"\r\n      >\r\n    ]\r\n  >\r\n\r\nFor a specific nictype:\r\n\r\ncompute.datacenters.first.servertypes.get("debian6Guest").interfacetypes.get("VirtualE1000")\r\n=>   <Fog::Compute::Vsphere::Interfacetype\r\n    id="VirtualE1000",\r\n    name="VirtualE1000",\r\n    datacenter="axref200",\r\n    servertype="debian6Guest"\r\n  >\r\n\r\nPlease let me know what you think.\r\n\r\nThanks Marc.'
1581,'',"[openstack|network] Added missing Network model attributes\nThe following patch adds the following missing attributes:\r\n\r\n```\r\n+---------------------------+--------------------------------------+\r\n| Field                     | Value                                |\r\n+---------------------------+--------------------------------------+\r\n| provider:network_type     | gre                                  |\r\n| provider:physical_network |                                      |\r\n| provider:segmentation_id  | 1                                    |\r\n| router:external           | False                                |\r\n+---------------------------+--------------------------------------+\r\n```\r\n\r\nNot sure if the code style I've used for the attributes is OK though,\r\nI did it so I don't break the 80 col. barrier.\r\n\r\nAdded also a small test for the new and existing attributes."
1580,'',"Nil access error for kas_key? coming out of excon\nWith the following code...\r\n\r\n```ruby\r\nrequire 'rubygems'\r\nrequire 'fog'\r\n\r\nFog.mock!\r\n\r\nFog.credentials = {\r\n  aws_access_key_id:     'key',\r\n  aws_secret_access_key: 'secret',\r\n  region:                'us-east-1'\r\n}\r\n\r\nFog::Storage['AWS'].directories.get('asdf')\r\n```\r\n\r\nThrows the following errors...\r\n\r\n```\r\n/Users/dboyd/.rvm/gems/ruby-1.9.3-p327/gems/excon-0.17.0/lib/excon/errors.rb:126:in `status_error': undefined method `has_key?' for nil:NilClass (NoMethodError)\r\n\tfrom /Users/dboyd/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.9.0/lib/fog/aws/requests/storage/get_bucket.rb:104:in `get_bucket'\r\n\tfrom /Users/dboyd/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.9.0/lib/fog/aws/models/storage/directories.rb:24:in `get'\r\n\tfrom fog.rb:15:in `<main>'\r\n```\r\n\r\nThis is with fog 1.9.0 and excon 0.17.0.\r\n\r\nI'm not entirely sure whose fault it is.  If the issue is excon specific, let me know and I can report it there.\r\n"
1579,'','fix the bug that prevented joyent nodes from being resized \npatch to allow joyent smartmachines to be resized'
1578,'','Adding networks on rackspace failing with no error.\nSeems like an issue of a missing attribute. Patch enclosed.'
1577,'',"Fog::Compute::Vsphere get_vm_by_ref method is misspelled in vm_reconfig_hardware\nMethod 'get_vm_by_ref' should be 'get_vm_ref' in vm_reconfig_hardware.rb, when run by default it returns 'NoMethodError' for 'get_vm_by_ref' because it doesn't exist anywhere."
1576,'','[rackspace|compute] updated mocking framework to support any flavor or image\nI updated MockData to create additional images/flavors if they are unknown. Hopefully, this should allow developers to utilize mocks without having to change their code.\r\n\r\nThis should address issue https://github.com/fog/fog/issues/1573. \r\n\r\nUsers wanting should use contain Fog::Rackspace::MockData::NOT_FOUND_ID for situations where it is desirable not to find an image or flavor.\r\n\r\n'
1575,'','[openstack] Unrecognized service: image warning message when running tests \nadded image service to Fog::OpenStack to prevent Unrecognized service: image warning message when running tests'
1574,'','Openstack: fix bin/openstack.rb errors.\nUpdates Fog::Bin for OpenStack to support :image.\r\n\r\nThis patch also fixes a bunch of copy/paste errors in the\r\ndeprecated [] method.'
1573,'',"Mock servers.create fail with rackspace\nThe following code will fail.\r\n\r\nHowever it runs fine without Fog.mock!\r\nCredentials have been removed here.\r\n\r\n```ruby\r\n#!/usr/bin/env ruby\r\nrequire 'rubygems'\r\nrequire 'fog'\r\n\r\nFog.mock!\r\n\r\n\r\ncompute = Fog::Compute.new({\r\n  :provider           => 'Rackspace',\r\n  :version            => :v2,\r\n  :rackspace_username => '',\r\n  :rackspace_api_key  => '',\r\n  :rackspace_auth_url => 'lon.auth.api.rackspacecloud.com',\r\n  :rackspace_endpoint => 'https://lon.servers.api.rackspacecloud.com/v2',\r\n})\r\n\r\ncompute.servers.create(:name => 'mahname', :flavor_id => 2, :image_id => '831acf2d-f1a7-4d1c-b045-7bf8e3a80f9d')\r\n```\r\n\r\n\r\n```bash\r\n/Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/mock_data.rb:129:in `block (2 levels) in keep': undefined method `key?' for nil:NilClass (NoMethodError)\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/mock_data.rb:129:in `each'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/mock_data.rb:129:in `block in keep'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/mock_data.rb:128:in `tap'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/mock_data.rb:128:in `keep'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/requests/compute_v2/create_server.rb:68:in `create_server'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/models/compute_v2/server.rb:91:in `create'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/models/compute_v2/server.rb:78:in `save'\r\n\tfrom /Users/haraldsk/.rbenv/versions/1.9.3-p327/lib/ruby/gems/1.9.1/gems/fog-1.9.0/lib/fog/core/collection.rb:52:in `create'\r\n```"
1572,'',"[AWS] Rudimentary AWS Data Pipeline functionality\nI have implemented basic functionality for the AWS Data Pipeline service.\r\n\r\nThere isn't much in the way of error handling and no mock handling at all, but basic CRUD operations are covered."
1571,'',"Error while trying to get() AWS S3 directory which is used as static website hosting\nfog version is (1.9.0)\r\n\r\nS3 bucket is named as site domain for example my-domain.com.ua\r\n\r\n    [7] pry(#<Deploy>)> connection.directories.get('my-domain.com.ua')\r\n    [WARNING] fog: followed redirect to my-domain.com.ua.s3-external-3.amazonaws.com, connecting to the matching region will be more performant\r\n    Excon::Errors::SocketError: hostname does not match the server certificate (OpenSSL::SSL::SSLError)\r\n    from /Users/Andrey/.rvm/rubies/ruby-1.9.3-p362/lib/ruby/1.9.1/openssl/ssl-internal.rb:121:in `post_connection_check'"
1570,'','Use Fog.providers and Fog.services to require files and instantiate services\nUsing the information in Fog.providers and the Fog.services to do the requires and instantiation in compute.rb, storage.rb, etc should help dry things a bit.  It might help with [1].  This will prevent the need to monkey patch compute and storage when creating a simple ad hoc provider which is my primary motivation. This passes all tests.  I have also made 2 minor corrections. \r\n\r\n[1] https://codeclimate.com/github/fog/fog/Fog::Compute#duplication\r\n'
1569,'','[rackspace|storage] added account model\nI added an account model to encapsulate View Account Details as well as the ability to update meta temp url key.\r\n\r\n@bradgignac @bradgignac Can you review this?'
1568,'','Make fog-vsphere independent from english language.\n...ven work with other localizations.'
1567,'','[Rackspace|Compute_v2] Added note about bootstrap method and RackConnect\nAdded a note to indicate that customers utilizing RackConnect and Cloud Servers should opt to use the server personality functionality instead of the bootstrap method as the public ip address gets reassigned when the RackConnect automation scripts are run.\r\n\r\nSee issue https://github.com/fog/fog/issues/1507 for more information.\r\n\r\n@brianseeders @bradgignac @brianhartsock Can you give me some feedback on this pull request?'
1566,'','fixed bug, floatingip methods to Fog::OpenStack::Network\nHi.\r\n\r\nquantum api need no underscore valiable name, on no mock mode. (ex floatingips\r\n\r\nupdated for ruby naming conventions. Â· 9ebd161 Â· kanetann/fog <https://github.com/kanetann/fog/commit/9ebd161e03e3931a3322776b6bc156a9bb071069>\r\n'
1565,'','[Rackspace|Storage] Updated File to use the same Metadata class as Directory\nI refactored File class to use the same metadata class I added in pull request https://github.com/fog/fog/pull/1563.\r\n\r\nThe new implementation is cleaner and supports adding metadata on file creation.'
1564,'','[Rackspace|Storage] Fixing Failing test\n This test consistently fails on either ruby 1.8.7 or ruby 1.9.3 because hash order is indeterminate. I believe the spirt of this test is to ensure that only one header value is generated and thus I have updated the test to reflect that. \r\n\r\nThat being said, I would be open to suggestions about changing the test or the code. '
1563,'','[Rackspace|Storage] Added support for container metadata\nThis pull request contains support for container metadata as well as tests for Rackspace directory model.'
1562,'','Upgraded the net-scp dep from ~>1.0.4 to ~>1.1 because 1.0.6 was yanked from RubyGems.org\nRubyGems.org yanked v1.0.6 causing problems\r\nwith installing the gem.'
1561,'',"Trouble installing after net-scp etc yanking from rubygems\nnet-scp 1.0.5 and 1.0.6 have been yanked from ruby gems. This caused serious trouble for us. It's all because of the latest security vulnerabilities of ruby gems afaik.\r\n\r\nRead more about it here:\r\n\r\nhttp://solutious.com/blog/2013/02/06/net-ssh-gem-code-signed/\r\n\r\nPerhaps Fog could depend on 1.1.x of net-scp?"
1560,'','Enable ebs-optimized spot instance requests\n'
1559,'',"[Rackspace|Storage] Refactor Storage\nI moved all of the CDN specific code from Storage to CDN class and in the process DRY'ed up the code. \r\n\r\nI have also added tests for Fog::Rackspace::Directory."
1558,'','Minor fixes to Terremark\nCouple of minor fixes:\r\n\r\n1. Ensure to always check status when deleting a vapp.\r\n2. Fix the internet service function to delete the services.'
1557,'','Terremark xml parser fixes - issue #1549\nFixes for: https://github.com/fog/fog/issues/1549'
1556,'','[rackspace|storage] fixed issue in ruby 1.8.7 where metadata was not being deleted\nFile metadata is not being removed when set to nil when using ruby 1.8.7. This bug was exposed by running the file_tests without using mocks.\r\n\r\nAfter reviewing the specs we should have been setting the key names to X-Remove-Object-Meta-<keyname> when we are trying to delete keys.\r\n\r\nhttp://docs.rackspace.com/files/api/v1/cf-devguide/content/Update_Object_Metadata-d1e2338.html'
1555,'','[riakcs] Add Riak CS provider.\nThis adds support for Riak CS, an S3-compatible storage platform built on Riak.\r\n\r\nhttp://basho.com/riak-cloud-storage/\r\n'
1554,'','[glesys] add platform to templates\nFix a bug and add a new feature to templates.\r\n\r\n```ruby\r\nFog::Compute[:glesys].templates # Show both OpenVZ and Xen templates\r\nFog::Compute[:glesys].templates.openvz # Show OpenVZ templates\r\nFog::Compute[:glesys].templates.xen # Show Xen templates\r\n```'
1553,'','[glesys] Fix bug when trying to attach a ip to a server\nThere is a bug when trying to attach a ip to a server. This PR fixed the issue.'
1552,'','[glesys] Attributes were overwritten when getting server details\nAttributes were overwritten when requesting full information about a\r\nserver. Essential the problem is that both the server details and the\r\nserver status were requested from Glesys then merged together to create\r\na Fog Glesys server model object. I moved some of the status attributes\r\ninto a usage attribute on the server instead.'
1551,'','vCloud Director 1.5 enhancements\n1. Support instantiating a vApp in an vOrg/vApp network.\r\n2. Configure a VM NIC interface onto to a network\r\n3. Poll for vApp readiness.'
1550,'',"[rackspace|lb] Fixed issue with paths having two slashes\nThis was causing the API to return 401's."
1549,'',"XML Parser changes have broken Terremark\nThe recent changes to the core/parser.rb : https://github.com/fog/fog/commit/0283cac581edc36fe58681c51d6fa2a5d2db3f41 has broken terremark cloud driver.  \r\nNone of the functionality works anymore. \r\n\r\nEg:\r\n```\r\n/Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/fog-1.9.0/lib/fog/terremark/vcloud.rb:74:in `default_network_id': undefined method `split' for nil:NilClass (NoMethodError)\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/fog-1.9.0/lib/fog/terremark/requests/shared/instantiate_vapp_template.rb:32:in `instantiate_vapp_template'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/fog-1.9.0/lib/fog/terremark/models/shared/server.rb:175:in `save'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/fog-1.9.0/lib/fog/core/collection.rb:52:in `create'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/knife-terremark-0.5.0/lib/chef/knife/terremark_server_create.rb:221:in `run'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/chef-11.0.0/lib/chef/knife.rb:460:in `run_with_pretty_exceptions'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/chef-11.0.0/lib/chef/knife.rb:173:in `run'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/chef-11.0.0/lib/chef/application/knife.rb:123:in `run'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/gems/chef-11.0.0/bin/knife:25:in `<top (required)>'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/bin/knife:19:in `load'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/bin/knife:19:in `<main>'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/bin/ruby_noexec_wrapper:14:in `eval'\r\n\tfrom /Users/cheezo/.rvm/gems/ruby-1.9.3-p194@fog-190/bin/ruby_noexec_wrapper:14:in `<main>'\r\n\r\n```\r\nSame for default_vdc_id, default_organization_id etc\r\n\r\n"
1548,'','Weird getaddrinfo socket errors.\nI\'m using fog 0.9 and I\'m experiencing a really annoying issue with fog/excon. I\'m uploading a large number of files to AWS storage like this:\r\n\r\n```ruby\r\nstorage.directories.new(:key => "mybucket").files.create(\r\n   ...\r\n)\r\n```\r\n\r\nMost files are uploaded without any issue but I often get this socket error:\r\n\r\n```\r\ngetaddrinfo: nodename nor servname provided, or not known (SocketError)\r\n```\r\n\r\nSimply retrying the command will sometimes work, or fail on a different file.\r\n\r\nIts happening on two computers in different locations and does not happen in a repeatable way. I have tried using persistent and non persistent connections with no luck.\r\n\r\nAny ideas on how I can debug this issue?'
1547,'','[ecloud] Cleaning up bad code\n'
1546,'','Tests are failing under 1.8.7 on Travis CI\nOther the last 4 days the Travis build has started erroring when running with Ruby 1.8.7\r\n\r\nSee https://travis-ci.org/fog/fog/jobs/4532988 as an example.\r\n\r\nI suspect the "error" is the two AWS/RDS timeouts.\r\n\r\nLooking back at where the issue could have been introduced I noticed @geemus has already attempted a fix with https://github.com/fog/fog/commit/9977a01fdb0026d0bcbf184852dd0017cd686741\r\n\r\nUsing http://ruby-journal.com/debug-your-failed-test-in-travis-ci/ as I guide I have confirmed the same issues on a Travis Ruby CI image but NOT when running 1.8.7 locally.\r\n\r\nFiles causing fails/errors are:\r\n\r\n* tests/hp/models/compute/security_group_tests.rb /cc @rupakg \r\n\r\nThis does not fail when running standalone but does when running with the AWS tests.\r\n\r\n```\r\n  Fog::Compute[:hp] | security_group (hp) +++++      \r\n      tests/hp/models/compute/security_group_tests.rb\r\n        a group with trailing whitespace\r\n        Fog::Compute[:hp] | security_group (hp)\r\n      - revoke access from another security group\r\n      \r\n      tests/hp/models/compute/security_group_tests.rb\r\n      Fog::Compute::HP::NotFound (Fog::Compute::HP::NotFound)\r\n        /home/travis/fog/lib/fog/hp/requests/compute/delete_security_group_rule.rb:41:in `delete_security_group_rule\'\r\n        /home/travis/fog/lib/fog/hp/models/compute/security_group.rb:37:in `delete_rule\'\r\n        ./tests/hp/models/compute/security_group_tests.rb:27\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:138:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:138:in `assert\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:114:in `test\'\r\n        ./tests/hp/models/compute/security_group_tests.rb:26\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `tests\'\r\n        ./tests/hp/models/compute/security_group_tests.rb:5\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `tests\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:37:in `initialize\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:13:in `new\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:13:in `tests\'\r\n        ./tests/hp/models/compute/security_group_tests.rb:1\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:61:in `load\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:61:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:58:in `each\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:58:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `initialize\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `new\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:72\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/bin/shindont:4:in `require\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/bin/shindont:4\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/bin/shindont:23:in `load\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/bin/shindont:23\r\n```\r\n\r\n* tests/aws/requests/rds/instance_tests.rb\r\n\r\n```\r\n  AWS::RDS | instance requests (aws, rds) +++++      \r\n      tests/aws/requests/rds/instance_tests.rb\r\n        success\r\n        AWS::RDS | instance requests (aws, rds)\r\n      The specified wait_for timeout (300 seconds) was exceeded (Fog::Errors::TimeoutError)\r\n        /home/travis/fog/lib/fog/core/wait_for.rb:10:in `wait_for\'\r\n        /home/travis/fog/lib/fog/core/model.rb:65:in `wait_for\'\r\n        ./tests/aws/requests/rds/instance_tests.rb:45\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `tests\'\r\n        ./tests/aws/requests/rds/instance_tests.rb:12\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `tests\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:37:in `initialize\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:13:in `new\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:13:in `tests\'\r\n        ./tests/aws/requests/rds/instance_tests.rb:1\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:61:in `load\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:61:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:58:in `each\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:58:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `initialize\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `new\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:72\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/bin/shindont:4:in `require\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/bin/shindont:4\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/bin/shindont:23:in `load\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/bin/shindont:23\r\n```\r\n\r\n* tests/aws/models/rds/server_tests.rb\r\n\r\n```\r\n  AWS::RDS | server (aws, rds) +++++#+      \r\n      tests/aws/models/rds/server_tests.rb\r\n        success\r\n        AWS::RDS | server (aws, rds)\r\n      The specified wait_for timeout (300 seconds) was exceeded (Fog::Errors::TimeoutError)\r\n        /home/travis/fog/lib/fog/core/wait_for.rb:10:in `wait_for\'\r\n        /home/travis/fog/lib/fog/core/model.rb:65:in `wait_for\'\r\n        ./tests/aws/models/rds/server_tests.rb:79\r\n        ./tests/helpers/model_helper.rb:13:in `model_tests\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `tests\'\r\n        ./tests/helpers/model_helper.rb:3:in `model_tests\'\r\n        ./tests/aws/models/rds/server_tests.rb:3\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `instance_eval\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:78:in `tests\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:37:in `initialize\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:13:in `new\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/../shindo.rb:13:in `tests\'\r\n        ./tests/aws/models/rds/server_tests.rb:1\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:61:in `load\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:61:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:58:in `each\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:58:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `initialize\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `new\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:49:in `run_in_thread\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/lib/shindo/bin.rb:72\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/bin/shindont:4:in `require\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/gems/shindo-0.3.5/bin/shindont:4\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/bin/shindont:23:in `load\'\r\n        /home/travis/.rvm/gems/ruby-1.8.7-p371/bin/shindont:23\r\n```\r\n\r\nThe final output is:\r\n\r\n```\r\nNo output has been received in the last 10 minutes, this potentially indicates a stalled build or something wrong with the build itself.\r\n\r\nThe build has been terminated\r\n```\r\n'
1545,'','[Rackspace|CDN]  Purge CDN-Enabled Objects\nAdded the ability to purge objects from CDN. Added cdn tests and mocks.'
1544,'','[glesys] The ip part of Glesys has some holes in it\nThe `Fog::Compute::Glesys::Ip` and `Fog::Compute::Glesys::Ips` models didn\'t work very well. When trying to fetch a ip for example no `ip` was returned, only `platform` and `datacenter`. So today I refactored most of the Glesys ip management in Fog.\r\n\r\n## Example code\r\n\r\n```ruby\r\nglesys = Fog::Compute[:glesys]\r\n\r\nglesys.ips # list all your own ips\r\nglesys.ips.free(:datacenter => "Falkenberg", :platform => "OpenVZ", :version => 4) # list all ips in the glesys ip pool on a particular datacenter and platform\r\nglesys.ips.get("127.0.0.1") # get a ip you own\r\nglesys.ips.attached # list all ips attached to a server\r\nglesys.ips.available # list all ips not attached to a server\r\nglesys.ips.take("127.0.0.1") # Take a ip that and attach it to your glesys account\r\nglesys.ips.release("127.0.0.1") # Release a ip, remove it from your account\r\nglesys.ips.attach(ip, server) # Attach a ip to a server\r\nglesys.ips.remove(ip) # Remove a ip from the server it is attached ot\r\n\r\nserver = glesys.servers.first\r\nserver.ips.attach(ip) # Attach a ip to the current server\r\nserver.ips.all # List the current ips attached to the server\r\nserver.ips.remove(ip) # Remove the ip from the server\r\nserver.ips.free # Returns a list of ips that is free from Glesys  ip pool and suits the current server\r\n\r\nip_address = server.ips.free.sample\r\nserver.ips.take ip_address, :attach => true # Attach a random new ip to the server\r\n\r\nip = glesys.ips.first\r\nip.attached? # Is the current ip attached?\r\nip.release # Release the ip, remove it from your account. Will raise a error if the ip is attached to a server\r\nip.attach(s) # Attach the ip to a server\r\nip.remove # Remove a ip if it is attached to a server\r\nip.destroy # Remove and release a ip\r\n```'
1543,'',"Decide and consolidate on layout and location of examples/starting guides etc.\nWe have a mix of documentation and examples scattered across the project and the fog.io website.\r\n\r\nGetting started guides, examples of using providers and the like.\r\n\r\nWe've discussed it in several places:\r\n\r\n* https://github.com/fog/fog/issues/1281\r\n* https://groups.google.com/forum/?fromgroups=#!topic/ruby-fog/r49Bpinncrk\r\n* https://github.com/fog/fog/pull/1532\r\n\r\nSo whilst we have sorted the general principal we still haven't decided on the standard places for these sorts of things.\r\n\r\nWe also haven't updated contribution guidelines to cover them as well.\r\n\r\nThis ticket is here to finalise a decision and to free up https://github.com/fog/fog/pull/1532 from the same discussion.\r\n\r\n/cc @geemus, @rubiojr, @krames and @rupakg "
1542,'','[openstack|compute] configurable :openstack_endpoint_type\n:openstack_endpoint_type is missing as a recognized parameter. This\r\npatch fixes that, and allows the :openstack_endpoint_type to be\r\nconfigurable instead of hardcoding the value to \'publicURL\'\r\n\r\nThat is, you can create the connection to the service as follows:\r\n\r\nrequire \'fog\'\r\n\r\nconn = Fog::Compute.new({\r\n:provider => \'OpenStack\',\r\n:openstack_api_key => ENV[\'OS_PASSWORD\'],\r\n:openstack_username => ENV["OS_USERNAME"],\r\n:openstack_auth_url => ENV["OS_AUTH_URL"]\r\n:openstack_tenant => ENV["OS_TENANT_NAME"],\r\n:openstack_endpoint_type => \'adminURL\', # publicURL, adminURL, etc\r\n})\r\n\r\nDefaults to publicURL to maintain backwards compatibility.'
1541,'','[rackspace|networks] Rackspace Cloud Networks\nAllows networks CRUD and creation of servers with custom networks.'
1540,'','[rackspace|dns] fix issue with zones.find when no links are provided\nLooks like there is a scenario where no links are returned, last page of data or if limit is greater than the total number of records.\r\n\r\n@minter does this fix work with your scenario?'
1539,'','Fog::Compute::Ecloud::Servers create method returns \'invalidsshkey\'\nThe error \'Error message="Ssh key id \'0\' is invalid." majorErrorCode="400" minorErrorCode="InvalidSshKey\' is always returned from the Terremark ecloud server when attempting to create a VM from template using the ecloud module - this is due to incorrect formatting of the xml that is passed to the Terremark server. According to Terremark\'s eCloud API documentation, the SshKey element should be nested within the LinuxCustomization element, but it is created outside using this method.\r\n\r\nThis patch fixes the problem.'
1538,'','Fog::Compute::Ecloud::Servers create method returns \'invalidsshkey\'\nThe error *\'Error message="Ssh key id \'0\' is invalid." majorErrorCode="400"         minorErrorCode="InvalidSshKey\'* is always returned from the Terremark ecloud server when attempting to create a VM from template using the ecloud module - this is due to incorrect formatting of the xml that is passed to the Terremark server. According to Terremark\'s eCloud API documentation, the SshKey element should be nested within the LinuxCustomization element, but it is created outside using this method.\r\n\r\nThis patch fixes the problem:\r\n\r\n    --- fog_fog/lib/fog/ecloud/requests/compute/virtual_machine_create_from_template_b.rb   2013-01-31 19:58:43.009360899 +0000\r\n    +++ fog_fog/lib/fog/ecloud/requests/compute/virtual_machine_create_from_template.rb     2013-01-31 19:59:50.037553661 +0000\r\n    @@ -90,8 +90,8 @@\r\n                         end\r\n                       end\r\n                     end\r\n    +                xml.SshKey(:href => options[:ssh_key_uri])\r\n                   end\r\n    -              xml.SshKey(:href => options[:ssh_key_uri])\r\n                 end\r\n                 xml.PoweredOn options[:powered_on]\r\n                 xml.Template(:href => options[:template_uri], :type => options[:template_type])'
1537,'',"Added Internet Archive S3 like server API support\nThe Internet Archive (IA) supports an S3 like server API.\r\n\r\nhttp://archive.org/help/abouts3.txt\r\n\r\nThere are examples of using this with other languages, such as accessing IA with boto for python, but no great ruby support, so I wanted to add it to fog so I could use IA with carrier wave and other places I now use fog for s3 access.\r\n\r\nIA uses a different url (us.archive.org instead of amazonaws.com), and has enough other differences (and limitations) that I think it warranted being its own provider and storage service rather than patch the AWS provider to allow overriding the base url (which is hard coded throughout the AWS provider code).\r\n\r\nThis pull request is based almost entirely on copying just the (s3) storage service from AWS, changing the naming for code and tests, and including some better defaults such as using schema = 'http', and port = 80, and stripping out AWS specific code related to IAM.\r\n\r\nLet me know what you think of this approach.\r\n\r\nMy plan from here is to enhance this working code with more IA specific functionality.  I want to remove some things it does not support, and it has many of its own options and additional meta data on buckets and files. That said, this is functional and usable now, tests pass, and so I feel comfortable submitting at least this much in a pull request, and for others to use.\r\n\r\nThanks for your consideration.\r\n- Andrew"
1536,'',"Fix warning\nFix for warning:\r\n\r\nExcon#ssl_verify_peer is deprecated, use Excon.defaults[:ssl_verify_peer] instead (xxx/bundle/ruby/1.9.1/gems/fog-1.9.0/lib/fog/rackspace/storage.rb:97:in `initialize')"
1535,'','Add support for pulling in >100 zones via Zones.each.\nThis patch was inspired by the comments to #1172.\r\n\r\nUses the hypermedia links returned by the response body to determine whether or not there are more results available.  If so, it loops over those until there is no more "next" link, indicating the last set of results.\r\n\r\nIt feels like this code could be a little cleaner, but I\'m using both the "domains" body subset as well as the "links" one, which makes it different than Zones.all.\r\n\r\nAnd I could probably use more test guidance, @brianhartsock - I didn\'t know if the proper way to do this would be to create 100+ dummy domains in testing (seemed like overkill).\r\n\r\nBut it fills a need that I have to iterate over all 300+ domains in an account, and I\'ve used it locally to do work, so the code itself seems solid.'
1534,'','can\'t create OpenStack images in mock mode\nIn order for fog\'s mocking to be useful, I need to be able to specify my own data. A surprisingly time-consuming amount of digging eventually turned up that I\'m meant to enable mocking and then just create whatever objects I need. This doesn\'t work for Images in the OpenStack provider, though. Witness:\r\n\r\n```\r\nFog.mock!\r\nFog::Compute::OpenStack::Image.new(:name => \'foo\', :id => \'foooo\')\r\nArgumentError: service is required for this operation\r\n  [backtrace elided]\r\n```\r\n\r\nI don\'t even know where to begin fixing this. I haven\'t been able to find any documentation on how mocking works, or how to create a new provider, or really anything about how to use this feature aside from "use Fog.mock! and it all works!"'
1533,'',"[glesys] Consistent naming of attributes\nI saw that the attributes in glesys template weren't consistent. This update will fix the naming. And this won't break anything since fog isn't released since I added the attributes. :v:\r\n\r\nLucky me!"
1532,'','[rackspace|compute] Adds documentation and examples for Rackspace Cloud Servers\nThis pull request contains getting started and API documentation along with sample code for Rackspace implementation of compute.'
1531,'',"OSX Mountain Lion HTTPS SSL issue: SSL_connect SYSCALL returned=5 errno=0 state=SSLv2/v3 \n\r\nI'm seeing an issue when I use the Fog 1.9.0 gem on Mac OSX Mountain Lion 10.8.2.\r\n\r\n```\r\nruby-1.9.3-p286@dynamodb/gems/excon-0.16.10/lib/excon/ssl_socket.rb:60:in `connect': SSL_connect SYSCALL returned=5 errno=0 state=SSLv2/v3 read server hello A (OpenSSL::SSL::SSLError) (Excon::Errors::SocketError)\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/excon-0.16.10/lib/excon/ssl_socket.rb:60:in `initialize'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/excon-0.16.10/lib/excon/connection.rb:364:in `new'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/excon-0.16.10/lib/excon/connection.rb:364:in `socket'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/excon-0.16.10/lib/excon/connection.rb:192:in `request_kernel'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/excon-0.16.10/lib/excon/connection.rb:103:in `request'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/fog-1.9.0/lib/fog/core/connection.rb:21:in `request'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/fog-1.9.0/lib/fog/aws/dynamodb.rb:130:in `request'\r\n\tfrom /Users/ddaniels/.rvm/gems/ruby-1.9.3-p286@dynamodb/gems/fog-1.9.0/lib/fog/aws/requests/dynamodb/list_tables.rb:22:in `list_tables'\r\n\tfrom ./dynamo-manage.rb:85:in `<main>'\r\n```"
1530,'rubiojr','[openstack|tests] fix deprecation warnings\nThis is intended to be a semi-long-running pull request to fix/cleanup/add openstack tests. The first commit just fixes some deprecated calls. More soon.'
1529,'','Fog::Compute::OpenStack::Server assumes key names for network addresses \n5e695499b97 assumes that the API result from OpenStack will have keys named "public" and "private" - which is not a valid assumption. I believe the keys are created, based on the name of the network, that is set up by the administrator when they do a `nova-manage network create` command. In essence, they are arbitrary values - and this code assumes that every administrator will set up their network names *exactly* like how TryStack does.\r\n\r\n```\r\n=>   <Fog::Compute::OpenStack::Server\r\n    id="8cf5b52a-1997-4470-8a4f-019ea2089239",\r\n    instance_name=nil,\r\n    addresses={"novanetwork"=>[{"version"=>4, "addr"=>"192.168.0.43"}, {"version"=>4, "addr"=>"69.25\r\n    flavor={"id"=>"2", "links"=>[{"href"=>"http://69.252.239.152:8774/1ad62edcb7664bc4b8742f5e69d983\r\n    host_id="b11c976307ec7ecac25ad49469dcc3d098746e37754be346b8deca52",\r\n    image={"id"=>"8e60f33c-3c58-4e1e-9998-32f2c3d72ac8", "links"=>[{"href"=>"http://69.252.239.152:8\r\n    metadata=    <Fog::Compute::OpenStack::Metadata\r\n      []\r\n    >,\r\n    links=[{"href"=>"http://69.252.239.152:8774/v2/1ad62edcb7664bc4b8742f5e69d9837f/servers/8cf5b52a\r\n    name="scott-test1",\r\n    personality=nil,\r\n    progress=0,\r\n    accessIPv4="",\r\n    accessIPv6="",\r\n    availability_zone=nil,\r\n    user_data_encoded=nil,\r\n    state="ACTIVE",\r\n    created=2013-01-29 21:41:48 UTC,\r\n    updated=2013-01-29 21:42:01 UTC,\r\n    tenant_id="919cddb917a2427bb8d915515802bab6",\r\n    user_id="cfed6ad6b72540558d2f66196da7477a",\r\n    key_name="sadkin00c_rsa",\r\n    fault=nil,\r\n    os_dcf_disk_config="MANUAL",\r\n    os_ext_srv_attr_host="oscomp-ch2-a03",\r\n    os_ext_srv_attr_hypervisor_hostname=nil,\r\n    os_ext_srv_attr_instance_name="instance-00000363",\r\n    os_ext_sts_power_state=1,\r\n    os_ext_sts_task_state=nil,\r\n    os_ext_sts_vm_state="active"\r\n  >\r\n[19] pry(main)> serv.public_ip_address\r\n=> nil\r\n[20] pry(main)> serv.private_ip_address\r\n=> nil\r\n[21] pry(main)> serv.addresses\r\n=> {"novanetwork"=>\r\n  [{"version"=>4, "addr"=>"192.168.0.43"},\r\n   {"version"=>4, "addr"=>"69.252.249.90"}]}\r\n```'
1528,'',"[openstack|compute] rename meta_hash to to_hash; make it public\nOpenStack's metadata class has a private `meta_hash` method. OpenStack metadata can be represented by a hash, and it'd be super rad to be able to do so.\r\n\r\nThis commit changes that method to be called `to_hash` and makes it a public method."
1527,'','[rackspace|identity] Fix credential parsing.\n'
1526,'',"[openstack|compute] fix get_metadata call\n`get_meta` isn't a method. `get_metadata` is :)"
1525,'','[digitalocean|compute] initial release\nDigitalOcean Compute Service Provider.\r\nSee https://www.digitalocean.com/api'
1524,'',"Set the User-Agent as 'fog' instead of 'hpfog'\nThis will help differentiate from HP's CLI tools that have a vendored 'hpfog' vs. mainline fog. @rupakg your thoughts?"
1523,'','Pass the management URL also\nWhen an implementation of Openstack does not have a public endpoint, the management URL needs to be passed.'
1522,'',"[openstack|storage] replace 'object_store' service type with 'object-store'\nSee #1496"
1520,'','Allow selection of domains via substring\nAdd a zones.find(substring) method to return only zones whose name matches that substring.\r\n\r\nUses the domain filter method detailed here: http://docs.rackspace.com/cdns/api/v1.0/cdns-devguide/content/list_domains.html'
1519,'',"[Glesys] Bugs and new features added to glesys compute server model\nThere is several errors in the glesys compute server model like attributes that are present but they shouldn't and attributes missing. I've cleaned up the attributes to match Glesys API. Other changes include a `setup()` method is added to setup the server, a wrapper around  `ssh()` method to us the `rootpassword` attribute if available and a `public_ip_address()` method.\r\n\r\nI would like to change the name on some attributes, is this viable? @geemus @antonlindstrom"
1518,'',"[glesys] Errors in Glesys templates\nSeveral errors in glesys template list request. Every time the template list was requested two requests was made to the same endpoint with the same arguments returning the same result, that is now fixed. The template model didn't map attributes correct, that is also fixed. :dancers:"
1517,'','OpenStack: get identity tests passing in real mode\nUpdates to the OpenStack identity tests to they pass in both real\r\nand mock modes.\r\n\r\nAlso, fixes an issue in the delete_user_role request where it\r\nwas expecting 200 instead of 204 (which seems to match the\r\nspec and implementation).'
1516,'','1.9 regression: AWS .bootstrap raises: connection closed by remote host (Net::SSH::Disconnect)\nI\'ve confirmed that the same call to fog does not occur in 1.8.0:\r\n\r\n```\r\n          server = fog_compute.servers.bootstrap({\r\n            :public_key_path => public_key_path,\r\n            :private_key_path => private_key_path,\r\n            :flavor_id => size,\r\n            :bits => 64,\r\n            :username => "ubuntu"\r\n          })\r\n```\r\n\r\nGives:\r\n\r\n```\r\n/Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/packet_stream.rb:87:in `next_packet\': connection closed by remote host (Net::SSH::Disconnect)\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:172:in `block in poll_message\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:167:in `loop\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:167:in `poll_message\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:204:in `block in wait\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:202:in `loop\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:202:in `wait\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh/transport/session.rb:81:in `initialize\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh.rb:186:in `new\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/net-ssh-2.6.3/lib/net/ssh.rb:186:in `start\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/core/ssh.rb:66:in `run\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/compute/models/server.rb:58:in `ssh\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/compute/models/server.rb:66:in `block in sshable?\'\r\n\tfrom /Users/drnic/.rvm/rubies/ruby-1.9.3-p374/lib/ruby/1.9.1/timeout.rb:68:in `timeout\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/compute/models/server.rb:66:in `sshable?\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/aws/models/compute/server.rb:205:in `block in setup\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/core/model.rb:74:in `instance_eval\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/core/model.rb:74:in `block in wait_for\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/core/wait_for.rb:5:in `wait_for\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/core/model.rb:65:in `wait_for\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/aws/models/compute/server.rb:205:in `setup\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p374/gems/fog-1.9.0/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap\'\r\n```\r\n\r\nThe VM exists and I can manually SSH into it as ubuntu user.'
1515,'','A whitespace fix :v:\nChange from tab to spaces, like the rest of the file.'
1514,'','[glesys] Ability to pass in options to server details\nThis gives us the option include the :includestate option in the\r\nrequest. And when this option is set to true we will get the status of\r\nthe server.'
1513,'','hp provider is broken in 1.9.0 and again in master\nEverything works in 1.8.0. In 1.9.0, this bug was introduced:\r\n```\r\n[2] pry(main)> c2 = Fog::Compute.new(:provider => \'HP\', :hp_secret_key => ENV[\'HP_SECRET_KEY\'], :hp_tenant_id => ENV[\'HP_TENANT_ID\'], :hp_account_id => ENV[\'HP_ACCESS_KEY\'], :hp_avl_zone => :az2)\r\nArgumentError: wrong number of arguments (0 for 3)\r\nfrom /Users/mray/.rvm/gems/ruby-1.9.3-p362/gems/fog-1.9.0/lib/fog/core/provider.rb:22:in `service\'\r\n```\r\n\r\nThere was a major merge from @rupakg and after connections can be made again (#1511), there\'s some weirdness:\r\n```\r\n[2] pry(main)> c2 = Fog::Compute.new(:provider => \'HP\', :hp_secret_key => ENV[\'HP_SECRET_KEY\'], :hp_tenant_id => ENV[\'HP_TENANT_ID\'], :hp_access_key => ENV[\'HP_ACCESS_KEY\'], :hp_avl_zone => \'az2\')\r\n=> #<Fog::Compute::HP::Real:70205245572940 @hp_access_key=XXX @connection_options={:headers=>{"User-Agent"=>"hpfog/0.0.19"}} @hp_tenant_id=XXX @hp_compute_uri="https://region-a.geo-1.identity.hpcloudsvc.com:35357/v2.0/" @auth_token="HPAuth_df550e7074aa9dc371373317ea96dade624653877e88cfbf6c2a2020358bcaac" @host="region-a.geo-1.identity.hpcloudsvc.com" @path="/v2.0/" @persistent=false @port=35357 @scheme="https" @connection=#<Fog::Connection:0x007fb3dd6f04f8 @excon=#<Excon::Connection:7fb3dd6f0458 @connection={:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"User-Agent"=>"hpfog/0.0.19"}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/mray/.rvm/gems/ruby-1.9.3-p362@knife-hp/gems/excon-0.16.10/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"region-a.geo-1.identity.hpcloudsvc.com", :host_port=>"region-a.geo-1.identity.hpcloudsvc.com:35357", :path=>"", :port=>"35357", :query=>nil, :scheme=>"https"} @proxy=nil @socket_key="region-a.geo-1.identity.hpcloudsvc.com:35357">, @persistent=false>>\r\n```\r\nhost isn\'t picking up the az like it did with 1.8.0, the User-Agent is hpfog/0.0.19 and the port is 35357. Something is clearly broken. You can\'t make calls off the connection for flavors, images and servers.'
1512,'',"Fix for ISSUE-1511\nfixed use of '==' for assignment"
1511,'',"hp provider is unable to retrieve endpoint service URL\n```\r\n[1] pry(main)> require 'fog'\r\n=> true\r\n[2] pry(main)> c2 = Fog::Compute.new(:provider => 'HP', :hp_secret_key => ENV['HP_SECRET_KEY'], :hp_tenant_id => ENV['HP_TENANT_ID'], :hp_access_key => ENV['HP_ACCESS_KEY'], :hp_avl_zone => :az2)\r\nRuntimeError: Unable to retrieve endpoint service url for availability zone 'az2' from service catalog. \r\nfrom /Users/mray/.rvm/gems/ruby-1.9.3-p362@knife-hp/gems/fog-1.9.1/lib/fog/hp.rb:211:in `get_endpoint_from_catalog'\r\n```\r\n\r\n@rupakg, there appears to be a typo in the `get_endpoint_from_catalog' method, patch soon. "
1510,'','[libvirt|volume] Fix typo in image_suffix\n'
1509,'','OpenStack: update tenant_list tests\nUpdates the tenant_list tests to pass in *real* mode.'
1508,'','OpenStack: update used limits tests.\nUpdates the get_limits request Mock and test so that it includes the\r\nnew totalFloatingIpsUsed limit.\r\n\r\nAlso, drops the totalKeyPairsUsed limit since it is no longer used\r\nsince https://bugs.launchpad.net/nova/+bug/1089877.'
1507,'','Intermittent failures in Rackspace\nWorking with OpenStack and Rackspace, I get indeterministic failures to get the public ip with `bootstrap` on fog.\r\n\r\nAfter calling `compute.servers.bootstrap`, sometimes `bootstrap` completes, and other times it hangs indefinitely... After looking into the `indefinite hanging`, I\'ve printed the result of the `def setup(credentials)` inside `rackspace/models/compute_v2/servers.rb` to add a debugging print statement (bad, I know):\r\n\r\n        def setup(credentials = {})\r\n          pp [:setup, credentials, public_ip_address, username]\r\n          requires :public_ip_address, :identity, :public_key, :username\r\n          Fog::SSH.new(public_ip_address, username, credentials).run([\r\n            %{mkdir .ssh},\r\n             ....\r\n        end\r\n\r\nWhich will sometimes result in the STDOUT to print:\r\n   \r\n    [:setup, {:password=>"VZ6qXX4wXYpA"}, "", "ubuntu"]\r\n\r\n'
1506,'','Add support for a few missing AWS tags in cloudwatch:ListMetrics and ec2:DescribeInstances\nThese were previously missing so I added them. Also ignores ctags files in .gitignore.\r\n\r\nLet me know if you want me to split these up.'
1505,'','Update hpfog 0.0.19 to upstream fog 1.9.0 (2)\nMerge the latest code from fog 1.9.0 release. Sync up with latest HP Fog providers (hpfog v0.0.19) release.\r\n\r\nAdd BlockStorage provider, add volumes and snapshots support. Add support for bootable volumes, persistent servers, cross-tenant acls and temp urls. Add support for Windows instances. See CHANGELOG.hp for details.\r\n'
1504,'',"OpenStack Identity delete_user_role request expected status should be 204 in Essex/Folsom\nFolks, I wonder if the delete_user_role identity request shouldn't expect 204?\r\n\r\nhttp://docs.rackspace.com/openstack-extensions/auth/OS-KSADM-admin-devguide/content/DELETE_deleteRoleFromUserOnTenant_v2.0_tenants__tenantId__users__userId__roles_OS-KSADM__roleId__Admin_API_Service_Developer_Operations-d1e1357.html#d463e1799\r\n\r\nTests against our Folsom Keystone confirm this I believe. Also:\r\n\r\nhttps://github.com/openstack/keystone/blob/stable/essex/keystone/identity/core.py#L533\r\n\r\ndoes not return value and that should be a 204 as I've been told.\r\n\r\nCurrently expects 200, Is that correct?\r\n\r\n@Keoven?"
1502,'','Update hpfog 0.0.19 to upstream fog 1.9.0\nMerge the latest code from fog 1.9.0 release. Sync up with latest HP Fog providers (hpfog v0.0.19) release.\r\n\r\nAdd BlockStorage provider, add volumes and snapshots support. Add support for bootable volumes, persistent servers, cross-tenant acls and temp urls. Add support for Windows instances. See CHANGELOG.hp for details. '
1501,'','[storm_on_demand] Fix sample config file values\nStorm On Demand values need underscrores'
1500,'','[rackspace|compute] fixing connection deprecation warnings\n fixing connection deprecation warnings'
1499,'',"Create mock aws instances\nHi,\r\n\r\nI'm trying to create some mock instances so when in mock mode I want to be able to run Fog::Compute[:aws].describe_instances I get mock objects but I can't seem to find such a model or request for this.\r\n\r\nThanks,\r\nJay"
1498,'','[openstack|identity] Configurable :openstack_endpoint_type\n:openstack_endpoint_type is missing as a recognized parameter. This\r\npatch fixes that, and allows the :openstack_endpoint_type to be\r\nconfigurable instead of hardcoding the value to \'adminURL\'\r\n\r\nThat is, you can create the connection to the service as follows:\r\n\r\nrequire \'fog\'\r\n\r\nconn = Fog::Identity.new({\r\n:provider => \'OpenStack\',\r\n:openstack_api_key => ENV[\'OS_PASSWORD\'],\r\n:openstack_username => ENV["OS_USERNAME"],\r\n:openstack_auth_url => ENV["OS_AUTH_URL"]\r\n:openstack_tenant => ENV["OS_TENANT_NAME"],\r\n:openstack_endpoint_type => \'publicURL\', # publicURL, adminURL, etc\r\n})\r\n\r\nDefaults to adminURL to maintain backwards compatibility.'
1497,'','[openstack|volume] Configurable :openstack_endpoint_type\n:openstack_endpoint_type is missing as a recognized parameter. This\r\npatch fixes that, and allows the :openstack_endpoint_type to be\r\nconfigurable instead of hardcoding the value to \'adminURL\'\r\n\r\nThat is, you can create the connection to the service as follows:\r\n\r\nrequire \'fog\'\r\n\r\nconn = Fog::Volume.new({\r\n  :provider => \'OpenStack\',\r\n  :openstack_api_key => ENV[\'OS_PASSWORD\'],\r\n  :openstack_username => ENV["OS_USERNAME"],\r\n  :openstack_auth_url => ENV["OS_AUTH_URL"]\r\n  :openstack_tenant => ENV["OS_TENANT_NAME"],\r\n  :openstack_endpoint_type => \'publicURL\', # publicURL, adminURL, etc\r\n})\r\n\r\nDefaults to adminURL to maintain backwards compatibility.'
1496,'',"OpenStack Storage Service\nMostly a copy&paste from Rackspace Storage:\r\n\r\n* Obvious name replacements (s/rackspace/openstack)\r\n* Use OpenStack.authenticate_v2 authentication\r\n* Removed CDN stuff for now, since I'm not sure if that's present in vanilla Swift installs.\r\n* Ported also the tests from Rackspace\r\n\r\nAll the tests passing, tested against Swift 1.4.8 (Ubuntu Precise) and Keystone 2012.2 (Precise again, backports from the Ubuntu Cloud archives)"
1495,'','[rackspace|compute] fixes chef bug #1492\nThis should address bug #1492 which is preventing chef from creating Rackspace Servers with Fog 1.9.0.\r\n\r\n@brianhartsock @bradgignac - Could you guys review please? Thanks!\r\n\r\n@geemus Due to the major impact of this bug on chef users, would it be possible to cut another release after this commit is accepted?\r\n\r\nThanks!'
1494,'','[openstack] string interpolation problem image create fixes #1493\nRelated issue https://github.com/fog/fog/issues/1493'
1493,'','Glance image create broken properties\nWhen creating a new image on openstack the image properties aren\'t set correctly.\r\nAfter uploading a image the properties look like this:\r\n```ruby\r\nFog::Image.new(provider: :openstack).images.first.properties\r\n>> {"\\#{key}"=>"0.7.0"}\r\n```\r\nSomething wen\'t wrong with string interpolation.'
1492,'',"Unable to Create Next Gen Rackspace Servers with Chef\nAn issue was reported this morning stating that knife was throwing the following exception when attempting to create a server:\r\n\r\n/var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/rackspace/models/compute_v2/server.rb:70:in `metadata=': Please save server before accessing metadata (RuntimeError)\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/attributes.rb:146:in `send'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/attributes.rb:146:in `merge_attributes'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/attributes.rb:141:in `each'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/attributes.rb:141:in `merge_attributes'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/model.rb:20:in `initialize'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/rackspace/models/compute_v2/server.rb:51:in `initialize'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/collection.rb:116:in `new'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/collection.rb:116:in `new'\r\nfrom /var/lib/gems/1.8/gems/fog-1.9.0/lib/fog/core/collection.rb:51:in `create'\r\nfrom /var/lib/gems/1.8/gems/knife-rackspace-0.6.2/lib/chef/knife/rackspace_server_create.rb:166:in `run'\r\nfrom /var/lib/gems/1.8/gems/chef-10.18.2/lib/chef/knife.rb:408:in `run_with_pretty_exceptions'\r\nfrom /var/lib/gems/1.8/gems/chef-10.18.2/lib/chef/knife.rb:168:in `run'\r\nfrom /var/lib/gems/1.8/gems/chef-10.18.2/lib/chef/application/knife.rb:123:in `run'\r\nfrom /var/lib/gems/1.8/gems/chef-10.18.2/bin/knife:25\r\nfrom /usr/local/bin/knife:19:in `load'\r\nfrom /usr/local/bin/knife:19\r\n\r\nFor more details see http://tickets.opscode.com/browse/KNIFE-217.\r\n\r\nI believe I have a fix and I will be submitting a pull request shortly."
1491,'','[glesys] Add description to server model\nOn Glesys it is possible to add a description to servers. Make that description available through fog.'
1490,'geemus','[tests] Changes to format testing helper\n* Adds and documents Shindo::Tests#data_matches_schema\r\n* Deprecates Shindo::Tests#format method\r\n* Strict mode is replace by expandable options\r\n* Uses Fog::Logger instead of p for debug output\r\n* Shindo::Tests#formats_kernel removed (was private)\r\n* Shindo::Tests#confirm_data_matches_schema added\r\n* #confirm_data_matches_schema uses yield\r\n\r\nRelated to issue #1477\r\n\r\nShindo::Tests#formats incorrectly treated missing keys as valid if their\r\nvalue is allowed to be "nullable" or NilClass. These keys are not\r\noptional. They are required but can be the value nil or the Nullable\r\nclass.\r\n\r\nUnfortunately due to lack of documentation and a bug in the code the\r\ncurrent Nullable classes can be interpreted as optional and work as such.\r\n\r\nThis replaces the old format checker with a new version that supports\r\noptions to control the matching behaviour related to extra keys in\r\neither the data or the schema.\r\n\r\nThis corrects the behaviour so extra keys in either the schema or the\r\nsupplied data fail the check unless non strict has been used.\r\n\r\nA legacy version of the #formats test is in place that passes the\r\noptions so it behaves as the old version does.\r\n\r\nPremptive patches have been added to fix those tests that were already\r\nbroken but passed the original checks.'
1489,'','Introduce Fog::AWS.compliant_bucket_names reader.\nAttempts to access Fog::AWS::COMPLIANT_BUCKET_NAMES from\r\noutside fog (e.g. carrierwave) result in uninialized constant error.\r\n\r\nImpetus for this change is that carrierwave defines slightly different regex\r\n(https://github.com/jnicklas/carrierwave/blob/master/lib/carrierwave/storage/fog.rb#L293)\r\nto determine whether to use path or subdomain style bucket access and\r\nit seems better to re-use this constant from fog. However attempts\r\nto access the COMPLIANT_BUCKET_NAMES constant via ::Fog::AWS::COMPLIANT_BUCKET_NAMES fail.\r\n\r\nAm I missing something or does this change make sense?'
1488,'tokengeek',"[Brightbox] General updates\nRequest to update firewall policies and a server's compatibility mode flag have been added to the API. This pull request adds these to fog"
1486,'','[xenserver|docs] Added XenServer provider specific ChangeLog\nHandcrafted with love.\r\n\r\nNo other provider does this AFAIK but hopefully it does no harm having it there?'
1485,'',"Added some task descriptions so they show up with 'rake -T'\nI guess it does no harm to have some additional task descriptions\r\nand help our memory.\r\n\r\nBefore:\r\n\r\n    rake changelog  # Update the changelog since the last release\r\n    rake console    # Open an irb session preloaded with this library\r\n    rake test       # Run the mocked tests\r\n    rake yard       # Generate YARD Documentation\r\n\r\nNow:\r\n\r\n    rake build      # Build fog-1.8.0.gem\r\n    rake changelog  # Update the changelog since the last release\r\n    rake console    # Open an irb session preloaded with this library\r\n    rake gemspec    # Updates the gemspec and runs 'validate'\r\n    rake test       # Run the mocked tests\r\n    rake validate   # Run before pushing out the code\r\n    rake yard       # Generate YARD Documentation\r\n\r\nDidn't want to describe all since some of them look potentially\r\nunsafe for non core devs. I can document them otherwise.\r\n"
1484,'','[openstack] arbitrary network ID in addresses\nThis is somewhat related to: https://github.com/fog/fog/pull/933\r\n\r\nRather than the standard "public" and "private" elements, some OpenStack providers are returning other names for network ID in server response, e.g. for the Nectar cloud (http://www.nectar.org.au/research-cloud), I am seeing: \r\n\r\n```"addresses":  {\r\n    "queensberry" : [\r\n        {\r\n            "version": 4,\r\n            "addr": "123.123.123.123"\r\n        }\r\n    ]\r\n}```\r\n\r\nMy first question is: does anyone know if this is actually legal w.r.t. the OpenStack API, I can\'t find any reference which specifically says it\'s *not* legal, although all their examples seems to only have "public" and "private" for network IDs.\r\n\r\nI\'m prepared to start working on a patch to handle arbitrary network IDs if it is indeed legal.'
1483,'','[Rackspace] updated to select default auth end point based on selected endpoint\nI updated Rackspace services to select default auth end point based on selected endpoint to make things more convenient for consumers of the UK Rackspace Cloud.\r\n\r\nThe developer is still able to override the default auth endpoint.'
1482,'',"[vsphere] vsphere fixes for latest HEAD changes\nCorrect use of Fog.mock? instead of ENV\r\nUse find_raw_datacenter to avoid the need of extra permissions\r\nFind datastores in subfolders\r\nnil pointer when finding vm\r\n\r\nI'm working on better mocks at another branch but I'm not done yet, need access to a vsphere server which hopefully will happen next week\r\nhttps://github.com/maestrodev/fog/tree/vsphere-tests"
1481,'','Added describe_reserved_cache_clusters to Elasticache\n'
1479,'','[vsphere] searching for VM improved to search whole cluster instead of current folder.\nThe current search options will either only find based on UUID or by VM name. The issue with the VM name is it will only check the top level folder instead of the whole datacenter which means if you use folders for organization the VM will never be found unless at top level. I also moved some functionality to a new function so other functions can take advantage of it without having to duplicate code. Like if I want to just verify that a VM exists and a method can be created to call and verify that a VM was returned as oppose to going through the hash build.\r\n\r\nThe only caveat is the get_virtual_machine will take a while depending on how many VMs are returned because the attribute of the name appears to not be included as part of the view created and accessing that property looks like it makes another call which slows down the entire process.\r\n\r\nraw_list_all_virtual_machines method was created and list_all_virtual_machines calls it so methods like the get_vm_by_name do not have to wait for the hash build from list_all_virtual_machines because the hash build is very slow depending on the VMs returned. An example would be, in my environment we have 600 VMs and just searching for a name takes about ~30 seconds, to build the hash takes about ~4 minutes.'
1478,'',"[vsphere] fixed an issue introduced in commit e8630a0 where @service is nil\nThere appears to have been a bug that made its way in that causes this error when attempting to find a VM by UUID. This change I submitted reverts the specific line to before commit SHA: e8630a00831cc17d61d48af9501773002dccc165 .\r\n\r\nNoMethodError: undefined method `searchIndex' for nil:NilClass\r\n\tfrom /Users/mblack/.rvm/gems/ruby-1.9.3-p125/gems/fog-1.8.0/lib/fog/vsphere/requests/compute/get_virtual_machine.rb:15:in `get_vm_ref'\r\n\tfrom /Users/mblack/.rvm/gems/ruby-1.9.3-p125/gems/fog-1.8.0/lib/fog/vsphere/requests/compute/get_virtual_machine.rb:6:in `get_virtual_machine'\r\n\tfrom (irb):5"
1477,'tokengeek','Formats helper does not complain when "nullable" values are missing\nWhen comparing API output with `Shindo::Tests#formats` it should complain when a key is missing.\r\n\r\nThere is a bug such that this does not happen when the value is expected to be `NilClass` or any "nullable" class such as `Fog::Nullable::String`\r\n\r\n### Expected\r\n\r\n```\r\n# :a is missing, invalid format\r\nformats_kernel({}, {:a => Fog::Nullable::String}) # => false\r\n```\r\n\r\n### Actual\r\n```\r\nformats_kernel({}, {:a => Fog::Nullable::String}) # => true\r\n```\r\n\r\nThese of course need to be tested in the context of `Shindo`. I have added test cases to `tests/helpers/formats_helper_tests.rb` to confirm. Will push the test cases to a suitable branch when I have an issue number.'
1476,'','adds support for bucket transitioning/fixes bucket lifecycle management\nThis tries to preserve the original behaviour of get/put _bucket_lifecycle call.  For the most part it works, calls to put a new lifecycle policy in will work with the old calls, however the return from get_bucket_lifecycle  has been modified to the be correct,  the modifications also allow for the use of full bucket policy applications, and the use of date based expiry, and transitioning to Glacier.'
1475,'','[rackspace|compute] Fix bug in bootstrap method\n fixed issue with bootstrap method where server was ready, but it had not received an ipv4 address yet. Added check for ip address in server ready block as well as a timeout parameter'
1474,'',"Ability to get Rackspace ServiceCatalog through Identity API\nRackspace introduced regions for their CloudFiles hosting platform and that means if you want to post to non-default region you need to specify the :rackspace_storage_url to the Fog::Storage constructor.\r\n\r\nFog::Rackspace::Identity.new now returns an instance that has #service_catalog method defined which will return all the services provided for a given API key and that will include all the endpoints available for CloudFiles connections. One can take that endpoint URL and pass it as :rackspace_storage_url to the Fog::Storage constructor to make it connect to the proper region.\r\n\r\nPlease let me know if there's something I can improve/change to get this applied upstream."
1473,'',"Ecloud tests are breaking live tests again\nWhen not running mocks and not having ecloud credentials the following happens:\r\n\r\n```\r\narkham:fog [master]â â¡ bundle exec shindo +aws tests/ecloud/compute/models/server_tests.rb\r\n  ...\r\n  Skipping tests for ecloud due to lacking credentials (add some to '/Users/paul/code/fog/tests/.fog' to run them)\r\n/Users/paul/code/fog/lib/fog/ecloud/compute.rb:299:in `initialize': No credentials (cloud auth, or basic auth) passed! (ArgumentError)\r\n\tfrom /Users/paul/code/fog/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /Users/paul/code/fog/lib/fog/core/service.rb:68:in `new'\r\n\tfrom /Users/paul/code/fog/lib/fog/compute.rb:30:in `new'\r\n\tfrom /Users/paul/code/fog/lib/fog/compute.rb:5:in `[]'\r\n\tfrom /Users/paul/code/fog/tests/ecloud/compute/models/server_tests.rb:2:in `<top (required)>'\r\n\tfrom /Users/paul/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `load'\r\n\tfrom /Users/paul/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread'\r\n\tfrom /Users/paul/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `each'\r\n\tfrom /Users/paul/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `block in run_in_thread'\r\n```\r\n\r\nThe problem (again) is that `tests/ecloud/compute/models/server_tests.rb` is being loaded by Shindo but part of this loading is trying `connection   = Fog::Compute[provider]` which then fails for anyone not using the mocks without ecloud credentials.\r\n\r\nMock's use their own credentials which include ecloud ones so it's only getting picked up with live tests but the code is not within the Shindo block so is getting run even when it should not (based on tagging).\r\n\r\nI already fixed this in 716f3f13be5fbfb710b8476e9cf91c5ff0376173 but it was reverted in cfc1d588478c3a89386809ca57bf0c2d96b259ee\r\n\r\n@ehowe - Was there a reason this was changed back?\r\n\r\nWithout ecloud credentials I can't run the live version to see what wasn't working and I can't see any reason why any of the values are being set outside of the Shindo block (apart from provider which doesn't need to be dynamic)."
1472,'','[rackspace] updated Rackspace to return a list of all services\nThe Rackspace class did not return all service classes thus throwing errors when attempting to execute Rackspace.collection.'
1471,'','[Rackspace|Compute] updated ready method on Image\nupdated ready method on Image to raise an exception if an error state occurs. This is similar to the behavior of Server.'
1470,'','[Rackspace|Compute] updated server.create_image to return Image Object\nUpdated create_image method on Fog::Compute::RackspaceV2::Server to return Image object instead of the object id.\r\n\r\nThe current Fog release does not contain this method and I wanted to make this change before a release was cut.'
1469,'','Add Tags to create_stack call\nCan now specify user-defined Tags to associate with the new stack.'
1468,'','Debug logging\nUpdated Logger to write debug statements out to standard out if DEBUG=true is past in through the environment'
1467,'',"[AWS|DynamoDB] Default to HTTPS\nI'm not sure if there was a reason that this wasn't defaulting to HTTPS, but figured it should."
1466,'','[docs::aws::storage] last of the aws/storage/requests\n'
1465,'','VSphere list all networks in nested folders\nsearch through all network adapters recursively to find one being searched for'
1464,'','vSphere list all VMs in nested folders\nInstead of looking at just the one directory. I create a container view for each datacenter and ask it to look for VMs recursively.\r\n'
1463,'','[rackspace] compute_v2 and blockstorage are mocked\n[ecloud] fixed a test and removed connection deprecation notices'
1462,'','[rackspace] compute_v2 and blockstorage are mocked\n[ecloud] fixed a test and removed connection deprecation notices'
1461,'','[Rackspace|Compute] update\nModified update method on Server model to update accessIPv4 and accessIPv6 as well as name. Added aliases for access_ipv4_address and :access_ipv6_address.\r\n\r\nMade tests more robust.'
1460,'tokengeek','[core] Fix service instance variable being included when doing model.to_json\n'
1459,'','Service credentials being exposed when doing model.to_json\nhttps://github.com/fog/fog/blob/master/lib/fog/core/model.rb#L15\r\n\r\ni think it shoud be @service = new_attributes.delete(:service) \r\nCalling \'to_json\' returns the service key-value pair\r\n\r\nExecuting commands like connection.images.first.to_json would return\r\n\r\n "{\\"service\\":\\"#<Fog::Image::OpenStack::Real:0x000001042d96f0>\\",\\"status\\":\\"active\\",\\"name\\":\\"cirros-0.3.0-x86_64-uec\\",\\"deleted\\":false,\\"container_format\\":\\"ami\\",\\"created_at\\":\\"2012-11-30T15:38:44\\",\\"disk_format\\":\\"ami\\",\\"updated_at\\":\\"2013-01-11T05:12:31\\",\\"properties\\":{\\"kernel_id\\":\\"477dfd38-007d-406d-9635-69e5c9420c74\\",\\"ramdisk_id\\":\\"8ec9627c-146d-4f88-858c-cdf6ebfb2137\\"},\\"min_disk\\":0,\\"protected\\":false,\\"id\\":\\"812962cd-c63a-4b66-92eb-8997d5b0555c\\",\\"checksum\\":\\"2f81976cae15c16ef0010c51e3a6c163\\",\\"owner\\":\\"e2bd3982635d4e34b6038451a2ff8db9\\",\\"is_public\\":true,\\"deleted_at\\":null,\\"min_ram\\":0,\\"size\\":25165824}" \r\n\r\n\r\n\r\n![Screen Shot 2013-01-11 at 2 08 44 PM](https://f.cloud.github.com/assets/768122/59306/b117aff6-5bb5-11e2-9e0e-9325c534b3cb.png)'
1458,'','[docs::aws::storage] more requests changing Rdoc to YARD format\n'
1457,'','[rackspace|compute] cleaned up attachment model\nI added attach_volume_method to server model and cleaned up the attachment model in order to make volumes easier to use.'
1456,'','[AWS Storage] Fix typo and use #get_header to handle mixed-case header keys\nChanges:\r\n\r\n* ```normalise_headers``` => ```normalize_headers```\r\n* Use ```get_header``` to be case insensitive when retrieving headers (Etag vs ETag)'
1455,'','Properly return all alarms\nThe alarms model was not properly checking for NextToken and was therefore only returning the first 50 alarms. This change fixes that.'
1454,'','[rackspace|compute] updated rebuild to support passing additional option...\nI updated Fog::Compute::RackspaceV2::Server to support passing additional options.'
1453,'','[xenserver] Added HostCpu model\nAdded missing HostCpu model and required tests'
1452,'','Rackspace Server/Image metadata operations\nUpdated Fog::Compute::RackspaceV2::Server and Fog::Compute::RackspaceV2::Image to support metadata operations. The implementation was inspired by the OpenStack provider.'
1451,'','Added request create_folder for vsphere compute. \nThis request will create VM folders in vsphere and returns the folder path.\r\n\r\nWorks like so...\r\n\r\n    create_folder("MyDatacenter", "WebPools/Production", "Pool01")'
1450,'','changed docs to YARD for head_object.rb\nopen to any suggestions, tips, or critiques (currently learning YARD documentation) '
1449,'','[xenserver] add missing host operations (enable/disable, reboot, shutdown)\n'
1448,'','[xenserver] StorageRepository.save should use sane defaults\n- Added required tests\r\n- Minor StorageRepository tests refactoring'
1447,'','vSphere vm_clone static ip customization\nThis change allows for a VM to be clone in vSphere and configure it with a static ip address or dhcp.\r\n\r\nIf in customization_spec hash there is an ipsettings hash it will configure for static ip if its absent it will configure for dhcp.\r\n\r\nIt needs additional work in the way of data validation. If the wrong data is put in the nic interface may not be configured or the clone process will be aborted by vSphere.\r\n\r\n'
1446,'','[ecloud] improvements and mocking\n4th times the charm?'
1445,'','Pull request to set \'NextToken\' correctly in ".../parsers/cloud_watch/describe_alarms.rb" \n\t\r\n             when \'NextToken\'\r\n-              @response[\'ResponseMetadata\'][name] = value\r\n+             @response[\'DescribeAlarmsResult\'][name] = value'
1444,'','[ecloud] Improvements and mocking\nAll tests actually pass now.  Also has 1.8 compatibility fixed.'
1443,'','[docs::aws::storage] rdoc to yard formatted all get requests\n'
1442,'','[xenserver] Use Nokogiri instead of slow REXML for parsing\n'
1441,'','Mock ecloud and add bugfixes and improvements.\nFixed 1.8 compatibility from last request and squashed commits.'
1440,'','[ecloud] Added mock support and also some bug fixes/improvements.\n'
1439,'','Aws storage mock fix\nUpdated the AWS Storage Mock class to prevent put_bucket_cors from failing during testing (with mock switched on)'
1438,'',"adding support for rackspace loadbalancer content caching\nHi,\r\n\r\nI am sending this pull request to add support to fog for rackspace's load balancers content caching feature.\r\nPlease let me know if you have any question!\r\n\r\nThanks!"
1437,'','[vsphere] allow to create a vm with multiple disks.\nunitNumber has to be unique.'
1436,'','[docs::aws::storage] reformatted fog/aws/storage/requests delete\n'
1435,'','[docs::aws::storage] reformatted delete requests\n'
1434,'','VCloud code really could use an example\nWhat about at the top of the Vcloud module we add some RDocs to show some basic usage?\r\n\r\n    compute = Fog::Compute.new(\r\n      :provider => \'vcloud\', \r\n      :vcloud_host => \'...\',\r\n      :vcloud_username => \'...\',\r\n      :vcloud_password => \'...\'\r\n    )\r\n\r\n    vdc = compute.vdcs.detect {|v| v.name == "My vDC" }\r\n    catalog = compute.catalogs.detect {|c| c.name == "My Catalog" }\r\n    template = catalog.catalog_items.detect {|i| i.name == \'precise64\' }\r\n\r\n    svr = compute.instantiate_vapp_template(\r\n      :vdc_uri => vdc.href,\r\n      :catalog_item_uri => template.href, \r\n      :name => \'fog test vapp\'\r\n    ).data\r\n    # and this is where I gave up because it\'s unclear fog even works for Vcloud\r\n'
1433,'','[docs::aws::storage] fixed some syntax and formatted a request\n'
1432,'','New xenserver features and examples\nAdded new example and the required (missing) code to make it possible.'
1431,'',"Vmware Distributed Virtual Switches\nVMware has the concept of [Distributed Virtual Switches](https://www.vmware.com/products/datacenter-virtualization/vsphere/distributed-switch.html). Currently fog doesn't support them at all and I'd like to change that. These are some very rough patches. Since I'm very new to ruby in general I'd like some feedback if this is the right path.\r\n\r\nThe only testing I've done is create a VM in the foreman and see if the VM gets the correct network backing. Known issues:\r\n* if a DVS is inside a folder instead of directly under the DC ```get_raw_network``` will not find it"
1429,'','fix register template process in cloudstack\nthere is no create_template method in cloudstack .. fix this bug.'
1428,'','Fog::Storage::AWS::Real\n\r\nAWS docs'
1427,'geemus','[docs] Creates release policy document to discuss\nThis documents the current release policy as it appears (based on the\r\nRakefile) but may not be comprehensive.\r\n\r\nFor github issue #1406'
1426,'','add IamInstanceProfile abilities to spot instances\nI filed Issue https://github.com/fog/fog/issues/1425\r\n'
1425,'','IAM Role support for spot instances\nCreating a new spot instance does not support the use of IAM Roles (the creation of an on-demand server *does* support IAM roles).'
1424,'','[vsphere] allow to create a vm with multiple disks.\nunitNumber has to be unique.'
1423,'','more docs for Fog::AWS::Storage::Model::File\nTried to have consistent formatting. \r\n\r\nAlways open to feedback.'
1422,'','Missing required arguments: openstack_auth_url(Fog::Compute.create_server & Fog.mock!)\nHi.\r\n\r\nI try to Fog::Compute.create_server("test", image.id, flavor.id) by OpenStack & Fog.mock!.\r\nbut, I got this error message.\r\n\r\nMissing required arguments: openstack_auth_url\r\n\r\nFog 1.7.0 was no problem, on same code.\r\nI write the steps to reproduce the following.\r\n\r\n\r\ngit clone git://github.com/fog/fog.git\r\n\r\ncd fog\r\n\r\nvim test.rb\r\n\r\n    require \'./lib/fog.rb\'\r\n\r\n    Fog.mock!\r\n    compute = Fog::Compute.new({\r\n      :openstack_username => \'admin\',\r\n      :openstack_api_key => \'admin\',\r\n      :openstack_tenant => \'admin\',\r\n      :openstack_auth_url => \'http://localhost:5000/v2.0/tokens\',\r\n      :provider => \'OpenStack\',\r\n    })\r\n     \r\n    flavor_name = \'256 server\'\r\n    image_name = \'cirros-0.3.0-x86_64-blank\'\r\n    flavor = compute.flavors.find { |f| f.name == flavor_name }\r\n    image = compute.images.find { |i| i.name == image_name }\r\n    server = compute.create_server("test", image.id, flavor.id)\r\n\r\nruby test.rb\r\n\r\n    /Users/kanetann/project/fog/lib/fog/core/service.rb:208:in `validate_options\': Missing required arguments: openstack_auth_url (ArgumentError)\r\n        from /Users/kanetann/project/fog/lib/fog/core/service.rb:58:in `new\'\r\n        from /Users/kanetann/project/fog/lib/fog/identity.rb:13:in `new\'\r\n        from /Users/kanetann/project/fog/lib/fog/identity.rb:5:in `[]\'\r\n        from /Users/kanetann/project/fog/lib/fog/openstack/requests/compute/create_server.rb:65:in `create_server\'\r\n        from test.rb:16:in `<main>\'\r\n    ruby test.rb  1.11s user 0.24s system 80% cpu 1.674 total\r\n\r\n'
1421,'','use CGI.escapeHTML instead of CGI.escape\nCGI.escape creates URL-safe encodings, but we need XML-safe encodings.\r\nIf the key name has a "/" in it (as for a directory structure) it gets\r\nreplaced with a URL-safe "%2F" which S3 treats as a literal part of the\r\nkey name. We only need to escape the parts of the key that could result\r\nin malformed XML.'
1420,'','S3 delete_multiple_objects for keys with "/"\nFog::Storage::AWS::Real#delete_multiple_objects doesn\'t seem to work on objects with keys that have a "/" in them.\r\n\r\nAfter digging around a bit, I think the problem is that the keys are being escaped with CGI.escape. If an object has the key "foo/bar.txt", it gets submitted to S3 as "foo%2Fbar.txt".\r\n\r\nAs the keys for multi-object deletion go into the XML body of a request instead of the headers, I think the fix might be to use CGI.escapeHTML instead of CGI.escape.\r\n\r\nhttps://github.com/jparker/fog/compare/delete_multiple_objects_escape_xml\r\n\r\nTesting that out on live data seemed to work.\r\n\r\n(It seems that S3 happily reports back to Fog that the objects have been deleted regardless of whether or not the object existed in the first place.)'
1419,'tokengeek','List of maintainers/provider and support levels.\nIt would be useful for people for us to list who has volunteered to maintain which particular provider/service or see which code is not being actively maintained.\r\n\r\nFor support levels you have providers where the companies are involved, the providers where it is a community effort with a volunteer or providers that are not quite there or abandoned.'
1417,'tokengeek','[Brightbox] Adds #dns_name to server\nLittle known fact is that the public version of the domain name of a\r\nBrightbox cloud server is the `fqdn` prefixed with public.\r\n\r\nThis is now fixed here until it is fixed in the main API and the value\r\ncan be referenced directly from the response.'
1416,'','Make use of #persisted? method\nIn many places we were checking for identity which was the shorthand for\r\nchecking if the resource had been saved by the service.\r\n\r\nThe #persisted? method was added to show a clearer intent and also offer\r\nminimal ActiveModel interface'
1415,'geemus','Deprecate connection option\nFor #1392 \r\n\r\nThis adds accessors to handle deprecation of the `connection` option, which as discussed on the ticket is actually an instance of a subclass of `Fog::Service` not `Fog::Connection` as implied.\r\n\r\nSo now passing `service` upon creation is the expected means of declaring the parent/containing service. `connection` still works but warns.\r\n\r\nLeft the tests as is so we can see the deprecated behaviour still works.\r\n\r\nSome models need to set up the service first so that they can refer there for additional data, a preliminary API call etc. These have been altered as well.\r\n\r\nIt then changes in small groups (per provider or provider/service) the calls. This change affects most models since they all piggy back on the service for requests.'
1414,'seanhandley','serverlove/models/compute/server.rb does not appear to parse\nA simple test program, such as (serverlove.rb):\r\n---\r\nrequire \'rubygems\'\r\nrequire \'fog\'\r\n\r\nFog.mock!\r\n\r\nconn = Fog::Compute.new({\r\n  :serverlove_uuid    => "XXXX",\r\n  :serverlove_api_key => "XXXX",\r\n  :provider           => "Serverlove"\r\n})\r\n\r\nserver = conn.servers.create( { :name => \'test\', :cpu => 500, :memory => 512 } )\r\n\r\nResults in the error:\r\n/Library/Ruby/Gems/1.8/gems/fog-1.8.0/lib/fog/serverlove/models/compute/server.rb:38:in `save\': undefined method `defaults\' for #<Fog::Compute::Serverlove::Server:0x1025a5fe8> (NoMethodError)\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.8.0/lib/fog/core/collection.rb:50:in `create\'\r\n\tfrom ./serverlove.rb:14\r\n\r\nI\'ve tried this on Ruby 1.8.7 under Mac OS X and Ubuntu with the same error.'
1413,'','add GitHub Flavored Markdown to README\n* This makes the example code easier to read, especially when perusing the docs on github'
1412,'',"[docs] question about how to format AWS nested responses\nFog::AWS responses typically return HTTP header hashes (from what I can tell).   I didn't see a intuitive way to format a method's semi nested @return. This PR contains a rough draft documenting it. Is this the best way to format it?  \r\n\r\nPLEASE DO NOT MERGE TO MASTER. \r\n\r\nThis PR should be closed and I'll apply feedback to rest of Fog::AWS's methods.\r\n\r\nTo see formating,\r\n````yard -n --single-db && yard server````\r\nhttp://localhost:8808/docs/Fog/Storage/AWS/Real:complete_multipart_upload"
1411,'','Added multi-region support for OpenStack Image service\nIn favor of #1407'
1410,'','fix typo\nFound a typo while looking at this file'
1409,'','[openstack|image] Configurable :openstack_endpoint_type\n:openstack_endpoint_type is missing as a recognized parameter. This\r\npatch fixes that, and allows the :openstack_endpoint_type to be\r\nconfigurable instead of hardcoding the value to \'adminURL\'\r\n\r\nThat is, you can create the connection to the service as follows now:\r\n\r\nrequire \'fog\'\r\nconn = Fog::Image.new({\r\n  :provider => \'OpenStack\',\r\n  :openstack_api_key => ENV[\'OS_PASSWORD\'],\r\n  :openstack_username => ENV["OS_USERNAME"],\r\n  :openstack_auth_url => ENV["OS_AUTH_URL"]\r\n  :openstack_tenant => ENV["OS_TENANT_NAME"],\r\n  :openstack_endpoint_type => \'publicURL\', #publicURL, adminURL, internalURL\r\n})\r\n\r\nDefaults to adminURL to maintain backwards compatibility.'
1408,'','[Rackspace] added list_addresses and list_addresses_by_network to compute_v2\nThis pull request implements  list_addresses and list_addresses_by_network for Fog::Compute::RackspaceV2'
1407,'',"Added multi-region support for OpenStack Image service\nThe OpenStack Compute class works just fine with multi-region support, but the Image class does not. This patch should resolve that -- I've been able to use it in a multi-region environment plus all tests have passed."
1406,'tokengeek',"Documented release process\nAt the moment fog releases are done (sort of) monthly by @geemus or on demand.\r\n\r\nEvery so often someone asks for a release, frequently because of a new AWS endpoint or a feature they have added.\r\n\r\n(Putting aside solutions/pending pull requests to make endpoints dynamic, not the issue)\r\n\r\nIt would be useful to document this so people wouldn't need to ask.\r\n\r\nFurther to this however is that I'm starting to work on some major refactoring of fog that may make `master` unstable.\r\n\r\nSo we can end up with the simple change (new endpoint) stuck behind an unstable change that needs full testing by all providers before we can consider a stable release. Or a new version of a provider's API.\r\n\r\nSo I think it's worth a discussion about how we should schedule future releases, relate them to branches and document that.\r\n\r\n* Do we offer a `stable` branch? `1.8_branch` ?\r\n* Aim for even minor releases being stable (1.8) and odd (1.9) less so?\r\n* Issue Release Candidates so early adopters can help test without it getting picked up by bundler for most people?\r\n* Any projects we can learn from?\r\n\r\nSome of the complexity disappears when fog goes modular and providers can version their own changes and fog is a stable snapshot of those versions, but it would be good to start somewhere.\r\n\r\nSo after a bit of discussion I'll add `RELEASE.md` to the project root with a write up. Who to speak to. Where to base changes. Which rake tasks to run.\r\n\r\nCheers!"
1405,'',"Updated default Rackspace compute provider to Cloud Server NG API\nThe legacy Rackspace Cloud Server interface is deprecated. In order to aid the transition, I have changed the default Rackspace Compute provider to return the Cloud Server NG service.\r\n\r\nIn order to access legacy Cloud Servers API, a :version => :v1 parameter will need to be passed like so:\r\n\r\nFog::Compute.new({\r\n      :provider                 => 'Rackspace',\r\n      :rackspace_username        => USER,\r\n      :rackspace_api_key    => API_KEY,\r\n      :version => :v1\r\n    })\r\n"
1404,'','Rackspace Cloud Block Storage models have the potential to create unintended resources\nThis pull request fixes #1402\r\n\r\nThe save method in both Fog::Rackspace::BlockStorage::Volume and Fog::Rackspace::BlockStorage::Snapshot create new cloud resources every time they are called. This has the potential to create unintended resources.\r\n\r\n'
1403,'','Fog::AWS::RDS::Server#security_group_names is not set\nwhen a rds server instance is retrieved it doesn\'t have security_group_names set\r\n\r\nThe work around is to compute it like this:\r\n\r\n    server.db_security_groups.map{|h| h[\'DBSecurityGroupName\']}\r\n\r\nPart of the issue here seems to be asymmetric nature of DBSecurityGroups in the AWS API. When [describing an instance](http://docs.amazonwebservices.com/AmazonRDS/latest/APIReference/API_DescribeDBInstances.html) it is array of hashes similar to this:\r\n\r\n    [{"Status"=>"active", "DBSecurityGroupName"=>"interactions"}]\r\n\r\nAnd when a [setting the values for a new instance](http://docs.amazonwebservices.com/AmazonRDS/latest/APIReference/API_CreateDBInstance.html) it is just an array of strings\r\n\r\n    ["interactions"]\r\n\r\nBut regardless security_group_names should be correctly setup when a Fog::AWS::RDS::Server is retrieved from the server.'
1402,'','Rackspace Cloud Block Storage models have the potential to create unintended resources\nThe save method in both Fog::Rackspace::BlockStorage::Volume and Fog::Rackspace::BlockStorage::Snapshot create new cloud resources every time they are called. This has the  potential  to create unintended resources.\r\n\r\nI am currently working on a fix.\r\n'
1401,'','Create snapshot\nThis pull request adds create_snapshot to Fog::Rackspace::BlockStorage::Volume model to make it more OO. #1400\r\n'
1400,'','Add create_snapshot to Fog::Rackspace::BlockStorage::Volume\nAdd create_snapshot to Fog::Rackspace::BlockStorage::Volume model to make it more OO'
1399,'',"[vsphere] Add vsphere public_ip_address correctly\nI didn't do it correctly in the previous pull request"
1398,'',"[vsphere] Add vsphere public_ip_address correctly\nI didn't do it correctly in the previous pull"
1397,'','[ecloud|compute] Fixes missing value\n`:connection` key was not paired with a value. Initializer just accepts\r\noptions hash as I read it so assume this was an oversight.'
1396,'','added floatingip methods to Fog::OpenStack::Network\n'
1395,'',"Issue/1350 [doc] added more options for aws/storage/file#save\nmerge https://github.com/fog/fog/pull/1394 before this PR.\r\n\r\nThis is an example // rough draft for how to doc technical details. This might help address goal to describe vendor/service specific details (see https://github.com/fog/fog/issues/1280). Specifically, @rupakg's  #_2 comment, \r\n\r\n> 2) Separate README per vendor including anything specific to the provider above and beyond base > doc.\r\n\r\nOpen to thoughts and opinions.\r\n"
1394,'','Issue/1350 added yard info about aws/storage/file encryption option\n'
1393,'','[AWS] CopySnapshot. supports cross-region snapshot copying.\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CopySnapshot.html'
1392,'tokengeek','Service is misnamed as `connection` within collection and models\nWhen the service code was rewritten, unfortunately `connection` was used instead of "service" which has passed down two levels and is available throughout all the models.\r\n\r\nSo within a `Fog::Model` we have `connection` attribute which is a `Fog::Service::Real` which in many cases has it\'s own `@connection` variable which is a `Fog::Connection`\r\n\r\nThis has caught me out a few times and is a source of confusion.\r\n\r\nSo the service generator passes itself as `connection` here: https://github.com/fog/fog/blob/master/lib/fog/core/service.rb#L94\r\n\r\nCollections are then built and passed the same to merge in merge to their own `connection` accessor: https://github.com/fog/fog/blob/master/lib/fog/core/collection.rb#L108\r\n\r\nFinally when collection creates a model it does the same: https://github.com/fog/fog/blob/master/lib/fog/core/model.rb#L7\r\n\r\nIn both `Collection` and `Model` it is an accessor attribute which means it may have been picked up and changed by existing code.\r\n\r\nI think we should look at replacing these with `service` so what is being dealt with is clearer.\r\n\r\nDeprecating `connection` and `connection=` as well so they still function as is.\r\n\r\nI also think it would be cleaner to initialise the service in `initialize ` rather than exposing accessor methods.\r\n\r\nI\'m happy to look at this as long as we agree it is worth fixing.'
1391,'tokengeek','[Brightbox] Standardise request\nWhilst DRYing up the code we replaced the standard version of `#request`\r\nwith one that had clearer arguments and returned parsed data.\r\n\r\nThis was mostly fine but introduced a few problems:\r\n\r\n* mock functionality expects the original interface\r\n* headers returned in request are not available\r\n\r\nThis makes the newer version available as `#wrapped_request` and as a\r\ndeprecated form through `#request`.'
1390,'tokengeek',"`Fog.credentials` is a global we should phase out of provider code\nSummary: `Fog.credentials` is a global parameter whose use has been encouraged by some of the earlier examples so has been picked up by several providers.\r\n\r\nWe spent a while looking at altering which sets of `.fog` files we should be able to load for #1314 . Specifically it was for ascending back up parent directories looking.\r\n\r\nWe could not safely allow that because that changes the possible output for `Fog.credentials` to change depending on the environment.\r\n\r\nOne thing this highlighted is that several providers and a few places in core are using a pattern where we are reading values out of `Fog.credentials` at a low level, inside the connection. Most often the `initialize` methods.\r\n\r\nSo the main reason we could not change how the files were loaded was that the accessing credentials were combined with loading of the credentials and is treated it as a global resource.\r\n\r\nSo you create a new Compute service instance with options but `Fog.credentials` is called as a global but *may* have loaded credentials from wherever they had located a file which *may* have added a setting that was wrong.\r\n\r\nIf you use the service Factory `Compute[:provider]` it loads and passes the options anyway but this wasn't documented.\r\n\r\n* I think we need to deprecate `Fog.credentials` so it starts warning.\r\n* Then affected code is updated to not rely on it.\r\n* Then we remove it in 2.0\r\n\r\nThe use in core code is that of public/private SSH key which I think is different enough from service credentials to be handled in another way."
1389,'geemus','[core] Adds #persisted? to Fog models\nFog models have been able to use #new_record? for years to use an\r\nActiveRecord like interface to check for peristence of a resource.\r\n\r\nWhen Rails 3 switched to using ActiveModel API this changed to\r\nbe #persisted?\r\n\r\nThis deprecates #new_record? and adds #persisted? as the first little\r\nstep to making fog models easier to use using ActiveModel API.\r\n\r\nAs discussed on the tickes, ActiveModel is not planned to become a\r\ndirect dependency for fog.\r\n\r\nRelates to #1276'
1388,'','[openstack|image] Fixes #1383\nruby 1.8.7 compat fixes for OpenStack Image Service uploads.\r\n\r\nFixes #1383'
1387,'','Doc typo\nFixing html escape typo in the Rackspace section of the Fog storage instructions'
1386,'',"Bugfix for Storage::Rackspace::File#save with etag attribute\nfixed bug where Fog::Storage::Rackspace::File raised Fog::Storage::Rackspace::NotFound if file was created with passed etag attribute. Changed to check existence based on `#last_modified` instead of `#etag`.\r\n\r\n@geemus initially recommended that I use either one for pull request #1251. I opted for `#etag`, but this wasn't a good choice because the user may want to set that when creating a file to ensure that the entire file was received by the server. `#last_modified` should not be set by the user. "
1385,'',"Support Tags on CloudFormation call cfn-create-stack\nHi All--is anyone working on adding Tags support to the cfn-create-stack call? This link shows the capability added to AWS on 8/21/2012\r\n\r\nhttp://aws.amazon.com/developertools/2555753788650372\r\n\r\nEventually, we'd like to utilize the tags for billing analysis as described here:\r\n\r\nhttp://copperegg.com/aws-cost-allocation-tips-and-tricks/\r\n\r\nOur initial tests indicate that a Tag specified on a CF template will indeed be passed on to the taggable resources that are created.\r\nMany Thanks!\r\n-davetchen"
1384,'','[Brightbox] Adds firewall request tests\nWere omitted when requests were added. Some issues with the formats\r\nhave have been updated as well which were missed due to the missing\r\ntests.'
1383,'','Possible ruby 1.8.7 compat issue in fog/openstack Image service\nThe test I\'m using:\r\n\r\n```ruby\r\nconn = Fog::Image.new({                                                         \r\n  :provider => \'OpenStack\',                                                     \r\n  :openstack_api_key => ENV[\'OS_PASSWORD\'],                                     \r\n  :openstack_username => ENV["OS_USERNAME"],                                    \r\n  :openstack_auth_url => ENV["OS_AUTH_URL"] + "/tokens",                        \r\n  :openstack_tenant => ENV["OS_TENANT_NAME"],                                   \r\n  :connection_options => { :ssl_verify_peer => false },                         \r\n})  \r\nimg = conn.images.create :name => \'foo\',\r\n                                                :disk_format => \'qcow2\',\r\n                                                :container_format => \'bare\',\r\n                                                :location => \'fake-img.qcow2\' \r\n```\r\n\r\nIt works as expected in 1.9.3, however, switching ruby implementation to 1.8.7:\r\n\r\n```\r\n[9709][rubiojr.napoleon] rvm use 1.8.7\r\nUsing /home/rubiojr/.rvm/gems/ruby-1.8.7-p371\r\nRunning /home/rubiojr/.rvm/hooks/after_use_jruby_opts\r\n\r\nruby -rubygems test.rb\r\n```\r\n\r\nresults in: https://gist.github.com/fc38c6266a83cc2d87d5\r\n\r\nIt may have something to do with the file size not being submitted? From the python backtrace in the response:\r\n\r\n```\r\nline 221, in get_image_meta_from_headers\\n    result[\'size\'] = int(result[\'size\'])\\nTypeError: int() argument must be a string or a number, not \'NoneType\'\\n"\r\n```\r\n\r\nTested against fog 1.6, 1.7, 1.8 and master fog, excon 0.16.10\r\n'
1382,'','A possible issue with @persistent = options[:persistent]  || true\nFog-1.1.2\r\nfile \r\nfog/aws/storage.rb:288\r\n\r\n@persistent = options[:persistent]  || true\r\n\r\nI was digging through source and just wondered if this would cause a problem if someone wanted @persistent to be false?\r\n\r\nPlease ignore this if I am being stupid.\r\n\r\nP.S. Cheers for Fog\r\n'
1381,'','[xenserver|docs] added storage repositories examples\nAnother set of examples'
1380,'','Random Error: "the specified s3 bucket name() is not a valid dns name"\nMy environment: Fog 1.8.0 / JRuby 1.7.1(1.9.3p327) / Rails 3.2.9 / OS X 10.8.2\r\n\r\nThe problem: I\'m getting this error sporadically when I try to save a file to S3.  Sometimes it works and sometimes it doesn\'t and I haven\'t been able to pin it down, however it seems to center around storage/get_bucket.rb file.  Most of the time after the request() call (line 47) the return value is not complete and is missing lots of entries.  When this happens Fog cannot create a proper "directory" object and creates one with a nil bucket name, and this causes a cascading failure.  :(\r\n\r\nLike I said, I can\'t really reproduce it perfectly.  Sometimes it works and sometime it doesn\'t.  It kinda makes me think of a race condition or some other threading problem.'
1379,'','Add Gem Version badge to README\nAs discussed with @geemus over email, adding the _Gem Version_ badge to README.'
1378,'','Fog is set to require multi_json 1.0, which does not have dump/load methods\nFrom ref https://github.com/intridea/multi_json/blob/v1.0.4/lib/multi_json.rb methods are later renamed and aliased from encode/decode to dump/load. If the gem restrictions are set loosely you must use the old method names.'
1377,'','Update docs/storage/index.markdown\nUse the term "bucket" rather than "directory" to clarify how S3 actually works. \r\nAlso added some comments around how to create pseudo-subfolders in S3 by using\r\ncommon path prefixes.'
1376,'','Getting different results with security groups when using mock\nHey guys,\r\n\r\nI\'m looking to switch the way my objects are created in fog by using\r\n\r\n```\r\nFog::AWS::AutoScaling.new\r\n```\r\n\r\ninstead of\r\n\r\n```\r\nFog::Compute[:aw]\r\n```\r\n\r\nsince I need to know pass the aws credentials.  As a result a lot of my tests are failing because before they were calling "security_groups" on the second approach and that no longer works with the new change.  For example this doesn\'t work when using Fog.mock!\r\n\r\n```\r\n[8] (pry) main: 0> Fog::AWS::AutoScaling.new.security_groups\r\nNoMethodError: undefined method `security_groups\' for #<Fog::AWS::AutoScaling::Mock:0x007ffdda804280>\r\nfrom (pry):6:in `__pry__\'\r\n```\r\n\r\n\r\n\r\nbut works for\r\n```\r\nFog::Compute[:aws].security_groups\r\n```\r\n\r\n\r\nSuggestions on how to fix this?\r\n\r\nThanks,\r\nJay'
1375,'','[xenserver|compute] added getting started examples\n'
1374,'','Added Http response code to Fog::Rackspace::Errors::Service\nIn order to help me tie fog exceptions back to the Rackspace API docs, I have updated Fog::Rackspace::Errors::Service error to include the HTTP response code.\r\n'
1373,'','proper user creation in OS create_server mock\nFixes bug that prevented users from being created.'
1372,'','Terminating EC2 instance Orphans EBS volumes\nWe created an EC2 image management tool using fog, and we are seeing a lot of orphaned EBS volumes after terminating instances through the tool (via fog). Do attached EBS volumes not get automatically deleted on EC2 instance termination? If not, are there any options we can send with the call to make it happen?'
1371,'','a workaround for lack of handling XML namespaces directly (required by Eucalyptus endpoint)\n'
1370,'','How do I create a sub-directory (or "folder") with Fog?\nI want to create sub-directories or "folders" under my bucket like you can with the AWS console. Is this possible with fog?\r\n\r\n(thanks!)'
1369,'','Fog.wait_for should raise timeout exception instead of returning false\nI updated Fog.wait_for to throw a timeout exception instead of returning false. This should help fog fail faster and help fog users find timeout exceptions easier. This request is documented in issue #1368.\r\n\r\nPlease let me know if you have any questions!'
1368,'','wait_for should throw an exception instead of returning false\nThe wait_for method currently returns false after the timeout occurs. It should throw an exception instead.\r\n\r\nHere is the relavent thread from Google Groups => https://groups.google.com/d/topic/ruby-fog/vUt_b_ymImo/discussion'
1367,'','Implement mocking for Compute::RackspaceV2\nThe Compute::RackspaceV2 implementation needs to add support for mocking'
1366,'','fix for tenant.users returning all users\npull request for issue 1362'
1365,'','Create_image and delete_image for Compute::RackspaceV2\nThis pull request implements the create_image and delete_image for RackspaceV2 cloud servers.'
1364,'','[rackspace|dns] creating a record now uses specified ttl\nTTL value for DNS entries will no longer be ignored by Rackspace DNS model and request.\r\nTTL is still optional.'
1363,'',"Accessing reservationId through server model\nIt would be great to be able to access the AWS reservationId through the 'servers' abstraction. /cc @geemus "
1362,'','tenant.users returns all users not just the users associated with the tenant (fog 1.8)\nIn fog 1.8\n\nThis commit:\n\nhttps://github.com/fog/fog/commit/27ba6d44a2e622ff64704ee527f3673b3a588e74\n\nchanges the users model to take :tenant_id instead of :tenant\n\nthe tenant model was not updated to pass in :tenant_id => self.id\n\nit currently passes in :tenant => self\n\nThis results in tenant.users returning all users every time, forking, and looking at tests to correct.'
1361,'',"OpenStack: Auth improvements\nOpenStack auth updates to select by service name.\n    \nThis patch updates the OpenStack auth implementation so that  it supports selecting API service by both 'name' and 'type'. This makes Fog's openstack implementation usable with providers which have multiple services for a given type (compute for example).\n    \n Previously the implementation was confusing because it used a config param called :openstack_service_name to select the service 'type' from the catalog. This patch  swaps it so that :openstack_service_name actually selects  by 'name'.\n    \n The previous logic to select service by type ('compute' for example) has been preserved in a new :openstack_service_type parameter. This option is used just as it was before for backwards compatibility.\n    \n This change is potentially breaking for anyone previously using :openstack_service_name directly (which I don't think is that common). As such we should probably make a release note saying that previous users of :openstack_service_name should migrate to use :openstack_service_type instead.\n\n----\n\nThis patch also fixes some exception class names and cleans up some unused exceptions in the OpenStack implementation.\n"
1360,'','OpenStack: Drop unused server_format hash.\nUpdates the compute server request tests to drop an unused\nhash.'
1359,'','OpenStack server test updates for real mode.\nUpdates to the OpenStack server tests to get things running in *real*\ntest mode.\n\nThis patch also adds some useful helper functions which\nare now used to:\n -get the flavor ref for testing\n -get the image ref for testing\n -get the resize flavor ref for testing (defaults to flavor + 1)\n -disable password testing (not all hypervisors support this in OS)'
1358,'','[openstack|identity] replace to_json with Fog::JSON.encode\nRefs #1338'
1357,'','Issue/1350 add aws page to fog.io.\nThis is a first draft at a /storage/aws page.\n\nFeedback is welcome!'
1356,'','Added SIGINT handler to the fog console\nPreviously ^C would exit the fog console.\n\nNow ^C is handled and ^D, exit or quit must by typed to exit the\nconsole.  This fixes a major personal annoyance of mine as the fog\nconsole did not behave like IRB or like the shell when you wanted to use\n^C to clear what you had just typed.'
1355,'',"Improve OpenStack server creation mocks\nThe OpenStack server creation mock and return value does not match reality.  Server creation returns more data than OpenStack returns and doesn't fill in fields like user_id when listing server details.\n\nWith this commit the proper user_id is filled in.\n\nAlso changed were some mocks and tests in the identity requests to help ensure the server tests will pass."
1354,'',"Add examples/ directory to the tree\nHey folks,\n\nHow do you feel about adding an 'examples' directory to the tree? I've got some fog/xenserver examples lying around (https://github.com/bvox/fog-xenserver-examples) and I believe that they would be easier to find if they where merged here.\n\nA directory structure like:\n\nexamples/xenserver/compute\nexamples/openstack/identity\nexamples/aws/storage\n...\n\nperhaps?"
1353,'','Correct the Blue Box create_block method\nThe check should be for ssh_public_key, not public_key'
1352,'','[xenserver] Added missing HostMetrics model, tests\nAdded missing HostMetrics model\n\nAdded missing HostMetrics model that wraps Host.metrics OpaqueRef.\n    \n      conn = Fog::Compute.new({\n        :provider => \'XenServer\',\n        :xenserver_url => \'xenserver-test\',\n        :xenserver_username => \'root\',\n        :xenserver_password => \'secret\',\n      })\n    \n      pp conn.hosts.first.metrics # => yields\n    \n      #  <Fog::Compute::XenServer::HostMetrics\n      #    reference="OpaqueRef:161923b3-47e4-7f8c-8995-3030be9d58f8",\n      #    uuid="00d47697-3682-1e91-154b-00116a5b7878",\n      #    live=true,\n      #    memory_free="3311230976",\n      #    memory_total="4217688064",\n      #    other_config={},\n      #    last_updated=2012-12-06 21:19:59 UTC\n      #  >\n'
1351,'','Add create_image for Compute::RackspaceV2\nFog is missing the implementation of create_image for Compute::RackspaceV2 as defined here \n\nhttp://docs.rackspace.com/servers/api/v2/cs-devguide/content/Create_Image-d1e4655.html\n\nI am currently working on this issue.'
1350,'','add AWS specific fog.io page\nPage should include high level yet AWS Storage specific info. For example, https://github.com/fog/fog/pull/706'
1349,'','[Brightbox] Add ServerGroup attribute in CloudIP model\n'
1348,'','[openstack|identity] Update User Role Membership Mocks\nSigned-off-by: Nelvin Driz <nelvindriz@live.com>'
1347,'','OpenStack servers can now retrieve security groups\nThis functionality was missing from the Server models. Extracting it by hand from the list_security_groups request is annoying and the missing functionality on the mock version of the request doubly so.\n\nIn support of this change:\n\nAdded default security group to the OpenStack compute mocks.\n\nOpenStack server creation mock now stores the security groups for the\ncreated server.\n\nOpenStack security group mock deletion now deletes created security\ngroups.\n\nOpenStack security group mock list now accepts a server id like the real\nimplementation.'
1346,'','[xenserver] Fix Fog::XenServer::Connection.authenticate\nFixes #1335\n\nXenserver expects string type for both password and username. Be\nsure that they are string.'
1345,'','Introduce AWS::COMPLIANT_BUCKET_NAMES constant\n'
1344,'','Rackspace API error messages are not set correctly in exceptions\nRackspace error responses don\'t have a top level \'message\' field, but it is nested in the specific error\n\nie http://docs.rackspace.com/servers/api/v2/cs-devguide/content/Synchronous_Faults-d1e1729.html\nor http://docs.openstack.org/api/openstack-compute/programmer/content/creating-servers.html\n\n```\n{\n  "badRequest": {\n    "message": "Invalid flavorRef provided.", \n    "code": 400\n  }\n}\n```\n\nThe HP and openstack providers had the exact same code, so I updated them too. They should extend Fog::Openstack::Errors::* but that\'s a different discussion\n'
1343,'','Support AWS S3 cors configuration for buckets\nAs per: http://docs.amazonwebservices.com/AmazonS3/latest/dev/cors.html\n'
1342,'',"Bug fix: Ensure Fog::VERSION gets defined\nIn the case where the constant `VERSION` is defined at global scope (in the application or due to some gem that pollutes the global namespace), `Fog::VERSION` would not get defined.   This caused a failure in `core/connection.rb`\xa0\n\nSimple fix: specify `false` for the second argument to `const_defined?` to restrict it to local scope.\n\n(An even simpler fix would be to remove the `const_defined?` guard.  I don't know what it's there for, but leaving it in place in case there's a reason for it.)"
1341,'','[openstack] Fix Test\nThere seems to be a difference in results coming from these two:\n\nexport FOG_MOCK=true && bundle exec shindont +openstack\nFOG_MOCK=true shindo tests/openstack/requests/compute/security_group_tests.rb\n\nSigned-off-by: Nelvin Driz <nelvindriz@live.com>'
1340,'','Improve missing service message\nThe OpenStack authentication used to raise an annoying NoMethodError if you tried to access a nonexistent service.  Now it raises a NotFound error with a useful message.'
1339,'',"[openstack] Show an error message when there aren't any endpoints available for a region\n"
1338,'','missing require \'json\' in openstack/requests/identity/create_tenant.rb\nCurrent fog/master\n\nCode triggering the issue:\n\n    require \'fog\'                                                               \n                                                                                \n    auth_url = "https://identity.example.net/v2.0/tokens"                       \n    username = \'admin\'                                                          \n    password = \'secret\'                                                         \n                                                                                \n    keystone = Fog::Identity.new :provider           => \'OpenStack\',            \n                                 :openstack_auth_url             => auth_url,               \n                                 :openstack_username          => username,               \n                                 :openstack_api_key              => password                \n                                 # Optional, self-signed certs                  \n                                 #:connection_options           => { :ssl_verify_peer => false }\n                                                                                \n    tenant = keystone.tenants.create :name           => \'rubiojr@example.net\',     \n                                                                :description => \'My foo tenant\' \n\n\nBacktrace:\n\n    /home/rubiojr/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.8.0/lib/fog/openstack/requests/identity/create_tenant.rb:12:in `create_tenant\': undefined method `to_json\' for #<Hash:0x000000029be6d0> (NoMethodError)\n      from /home/rubiojr/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.8.0/lib/fog/openstack/models/identity/tenant.rb:48:in `create\'\n      from /home/rubiojr/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.8.0/lib/fog/openstack/models/identity/tenant.rb:43:in `save\'\n      from /home/rubiojr/.rvm/gems/ruby-1.9.3-p327/gems/fog-1.8.0/lib/fog/core/collection.rb:50:in `create\'\n      from test.rb:43:in `<main>\'   \n\n\nAdding "require \'json\'" fixes the issue, not sure how you\'d like to fix this though.'
1337,'','[openstack|identity] Added sample code to README.identity.md\nHow do you guys feel about adding this here? \nDo we have a better place to put this kind of stuff?'
1336,'',"I there a way to rename a files prefix (change folder) on S3 using fog efficiently?\nHi, I have a looooot of files that resides in some subdirectories (I know it's actually just prefixes). Is there a way using fog to change/remove those prefixes of those files?"
1335,'rubiojr','Fog::XenServer::InvalidLogin\nFog raises `Fog::XenServer::InvalidLogin` error, even though I can connect to the server with these login using the code below;\n\n      def initialize(host, username, password)\n        @factory = XMLRPC::Client.new(host, \'/\')\n        @factory.set_parser(XMLRPC::XMLParser::REXMLStreamParser.new)\n        response = @factory.call(\'session.login_with_password\', username, password )\n        raise Fog::XenServer::InvalidLogin.new unless response["Status"] =~ /Success/\n        @credentials = response["Value"]\n      end\n    \nThis code is actually part of `Fog::Xenserver` module but It does not raise any error when I type it directly to the irb.\n'
1334,'','[AWS|cloud_watch] Add Metrics#each, which follows NextToken\nThis PR supersedes https://github.com/fog/fog/pull/1212.'
1333,'','Asg mocks\nImplement resume/suspend processes mocks for auto scaling groups.'
1332,'','[openstack|compute] Update Quota Mocks based on Folsom Stable\nBasis:\nhttps://github.com/openstack/nova/blob/stable/folsom/nova/quota.py#L34\n\nSigned-off-by: Nelvin Driz <nelvindriz@live.com>'
1331,'','vm_clone.rb augmentation \nFound some more items that could be used with vm_clone.rb. Need more help with the tests. '
1330,'','vm_clone cannot use server model with wait => false\nWhen cloning a machine you cannot load up the object in the server model since it\'s still not fully a "server". \n\nProblem exists in the way the model loads up the ID field. ID = vm_ref when machine is being provisioned and ID = UUID when it\'s done being made. '
1329,'','Added functionality to vm_clone.rb\nFixed up with new features to clone with. \nAdded new attributes to server model\nFixed some of the existing implementation usage. '
1328,'','Support for Proxmox VE\nProxmox is quite popular platform for in-house virtualised environments (http://pve.proxmox.com/pve2-api-doc/). Are there any plans supporting it?\n\nIf "not yet" - would it be interesting if I\'ll work on it?'
1327,'','OpenStack: security group test fixes.\nUpdate the OpenStack security group test to support the correct\nformat for create_security_group responses. This patch\nremoves the extra [] wrapping the response and makes it so the\nreal tests run once again.\n\nAlso updates the existing Mock for create_security_response so\nit handles it properly as well.'
1326,'','Add a generic destroy operator on a bucket.\nAtmos already implements a recursive delete operation and it would\nbe nice to implement similar functionality for ever provider. Ths\nconsolidates the deletion code, removes the duplicated effort, and\nmakes it straigtforward to improve the delete operation (to make it\nmulti-threaded, for example).'
1325,'','OpenStack: updates to quota tests.\nUpdates to the OpenStack quota tests to support the latest\nchanges in Folsom/Grizzly. With these changes I am able to run\nthe *real* tests again with the latest upstream OpenStack builds.\n\nAlso updates the quote tests so that they update quotas back to previous values for the tenant being tested. This makes it so the tests clean up after themselves... (thus subsequent runs give the same results).\n\nThis change has no functional effect on Fog users for previous\nreleases of OpenStack (Folsom, etc,) but should allow us to\nsupport the latest upstream codebase and run Fog *real* tests again.'
1324,'','OpenStack: Remove volumes from limits tests.\nIn OpenStack Grizzly Nova no longer supports volumes directly. This has been moved to another service called Cinder. This removes the volume specific settings from the OpenStack compute limits tests and Mock.\n\nThis change has will has no effect on users of previous of Fog for previous releases (Folsom, etc) but should allow us to easily support the latest upstream codebase and run Fog *real* tests.'
1323,'','Fog 1.7.0 is not parsing correctly Eucalyptus XML documents. Empty sets are always returned in collection queries.\nFog 1.7.0 is not parsing correctly Eucalyptus XML documents. Empty sets are always returned in collection queries.\n\nExample AWS response:\n`\n<?xml version="1.0" encoding="UTF-8"?>\n<DescribeInstancesResponse xmlns="http://ec2.amazonaws.com/doc/2012-07-20/">\n    <reservationSet>\n        <item>\n\t\t\t<instancesSet>\n\t\t\t    ...\n            </instancesSet>\n        </item>\n    </reservationSet>\n</DescribeInstancesResponse>\n`\nExample Eucalyptus 3 response:\n`\n<?xml version="1.0"?>\n<euca:DescribeInstancesResponseType xmlns:euca="http://ec2.amazonaws.com/doc/2012-07-20/">\n\t<euca:reservationSet>\n\t\t<euca:item>\n\t\t\t<euca:instancesSet>\n\t\t\t    ...\n\t\t\t</euca:instancesSet>\n\t\t</euca:item>\n\t</euca:reservationSet>\n</euca:DescribeInstancesResponseType>\n`\n\nThe difference is that AWS sets ec2 schema as the default one.\n\nfog is using Nokogiri for the XML document parsing. Fog parser classes (Fog::Parsers::Base, etc) overwrite start_element/end_element methods. The latter methods receive:\n* plain element name in the AWS case (like \'instancesSet\')\n* combined namespace prefix and name in the Eucalyptus case (like \'euca:instancesSet\')\n\nFog is comparing element against plain names (like \'instancesSet\', \'instanceState\', etc) so the parsing process does not work for Eucalyptus.\n\nThe problem can be fixed by overwriting start_element_namespace/end_element_namespace methods of Nokogiri::XML::SAX::Document class which get name/prefix as separate method arguments.'
1322,'',"iam tests should not call Fog.mock!\nIn particular these:\n\n./tests/aws/models/iam/access_keys_tests.rb:  Fog.mock!\n./tests/aws/models/iam/policies_tests.rb:  Fog.mock!\n./tests/aws/models/iam/users_tests.rb:  Fog.mock!\n\nThis prevents real tests from ever running and introduces the danger that this could cause all the tests that followed it to run in mocked also (currently I don't believe this would actually happen due to the way shindo isolates/runs things)."
1321,'','[Rackspace] CloudFiles last_modified dates are parsed in the wrong time zone\nA CloudFiles directory listing will return last_modified dates for each object in the following format:\n\n2012-11-29T14:56:54.387520\n\nNote that there is no tome zone information.\nThe last_modified date is in UTC, however fog parses it with local time zone.\n\nIn my case, result with fog:\n\n2012-11-29 14:56:54 +0100\n\nShould be:\n\n2012-11-29 15:56:54 +0100  or  2012-11-29 14:56:54 UTC'
1320,'tokengeek',"[Brightbox] Refresh tokens\nThis adds support for refresh tokens to authenticate with Brightbox's Compute service.\n\nAlso major clean up of the internals to allow better testing and maintenance."
1319,'',"Expire sts token\nSet `aws_credentials_expire_at` - either passed in option or from returned token.\n\nDynamoDB access through Fog is not handling an expired session token. After 12 hours, we started receiving 400 status codes from the DynamoDB service. Have the `aws_credentials_expire_at` get set from either options or returned value from the token. I'm not sure that the returned value in `Expiration` will be compatible with the time check."
1318,'','new gem release that includes Australia AWS region please\n'
1316,'',"Creating user via `Aws.iam.users` ignores `:path`\nWhen creating an AWS IAM user, using the `Aws.iam.users.create` method, the `:path` is ignored.\n\nI.e.\n\n```ruby\nuser = Aws.iam.users.create({:id => 'some_id', :path => '/some_path/'})\nuser.path != '/some_path/'\n```\n\nFixes issue#1313"
1315,'','OpenStack floating_ip (aka address) test fixes\nUpdates to the OpenStack address tests so that:\n\n * The tests cleanup after themselves when executed in Real mode.\n   Previously running these tests in Real mode would leak servers\n   and floating IPs.\n\n * DRY things up a bit.\n\n * Make use of the floating IP we create in subsequent tests. Previously\n   the last floating IP in the full list was used. This could be\n   problematic in some cases.\n\n--\n\nAlso adds a missing Mock class for the release_address request so\nthat FOG_MOCK tests continue to pass.'
1314,'tokengeek',"Find credentials\n@postmodern seems to have lost track of PR748, so I've tweaked it and added tests to make it acceptable for merging."
1313,'',"Creating user via `Aws.iam.users` ignores `:path`\nWhen creating an AWS IAM user, using the `Aws.iam.users.create` method, the `:path` is ignored.\n\nI.e.\n\n```ruby\nuser = Aws.iam.users.create({:id => 'some_id', :path => '/some_path/'})\nuser.path != '/some_path/'\n```\n"
1312,'','Sync with latest OpenStack flavors extensions.\nUpdates the OpenStack flavors model/request/and tests so\nthat they support the latest upstream flavor extensions in\nNova.\n\nAlso updated the Fog tests so they pass with both mocks and reals\n(tested against OpenStack deployed on Fedora).'
1311,'',"Moves Fog::VERSION to fog/core, Adds User-Agent header\nThis is the fix for #1310\n\n`Fog::VERSION` is now in it's own file which is required from within `lib/fog/core` so should be available to individual providers without needing to bring in everything in `lib/fog`\n\nLazily this also includes the change to add the User-Agent header"
1310,'tokengeek',"User-Agent change uses Fog::VERSION and drags in excess code.\nWe have been using just the Brightbox part of fog in our CLI happily with `require 'fog/brightbox'` but the User-Agent change I added causes a dependency on `Fog::VERSION`\n\n`Fog::VERSION` is defined in `lib/fog.rb` which also pulls in the rest of fog.\n\nSo I'm reverting immediately and will look to reapply"
1308,'','Bundle is excluding faster JSON libraries from MultiJSON\nBundler is excluding any of the faster JSON gems that MultiJSON can choose from forcing it down to the slowest option. This affects Ruby 1.8.7 but Ruby 1.9 has the `json` gem already.\n\nRun code touching `Fog::JSON` locally on Ruby 1.8.7 and you see:\n\n```\n[WARNING] MultiJson is using the default adapter (ok_json). We recommend loading a different JSON library to improve performance.\n```\n\nInstall `json` gem and you still see it.\n\nI updated `fog.gemspec` to add `json` as a dependency and deprecation disappears now Bundler is requiring it.\n\nNot keen on foisting `json` as a dependency on people but we do have `multi_json` anyway.\n\nAdding `json` as a dependency does not solve the problem for anyone wishing to use any of the other supported JSON libraries.'
1307,'',"[openstack] Bulk Update\nWhat's included:\n\nRefactored Authentication\nKeep Unscoped Token to be reused when scoped token is invalidated due to membership grant/revoke\n`reset_server_state` request\n`get_limits` request"
1306,'','Some improves to rackspace openstack code\nSome improves to the code for the latest Rackspace Openstack API. \n\nMore work necessary to bring the code up to all the latest rackspace features as outlined in\n\nhttp://docs.rackspace.com/servers/api/v2/cs-devguide/content/ch_preface.html and http://docs.openstack.org/trunk/openstack-compute/developer/openstack-compute-api-1.1/content/index.html\n\nbut these are the ones i need for now. I wish i had time to complete the task. '
1305,'','Add support for volume_pool_name\nThis is related to the issue #1304. This adds support to volume_pool_name for Libvirt.'
1304,'',"[libvirt] volume_pool_name ignored on server create\nWith libvirt, creating a new server always uses the 'default' volume pool.\n\nLooks like this line is missing from libvirt/models/compute/server.rb:\n\n338:      options[:pool_name]   = volume_pool_name if volume_pool_name"
1303,'','Real mock ips - because bad IPs break stuff\nI kept hitting problems with the current way of mocking IPs.\n\nSo here I have simplified it by using a little love from the IPAddress class[1] and straight rand... rather than using Mock.random_numbers repeatedly.\n\nHope this helps others too.\n\n1: https://github.com/LightMesh/ipaddress'
1302,'','[core] Adds fog User-Agent header\nAs discussed in #1026 this adds a User Agent HTTP header to help identify\nthe version of fog is accessing APIs.'
1301,'','Allow defining AWS CDN distribution Cache Behavior\nIt appears it is not possible to define any Cache Behavior in AWS Cloudfront with fog.\nIn Amazon API reference:\n\n```xml\n   <CacheBehaviors>\n      <Quantity>number of cache behaviors</Quantity>\n      <!-- Optional. Omit when Quantity = 0. -->\n      <Items>\n         <CacheBehavior>\n            <PathPattern>pattern that specifies files that this \n               cache behavior applies to</PathPattern>\n            <TargetOriginId>ID of the origin that this cache behavior \n               applies to</TargetOriginId>\n            <ForwardedValues>\n               <QueryString>true | false</QueryString>\n               <Cookies>\n                  <Forward>all | whitelist | none</Forward>\n                  <!-- Required when Forward = whitelist, \n                     omitted otherwise. -->\n                  <WhitelistedNames>\n                     <Quantity>number of cookie names to forward \n                        to origin</Quantity>\n                     <Items>\n                        <Name>name of a cookie to forward to \n                           the origin</Name>\n                     </Items>\n                  </WhitelistedNames>\n               </Cookies>\n            </ForwardedValues>\n            <TrustedSigners>\n               <Enabled>true | false</Enabled>\n               <Quantity>number of trusted signers</Quantity>\n               <!-- Optional. Omit when Quantity = 0. -->\n               <Items>\n                  <AwsAccountNumber>self | AWS account that can create \n                     signed URLs</AwsAccountNumber>\n               </Items>\n            </TrustedSigners>\n            <ViewerProtocolPolicy>allow-all | \n               https-only</ViewerProtocolPolicy>\n            <MinTTL>minimum TTL in seconds for files \n               specified by PathPattern</MinTTL>\n         </CacheBehavior>\n      </Items>\n   </CacheBehaviors>\n```\n\nEdit : I just realized it was not available in the Amazon API Version that is currently in use (2010-11-01)'
1300,'','Make aws region easy to add\nI added (example values from https://github.com/aswoodward/fog/commit/fcf829839d897a81bbcbd36db02fe4f0c6ec74e5) \n\nFog::AWS.additional_regions_info([{"messageSet" => [], "regionName" => "ap-southeast-2", "zoneName" => "ap-southeast-2a", "zoneState" => "available"},{"messageSet" => [], "regionName" => "ap-southeast-2", "zoneName" => "ap-southeast-2a", "zoneState" => "available"}])\n\nFog::AWS.set_additional_elb_hosted_zone_mapping({"ap-southeast-2" => "Z1WI8VXHPB1R38"})\n\nthis should cover the code changes in the pull request above except for lib/fog/aws/models/compute/server.rb  i was unsure what that did. \n\nAlso I am looking for advice on how to test this. \n\nAlso now that i looked at the code again perhaps a Fog::AWS.regions should handle all this logic in one place?\n\nIt looks like other services could use the same treatment. I see "add support for HP availability zone az-3.region-a.geo-1"  Maybe this concept can be further pulled out to support everyone. '
1299,'','Upload progress for files\nWhen uploading files using the Storage providers, the Excon library chunks files for me which is what I want, but I would like to access the progress of the upload. Is this possible at all?'
1298,'','Add attr group.\nThis commit adds the group object to the\ncloudstack compute model.'
1297,'','Support for the Post Object restore request. For retrieving an object from AWS Glacier\nHere is the reference on AWS.\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/RESTObjectPOSTrestore.html\n\nI have not built the Mock Class or written tests. I am happy to work on that over time. I needed this tonight and figured I would share.\n\nThanks for a great gem!'
1296,'','[oVirt] adds host collection/model\n'
1295,'','[Brightbox] Account updates\nThis is a series of updates and fixes for the Brightbox `Account` model connected to the `#reset_ftp_password` method.\n\nTested against our production systems, pushing to get green light from Travis CI'
1294,'','Impossible to access files with an accent in the name\nHello,\n\nWe are using fog to manage files on our S3 server.\nWe have a file with an accent in it and which is the list if we do:\n\n    directory.files\n\nBut when we try access it with the same path name:\n\n    directory.files.get "uploads/courrier_debut_saison_comm_rÃ©g_KP.pdf"\n\nfog returns nil.\n\nAny idea ?\n\n(.encoding on the string returns #<Encoding:UTF-8>)'
1293,'','[Brightbox] Adds Servers#bootstrap\nThis adds the bootstrap method needed to create a server and gain a\npublic IP address as per the fog documentation.'
1292,'','Fixes Issue 1291\n...use merge! instead of merge to set the opts local variable in place,  otherwise the options passed to the method are droppedon the floor\n\nhttps://github.com/fog/fog/issues/1291'
1291,'',"AutoScaling Group destroy options bug\nHey guys,\n\nLooks like there is a bug in the auto scaling group destroy options where it merges in ForceDelete if :force => true was passed to destroy. \n\nSee\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/models/auto_scaling/group.rb#L128\n\nI'll put in a pull request for this, just wanted to create an issue first.\n\nThanks,\nJay"
1290,'','Cannot describe and delete RDS DB Option Groups\nLooks like describing and removing of option groups for RDS is not implemented. http://docs.amazonwebservices.com/AmazonRDS/latest/APIReference/API_DescribeOptionGroups.html'
1289,'',"Extract bulk of Rakefile to isolated classes\nThis extracts the following aspects of fog's `Rakefile` into distinct classes:\n\n* Changelog generation\n* Documentation tasks\n* Testing tasks\n\nThis is mostly to clean it up but doing this has already highlighted a few things related to documentation that is making a releases a bit of a bottleneck for @geemus that we are addressing.\n\nThere are still improvements possible.\n\nI'm not certain if placing the classes where I have make them sound like `Rake` tasks of fog's that others can use rather than supporting files."
1288,'',"AWS S3 Metadata improvements\nThere are a few improvements that could be made to the AWS meta-data implementation.  This would be a breaking change.\n\n* Abstract out the x-amz portion of the metadata (remove provide specific dependency)\n* Don't require direct attributes access\n\nSee #1251 for an example of how this was proposed on Rackspace."
1286,'','Creating an AWS instance not working with jruby 1.7.0\n\nHopefully this is just something with my environment. I\'ve been trying to use rubber to set up an AWS instance for a jruby rails project and it is just not playing nicely. I\'ve tracked it down to fog and can reproduce the error without rubber being involved at all. \n\nIt works fine with ruby 1.9.3.\n\nI\'ve tried various jruby-openssl 0.7.4, 0.7.7 and the version shipped with jruby.\n\nI\'ve tried jruby 1.7.0 and the current head.\n\nI\'ve tried running jruby with `--1.8` and `--1.9`.\n\n\nThe error goes:\n\n    NoMethodError: undefined method `each\' for nil:NilClass\n      merge_attributes at <home>/.rvm/gems/jruby-1.7.0@project/gems/fog-1.7.0/lib/fog/core/attributes.rb:143\n                  save at <home>/.rvm/gems/jruby-1.7.0@project/gems/fog-1.7.0/lib/fog/aws/models/compute/server.rb:168\n                create at <home>/.rvm/gems/jruby-1.7.0@project/gems/fog-1.7.0/lib/fog/core/collection.rb:50\n       create_instance at <home>/.rvm/gems/jruby-1.7.0@project/gems/rubber-2.1.2/lib/rubber/cloud/fog.rb:27\n                  send at org/jruby/RubyKernel.java:2072\n        method_missing at <home>/.rvm/gems/jruby-1.7.0@project/gems/rubber-2.1.2/lib/rubber/thread_safe_proxy.rb:13\n       create_instance at <home>/.rvm/gems/jruby-1.7.0@project/gems/rubber-2.1.2/lib/rubber/recipes/rubber/instances.rb:297\n      create_instances at <home>/.rvm/gems/jruby-1.7.0@project/gems/rubber-2.1.2/lib/rubber/recipes/rubber/instances.rb:217\n                  call at org/jruby/RubyProc.java:261\n                  call at org/jruby/RubyProc.java:213\n\nTaking rubber out of the picture, I\'ve managed to reproduce the error with this little script:\n\n```ruby\n#!/usr/bin/env ruby\nrequire \'fog\'\n\ncompute = Fog::Compute[:aws]\nserver = compute.servers.new(:image_id => "ami-fefcbcac", :flavor_id => "t1.micro", :key_name => "mydevkey")\nbegin\n  server.save\nrescue Exception => e\n  puts e.backtrace\n  puts "Nope, still broked. Cleaning up"\n  compute.servers.select { |s| s.state == \'running\' }.each { |s| s.destroy }\n  puts "Done!"\nend\n```\n\nIt needs to do the cleanup because it creates the instance and sets it running, then dies with the above error.\n\nThe minimal gem bundle to get the above script to go is just a `gem "fog"` in the Gemfile:\n\n    Gems included by the bundle:\n      * builder (3.1.4)\n      * bundler (1.2.2)\n      * excon (0.16.10)\n      * fog (1.7.0)\n      * formatador (0.2.4)\n      * mime-types (1.19)\n      * multi_json (1.3.7)\n      * net-scp (1.0.4)\n      * net-ssh (2.6.1)\n      * nokogiri (1.5.5)\n      * ruby-hmac (0.4.0)\n\nFeel free to call me an idiot if it\'s something simple and I just didn\'t RTFM.\n'
1285,'','removed Fog::AWS[:rds] this was creating issues with AWS security creden...\nRemoved Fog::AWS[:rds] portion on the owner_id method. On instance creation this was causing an AWS permission error stating that  :aws_access_key_id and :aws_secret_access_key where not defined. \n\nBenton Roberts(a fog contributor) broberts@mdsol.com whom originally submitted the tagging addition has approved this patch.'
1284,'','auto scaling groups attributes not consistent\nHi,\n\nI just ran into an issue where I thought I was creating auto scaling groups using the auto scaling groups model but noticed my max_size, min_size, and load_balancer_names weren\'t being set.  Looking at the code I see that the attributes name is different and that for these it has aliases for example \'LoadBalancerNames\' so passing "load_balancer_names" into the initializer doesn\'t set the load balancer names.  Other attributes get set though.  Any reason why not allow all the attributes that are passed to be set using either method?  Let me know if I\'m missing something and passing "load_balancer_names" should work.\n\nThanks,\nJay'
1283,'',"Fix describe_instances stateReason handling\nBefore this the state_reason code was always 0 ('..'.to_i) and message was\nlost"
1282,'',"[Brightbox] Documentation updates\nSince we have switched to using Yard, this revisits the Brightbox documentation to make it more declarative.\n\nWe've generated baseline documentation for most of the requests in the 1.0 API"
1281,'','docs consolidation - fog.io vs github wiki\nSome discussion has been going on about where the canonical source of info should be between fog.io and github wiki. I think there are pluses and minuses on both sides so I just wanted to open this up to discussion.'
1280,'geemus',"move /docs into own repo, move hosting to github pages\nFor various historical reasons fog.io was in the same repo and hosted on S3 static pages, but I think the time has come for it to have it's own repo and that the whole setup can be greatly simplified by putting this on to github pages instead of s3 static stuff."
1279,'','Inconsistent usage of cpus / vpcus in libvirt / requests.\nReported number of cpus was always 1 for libvirt domains.'
1278,'','[vsphere] ensure reload works correctly for server\nNot sure if there is a better way...'
1277,'',"AutoScalingGroup get returning only the first record no matter the id passed for Mock mode\nHi,\n\nWhen running in Mock mode I create several auto scaling groups that show up in the collection when running:\n\n```\nFog::AWS[:auto_scaling].groups\n```\n\nAfterwards I try to run a get on a group and only the first group is returned.  I can't get it to find any of the others.\n```\nFog::AWS[:auto_scaling].groups.get(id)\n```\n\nTry creating several auto scale groups then try fetching the last one, it will return the first one you created."
1276,'',"Active Model compliance\nWe mentioned this as part of #1250 and @geemus asked me to break it out.\n\nWhilst we are not keen as bringing in Active Model as a dependency there may be some benefits in at least meeting the minimal interface.\n\nIt means people building on top of `fog` can require fog and activemodel and start adding whatever functionality to the models they want.\n\nIt's been mentioned on the mailing list and there's a possible use in an app of mine.\n\n* Wes has mentioned local caching/persistence as possible useful use case.\n* Validations: is an image set?, is the region in this list?\n* Callbacks: (before) enough credit to build server? (after) ping chatroom new server was built?\n\n\n**None of this stuff is intended for fog but for application builders using fog as it's cloud API layer!**\n\n\nIf you take compliance as passing https://github.com/rails/rails/blob/master/activemodel/lib/active_model/lint.rb then are a dozen methods to add. The only really interesting ones are `persisted?` and `errors`\n\nWe already test for persistence in many places by checking for `identity` - if set then the API has created it for us.\n\n`errors` is the tricky one since if we add it to become compliant then it would make sense to use it rather than raising Errors but that my change things too much. In many cases I prefer an Error to handle.\n\nMost of it would just be default behaviour in `Fog::Model` but we need to ensure nothing breaks and it's not too much work add to add all model classes in meaningful ways.\n\nAlso I suspect it makes sense to have it as a _development_ dependency so tests can use `ActiveModel::Lint::Tests`"
1275,'',"Replace Rspec mocks\nThe following two test files are using Rspec for mocking:\r\n\r\n* `tests/dynect/requests/dns/dns_tests.rb`\r\n* `tests/vcloud/requests/compute/disk_configure_tests.rb`\r\n\r\nWe have decided (#1266) to move to `minitest`\r\n\r\nWe should switch to using minitest's mocks/stubs _if appropriate_ for these tests to remove Rspec.\r\n\r\n@geemus can you check if these could be mocked with Excon's mocks? If so then we can just use that instead."
1274,'','Stop generating and hosting own API docs\nI was cleaning up the Rake tasks and noticed that we are currently generating our own API docs, then using @geemus credentials to copy them to AWS somewhere under http://fog.io\r\n\r\nNow the documentation is being created anyway at http://rubydoc.info/gems/fog and has been since `1.3.1`\r\n\r\nHow about we update the link in the docs and clear away the Rake tasks?'
1273,'','Documentation updates\nTwo small changes in the docs.\r\n\r\n* Updating the folder reference on http://fog.io since `rdoc` directory was renamed `doc`.\r\n* Updates to the **Contributing** section.'
1272,'','VMWare vsphere provider refactor\nmissing:\r\n- new model tests\r\n- templates model\r\n\r\nthis patch includes a lot of changes and cleanups, exposing more fog\r\ncollections/models and rewriting most requests\r\nit includes valuable feedback from endzyme <nick.huanca@gmail.com>'
1271,'','Add support for AWS Australia (ap-southeast-2).\n'
1270,'tokengeek','Update contributor guidelines with notes about 1.8.7 support\nWhen discussing #1250 the general consensus is that dropping 1.8.7 support is not beneficial and may be disruptive for users of some LTS distros.\r\n\r\nSo the contributors documentation needs to be updated pointing out that fog does support 1.8.7 and will do for the foreseeable future.\r\n\r\nAs such all patches should be expected to be compatible with 1.8.7 and any dependencies should be the same.'
1269,'','CDN put_distribution_config for AWS\nFolks,\r\n\r\nHas anyone tried "put_distribution_config" with fog, I get the following error:\r\n\r\n<Code>IllegalUpdate</Code><Message>Distribution may not be updated with this API version.</Message></Error>\r\n\r\nThe API reference does say that I have to use the newer API, that is "2012-05-05", so I updated my call to this:\r\n\r\n```ruby\r\ncf = Fog::CDN.new({\r\n      :provider => "AWS",\r\n      :version  => "2012-05-05",\r\n      :aws_secret_access_key => "#{account["Secret Access Key"]}",\r\n      :aws_access_key_id => "#{account["Access Key Id"]}"\r\n    })\r\n```\r\n\r\nAfter doing this, my get itself fails, I get the following error:\r\n\r\n"EndTag: \'</\' not found (Nokogiri::XML::SyntaxError)"\r\n\r\nHas anyone else seen this, has anyone been able to update a distribution by using "put_distribution_config".\r\n\r\nI am trying to delete an existing distribution and hence first I need to disable it using the put_distribution_config api call.\r\n\r\nThanks.'
1268,'',"[AWS] [Compute] Nokogiri::XML::SyntaxError: Extra content at the end of the document\nHi,\r\n\r\nI recently installed Fog as a gem in my Rails 2.3.8 site.  In console:\r\n\r\noptions = {\r\n        :provider => 'AWS',\r\n        :region => region,\r\n        :aws_access_key_id      => access_key_id,\r\n        :aws_secret_access_key  => access_key_secret\r\n      }\r\n      \r\nconnection =      Fog::Compute.new(options)\r\nconnection.describe_security_groups\r\n\r\nResults in:\r\n\r\nNokogiri::XML::SyntaxError: Extra content at the end of the document\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/nokogiri-1.5.5/lib/nokogiri/xml/sax/push_parser.rb:47:in `native_write'\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/nokogiri-1.5.5/lib/nokogiri/xml/sax/push_parser.rb:47:in `write'\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/nokogiri-1.5.5/lib/nokogiri/xml/sax/push_parser.rb:55:in `finish'\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.7.0/lib/fog/core/connection.rb:23:in `request'\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.7.0/lib/fog/aws/compute.rb:382:in `_request'\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.7.0/lib/fog/aws/compute.rb:377:in `request'\r\n\tfrom /home/coliver/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.7.0/lib/fog/aws/requests/compute/describe_security_groups.rb:43:in `describe_security_groups'\r\n\tfrom (irb):34\r\n\r\n\r\nThe same result happens with connection.security_groups or connection.servers.  I'm not sure what I'm doing wrong.  \r\n\r\nLooking at the raw XML coming back from AWS seems correct.\r\n"
1267,'','launch configuration user data is encrypted\nIs there any way in fog to decrypt this?'
1266,'',"Replace Shindo testing with... (discuss)\n@geemus has mentioned a few times that perhaps `shindo` is a barrier to contributions.\r\n\r\nThere does seem to be a pattern of: 1) pull request received, 2) great needs tests, 3) okay will look at that... 4) nothing\r\n\r\nWes has mentioned `minitest` so I think that is the front runner as a replacement.\r\n\r\nSo this is another discussion ticket to get out any potential issues related to testing.\r\n\r\n* `minitest`/`minispec`?\r\n* something else?\r\n* continuing to use Excon's mocks?\r\n* best practices to implement?\r\n* timescale to transition?\r\n* CI support (multiple test frameworks)\r\n\r\nNote we currently have `rspec` as a developer dependency and two small users of it. I plan to ticket removal of that but it isn't worth it until we have decided on a replacement.\r\n\r\nIn terms of roadmapping it could be useful to switch testing before we lock down model interfaces (#1252)."
1265,'','Removes dead link to DNS tests\nfog.io documentation had an outdating link to examples.\r\n\r\nCloses #1198'
1264,'',"Do not add empty security group\nPreviously, not setting a security group leads to an invalid\r\nsignature (when using api keys). This was caused b/c\r\nan extra securitygroupid was added with '' as its value.\r\n\r\nThis was calculated as a part of the signature, but dropped\r\nfrom the request, leading to the error:\r\n    unable to verify user credentials and/or request signature\r\n\r\nThis commit only adds a securtygroupid param if the result of\r\nthe querying for groups does not return []. This will prevent the\r\nextra security group from being added."
1263,'',"[cloudstack] signature is invallid when parameter values are ''\nwith Ruby 1.8.7, excon 0.16.7 and master of fog, I am seeing the following issue.\r\n\r\nWhen I don't supply security_group_ids, it is automatically added as a parameter with '' as its value (I still need to dig and find the code that does this).\r\n\r\nThis is used as a parameter when the signature is generated.\r\n\r\nThis is fine, except excon drop parameters that have a value of ''.\r\n\r\n  in the following code:\r\n    ruby-1.8.7-p334/gems/excon-0.16.7/lib/excon/connection.rb:213\r\n       [*values].each do |value|\r\n\r\n  if values is '', it becomes [] which means that parameter is not added.\r\n\r\nThis means that any parameters that have the value of '' will be used to generate the signature, but not passes as part of the query string, resulting in:\r\n\r\n     unable to verify user credentials and/or request signature\r\n\r\nMy proposed fix is to patch fog as follows:\r\n\r\n   when generating the signature, if a value of a parameter is '', then it should be dropped before the signature is generated.\r\n\r\nI am happy to write this patch up with tests and get a PR in the next week or so."
1262,'','User data is lost on get AWS EC2\nWhen using EC2 doing a server create in mock mode:\r\n\r\n```ruby\r\nFog.mock!\r\nserver = Fog::Compute[:aws].servers.create(user_data: "some data")\r\nserver.wait_for { ready? }\r\nFor::Compute[:aws].servers.get(server.id).user_data\r\n=> nil\r\n```'
1261,'','Support for metadata in Rackspace compute_v2\nMetadata for Rackspace compute_v2 nodes was previously not being passed in the requests for create_server.'
1260,'brianhartsock','[storage] Rackspace Access-Control-Allow-Origin\nAdd support for Rackspace Files Access-Control-Allow-Origin and Origin headers'
1259,'',"update bluebox createblock request to encode key values using CGI.escape, rather the URI.encode\nURI.encode was not encoding the '+' characters within ssh keys"
1258,'','Fix warning for bucket_name to follow latest google standards\nUpdated link and regex\r\nSolves issue #1257\r\n'
1257,'','bucket not a valid dns name\ni\'m getting a bunch of warnings:\r\n\r\n    fog: the specified google storage bucket name(appname_development) is not a valid dns name.  See: http://code.google.com/apis/storage/docs/developer-guide.html#naming\r\n\r\nWhen i go to the link (which should be https://developers.google.com/storage/docs/bucketnaming ) the name i chose is indeed valid.\r\n\r\nSo i think we should remove this warning (or fix it). Let me know if i\'m missing something. Thanks\r\n\r\nThe logic is now\r\nhttps://github.com/fog/fog/blob/master/lib/fog/google/storage.rb#L228\r\n\r\n```ruby\r\nunless subdomain =~ /^(?:[a-z]|\\d(?!\\d{0,2}(?:\\.\\d{1,3}){3}$))(?:[a-z0-9]|\\.(?![\\.\\-])|\\-(?![\\.])){1,61}[a-z0-9]$/\r\n```\r\n\r\nSeems the problem is with the "_"\r\n\r\nbut "Bucket names must contain only lowercase letters, numbers, dashes (-), underscores (_), and dots (.). Names containing dots require verification."\r\n'
1256,'',"[dns] Add more record tests\n@geemus Is this a good idea?  Not for sure if this will break other providers, but this test currently breaks (and hence will verify the success of #1141)\r\n\r\nWouldn't be too hard to make this Rackspace specific but I figured it could make sense for other providers if they all support AAAA and CNAME."
1255,'',"[Docs] Switches to using Yard for documentation\nThis replaces RDoc as a developer dependency with Yard to allow\r\nuse of it's tags to be more declaritive with documentation.\r\n\r\nThe Rake task for generating and uploading API docs to fog.io has also\r\nbeen updated.\r\n\r\nReferences #1249"
1254,'','[AWS] Adds ModifyVolumeAttribute\nAdds ModifyVolumeAttribute functionality.'
1253,'','Steps to split Fog into modules\nIt\'s been mentioned before #473 but splitting Fog into modules is back on the agenda since we discussed a rough roadmap for Fog in #1250.\r\n\r\nRather than rushing into possible ways it is probably worth listing exactly what people want to get out of this. Based on discussions so far I\'ve got:\r\n\r\n* Standardised service interfaces with canonical tests to check (#1252)\r\n* Reduce burden on @geemus  for Fog releases\r\n* Allow providers to update their services without Wes being (unintentional) blocker\r\n* Cleaner separation between core issues and provider issues\r\n* Reduce dependencies for single provider when using Fog as library (no `libxml` for JSON API)\r\n* Minimal memory usage when using single provider\r\n* Reduce number of files when used on PaaS services like Heroku\r\n* Cleaner way to version APIs\r\n* Maintain community without fragmenting to provider ghettos (https://github.com/fog/fog/issues/473#issuecomment-1903823)\r\n* Still simple for users to pick up and start using\r\n* Reduce "churn" updating hardcoded references to new Regions or Images should not warrant a release of Fog but people should be able to update to use them (So provider point release)\r\n\r\nSo there\'s lots of technical gains we can achieve but we need to make sure we don\'t damage the community.\r\n\r\nNext up is discussing possible ways to do this. Then we can get issues for the smaller parts.\r\n\r\nCan we just break everything into gems? Do we have dependencies in `fog-core` we need to break first?\r\n\r\nIs this Fog 2.0 so we can be backwards incompatible?\r\n\r\nThreads, autoloading... etc.'
1251,'',"Rackspace storage metadata\nI needed support for object level metadata on Rackspace Cloud Storage. I assume you're open to this based on AWS::File#metadata? \r\n\r\nI added some tests as well, but only for what I changed. Let me know if there's anything else I can do to get this patch in. Shindo was definitely new to me. Not sure if I'm using it correctly."
1250,'',"Rough Roadmap\nFog's just hit 1.7.0\r\n\r\nIt's been discussed a few times about bigger changes that we really should schedule.\r\n\r\nImmediately I can think of dropping Ruby 1.8 support and splitting Fog up somehow.\r\n\r\nI quite like the idea of Fog 1.9.0 dropping 1.8 support and Fog 2.0 being modular. Of course you can argue dropping 1.8 support is big enough to be a 2.0 change as well.\r\n\r\nWhat's the best way for everyone supporting Fog to throw ideas into a hat so us core folks can come up with milestones we can work to?"
1249,'',"Use of Yard doc tags\n@geemus and myself have snuck in a few Yard tags in documenting some of the classes.\r\n\r\nI've working on more documentation for the Brightbox provider but finding plain Rdoc verbose.\r\n\r\nShould we replace the existing use of Yard (which isn't a development dependency) or look at using Yard for documentation (which should still do the Rdoc ones fine)?"
1248,'','describe_security_groups returns empty objects\nHi,\r\n\r\nWhen getting results back from describe_scaling_groups I\'m getting some objects back that on have these defined:\r\n\r\n```\r\n{"ipPermissions"=>[], "ipPermissionsEgress"=>[]}\r\n{"ipPermissions"=>[], "ipPermissionsEgress"=>[]}\r\n{"ipPermissions"=>[], "ipPermissionsEgress"=>[]}\r\n```\r\n\r\nThe commands I\'m running to get the results above from the fog console\r\n\r\n```\r\nconnector=Fog::Compute[:aws]\r\nsecurity_groups = connector.describe_security_groups.body["securityGroupInfo"]\r\nsecurity_groups.each do |sg|\r\n  unless sg["GroupName"]\r\n    puts sg\r\n  end\r\nend\r\n```\r\n\r\nWhat I\'m trying to do is get a list of the security groups and the total size is 93 but only 32 have real information.\r\n\r\nThanks,\r\nJay\r\n\r\n'
1247,'',"Adding Hetzner compute api\nHi,\r\n\r\nI am adding the Hetzner (www.hetzner.de) compute api. They rent out dedicated hardware which can be configured and rebooted via an api.\r\n\r\nI have the basic setup working, I can see my servers, reboot them, get the available images. **I could really use a couple of hints on how to proceed** to get this more in line with the fog standards (although I tried following them) the current changes: https://github.com/ahmeij/fog/compare/hetzner\r\n\r\nAlso a question, in a lot of implementations there is a method 'setup' on the server model, which seems to be a duplicate for most of them, should this method be moved to the core/server model? (I can make the change in another feature branch if needed)\r\n\r\nThanks, Andre"
1246,'',"[aws|compute] Fix #1245 - mock register_image fails with block device mapping\nWhen calling register_image in mock mode with a block device mapping, it is failing with:\r\n\r\n```\r\n undefined method `[]=' for nil:NilClass (NoMethodError)\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:108:in `register_image'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:107:in `each'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:107:in `register_image'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:100:in `each'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:100:in `register_image'\r\n       ...\r\n```\r\n\r\nThis changeset fixes the problem, and adds mock tests for register_image with block device mapping.\r\n"
1245,'','[aws|compute] mock register_image fails when given a block device mapping\nWhen fog is in mocking mode, calling register_image with a block device mapping:\r\n\r\n```ruby\r\nFog::Compute[:aws].register_image(\'image\', \'image\', \'/dev/sda1\', \r\n [ \r\n   { \'DeviceName\' => \'/dev/sdh\', \r\n     "SnapshotId" => "snap-123456789", \r\n     "VolumeSize" => "10G", \r\n     "DeleteOnTermination" => true\r\n  }\r\n]\r\n)\r\n```\r\n\r\nit fails with:\r\n\r\n```\r\n      undefined method `[]=\' for nil:NilClass (NoMethodError)\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:108:in `register_image\'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:107:in `each\'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:107:in `register_image\'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:100:in `each\'\r\n        /Users/brice/devl/fog/lib/fog/aws/requests/compute/register_image.rb:100:in `register_image\'\r\n```\r\n\r\nI\'m preparing a pull request to fix this issue.'
1244,'seanhandley','Bumped mocked maximum value for Provisioned IOPS\nThis change only affects the mock for AWS volumes. AWS announced today that they are going to increase the maximum soon.'
1243,'','[Brightbox] Deprecates overloaded requests\nThe API clients used in the Brightbox API are locked to one account but we are rolling out support for user applications that are related to a user and their permissions.\r\n\r\nSome of the original requests were implemented without needing identifiers - because they would have been redundant. Now to keep the naming as consistent as possible we are adding requests that optionally take identifiers and deprecating the older behaviour.\r\n\r\nSimpler versions of the requests (without needing identifiers) are available which should be used instead.'
1242,'','[Brightbox] User apps support\nThis adds the ability to authenticate as a User (rather than an API Client) using the OAuth2.0 "password" grant type.\r\n\r\nAlso adds requests for management of ApiClients and UserApplications and an ApiClient model.'
1241,'','RackspaceV2 bootstrap, setup, public_ip_address\nI was looking at [1141](https://github.com/fog/fog/pull/1141), which adds bootstrap method, but it does not implement the setup step, which is needed to add public_key to the new remote server on RackspaceV2.  Also, currently `server.sshable?` and `server.ssh` are not supported because method public_ip_address is missing from Fog::Compute::RackspaceV2::Server.  So I have added\r\n\r\n* *lib/fog/rackspace/models/compute_v2/server.rb*\r\n * *public_ip_address* - required by server.setup, server.sshable?, server.ssh, etc\r\n * *setup* - used to add public_key to authorized_keys on new server, as well as JSON attributes and metadata\r\n* *lib/fog/rackspace/models/compute_v2/servers.rb*\r\n * *bootstrap* - convenient and consistent way to initialize servers across providers'
1240,'','expect public_key option instead of ssh_key on block create\nBugfix for regression introduced by explicitly defining options passed to block creation endpoint.'
1239,'','Joyent server creation should not wait for server to be ready\nAlign with other providers for consistency'
1238,'','Move ssh private_key, public_key, username to Server model to reduce duplication\nBased on comment in https://github.com/fog/fog/pull/1224\r\n\r\nImplement ssh capabilities for all providers as long as they provide the ssh keys and public_ip_address\r\n'
1237,'','[Fog::Storage::AWS::File] Add support for x-amz-website-redirect-location\nAdd support for x-amz-website-redirect-location'
1236,'','Strange Timestamp issues on AWS header\n I recently started getting weird Amazon errors on requests. Anyone else have this issue? The main errors are\r\n\r\n     AWS authentication requires a valid Date or x-amz-date header\r\nand\r\n\r\n     The difference between the request time and the current time is too large.\r\nThis works fine on all my other machines, just on one development machine. Its running Mac OSX with Ruby 1.9 and Rails 3.0.10, the timestamps is fine on the machine. The header seems to be coming in as epoch time for some reason...\r\n`Excon::Errors::Forbidden (Expected(200) <=> Actual(403 Forbidden)\r\n  request => {:connect_timeout=>60, \r\n  :headers=>{"Date"=>"Wed, 31 Dec 1969 23:59:59 +0000", "Authorization"=>"AWS AUTHKEY", "Host"=>"my-development.s3.amazonaws.com:443"}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/temp/.rvm/gems/ruby-1.9.2-p180/gems/excon-0.16.2/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"my-development.s3.amazonaws.com", :path=>"/", :port=>"443", :query=>{}, :scheme=>"https", :expects=>200, :idempotent=>true, :method=>"GET", :response_block=>#<Proc:0x007fe4c3cc51f0@/Users/temp/.rvm/gems/ruby-1.9.2-p180/gems/fog-1.5.0/lib/fog/core/connection.rb:16 (lambda)>}\r\n  response => #<Excon::Response:0x007fe4c3c77a18 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AccessDenied</Code><Message>AWS authentication requires a valid Date or x-amz-date header</Message><RequestId>AF3S5E9BAA514F1</RequestId><HostId>SOMETHING</HostId></Error>", @headers={"x-amz-request-id"=>"AF3S5E9BAA514F1", "x-amz-id-2"=>"SOMETHING", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Thu, 25 Oct 2012 19:03:39 GMT", "Server"=>"AmazonS3"}, @status=403>):\r\n`\r\n\r\n`ERROR Excon::Errors::Forbidden: Expected([200, 206]) <=> Actual(403 Forbidden)   request => {:connect_timeout=>60, \r\n:headers=>{"Date"=>"Thu, 01 Jan 1970 00:00:01 +0000", "Authorization"=>"AWS AUTHKEY", "Host"=>"my-development.s3.amazonaws.com:443"}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/temp/.rvm/gems/ruby-1.9.2-p180/gems/excon-0.16.2/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"my-development.s3.amazonaws.com", :path=>"/2012%2F10%2F18%2F19%2F32%2F28%2F836%2Fdragonfly20121018_47202_2lm4t0", :port=>"443", :query=>nil, :scheme=>"https", :expects=>[200, 206], :idempotent=>true, :method=>"GET"}   response =>\r\n#<Excon::Response:0x007fd11e048ea8 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>RequestTimeTooSkewed</Code><Message>The difference between the request time and the current time is too large.</Message><MaxAllowedSkewMilliseconds>900000</MaxAllowedSkewMilliseconds><RequestId>85D12B885D8B4DBE</RequestId><HostId></HostId><RequestTime>Thu, 01 Jan 1970 00:00:01\r\n+0000</RequestTime><ServerTime>2012-10-26T21:19:18Z</ServerTime></Error>", @headers={"x-amz-request-id"=>"85D12B885D8B4DBE", "x-amz-id-2"=>"SOMETHING", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Fri, 26 Oct 2012 21:19:16 GMT", "Server"=>"AmazonS3"}, @status=403>\r\n`'
1235,'',"Add OpenStack EC2 credential management\nThis wraps API discovered from python-keystoneclient that allows CRUD for EC2 credentials and access through Fog models from a user for the OpenStack service.  Unfortunately I haven't been able to find documentation for this API.\r\n\r\nAlso, 401 handling for Fog::OpenStack::Identify::Real#request was altered to prevent an infinite loop.  See the message on 9430abb5 for details.\r\n\r\nShould I be documenting this new API? If so, where should I look for an example?"
1234,'','Vm clone add options 20121029\nAdded resource_pool (actually working) and fixed options check. Also added datastore setting via string. '
1233,'','Allows tests to run against FOG_RC setting\nhttps://github.com/fog/fog/commit/dce5e800fdebefdb64ea5ccd3418c80518d43276 introduced\r\nchanges in the test helper to use a specific test file (`tests/.fog`)\r\nand set of credentials (`default`) for tests.\r\n\r\nThis changes this to honour the existing environment variables if set.\r\n\r\nI use multiple configs to test against different versions of endpoints and the original change messes up that workflow and some of our CI settings.'
1232,'','Amazon RDS tagging\nThis pull request implements Tags for Amazon RDS instances. There are three requests:\r\n\r\n* list_tags_for_resource\r\n* add_tags_to_resource\r\n* remove_tags_from_resource\r\n\r\nand three parallel instance methods for the AWS::RDS::Server model:\r\n\r\n* tags() -> Hash\r\n* add_tags(Hash)\r\n* remove_tags(Array<String>)\r\n\r\nTests are supplied, with mocking support. Full RDS suite passes in Mocking mode.\r\n'
1231,'','Openstack auth error\n```\r\nfog\r\n  Welcome to fog interactive!\r\n  :default provides Ecloud and OpenStack\r\n>> \r\n?> \r\n?> openstack = Fog::Compute.new(:provider => "OpenStack")\r\nExcon::Errors::InternalServerError: Expected([200, 204]) <=> Actual(500 InternalServerError)\r\n  request => {:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"Content-Type"=>"application/json", "Host"=>"192.168.1.113:35357", "Content-Length"=>93}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/usr/local/rvm/gems/ruby-1.9.3-p286/gems/excon-0.16.7/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"192.168.1.113", :host_port=>"192.168.1.113:35357", :path=>"/v2.0/", :port=>"35357", :query=>nil, :scheme=>"http", :expects=>[200, 204], :body=>"{\\"auth\\":{\\"passwordCredentials\\":{\\"username\\":\\"admin\\",\\"password\\":\\"admin\\"},\\"tenantName\\":\\"admin\\"}}", :method=>"POST"}\r\n  response => #<Excon::Response:0x00000002647da8 @body="{\\"error\\": {\\"message\\": \\"An unexpected error prevented the server from fulfilling your request. get_version() got an unexpected keyword argument \'auth\'\\", \\"code\\": 500, \\"title\\": \\"Internal Server Error\\"}}", @headers={"Vary"=>"X-Auth-Token", "Content-Type"=>"application/json", "Content-Length"=>"199", "Date"=>"Fri, 26 Oct 2012 10:06:55 GMT"}, @status=500>\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/excon-0.16.7/lib/excon/connection.rb:292:in `request_kernel\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/excon-0.16.7/lib/excon/connection.rb:103:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/openstack.rb:156:in `retrieve_tokens_v2\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/openstack.rb:104:in `authenticate_v2\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/openstack/compute.rb:328:in `authenticate\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/openstack/compute.rb:258:in `initialize\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/core/service.rb:68:in `new\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/core/service.rb:68:in `new\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/lib/fog/compute.rb:62:in `new\'\r\n\tfrom (irb):3:in `<top (required)>\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/bin/fog:50:in `block in <top (required)>\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/bin/fog:50:in `catch\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/gems/fog-1.5.0/bin/fog:50:in `<top (required)>\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/bin/fog:19:in `load\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/bin/fog:19:in `<main>\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/bin/ruby_noexec_wrapper:14:in `eval\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.3-p286/bin/ruby_noexec_wrapper:14:in `<main>\'\r\n\r\n```\r\n\r\nin openstack auth console (i use devstack)\r\n```\r\n(root): 2012-10-26 18:06:55,976 ERROR wsgi __call__ get_version() got an unexpected keyword argument \'auth\'\r\nTraceback (most recent call last):\r\n  File "/opt/stack/keystone/keystone/common/wsgi.py", line 204, in __call__\r\n    result = method(context, **params)\r\nTypeError: get_version() got an unexpected keyword argument \'auth\'\r\n(eventlet.wsgi.server): 2012-10-26 18:06:55,978 DEBUG wsgi write 10.0.0.2 - - [26/Oct/2012 18:06:55] "POST /v2.0/ HTTP/1.1" 500 347 0.007063\r\n\r\n```\r\n\r\n\r\nHow to fixed it?'
1230,'','[AWS::Mock|create_image] automatic registration of ebs image upon image_...\n...create'
1229,'',"[VMWare] fixed vm listing problem\nthe vm listing request was using the inventory method which was:\r\na. deprecated\r\nb. broken on certian conditions (which I'm uncretian of but could reproduce).\r\n\r\nthis also uses a better / cleaner method to find all vms"
1228,'',"Error fog and carrierwave on google cloud storage\nhi, \r\ni've storage files on google cloud, but, on upload, i receive this error:\r\n\r\nundefined method `encoding' for #<ActionDispatch::Http::UploadedFile:0x007fdb4e062670>\r\n \r\nhow i can fix this?"
1227,'',"Error fog and carrierwave on google cloud storage\nhi, \r\ni've storage files on google cloud, but, on upload, i receive this error:\r\n\r\nundefined method `encoding' for #<ActionDispatch::Http::UploadedFile:0x007fdb4e062670>\r\n \r\nhow i can fix this?"
1226,'','Rdoc vsphere vm clone\nAdded documentation. '
1225,'','Openstack provider fixes to work with Rackspace open cloud\nFix some issues to use openstack provider on the Rackspace open cloud.\r\n\r\nI got it to work using my rackspace password (not the api key) and region is mandatory (DFW or ORD)\r\n\r\nI kept the existing behavior intact so it should still work with other implementations, but fixed some cases where rackspace causes errors. I have commented the code with the specifics.\r\n\r\nidentity_public_endpoint is returned nil from Rackspace so the hack I found to work was to strip the last part of the openstack_management_url\r\n\r\nSome times I get the error "OpenStack binding only supports version 2 (a.k.a. 1.1)", traced it and is indeed Rackspace returning the v1.1 urls for openstack_management_url, but just some times\r\n'
1224,'',"Implement ssh to joyent and vsphere compute servers\nAdd attributes needed for ssh'ing to joyent and vsphere compute servers\r\n\r\nAlso, the Joyent server creation should not wait for server to be ready (to match the other providers behavior)\r\n"
1223,'','Adding Google Compute Engine Driver\n'
1222,'',"Changed the list server request to get details\nI need the state of the server on reach qetests. The simple request doesn't provide that.\r\n"
1221,'','[AWS::Mock|create_image] automatically registers ebs-backed image upon m...\n...ocked creation'
1220,'',"Use test-only credentials for tests, avoid unmocked tests by default\nThis pull request is for #1218.\r\n\r\nTests will use :default in tests/.fog for credentials instead of the user's default credentials in ~/.fog\r\n\r\nUnmocked tests will not be run by default.  This allows the tests to pass when the users don't have the necessary credentials."
1219,'','Added OpenStack::Server#created and #updated\nMy OpenStack compute environment returns these two fields in the\r\nresponse from get_server_details.  This commit exposes them in the\r\nServer objects.'
1218,'','`rake test` should not use ~/.fog\nI tried to run the fog tests, but it complained until I added some default credentials. (I already had a ~/.fog, but never created a default entry).\r\n\r\nI chose to use fake credentials, then fog gave me scary failures like the following that make me believe that fog may have tried to do things I didn\'t approve of to my AWS account.  Possibly things that could disrupt services hosted with my account and/or cost me money.\r\n\r\nThe fog tests should not rely on any file outside the checkout directory for safety and non-scarieness.\r\n\r\n```\r\n  Fog::CDN[:aws] | invalidation (aws, cdn)     \r\n    tests/aws/models/cdn/invalidation_tests.rb\r\n      Fog::CDN[:aws] | invalidation (aws, cdn)\r\n    - succeeds\r\n    \r\n    tests/aws/models/cdn/invalidation_tests.rb\r\n    Expected(201) <=> Actual(403 Forbidden)\r\n  request => {:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"Content-Type"=>"text/xml", "Date"=>"Thu, 18 Oct 2012 21:53:02 +0000", "Authorization"=>"AWS 0123456789abcdef0123456789abcdef:c96KX3Pocm/SjYwbIaHql+tJKn8=", "Host"=>"cloudfront.amazonaws.com:443", "Content-Length"=>268}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/usr/local/lib/ruby/gems/1.9.1/gems/excon-0.16.7/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"cloudfront.amazonaws.com", :host_port=>"cloudfront.amazonaws.com:443", :path=>"/2010-11-01//distribution", :port=>"443", :query=>nil, :scheme=>"https", :body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?><DistributionConfig xmlns=\\"http://cloudfront.amazonaws.com/doc/2010-11-01/\\"><S3Origin><DNSName>fog_test.s3.amazonaws.com</DNSName></S3Origin><Enabled>true</Enabled><CallerReference>1350597182</CallerReference></DistributionConfig>", :expects=>201, :idempotent=>true, :method=>"POST", :response_block=>#<Proc:0x007fbe5cb7edb0@/Users/drbrain/Work/git/fog/lib/fog/core/connection.rb:16 (lambda)>}\r\n  response => #<Excon::Response:0x007fbe5d878e08 @body="<?xml version=\\"1.0\\"?>\\n<ErrorResponse xmlns=\\"http://cloudfront.amazonaws.com/doc/2010-11-01/\\"><Error><Type>Sender</Type><Code>InvalidClientTokenId</Code><Message>The security token included in the request is invalid</Message></Error><RequestId>32a9505f-196e-11e2-901c-e1193d0877bd</RequestId></ErrorResponse>", @headers={"x-amzn-RequestId"=>"32a9505f-196e-11e2-901c-e1193d0877bd", "Content-Type"=>"text/xml", "Content-Length"=>"307", "Date"=>"Thu, 18 Oct 2012 21:53:05 GMT"}, @status=403> (Excon::Errors::Forbidden)\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/excon-0.16.7/lib/excon/connection.rb:292:in `request_kernel\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/excon-0.16.7/lib/excon/connection.rb:103:in `request\'\r\n      /Users/drbrain/Work/git/fog/lib/fog/core/connection.rb:20:in `request\'\r\n      /Users/drbrain/Work/git/fog/lib/fog/aws/cdn.rb:185:in `request\'\r\n      /Users/drbrain/Work/git/fog/lib/fog/aws/requests/cdn/post_distribution.rb:85:in `post_distribution\'\r\n      /Users/drbrain/Work/git/fog/lib/fog/aws/models/cdn/distribution.rb:65:in `post_distribution\'\r\n      /Users/drbrain/Work/git/fog/lib/fog/aws/models/cdn/distribution.rb:48:in `save\'\r\n      /Users/drbrain/Work/git/fog/lib/fog/core/collection.rb:50:in `create\'\r\n      tests/aws/models/cdn/invalidation_tests.rb:4:in `block (2 levels) in <top (required)>\'\r\n      tests/helpers/succeeds_helper.rb:6:in `instance_eval\'\r\n      tests/helpers/succeeds_helper.rb:6:in `block in succeeds\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:139:in `instance_eval\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:139:in `assert\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:115:in `test\'\r\n      tests/helpers/succeeds_helper.rb:5:in `succeeds\'\r\n      tests/aws/models/cdn/invalidation_tests.rb:3:in `block in <top (required)>\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:79:in `instance_eval\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:79:in `tests\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:38:in `initialize\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:14:in `new\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo.rb:14:in `tests\'\r\n      tests/aws/models/cdn/invalidation_tests.rb:1:in `<top (required)>\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `load\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `each\'\r\n      /usr/local/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `block in run_in_thread\'\r\n    \r\n```'
1217,'',"Update lib/fog/vsphere/requests/compute/vm_clone.rb\nAdded more options for destination folder to copy new clone to. (No Checks on if new dest_folder exists). ln 128 - 130\r\nAdded resource_pool option is mentioned needing revisit in source. ln 118 & 121\r\nRenamed 'path' option to 'template_location' (need to include some logic to support people using path still) "
1216,'','Poor Documentation on VSphere::Real Methods\n@geemus && @bradgignac \r\n\r\nWould like to see (or contribute) more documentation on how to effectively the VSphere Compute methods. Having to rtfsc gets tiresome and better documentation would be helpful to understand what options are available to be set and better sees holes where feature enhancements could be made. \r\n\r\nOne example is the inability to change the resource_pool of the machine being cloned via the method vm_clone(). This is not a problem with Rbvmomi but just needs to be enhanced in the source. \r\n\r\ncheers'
1215,'','AWS::Mock create_image has different behavior than AWS::Real create_image\nAWS::Real create_image(instance_id, image_name, image_description) creates an ebs-backed ami on AWS which is automatically registered by AWS, however AWS::Mock create_image(instance_id, image_name, image_description) does not register a ami as expected.\r\n\r\nDocumentation for create_image creating ebs-backed ami:\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateImage.html\r\n\r\nDocumentation note about automatic registration of ebs backed ami: \r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-RegisterImage.html'
1214,'tokengeek','[Brightbox] Server initialisation fails unless a config file is in place\nAffects Fog 1.6\r\n\r\nDiscovered by @rubiojr as part of https://github.com/rubiojr/knife-brightbox/issues/6\r\n\r\nWe introduced a dynamic lookup in https://github.com/fog/fog/commit/b221b97ba62622ea60f623af6d41c6db9d9798ec to query the list of images available and pick the most suitable default rather than hardcoding it in Fog.\r\n\r\nUnfortunately using `Fog::Compute[:brightbox]` as the basis of the connection actually creates a new connection based on details in the `~/.fog` file to perform this lookup.\r\n\r\nNever spotted this because I always have this file in place but if you are creating your own connection with parameters and do not have this file `Fog::Compute::Brightbox::Server.new` fails because this second connection doesn\'t have the required arguments.\r\n\r\nLooking further the `connection` that should be used is not available at that point in time (is `nil`) so it\'s not a simple exchange.\r\n\r\nThe connection attribute is merged in afterwards so currently there isn\'t a way to use an existing connection in a model\'s `initialize` that I can see.\r\n\r\n```\r\n$ connection = Fog::Compute.new(:brightbox_client_id => "cli-xxxxx", :brightbox_secret => "xxxxxxxx", :provider => "Brightbox")\r\n#<Fog::Compute::Brightbox::Real>\r\n$ connection.servers.first\r\nArgumentError: Missing required arguments: brightbox_client_id, brightbox_secret\r\nfrom /Users/paul/code/fog/lib/fog/core/service.rb:208:in `validate_options\'\r\n```'
1213,'',"[openstack] Ensure String Username for Authentication\nWhen username is composed of only integers, openstack raises a\r\nProgrammingError when trying to authenticate user.\r\n\r\n-- I am actually even unsure if it should be allowed that a user to have a username composed of all numbers, anyway OpenStack allows it, so here's the pull request."
1212,'',"Fog::AWS::CloudWatch#all follows NextToken\nI'm not sure about the general idea of following NextToken without any constraints. This seems like it has the potential to eat up a lot of memory and time. However, having #all not return all of the available results seems to lead to confusion."
1211,'','[AWS|cloud_watch]: fix list_metrics NextMarker should be NextToken\nSee http://docs.amazonwebservices.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html'
1209,'',"Public URL and File Destroy\nI recently started using CarrierWave and had great success using AWS for storage. Although it was successful its performance wasn't suitable for an application I was developing for the Australian market. Hence I started to have a look at Ninefold (who uses Atmos) but found Fog failed to work with CarrierWave.\r\n\r\nI'm relatively new to cloud storage so after a few of days of research and reverse engineering I identified that the public_url method didn't seem to work as expected. I've made some changes to get it working as expected and done some rudimentary manual testing. Ideally automated testing (ie RSpec) would be more desirable but without the background in cloud storage I found it difficult to do.\r\n\r\nI've also identified a problem with file deletion where a Fog::Storage::Atmos::NotFound exception occurs if the file doesn't exist.  I figured if you wanted to delete the file then the fact it didn't exist doesn't really matter because you got what you wanted: the file is gone so why throw an exception.  To that effect I've changed the File.destroy method.  \r\n\r\nLet me know what you think."
1208,'','[aws|cloud_watch] Add instrumentation support.\n'
1207,'',"Fixes fog/fog#1206\nGoogle's [CORS implementation](https://developers.google.com/storage/docs/cross-origin) implements a canonical resource parameter that was not included in the hashed headers."
1206,'',"Google Cloud Storage and Cors\nGoogle's [CORS implementation](https://developers.google.com/storage/docs/cross-origin) implements a canonical resource parameter that is currently not included in the hashed headers.\r\n\r\nNeed to add **cors** to the array on line 246:\r\nhttps://github.com/fog/fog/blob/f906a33b9fe920ecabe1e52ecda07a78def31bb2/lib/fog/google/storage.rb\r\n\r\n\r\n"
1205,'','[AWS|Glacier] Fix description header not being passed through Fog.escape\nThis fixes #1202 for me . I think this is the right think to do - escaping header values systematically seemed to produce invalid signatures too.'
1204,'','Add force option to auto scaling group model destroy method\n'
1203,'',"Beginning implementation of RDS subnet groups\n@geemus, @estonfer --\r\n\r\nBeen a while since I've had a chance to look at this again but I've just pushed some changes that form the beginning of proper RDS subnet group support for fog. So far, just create_db_subnet_group and describe_db_subnet_groups are implemented. Next I need to add support for modifying and deleting RDS subnet groups, but first I wanted to see if you guys could check this over to make sure I'm on the right track.\r\n\r\nI based the implementation largely on RDS security groups. One thing in particular to notice is that I'm representing the subnets in a SubnetGroup model as simply an array of strings (the subnet IDs) rather than as a collection of Subnet objects. I'm wondering if this is an acceptable approach, given that the models would cross service namespace boundaries and the simple fact that IDs are basically all you'd need in order to work with the groups. (and also that it was a heck of a lot easier for me to undertand/implement!)\r\n\r\nAnyway, I'd really appreciate it if one of you could please look this over and let me know if I should continue on as I've begun.\r\n\r\nThanks!"
1202,'','Glacier: UTF-8 descriptions break signature?\nso, i think there may be an issue with having UTF-8 strings in archive descriptions.  my code looks something like this:\r\n\r\n```\r\nglacier = Fog::AWS::Glacier.new(:aws_access_key_id => XXX, :aws_secret_access_key => YYY)\r\nvault = glacier.vaults.get(\'some_vault_id\')\r\nfile_name = "/2011/BB/@clips/ÐÐ¾Ð¼ 14.06 ÑÐ°ÑÐ¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð¼Ð½Ð°Ñ.jpg"\r\nvault.archives.create(:body => File.open(file_name), :description => file_name, :multipart_chunk_size => 1024 * 1024)\r\n```\r\n\r\nwhen it gets run, i receive this error back from AWS:\r\n\r\n```\r\nresponse => #<Excon::Response:0xb98c58c @body="{\\"message\\":\\"The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.\\\\n\\\\nThe Canonical String for this request should have been\\\\n\'POST\\\\n/-/vaults/icebox_vault_9342004be9/multipart-uploads\\\\n\\\\ndate:Thu, 11 Oct 2012 05:05:31 +0000\\\\nhost:glacier.us-east-1.amazonaws.com\\\\nx-amz-archive-description:/2011/BB/@clips/\\xC3\\x90\\xC2\\x94\\xC3\\x90\\xC2\\xBE\\xC3\\x90\\xC2\\xBC 14.06 \\xC3\\x91\\xC2\\x80\\xC3\\x90\\xC2\\xB0\\xC3\\x91\\xC2\\x81\\xC3\\x90\\xC2\\xBF\\xC3\\x90\\xC2\\xBE\\xC3\\x90\\xC2\\xBB\\xC3\\x90\\xC2\\xBE\\xC3\\x90\\xC2\\xB6\\xC3\\x90\\xC2\\xB5\\xC3\\x90\\xC2\\xBD\\xC3\\x90\\xC2\\xB8\\xC3\\x90\\xC2\\xB5 \\xC3\\x90\\xC2\\xBA\\xC3\\x90\\xC2\\xBE\\xC3\\x90\\xC2\\xBC\\xC3\\x90\\xC2\\xBD\\xC3\\x90\\xC2\\xB0\\xC3\\x91\\xC2\\x82.jpg\\\\nx-amz-date:20121011T050531Z\\\\nx-amz-glacier-version:2012-06-01\\\\nx-amz-part-size:1048576\\\\n\\\\ndate;host;x-amz-archive-description;x-amz-date;x-amz-glacier-version;x-amz-part-size\\\\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\'\\\\n\\\\nThe String-to-Sign should have been\\\\n\'AWS4-HMAC-SHA256\\\\n20121011T050531Z\\\\n20121011/us-east-1/glacier/aws4_request\\\\nc13b937313e6e695dbb0760a4f5df4738ba0293fd820ab9f0d93ff0c7c127d4e\'\\\\n\\",\\"code\\":\\"InvalidSignatureException\\",\\"type\\":\\"Client\\"}", @headers={"x-amzn-RequestId"=>"6TBN5NMAhaAqQFmnAMmFj-EfbEU8rYeK2phpU1vWC0GPtC8", "Content-Type"=>"application/json", "Content-Length"=>"1008", "Date"=>"Thu, 11 Oct 2012 05:05:30 GMT"}, @status=403>\r\n```\r\n\r\nit works perfectly fine if i change description to something like "foo".\r\n\r\ncan you guys confirm this is true or untrue?\r\n'
1201,'','Please review fixes to ninefold implementation\n'
1200,'','Added usagePrice to get the hourly cost for a reserved instance\n'
1199,'',"Excon::Errors::Timeout: write timeout reached while uploading a big file to s3\nfog 1.6.0\r\nexcon 0.16.4\r\ncarrierwave 0.6.2\r\ns3 region: eu-west-1\r\n\r\n~ 30 MiB file upload. Doesn't happen with small files.\r\n\r\n"
1198,'','References to examples/dns_tests.rb  broken in markdown\nIn the markdown at https://github.com/fog/fog/blob/master/docs/dns/index.markdown - I see a reference to:\r\nhttps://github.com/fog/fog/blob/master/examples/dns_tests.rb\r\n\r\nIt seems to be moved or missing.\r\n\r\nThe same issue shows up at http://fog.io/1.6.0/dns/.'
1197,'','modified create function to include options. changed "diskConfig" to "OS...\n...-DCF:diskConfig" to allow disk configuration to be properly set.'
1196,'','Add config instructions to README\nAdds basic instruction to add config that is necessary for tests to run successfully'
1195,'','Provide a generic, threaded clear_container method\nProblem\r\n\r\nThe delete operation, when performed on a large container (S3 bucket, for example) can take a significant amount of time (order of 10s of hours for containers with millions of items). Some providers have the API call to delete multiple objects, which does help, but is not generic.\r\n\r\nProposal\r\n\r\nProvide a method to remove a bucket and if the "threaded" parameter is passed, create multiple threads to delete objects and at least one thread to enumerate the objects in the container.\r\n\r\nIn terms of the design, I was thinking it would make sense to extend Service into StorageService and add a generic method there. The requirements, from the other services, would then be to agree on a name for the delete_key method (I think that\'s largely the case right now?) and then have each storage class inherit from that class, as opposed to Service. Does this make sense? I\'m happy to actually implement all of the above, but wanted to agree on the design, before I go ahead and do something. '
1194,'','Ignore existing directory when creating on local storage\nRebased version of #1193'
1193,'',"Ignore existing directory when creating on local storage\nI'm trying to use fog with local storage in my dev environment and s3 for my production environment (since they use the same api--sweet).  However I ran into an issue when creating directories.  s3 simply returns a pre-existing bucket when you try to re-create it, but locally Dir.mkdir returns an error.  This change simply checks for a currently existing directory before trying to create.\r\n\r\nI added a test, but I haven't used Shindo and I couldn't seem to get either the file or directory tests to run under local (using shindo tests/local)..."
1192,'','Amazon Simple Workflow service\nFolks,\r\n\r\nIs there a reason why we dont have Simple Workflow covered? There is a API for it http://docs.amazonwebservices.com/amazonswf/latest/apireference/Welcome.html?r=2945 , I have been working on this a lot lately and have put some code together to contribute. Wondering if anyone else is working on this?'
1191,'','cannot authenticate against the new rackspace openstack V2 support \ntrying to authenticate against the new compute_v2 support for rackspace.\r\n\r\n\r\nrunning the following (I\'m running from the UK so using the lon prefix on urls) \r\n\r\n\r\n\r\nconn = Fog::Compute.new({:provider => "Rackspace",\r\n          :rackspace_api_key => "myapikey",\r\n          :rackspace_username => "myusername",\r\n          :rackspace_auth_url => "https://lon.identity.api.rackspacecloud.com/v2.0/",\r\n          :rackspace_endpoint => \'https://lon.servers.api.rackspacecloud.com/v2/9999999\',\r\n           :version => :v2 })\r\n \r\nwhere i use my key and username and 99999999 is my account no.         \r\n\r\nget the following response \r\n\r\nC:/Ruby193/lib/ruby/gems/1.9.1/gems/fog-1.6.0/lib/fog/rackspace/compute_v2.rb:11\r\n7:in `authenticate\': undefined method `match\' for nil:NilClass (NoMethodError)\r\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/fog-1.6.0/lib/fog/rackspace/com\r\npute_v2.rb:77:in `initialize\'\r\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/fog-1.6.0/lib/fog/core/service.\r\nrb:68:in `new\'\r\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/fog-1.6.0/lib/fog/core/service.\r\nrb:68:in `new\'\r\n        from C:/Ruby193/lib/ruby/gems/1.9.1/gems/fog-1.6.0/lib/fog/compute.rb:73\r\n:in `new\'\r\n        from fog_rack.rb:14:in `<main>\'\r\n\r\nthis is because  in lib\\fog\\rackspace\\compute_v2.rb \r\n in the authenticate method   \r\n    credentials = Fog::Rackspace.authenticate(options, @connection_options)\r\n returns nil instead of a token \r\n hence the line fails \r\n   account_id = credentials[\'X-Server-Management-Url\'].match(/.*\\/([\\d]+)$/)[1]\r\n\r\nany ideas? It would be good to update the fog.io website with a sample for compute_v2. '
1190,'','Added Marker to Elasticache and RDS describe_events\nAdded parsing for Marker.  AWS limits response to 100 lines and gives you a marker to get the next batch with'
1189,'',"Extend create image\nThis pull request extends create image to include all of the BlockMapping stuff\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateImage.html\r\n\r\nI've only added create_image tests as mocking, running the tests with FOG_MOCK=false take over 11 minutes during my test, which is pretty lengthy (and timed out wait_for{state == 'available'}), if we want to go with real runs as well we can do that."
1188,'','Add support for OnApp\nIs there a plan to add support for OnApp (http://onapp.com) cloud platform? API documentation can be found from here http://cdn.onapp.com/files/docs/onapp_cloud_2-3-3_api-guide_v1-7.pdf'
1186,'','Added Description field to Outputs section of DescribeStacks parser\nDescribeStacks parser for AWS::CloudFormation was missing the Description tag'
1185,'','Storage of Parse.com\nI want to implement a storage to upload file of [Parse](https://parse.com/docs/rest#files). But I seldom find a guide about how to contribute. Where should I start?'
1184,'',"Added support for scheduler hints in OpenStack\nAdded support for openstack scheduler hints when creating new servers.\r\n\r\nhttp://docs.openstack.org/trunk/openstack-compute/admin/content/scheduler-filters.html\r\n\r\nUsage:\r\n\r\n```ruby\r\nopenstack.servers.create(\r\n  name:  'abc',\r\n  image_ref: '123',\r\n  flavor_ref: 'ab-1',\r\n  os_scheduler_hints: {different_host: ['id1', 'id2'] }\r\n)\r\n```"
1183,'','failing mocked tests for aws autoscaling\n@redzebra - looks like the tests are failing outside 1.8.7 on the autoscaling mocks, any chance you could take a look: https://travis-ci.org/#!/fog/fog I tried, by changing the string.to_a things to [*string], which fixed the errors, but caused other ones, so if you could check it out that would be great.'
1182,'','[aws|cdn] add request mock support for AWS Cloudfront\nThis patch adds support for mocking the cloudfront API.\nCDN Tests now can both be run with mocking and non mocking\nactivated.\n\n'
1181,'',"General Update of Test Mocks (WIP) + `update_image_members` Request\nStill working on fixing some of the shindo tests that failed due to the changes. Although I think I should've separated the `update_image_members` request to another Pull Request"
1180,'',"Fix for mock OpenStack create_security_group\nHi there.  According to the OpenStack API documentation at http://api.openstack.org, sending a POST to os-security-groups returns a JSON hash, not a JSON hash enclosed in an array.\n\nThis patch removes the extraneous array and now my mocked create_security_group behaves identically to a real one, at least on HP's OpenStack cloud."
1179,'','[compute|ecloud] Fixed minor problems\nFixed a problem where querying servers by group would return nil.  Also fixed a couple of bad request names.'
1178,'','Added describe_events to RDS\nSimply copied describe_events from Elasticache and updated for RDS.'
1177,'',"How to set mock data\nI'm using a specific keypair name, and my mocks are returning with failures:\n\n````ruby\nFog::Compute::AWS::NotFound:\n       The key pair 'custom-key' does not exist\n````\n\nI've tracked this down to being looked up in a `#data` hash somewhere, but I can't find where I'm supposed to set that at.\n\nSorry for the newbie question!"
1176,'','Added ParameterValue to aws/elasticache engine_defaults_parser\nDescribeCacheParameters action was not displaying the ParameterValue because it was missing as a tag in the parser.  Tag was added into aws/parsers/elasticache/engine_defaults_parser.rb and value is displayed correctly.'
1175,'','Specifying :az1 with HP provider still returns :az3\nThe current state of the \'HP\' provider is somewhat broken with regards to selecting your Availability Zone. If you don\'t specify one or specify \'az1\', you end up in \'az3\'. Only \'az2\' can be selected.\n\nWith Fog::Compute.new() hp_avl_zone => :az1 doesn\'t work, but :az2 does (and :az3 is broken per https://github.com/fog/fog/pull/903). \n\nExample:\n\n```\n[129] pry(main)> connection = Fog::Compute.new(:provider => \'HP\', :hp_secret_key => ENV[\'HP_SECRET_KEY\'], :hp_tenant_id => ENV[\'HP_TENANT_ID\'], :hp_account_id => ENV[\'HP_ACCESS_KEY\'], :hp_avl_zone => :az1)\n=> #<Fog::Compute::HP::Real:2468135900 @hp_account_id=123456789 @hp_servicenet=nil @connection_options={} @hp_tenant_id=987654321 @hp_compute_uri="https://az-3.region-a.geo-1.compute.hpcloudsvc.com/v1.1/987654321" @auth_token="HPAuth_1234c3c2e4b08b0488437890" @host="az-3.region-a.geo-1.compute.hpcloudsvc.com" @path="/v1.1/987654321" @persistent=false @port=443 @scheme="https" @connection=#<Fog::Connection:0x007f8471547840 @excon=#<Excon::Connection:0x007f8471547818 @connection={:chunk_size=>1048576, :connect_timeout=>60, :headers=>{}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/mray/.rvm/gems/ruby-1.9.3-p194@knife-hp/gems/excon-0.16.3/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"az-3.region-a.geo-1.compute.hpcloudsvc.com", :path=>"", :port=>"443", :query=>nil, :scheme=>"https"}, @proxy=nil, @socket_key="az-3.region-a.geo-1.compute.hpcloudsvc.com:443">, @persistent=false>>\n```\n\ncc @rupakg '
1174,'','Attempting Euca3 Walrus using AWS S3\nIs this an issue because of virtual hosting of S3? By default Eucalyptus has DNS disabled. Is it possible to disable the fogs use of virtual hosting?\n\n\nMy attempt log below:\n\ns3 = Fog::Storage::AWS.new({:aws_access_key_id => MY_ACCESS_KEY, :aws_secret_access_key => MY_SECRET_KEY, :endpoint=>"http://172.31.254.5:8773/services/Walrus"})\n => #<Fog::Storage::AWS::Real:95103270 @use_iam_profile=nil @aws_access_key_id=MY_ACCESS_KEY @aws_session_token=nil @aws_credentials_expire_at=nil @connection_options={} @endpoint="http://172.31.254.5:8773/services/Walrus" @host="172.31.254.5" @path="/services/Walrus" @port=8773 @scheme="http" @connection=#<Fog::Connection:0xb53bbf4 @excon=#<Excon::Connection:0xb53bbe0 @connection={:chunk_size=>1048576, :connect_timeout=>60, :headers=>{}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/excon-0.16.3/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"172.31.254.5", :path=>"/services/Walrus", :port=>"8773", :query=>nil, :scheme=>"http"}, @proxy=nil, @socket_key="172.31.254.5:8773">, @persistent=nil>> \n\ns3.directories\n[WARNING] fog: the specified s3 bucket name(172.31.254.5) is not a valid dns name, which will negatively impact performance.  For details see: http://docs.amazonwebservices.com/AmazonS3/latest/dev/BucketRestrictions.html\nExcon::Errors::NotFound: Expected(200) <=> Actual(404 Not Found)\n  request => {:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"Date"=>"Tue, 25 Sep 2012 20:25:36 +0000", "Authorization"=>"AWS MY_ACCESS_KEY", "Host"=>"172.31.254.5:8773"}, :instrumentor_name=>"excon", :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/excon-0.16.3/data/cacert.pem", :ssl_verify_peer=>true, :write_timeout=>60, :host=>"172.31.254.5", :path=>"/172.31.254.5", :port=>"8773", :query=>nil, :scheme=>"http", :expects=>200, :idempotent=>true, :method=>"GET", :url=>"172.31.254.5", :response_block=>#<Proc:0xb4506cc@/home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/core/connection.rb:16 (lambda)>}\n  response => #<Excon::Response:0xb709fa8 @body="<?xml version=\\"1.0\\"?><Response><Errors><Error><Code>404 Not Found</Code><Message>unknown</Message></Error></Errors><RequestID>unknown</RequestID></Response>", @headers={"Content-Type"=>"text/plain; charset=UTF-8"}, @status=404>\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/excon-0.16.3/lib/excon/connection.rb:285:in `request_kernel\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/excon-0.16.3/lib/excon/connection.rb:101:in `request\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/core/connection.rb:20:in `request\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/aws/storage.rb:392:in `request\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/aws/requests/storage/get_service.rb:32:in `get_service\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/aws/models/storage/directories.rb:13:in `all\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/core/collection.rb:130:in `lazy_load\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/core/collection.rb:18:in `empty?\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/core/collection.rb:75:in `block in inspect\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/formatador-0.2.3/lib/formatador.rb:92:in `indent\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.6.0/lib/fog/core/collection.rb:68:in `inspect\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/railties-3.0.7/lib/rails/commands/console.rb:44:in `start\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/railties-3.0.7/lib/rails/commands/console.rb:8:in `start\'\n\tfrom /home/barrett/.rvm/gems/ruby-1.9.2-p290/gems/railties-3.0.7/lib/rails/commands.rb:23:in `<top (required)>\'\n\tfrom script/rails:6:in `require\'\n\tfrom script/rails:6:in `<main>\'\n\n\n'
1173,'',"[aws|cdn] small fixes and aws cdn models\nHi,\n\nPlease find a set of changes related to AWS CDN, which includes:\n\n* a fix from one of my previous patch\n* test coverage for streaming distributions\n* documentation fixes\n* full models (and tests) covering distributions, streaming distributions and invalidations\n* cdn documentation for models\n\nPlease bear with me as those are the first models I'm writing, do not hesitate to comment and review :)\n\nThanks!\nBrice\n"
1172,'',"Support pagination for >100 records with Rackspace DNS\nI'm not sure what to do about adding test coverage for this, as there already is test coverage over the API I am using..\n\n"
1171,'',"Fog.unmock! did not turn mocks off while running\nI may be misinterpreting the design here, but I'd think that this code would temporarily turn off mocks in a more elegant way than catching and ignoring the unmocked exception that gets thrown.\n\n      # no mock for this\n      mocking = Fog.mocking?\n      Fog.unmock!\n\n      websiteConfiguration = @specUtilities.getBucketWebsiteConfiguration().body\n\n      # turn mocks back on if specified by runner\n      if(mocking) then\n        Fog.mock!\n      end"
1170,'','get_bucket_website mock not implemented for aws s3\n'
1169,'','can\'t seem to create archives on Glacier...\nguys, i\'ve been playing around with fog trying to create archives on Glacier, but it doesn\'t seem to be working (even though fog sorta acts like it is working).  i\'ve also confirmed on my AWS console that archives aren\'t getting created.\n\nhere\'s a sample with some output.  any help would be greatly appreciated.\n\n1.9.3p194 :034 > glacier = Fog::AWS::Glacier.new :aws_access_key_id => AWS[:key], :aws_secret_access_key => AWS[:secret]\n => #<Fog::AWS::Glacier::Real:100763270 @use_iam_profile=nil @region="us-eas...\n =>   <Fog::AWS::Glacier::Vault id="test"...\n1.9.3p194 :036 > archive = vault.archives.create :body => \'foo\', :description => \'bar\'\n =>   <Fog::AWS::Glacier::Archive id="i_3SKVAQ2KKBKD8gCx9...\n1.9.3p194 :037 > vault.number_of_archives\n => 0 \n1.9.3p194 :039 > vault.archives.all\n => nil \n'
1168,'','[Ninefold|Storage] Use Atmos in Ninefold storage.\nCurrently, code is duplicated between ninefold and atmos. We should\nremove the code duplication and extend the atmos module in Ninefold.'
1167,'',"Ninefold\nThis eliminates a bunch of duplicated code between atmos and ninefold storage.\n\nConfused about why it's pulling in additional commits (I did a fetch and a rebase beforehand, so that should have avoided this?)."
1166,'','allow port to be included in queue_url\nThe method currently fails when we use the QueueUrl provided from SQS list_queues {"QueueUrls"=>["https://sqs.us-east-1.amazonaws.com:443/77XXXXXXXX/sample-queue"], ...}'
1165,'','Make region available to mock\n'
1164,'','[openstack|network] Add support for OpenStack Quantum\nAdded support for [OpenStack Networking (Quantum)](http://www.openstack.org/software/openstack-networking/).\n\n* New service Fog::Network\n* Full support for [Quantum API v2](http://docs.openstack.org/api/openstack-network/2.0/content/index.html)\n* Example: [gist](https://gist.github.com/3764572)\n* Test cases (for models and requests)\n\nTested on OpenStack Quantum Folsom RC1.'
1163,'',"Correct the handling of the power_on option for vsphere clone_vm request\nThe current code ignore the actual option passed on for 'power_on' and always goes with 'true' because of the OR\n\nHave fixed this so that the option passed in is always considered\n\nAlso, have no clue on how to test this... (looked at the test code; but it didn't seem very apparent.)"
1162,'','route53 delete_hosted_zone has no mocks\nI may take a stab at this one via a pull request later.'
1161,'','[aws|cdn] Add the missing get invalidation request\nPlease find this patch adding test coverage to AWS/CDN, along with the get_invalidation request implementation.'
1160,'','Recursive, rsync-like directory handling\nFog should provide a way to recursiely handle directories and provide a feature set that would make it easy to implement tools such as scp, s3cmd or rsync.\n'
1159,'',"More examples in the documentation\nPlease someone update the documentation and provide more examples.\n\nl think all the features supported by fog (everything seen in the feature matrix) should have examples on how to use them.\n\nFor example I now need some code that does autoscaling in AWS, and I couldn't find anything yet. Can someone give me a hand in this?"
1158,'',"aws cdn generated xml doesn't match aws rest documentation schema\nlikely since an update occured on 2012-05-05\n\nhttp://docs.amazonwebservices.com/AmazonCloudFront/latest/APIReference/CreateDistribution.html"
1157,'','aws cdn has no mocks\n'
1156,'','Added Load Balancing API calls\n- Updated fog calls parameters\n- Updated documentation'
1155,'','correct the options checking in BlueBox create_block\npassword and ssh_key are passed in as strings and not symbols when using\xa0servers.create(opts)'
1154,'','Fog::Mock data persistence hooks\nHi,\n\nPlease find an attempt to provide Fog::Mock data persistence hooks in Fog::Mock to allow fog based application to persist the mock data between application calls.\n\nThe idea is to be able to write acceptance tests like this fake cucumber one:\n\n```\n  Scenario: creating an S3 bucket\n    Given I run \'s3 bucket create test\'\n    When I run `s3 bucket list`\n    Then the output should contain exactly:\n    """\n      +---------+\n      | bucket  |\n      +---------+\n      | test    |\n      +---------+\n    """\n```\n\nThis is covered by minimal tests (let me know if more or different tests are needed).\n\nThe PR also contains modifications to bin/fog to reload/dump mocked data provided FOG_MOCK is true and the FOG_STATE_FILE environment variable contains a path to a file that will upon fog exit contain all the mocked data.\nEx:\n\n```\nbrice@macbook% FOG_MOCK=true FOG_STATE_FILE=/tmp/fogirb.yaml bundle exec bin/fog\n  Welcome to fog interactive!\n  :default provides AWS and VirtualBox\n>> Fog::Compute.new(:provider => \'aws\').servers.create.identity\n"i-5e9f3a97"\n>> exit\n\nbrice@macbook% FOG_MOCK=true FOG_STATE_FILE=/tmp/fogirb.yaml bundle exec bin/fog\n  Welcome to fog interactive!\n  :default provides AWS and VirtualBox\n>> Fog::Compute.new(:provider => \'aws\').servers.get(\'i-5e9f3a97\').identity\n"i-5e9f3a97"\n```\n\nThanks!\nBrice\n'
1153,'',"describe_auto_scaling_groups returning several groups when only one should be returned\nHi,\n\nUsing describe_auto_scaling_groups and passing it a group name should only return one group but it returns several groups that are empty and then the last one has contents.\n\n```\noptions = { 'AutoScalingGroupNames' => [@group_name] }\nresponse = @connector.describe_auto_scaling_groups(options)\nresponse.body['DescribeAutoScalingGroupsResult']['AutoScalingGroups']\n```\n\nWhat I'm trying to fetch is the instance ids so in order to get this I have to iterate over all the groups returned and check for instance_ids greater than 0.  Is there a bug here as I would have expected only one group returned.\n\nThanks,\nJay"
1152,'','S3 Bucket versioning: connection is required for this operation (ArgumentError)\nHello,\nI\'m trying to create a versioned bucket, like this:\n\n```ruby\n          connection = Fog::Storage::AWS.new(@aws_credentials)\n          directory = connection.directories.create(\n            :key        => bucket_name,\n            :public     => false,\n            :versioning => true\n          )\n```\n\nI get this:\n\n```\n[snip]/fog-1.5.0/lib/fog/core/attributes.rb:163:in `requires\': connection is required for this operation (ArgumentError)\n  from [snip]/fog-1.5.0/lib/fog/aws/models/storage/directory.rb:73:in `versioning=\'\n  from [snip]/fog-1.5.0/lib/fog/core/attributes.rb:146:in `block in merge_attributes\'\n  from [snip]/fog-1.5.0/lib/fog/core/attributes.rb:141:in `each\'\n  from [snip]/fog-1.5.0/lib/fog/core/attributes.rb:141:in `merge_attributes\'\n  from [snip]/fog-1.5.0/lib/fog/core/model.rb:10:in `initialize\'\n  from [snip]/fog-1.5.0/lib/fog/core/collection.rb:105:in `new\'\n  from [snip]/fog-1.5.0/lib/fog/core/collection.rb:105:in `new\'\n  from [snip]/fog-1.5.0/lib/fog/core/collection.rb:49:in `create\'\n```\n\nIs this intended/am I doing something wrong?\n\nUsing\n```ruby\n          connection = Fog::Storage::AWS.new(@aws_credentials)\n          connection.put_bucket_versioning(bucket_name, "Enabled")\n\n          directory = connection.directories.create(\n            :key        => bucket_name,\n            :public     => false\n          )\n```\n\nAppears to work.'
1151,'',"Fix AWS signed_params\nThis fixes the aws signed_parameters method to better fix the specification. The edge cases of the specification are not tested by the Amazon API, but when using it with ec2 compatible api's and other non-standard endpoints, the edge cases become important and the existing code fails."
1150,'','Run live test suite on Travis CI\nSensitive data may now be asymmetrically encrypted into secure environment variables for use by Travis CI using a repository\'s public key via the [travis gem](https://github.com/travis-ci/travis-cli).\n\n    travis encrypt fog/fog FOO=BAR\n\nproduces\n\n    secure: "q872UEyzFb/ZlJGE5HI8+r8l9bZKJ6Y8LRORYE+NvlkBGNrBOvK9U4f3DP+H\\nRL/D9p0hvGcgLJdMswX57Xur8YOHwUN6WkrCD601QRUG2013k4tSKbSMUkVc\\nNiyGG+RMcJndN/F7n0/IgE+1+YnYkmpZqop97PYLdJWCwsGVeg8="\n\nSeveral secure environment variables can be added to the build matrix in tandem.\n\n    env:\n      - [\n          {secure: ""},\n          {secure: ""}\n        ]\n\nOn release branches, would it be possible to run all tests by adding credentials for the Engine Yard sponsored remote testing accounts?'
1149,'',"How to I provide credentials to this initialization?\nHi,\n\nI know I can just have a ~/.fog file with the credentials but if someone want to point this file in a different location or pass the aws keys to the initialization of the aws object how is this accomplished with this:\n\n```\nFog::AWS[:auto_scaling]\n```\n\nThis is what I get if I don't have the .fog file in place:\n\nArgumentError: Missing required arguments: aws_access_key_id, aws_secret_access_key\n\nThe reason I would like to use this is so I swap in different models to the [ ].\n\nThanks,\nJay"
1148,'','1.6 Release and maybe a release schedule?\nHey,\n\nSo I am doing my poke for the 1.6 as I see a lot of AWS changes have been put in like Glacer and etc and hey I can use that new API for AWS|Computer :)\n\nAlso to prevent pestering what do you guys think of a release schedule?  I see fog had added a lot of automate testing for the merges with travis-ci and it seems monthly new stuff is fixed/added it might be a  good release schedule to be agressive.  IMHO.\n\nZuhaib'
1147,'','update fog with hpfog 0.0.16 \n..update fog with hpfog 0.0.16. this will add the latest enhancement for hp support. \nthis was created from the gem downloaded from the hp cloud site at \n  https://docs.hpcloud.com/bindings/fog/install\n'
1146,'',"Rackspace Block Storage\nThis pull request provides an implementation of Rackspace's Block Storage service, which is currently in preview."
1145,'','[Openstack|Compute] Security Groups are not assigned correctly to servers\nAccording to API, security groups needs to be appended with a name prefix, e.g.:\n\n```json\n {\n    "server": {\n        "name": "server-1",\n        "imageRef": "cedef40a-ed67-4d10-800e-17455edce175",\n        "flavorRef" : "1",\n        "security_groups": [\n            {"name": "sec-group-1"},\n            {"name": "sec-group-2"}\n        ],\n        "config_drive": "0c5eb502-3ee7-42e2-acfc-399b67fe72db"\n    }\n}\n```'
1144,'',"[openstack|rackspace|hp] Make OpenStack implementations reuse base API code\nCurrently both the `RackspaceV2` and `HP` providers are standalone modules, distinct from the `OpenStack` module. However they are both implementations of the same OpenStack API, and there is therefore a lot of code duplication and in some cases fewatures present on one provider that should be common to all three. I propose creating a new `RackspaceCloud` provider and making the classes in it and `HP` extend the existing `OpenStack` module's classes, where necessary.\n\nBecause OpenStack supports extensions, this will also be useful as an example for third-party implementations that extend the basic OpenStack functionality, like [Nicira](http://nicira.com/en/openstack).\n\nI have been working on the [jclouds](https://github.com/jclouds/jclouds/tree/master/apis/openstack-nova) OpenStack client code, where this is the standard practice, and the providers each extend a particular API. I think a similar model should work nicely here.\n\nTo start with, I suggest creating the `RackspaceCloud` provider module as a PoC to develop the idea of a child provider based on `OpenStack`. At the same time copying some of the shared fields and requests from the existing `RackspaceV2` classes back to `OpenStack` so that the functionality will be available. This should minimise disruption and client changes for existing users."
1143,'','Google changed their URL scheme for Google Cloud Storage.\nPretty simple change. See https://developers.google.com/storage/docs/reference/releasenotes for more details.'
1142,'bradgignac','Add Accept header with application/json media type to OpenStack requests\nThe Fog code expects JSON data to be returned, and in some cases enforces this by appending `.json` to the URI. However, this is not employed consistently. Since the OpenStack  specification does not require JSON to be the default media type many calls will fail if connecting to an implementation that returns XML or even some other media as a default.\n\nI have added an Accept header to the requests for compute, identity and volume services, set to `application/json`. This has been tested on an OpenStack implementation configured to default to XML representations.'
1141,'','Minor Rackspace improvements.\nThese are just a few changes I found necessary/helpful when doing some server provisioning with fog and Rackspace\'s v2 compute cloud and DNS service.\n\n- Implemented bootstrap method for Rackspace Compute v2. \n\n- Added ability to set "metadata" and "personality" fields when creating a server on Rackspace Compute v2. (Allows you to send "cloud-init" data for post provision bootstrapping if your OS supports it.)\n\n- Improved response parsing when dealing with Rackspace DNS service. (Basically, "A" and "AAAA" record values are now compared as IP addresses instead of strings. You can send Rackspace something like "192.168.001.001" as a value and you will get "192.168.1.1" in the response which doesn\'t match with simple string comparison.)\n\nI haven\'t had time yet to familiarize myself with fog\'s unit testing but I thought I would start the request even without tests in case someone wanted to add them before I got around to it.\n\nIf you would prefer the DNS change as a separate pull request, let me know.'
1140,'','[aws|auto_scaling] Add instrumentation support.\nAdd the ability to instrument AWS auto_scaling requests.'
1139,'','Ninefold - added all load balancer commands for Ninefold\nWorking with load balancers and load balancer rules in Ninefold.'
1138,'',"Ninefold - added load balancers to ninefold commands\nI've added load balancers to the list of ninefold commands. Basic list and create stuff."
1137,'',"[AWS|Storage] Mark upload_part as idempotent s3\nThe [upload part](http://docs.amazonwebservices.com/AmazonS3/latest/API/mpUploadUploadPart.html) request is safe to retry - if you repeat it s3 just overwrites the previously received part with the same partNumber. Surely this means we should mark the request as idempotent so that excon will retry for us in case of failures? At the moment it looks like failure on any part would make the whole upload fail and call abort_multipart_upload\n\nI also think we should be setting Content-MD5 to enable s3 to reject invalid parts. I noticed [Fog::Storage.parse_data](https://github.com/fog/fog/blob/master/lib/fog/storage.rb#L81) has some commented out code for calculating this, but I wasn't sure what was up so I just updated the file model to calculate the MD5 for the part"
1136,'','For HP Compute model Server add method to return security groups\nFor HP Compute model Server there was only a method to provide  new security groups. Added method to return security groups you can access the current security groups. \n'
1135,'','[Rackspace Storage] Rackspace CloudFiles now offers multiple regions, but I am unable to interact with items in ORD (chicago) region.\nRackspace CloudFiles now lets you specify which region to create your cloudfiles container.\n\n![Cloudfiles region picker](http://c43e61ef3bb7e42ee753-ec12e1b9df26854d7c88c49e899f5a12.r18.cf1.rackcdn.com/41ed8061de82d60954991ba4a8ee9af0.png)\n\nI am currently unable to interact with rackspace cloudfiles containers in the new ORD (chicago) cloudfiles region.\n\n\n\n## Expected\n\nWhen I run ```connection.get_containers``` I should get a list of all containers tied to my account.\n\n## Actual\n\nWhen I run ```connection.get_containers``` I get a list of only the containers in the DFW (dallas) region. ORD (chicago) region entries are omitted. \n\n'
1134,'',"[AWS|Compute] Add the ablity to pass :version and use newer AWS API\nSo the main gist of the change is the ability to use :version so you can use newer AWS API.  This is useful for new features AWS add that you can use without any fog changes like the new ebs_optimzed flag.  Not having this feature has caused a patch to Opscode Knife to be blocked till a new fog release, http://tickets.opscode.com/browse/KNIFE_EC2-79\n\nSo now you can write code like this:\nconnection = Fog::Compute.new({\n  :provider                 => 'AWS',\n  :aws_access_key_id        => 'XXXXXXXX',\n  :aws_secret_access_key    => 'XXXXXXXXXX',\n  :region                   => 'us-west-1',\n  :version                  => '2012-07-20'\n})\n\nserver = connection.servers.create({:flavor_id => 'm1.large',:ebs_optimized => true})\n\nBut to get this change to work I was required to modify /fog/compute.rb as it turned out some bad code was added that stripped out :version since it was used for Rackspace version switching. I pushed that code inside the case statement for when Rackspace is used as I see no one else uses :versions in the way Rackspace does.\n\nI dont have a Rackspace Cloud Server account right now so I cant test but I am pretty confident on a pure code level it is safe.\n\nAlso during compute testing I found that the test had a deleted Window AMI used and this caused the test to hang for me.  I updated the AMI to the latest but I see a few other failures not related to the code I touched so I left it alone.  Looks like the test code can use some TLC.\n\nAnd lastest, where is my fog t-shirt from my last commits ;)"
1133,'',"[AWS|RDS] expose the SnapshotType attribute & allow filtering by it\nAs of d135486 we're using an RDS api version that returns the automated daily backups as snapshots. Snapshots gain an extra attribute (SnapshotType: automated or manual) and you can filter snapshots by type.\n\nMaybe I'm just looking in the wrong place, but I couldn't find anywhere that said that changing to api version 2012-01-15 would result in these extra snapshots being returned or the extra data field. Does anyone know where this info can be had? And what should fog (if anything) do to warn users that the underlying apis have changed?"
1132,'','No means of accessing Openstack API pagination\nThe Openstack API returns [paginated collections](http://docs.openstack.org/api/openstack-compute/2/content/Paginated_Collections-d1e664.html).\n\nCurrently fog does not support a way to access the second (or further) pages.\n\n```ruby\nopenstack = Fog::Compute.new(:provider => "OpenStack")\n# Create 1001 VMs \n# Code not shown...\nservers = []\nopenstack.servers.each do |s|\n  servers << s\nend\n# This will always be max. 1000\nputs servers.size\n```\n'
1131,'','[OpenStack] fixes wrong method name\n'
1130,'','[Core] fix format_helper assuming p returns nil\nAs discussed here: https://groups.google.com/forum/#!topic/ruby-fog/_jZMqWTW2GI\n\nThis could make some of the non mocked tests fail, although only in that it would reveal failures that had been hidden on 1.9 until now.\n'
1129,'','AWS.collections fails in fog intereactive\nAWS.collections fails in fog interactive with the following error:\n\n`ArgumentError: Unrecognized service: :beanstalk`'
1128,'',"fix for #1089: Force delete an auto scaling group\nThis is a fix for #1089, you can 'force delete' an auto scaling group"
1127,'','For HP comment metatada attribute of image.rb in model\nIn the HP support put back the metadata attribute for the image.rb in the model '
1126,'','For HP please uncomment metatada attribute of image.rb in models\n\nIn fog / lib / fog / hp / models / compute / image.rb \ncan we uncomment \n  #attribute :metadata       #TODO: Need to add it back when Metadata API is done\nso i can access this metadata as it works now. \nI am doing a fair big of testing with the hp openstack api so i will report new issues as i find them.\nAs an aside the hp openstack api works quite well and you can dso alot of similar things to amazon aws so it looks good.  \n\nNeill Turner'
1125,'','Fix 1.8.7 tests\nHopefully this will get travis green for 1.8.7'
1124,'','Initial support for glacier\n'
1123,'','S3 keys containing "\\x8" inhibit bucket listing\nI\'ve been using fog to upload 300GB of user data to S3, and we hit a filename that contained a backspace (ASCII code 8). Whenever fog tries to list a bucket, when it encounters the file in the batch, it chokes due to Nokogiri objecting to the malformed XML.\n\nI did a terrible thing to get around it:\n```ruby\n\nmodule Nokogiri; module XML; module SAX\n  class PushParser\n    alias_method :old_write, :<<\n\n    def <<(chunk, last_chunk=false)\n      chunk = chunk.gsub("&#x8;", "")\n      old_write(chunk, last_chunk)\n    end\n  end\nend; end; end\n```\nBut this only prevents the problem from stopping our scripts, it doesn\'t actually fix it. It doesn\'t [appear](https://forums.aws.amazon.com/thread.jspa?threadID=10869) that AWS is particularly interested in making their web service emit valid XML in this instance. One possibility is Base64 encoding the key as it goes through Nokogiri, but that requires pre-processing the XML, which is fairly terrible.'
1122,'',"Retry request from AWS/Storage when failed with 200 : JRUBY\nHi, \n\nI debugged the following issue in JRuby 1.6.7 + Nokogiri - 1.5.4 & 1.5.5 , excon - 0.16.2 .\n\nI am using the asset_sync gem which uses fog to sync assets. \n\nAssetSync calls \n\n```\nFog::Storage.new(self.config.fog_options).directories.get(self.config.fog_directory, :prefix => self.config.assets_prefix)\n```\n\nThe following behaviour is observed when :prefix value is set which is changed to 'prefix' . \n\nThe first request to S3 for fetching information about  seems to fail with no details in the `body` with no `Name` as seen in request 2 of [this gist](https://gist.github.com/8f7b42805e8c67d00a23). Requesting the same again gets the actual body with `Name` which happens at.\n\nGist: https://gist.github.com/8f7b42805e8c67d00a23\nLocation of Error: https://github.com/fog/fog/blob/master/lib/fog/aws/models/storage/directories.rb#L24\n\nIs it possible that you can suggest a solution for this problem within fog ?\n\nThanks,\nSairam\n\nP.S: Its 5 AM local time and am finally happy to find the root cause . It will be a bummer if I get redirected to Nokogiri on this issue."
1121,'',"Fix for RDS VPC subnet groups\nAlthough the db_subnet_group_name option is available in the AWS::RDS::Server model, it's not currently being passed through to the actual request."
1119,'',"Fixed the link to GitHub issues\nFixed the formatting of the link to Fog's GitHub issues."
1117,'',"Multidelete\nAdded the versioned implementation of multi-delete and unit-tests for it. This builds on Garret Alfert's patch -- I wasn't sure how to add this to an existing pull request, but would be happy to do that as well."
1116,'',"Add generic support for EMC Atmos.\nI modified the ninefold provider to provide generic Atmos support. The one additional required argument is the endpoint, which should be specified as a full URL for the API, e.g. https://storage.synaptic.att.com/v2.0 or something along those lines. The URL may also include a port. If the port is not included, it is inferred from the protocol: http or https. Any other protocol will result in an ArgumentError exception.\n\nI thought this would be useful as there are many Atmos providers and it doesn't make sense to make the support for it provider-specific."
1115,'','Enable AWS spot requests in a VPC by specifying subnet_id\nAdding the "subnet_id" attribute for spot requests so they can be created in a VPC.'
1114,'','baremetalcloud compute requests were updated and tested. \n- Updated "@host" variable to "noc.newservers.com" which is the current host for API calls\n- Added two calls: add_server_by_configuration.rb and list_configurations.rb\n-- These calls should be used instead of add_server and list_plans, although we still support them.\n- General comments were updated.\n\nFog is doing the baremetalcloud\'s API abstraction on knife-baremetalcloud plugin:\nhttps://github.com/baremetalcloud/knife-baremetalcloud'
1113,'','m1.medium instance type\nAdded m1.medium instance type for AWS flavors'
1112,'','[hp|storage] Use response_block param, as excon has deprecated implicit blocks\nExcon has deprecated implicit blocks (geemus/excon@2a67955ed84056d5cb5a9e61a9fe63d22a4b3014)\n'
1111,'','Addressing issue #1049: When using mock mode, Range header is ignored in get_object()\nNow the Range header is accepted and it returns subset of data according to byte range. Range header parsing is implemented using Rack::Utils#byte_ranges code.\n\nIt solves issue: https://github.com/fog/fog/issues/1049'
1110,'','IncludeAllInstances parameter added to Fog::Compute::AWS::Real.describe_instance_status\nAdded a request parameter\xa0_IncludeAllInstances_ which was unsupported by fog - it is described in [AWS doc](http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeInstanceStatus.html), _Request Parameters_ section.'
1109,'',"AWS Glacier Support\nIs anyone working towards adding Glacier support for this gem?  Didn't want to duplicate effort..."
1108,'','Deleting a route table\nLooks like you cannot delete a route table in AWS associated with a VPC using fog http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-DeleteRouteTable.html , I just could not find this, is this implemented?'
1107,'',"Update public_url to handle new header casings from Rackspace\nFor some reason here in the past week or so Rackspace decided to start returning the `X-CDN-URI` headers as `X-Cdn-Uri`, which causes the `public_url` methods to return `nil`.\n\nThis patch fixes that, but I'm worried they'll arbitrarily switch back at some point or do something equally as inane."
1106,'','Better mocks for invalid Provisioned IOPS values\nThis adds two conditions for the create_volume :aws mocks that checks to make sure that the iops values are between 100 and 1000.'
1105,'','updated fog/aws/models/compute/security_group.rb\nadded initialize:  "attribute :ip_permissions_egress,  :aliases => \'ipPermissionsEgress\'" '
1104,'',"Submit password/ssh_key/username through POST body\nPassword or ssh_key, and username are currently submitted through the\nrequest's querystring, which means they will appear in server logs.\n\nThis change moves the sensitive parameters to the request body, adds\nclient-side checking of the required parameters, and corrects the method\ndocumentation to reflect addition of location_id parameter and specify\nthe parameter types as strings (they are alpha-numeric UUIDs)."
1103,'','Documentation error for delete_object\n'
1102,'','use 10.04 instead of 12.04\nIf I had read the comment above I would have picked the correct ami (10.04 LTS)'
1101,'',"[aws|dns] automatically figure out the ELB's hosted_zone_id if possible\n* Fixes #1098\n\nI have tested this on a live system and it works for me."
1100,'','remove repository_url from notification template\nInterpolation of %{repository_url} is currently broken on Travis CI. See [travis-ci #669](https://github.com/travis-ci/travis-ci/issues/669)'
1099,'',"[aws|dns] parse ASCII code * in wildcard domain. Fixes #1093\nI'm not able to run the integration tests on this atm, may want to do that."
1098,'','Route53 ALIAS -> ELB HostedZoneID mapping\nWhen you create an ALIAS record to an ELB via the Route53 console, all you have to do is paste the DNS name of the ELB and it will figure out the corresponding HostedZoneID for you.\n\nHowever, when you create such a record via the API, you need to specify both the DNS name and the HostedZoneID yourself. This is all fine if you own the ELB in your account, but there is no way to do this lookup for an ELB belonging to another AWS account, even though AWS has no trouble doing so from the web console.\n\nAfter discussing this w/ AWS support, it turns out there\'s a simple trick to do this mapping ourselves. Each AWS region has a single HostedZoneID for ELBs in that region. This mapping is the same for all AWS accounts. Here is the list given to me by AWS support:\n\n```ruby\n  def self.zone_mapping\n    @zone_mapping ||= {\n      "us-east-1" => "Z3DZXE0Q79N41H",\n      "us-west-1" => "Z1M58G0W56PQJA",\n      "us-west-2" => "Z33MTJ483KN6FU",\n      "eu-west-1" => "Z3NF1Z3NOM5OY2",\n      "ap-northeast-1" => "Z2YN17T5R711GT",\n      "ap-southeast-1" => "Z1WI8VXHPB1R38",\n      "sa-east-1" => "Z2ES78Y61JGQKS",\n    }\n  end\n```\n\nI propose we handle this lookup in Fog if the user specifies an AliasTarget and only an ELB DNS name (with no HostedZoneID). Since we can figure out the HostedZoneID automatically for all records matching `*.region-name.elb.amazonaws.com`, I think we should do so, rather than requiring app developers to do this mapping themselves.\n\nFYI, this is not documented in AWS stuff anywhere, though they told me they\'d do so at some point.'
1097,'','notify #ruby-fog on freenode instead of emailing\nTravis occasionally sends emails to the wrong address when a repo is owned by a group. This sends notifications to the already existing freenode room, and does not send emails.'
1096,'','add Travis CI build status image\nFollowing acceptance of #1092 adding the CI status image to the readme may be useful.'
1095,'','Default ImageId for sa-east-1 missing\n'
1094,'','[compute|Ecloud] Fixed ecloud provider showing as available when no credentials were provided.\nEcloud provider will no longer show as an available provider when you have no credentials for it.'
1093,'','Route53 wildcard escaping\nSo, it turns out that the Route53 API accepts the `*` character in requests involving wildcard domains. However, when you retrieve these records using ListResourceRecordSets, the `*` is actually returned as `\\052` (the ASCII hex code). Example:\n\n```xml\n<ListResourceRecordSetsResponse xmlns="https://route53.amazonaws.com/doc/2012-02-29/">\n   <ResourceRecordSets>\n      <ResourceRecordSet>\n         <Name>\\052.mydomain.com.</Name>\n...\n```\n\nIn my mind, this feels like something Fog should make me not have to care about. However, there are likely people already depending on this weird behavior in their usage of Fog (myself included), and I couldn\'t find it properly documented anywhere in AWS docs. Did find a few other references to the problem via Googling (like pcorliss/ruby_route_53#7).\n\nShould the Fog parsers handle this for the user and return this escaped character as an actual `*`, or should it stay as is?'
1092,'','Add barebones configuration for Travis CI\nOnly mocked tests are run on Travis, but this still appears to be valuable. \n\n3 tests still failing per #1090.'
1091,'','HP cloud avl zones\nHP compute avl zones were hardcoded to assume that the first response is for az-1, then az-2 (and not support for az-3). Change this to look up the avl zone based on the passed in zone string. The passed in avl zones should now be strings of the form "az-1", "az-2", etc, as opposed to symbols that are currently used. This also adds support for the new zone, az-3, for free.'
1090,'','Get mocked tests running on Travis CI\nFog::Compute tests all pass locally, but [3 fail on Travis](http://travis-ci.org/#!/ent-io/fog/builds/2135912/L15112).\n\nAWS::ELB load_balancer_tests [fail](http://travis-ci.org/#!/ent-io/fog/builds/2135912/L14098) in both environments. \n\n    $ ruby --version\n    ruby 1.9.3p194 (2012-04-20 revision 35410) [i686-linux]\n    $ gem --version\n    1.8.24\n\n'
1089,'','Cannot "force" delete an Amazon AWS Auto Scaling group\nStarting with API version 2011-01-01, you can force delete an auto scaling group in AWS, checking this out here http://docs.amazonwebservices.com/AutoScaling/latest/APIReference/API_DeleteAutoScalingGroup.html , but in FOG https://github.com/fog/fog/blob/master/lib/fog/aws/requests/auto_scaling/delete_auto_scaling_group.rb (delete_auto_scaling_group) you cannot pass force delete as a bool parameter. Wondering what is the reason for this?'
1088,'',"Fix test tagging\nThere were several problems with Shindo's tests due to their tagging.\n\n* Several providers were not listed under `all_providers` so were not being added to the ignore list\n* Storage tests were declared with symbols\n* Several tests were tagged with symbols and one untagged\n\nSince shindo does not ignore tags when declared as symbols these tests were being run even when you had no credentials. This was ~90 failing tests.\n\nThe final commit was to cut down on future maintenance by building the `all_providers` list dynamically."
1087,'','Ecloud provider is always "available" (without credentials)\nNot a big problem but the `Ecloud` provider is not set up to have any required configuration so it is always available as a provider (https://github.com/fog/fog/blob/master/lib/fog/ecloud/compute.rb#L34)\n\nA very quick look and it seems to allow different authentication methods so none of the individual values are required but at least one set of them is.\n\nSo I\'m unable to use the service for lack of credentials but it is appearing in my list of providers.\n\nI can see it being solved in a two ways:\n\n* One of the values (such as `ecloud_authentication_method`) is actually required\n* The `available?` logic is overridden to check for at least one acceptable combination of configuration values in the same way as other providers check for certain gems and are unavailable if they are missing.'
1086,'',"Rewrite tests to use 1.8 compatible Hash syntax\nSome Ruby 1.9 style hashes were used in some tests meaning syntax errors when attempting to run with 1.8.\n\nI've rewritten them to the older form and things are testable again."
1085,'','Add gsub to replace URL-encoded characters in the public_url method\n'
1084,'',"[rackspace|compute] Don't intern nil strings.\n"
1083,'','Make tests exit when complete\nWhen I check out the latest release ([v1.5.0](https://github.com/fog/fog/commit/2e57e2029abbb618411c20f8974e64d8d3fd31fe) at this time) and run tests with\n\n    bundle exec rake\n\nthey appear to pass as expected with\n\n    6 pending, 121 succeeded in 44.094981619 seconds\n\nbut the script [never completes](http://travis-ci.org/#!/ent-io/fog/builds/2069710) as it times out after 25 minutes. \n\nShould the test suite take this long running only mock_tests ?'
1082,'',"Added support for Amazon RDS VPC subnet groups.\nThis PR adds support for VPC Subnet Group Names (DBSubnetGroupName parameter) when creating and retrieving Amazon RDS server instances.\n\nTwo things to note here:\n- To support this, I needed to bump the RDS API version to 2012-01-15. I don't think this should affect anything but it's worth pointing out.\n- I didn't see where or how to add tests for the support of this field -- if someone give me some guidance on that front then I'd be more than happy to add them.\n\nThanks!\n\n"
1081,'','Move Dynect endpoint from api2 to api-v4\nI\'ve had the problem before that Dynects api2 will fail when being called from a system that has both, IPv6 and IPv4 connectivity.\nThe message returned looks something like this:\n\n```\n@body="{\\"status\\": \\"failure\\", \\"data\\": {}, \\"job_id\\": 1234567890, \\"msgs\\": [{\\"INFO\\": \\"login: IP address does not match current session\\", \\"SOURCE\\": \\"BLL\\", \\"ERR_CD\\": \\"INVALID_DATA\\", \\"LVL\\": \\"ERROR\\"}, {\\"INFO\\": \\"login: There was a problem with your credentials\\", \\"SOURCE\\": \\"BLL\\", \\"ERR_CD\\": null, \\"LVL\\": \\"INFO\\"}]}", @status=400>\n```\n\nFor our own (custom) library this was fixed by just moving from the \'api2.dynect.net\' endpoint to \'api-v4.dynect.net\'. We didn\'t change anything else and it just worked for us.\nI just tried this locally and switching the endpoint solved the problem in fog for me.'
1080,'',"public_url shows %2F when the bucket contains directories\nI've come across this a few times and have been gsub'ing the public_url in order to fix it, but was wondering if maybe I was doing something wrong when creating directory structure on file uploads.\n```ruby\n#!/usr/bin/env ruby\n\nrequire 'rubygems'\nrequire 'fileutils'\nrequire 'date'\nrequire 'chronic'\nrequire 'fog'\n\n#Set the default directory for relative paths.\nDir.chdir(File.expand_path(File.dirname(__FILE__)))\n\n# Import EC2 credentials e.g. @aws_access_key_id and @aws_access_key_id\nrequire './s3_credentials.rb'\n\n## S3 Upload\n# Create a connection\nasia_connection = Fog::Storage.new({\n  :provider              => 'AWS',\n  :aws_access_key_id     => @aws_access_key_id,\n  :aws_secret_access_key => @aws_secret_access_key,\n  :region                => 'ap-southeast-1'\n})\n\nnew_file = asia_connection.copy_object('csi-testbucket-eric', 'my/full/path/calgary.txt','csi-testbucket-eric-asia','my/full/path/calgary.txt', {'x-amz-acl' => 'public-read'})\nnew_new_file = asia_connection.directories.new(:key => 'csi-testbucket-eric-asia').files.new(:key => 'my/full/path/calgary.txt')\n\nputs new_new_file.public_url\n```\n\nPublic URL: `https://csi-testbucket-eric-asia.s3.amazonaws.com/my%2Ffull%2Fpath%2Fcalgary.txt`\n\nAm I not performing the copy_object correctly to support folders? Not sure if I'm doing something wrong or its a possible bug?"
1079,'',"[ecloud|compute] Missing API calls/error handling\nAdded some of the API calls that were missing, also added some error handling for a few edge cases I've encountered."
1078,'','Cloudstack: added registerTemplate request\nAdded registerTemplate request support.\nAccording to the documentation added *hypervisor* field to the templates responses.'
1077,'','[rackspace|compute] Set password attribute on V2 servers.\nI missed this during my first pass on Rackspace Cloud Servers v2.'
1076,'','Change iprange --> ec2_secg in Mock.\nI assume this was a simple copy/paste error from the code above. Anyway, it fixes the "undefined local variable or method `iprange\'" testing error.'
1075,'','CloudStack: images.get always returns nil\nHere is the test code:\n\n    > compute.images.all\n    => <Fog::Compute::Cloudstack::Images\n    [\n      <Fog::Compute::Cloudstack::Image\n        id=1003,\n        ...\n    ]\n\n    > compute.images.get 1003\n    => nil\n\nThis happens because according to the [CloudFoundry API Reference for method listTemplates](http://download.cloud.com/releases/3.0.0/api_3.0.0/user/listTemplates.html) it has required parameter *templatefilter* that is not specified in the *get* method implementation.'
1074,'','CloudStack: images.get always returns nil\nHere is the test code:\n\n    > compute.images.all\n    => <Fog::Compute::Cloudstack::Images\n    [\n      <Fog::Compute::Cloudstack::Image\n        id=1003,\n        ...\n    ]\n\n    > compute.images.get 1003\n    => nil\n\nThis happens because according to the [CloudFoundry API Reference for method listTemplates](http://download.cloud.com/releases/3.0.0/api_3.0.0/user/listTemplates.html) it has required parameter *templatefilter* that is not specified in the *get* method implementation.\n\nI will provide the fix soon.'
1073,'',"Make private IP address available in Rackspace server\nThese seems like a simple update to me, but, I'm new to this. Does anyone have any constructive feedback? The method originally returned nil, but the value is present in the source array (implementation as in the public_ip_address method)."
1072,'','[rackspace|storage] Override path when generating sha1 to make tests pass\n@yob See if this works for you?'
1071,'','fix reboot guest in vsphere to reboot rather than shutdown guest\nfix reboot guest in vsphere to reboot rather than shutdown guest, also fixes a mocking test in aws security groups.'
1070,'',"Revert 530122d\nThis commit reverts commit 530122d. Commit 530122d contained changes to\nhow the mac address for an domain's interfaces was retrieved.  The\nchange was made due to an broken development environment and was\nunnecessary."
1069,'',"Improve libvirt support\nPreviously to this pull request, the XML erb template used to generate a new libvirt domain set the VNC settings to listen and require a password, even if the options passed were empty.   In addition the mac address of an interface for a KVM instance isn't always able to be retrieved by libvirt.  This seems to be a version difference, but I don't know which versions this is broken in.  In these instances, the mac address gets set to nil. \n\nThis pull request updates the XML erb template to not require a VNC password or set the listen address if the options for those parameters are empty or nil.  Further, this pull request uses virsh to dump the XML for a domain, then attempts to extract the mac address from the XML if libvirt could not get the mac address itself."
1068,'','Extending Support for vCloud Director 1.5\nThis patchset extends support for vCloud Director 1.5 in fog with the following features:\n\n1. Ability configure the no.of.vcpus, password for a vApp.\n2. Ability to Join a Org-wide network via the vApp-level network\n3. Ability to terminate the vApp\n4. Other minor fixes'
1067,'','add high io flavor to aws flavors\n```\n      <Fog::Compute::AWS::Flavor\n        id="hi1.4xlarge",\n        bits=64,\n        cores=35,\n        disk=2048,\n        name="High I/O Quadruple Extra Large Instance",\n        ram=61952\n      >\n```'
1066,'',"[aws|compute] Nicer interface for security group authorizations\nDon't use a specially formatted string for passing two arguments. Use a\nhash instead.\n\nThis changes the interface introduced in pull #986.\n\nDefault to using self.owner_id as the account if not specified."
1065,'',"Rackspace Compute v2\nThis is a partial implementation of the Rackspace Compute v2 API documented here. Currently, it does not support the following:\n\n* SSH features\n* Metadata\n* Image Creation/Deletion\n* Rescue Mode\n\nThere's a few tests I need to write before merging, but I'd like some feedback on the versioning approach. Also, is it cool to ship a partial implementation?\n\n/cc @brianhartsock "
1064,'','Change SQS Endpoints to sqs.<region>.amazonaws.com\nThe SQS API endpoints as defined in\nhttp://docs.amazonwebservices.com/general/latest/gr/rande.html#sqs_region\nuse sqs.<region>.amazonaws.com while fog is currently using <region>.queue.amazonaws.com\n\nWe have had a few issues with the <region>.queue.amazonaws.com endpoints causing 403 errors with SignatureDoesNotMatch and SIGTERM problems. \n\nThis commit changes to the published endpoints.\n\nBest\nStu'
1063,'','Feature/elasticache/mocking\nThis pull request implements mocking support for testing AWS Elasticache clusters. Nothing in the online (non-mocking) implementation is changed, so impact should be minimal. Test with:\n\n    FOG_MOCK=true bundle exec shindo tests/aws/requests/elasticache/cache_cluster_tests.rb'
1062,'',"Initial AWS instrumentation\nRef #270\n\ncc @ktheory @mkb @shaiguitar -- not cc'ing others I think will see this anyway\n\nI've been using this for a while in production and am tired of keeping up with the merges. Wanted to open this PR for discussion around this approach and whether this would be a good start for general instrumentation in fog.\n\n@mkb and @shaiguitar [played with instrumentation](https://github.com/shaiguitar/fog/compare/instrumentation) a while back but that approach essentially offered the same info as instrumenting excon. The approach I've used here is a bit more intrusive but gets a higher-level look at what's going on.\n\nComments please!"
1061,'',"Rackspace API Versioning\nI'm starting to work on Rackspace's Compute v2 API, and I haven't seen any examples of API versioning inside of Fog. Here's what I'm thinking right now: \n\nhttps://gist.github.com/3185711\n\n@dprince Will you be handling this with OpenStack anytime soon? I'd love to know if you have any thoughts.\n"
1060,'','Add Sao Paulo server to Amazon known regions\nThis has been driving me crazy in the last days.\n\nAs seen on http://status.aws.amazon.com/#SA_block .'
1059,'','Fog::Identity::OpenStack.new(options) does not set correct endpoint\nWhen passing "openstack_management_url" and/or  "openstack_auth_uri", the connection is always set to localhost.  I tried to allow the class (Fog::Identity::Openstack) to accept "openstack_identity_endpoint" and then parse that value to use for the uri.  This allowed me to connect and view tenants, yet "list_users" action returns Fog::Identity::OpenStack::NotFound.  Am I missing some options?'
1058,'','Fix / partial rollback of commit 4d81b869\nFix / partial rollback of [commit 4d81b869](commit 4d81b869)\n\nThis pull request partially rolls back a commit made nearly six months back, which broke the Amazon Elasticache tests -- they have been broken since. The organization I work for discovered this when upgrading to Fog 1.4 broke our application. To verify the brokenness (Elasticache account required), run:\n\n    bundle exec shindo tests/aws/requests/elasticache/cache_cluster_tests.rb\n\nThe [commit in question](commit 4d81b869) adds several `strip` method calls to one particular AWS API parameter, which is *optional* in most cases, with the result that `strip` is called on `nil` in the default case. It seems the author of the commit discovered that Amazon honors leading and trailing whitespace is most (if not all) of its API parameters. Since this did not suit the needs of the author\'s application, they decided to patch several service modules in the Fog library -- but for this API parameter only.\n\nFirst, let me express my strong opinion that this commit was poorly thought out, for the following reasons:\n\n1. There may be a reason why some users would want leading or trailing whitespace in this parameter.\n\n2. It produces code and behavior inconsistent with the rest of the Fog library, and thus *unexpected* behavior. Why trim this parameter and no others? What about other cloud providers -- do they enforce such a restriction?\n\nMy point is, if we collectively decide that Fog is going to trim whitespace from service parameters, then let\'s do so consistently, and for a good reason -- not just in a particular case, because it makes someone\'s application code shorter.\n\nSecondly, this event has raised a code quality "yellow light" within my organization, because a commit that obviously breaks the tests has been in the repo for several months. In a project of this size, where end-to-end testing is so problematic, it\'s probably not realistic to expect that the person who merges the code into the master branch run the tests for the service module(s) in question (though that *would* be ideal). However, I think it *is* reasonable to insist that all authors:\n\n1. RUN THE TESTS WHILE CODING; and\n2. DO **NOT** SUBMIT CODE THAT BREAKS THE TESTS.\n\n@geemus Please let me know whether you agree on both of these points. Would love to have a discussion surrounding continuous integration, even if only in `FOG_MOCK` mode. Several new services seem to be popping up that provide this for open-source projects.\n\n-benton\n\n\n[commit 4d81b869]: https://github.com/fog/fog/commit/4d81b869bc86f84845be9eb5a694f31b13376951'
1057,'','Fog::AWS::IAM#each paging support\n'
1056,'',"Typo in Rackspace Load Balancer set_ssl_termination\nHere's the update for #1053 on fog/fog"
1055,'','Local storage support for #public_url.\nWhile working on a Rails project we ran into the need for local storage to support public URLs.'
1054,'','Allow Ninefold option of specifying api url\nThis change is for using fog to test in our non-production environments, hence we need to be able to supply url of the api endpoint.'
1053,'',"Typo in Rackspace Load Balancer set_ssl_termination\nThere's a typo in Fog::Rackspace::LoadBalancers::Real.set_ssl_termination (lib/fog/rackspace/requests/load_balancers/set_ssl_termination.rb) on line 19 -\n\n```ruby\ndata['secureTrafficOnly'] - options[:secure_traffic_only]\n```\n\nshould be\n\n```ruby\ndata['secureTrafficOnly'] = options[:secure_traffic_only]\n```\n"
1052,'','[cloudstack|security_group] fix rule revoke mock\nand rule attributes'
1051,'','Default to being less pessimistic about excon\nRequire anything greater than 0.14\n\n- It limits using more recent gems through a project\n- If there are explicit breaking changes in future versions, then add an additional <='
1050,'','[AWS|Autoscaling] fix group#instances returning all autoscaled instances...\nattributes[:instances] already has all the data - we just need to load it into a collection\n\naddresses #960'
1049,'','When using mock mode, Range header is ignored in get_object()\nWhen using mock mode, get_object() method on Fog::Storage::AWS::Mock does not support Range header in request. Instead whole file is returned.'
1048,'','Fix for issue #1047\nfix for RDS mocking to avoid state flipping between "modifying" and "available"\n\nIssue #1047'
1047,'','Fog::AWS::RDS::Server mocking state cycling on reload\nI\'m running into an issue with Fog::AWS::RDS::Server mocking. \n\nEvery time I call .reload on it, it seems to cycle the state from "modifying" to "available", which makes it unreliable for testing in a lot of cases. I have tried digging through and I\'m trying to find where this happens, but so far I haven\'t been able to find the source of the issue.'
1046,'','Stop vSphere vms before destroying, or destroy will fail\nvSphere throws an error trying to destroy a running vm\nSeems that in other providers destroy will go ahead whether the vm is running or not, so vSphere should do the same'
1045,'','[cloudstack|server] assign security group\n'
1044,'','[cloudstack|security_groups] add groups and rules\n* add volume tests back into tests/cloudstack/models/\n* represent rules as a resource\n* fix job representations'
1043,'','When using mock mode, fog file cannot be read\nI use carrier wave + fog to upload file to s3.\nSo I enable mock mode of fog for testing.\nProblem is, I do some post processing over the uploaded file, so I re-read the file by calling:\nmy_model.avatar.read\n\nThen I receive: Undefined body of nil.\n\nLook like under mock mode, the fog.directories.head(fog_path) return a nil object even when it should not, thus cause the file to not be able to read.'
1042,'','[openstack|image] Stream OpenStack image\nThe excon gem already supports passing in a File for the body\ninstead of a String. Also close the file after the request has been\nprocessed.'
1041,'','Add support for multiple regions in OpenStack\nMultiple endpoints for the same service can be returned by identity, one for each service region.\n\nThis patch adds support for this, when multiple regions are returned an error is raised unless a region is choosed using a new opentack_region parameter.\n\n'
1040,'','fog bombs out using ruby 1.8.x because it cannot find Mutex without requiring thread.\nfog bombs out because it cannot find Mutex without requiring thread.'
1039,'','Fix typo listing datacenters in vSphere provider\n'
1038,'','Unify Rackspace Requests and Authentication\nCurrently, each Rackspace service rolls its own request and authentication code. Over time, the request-related features supported by each service have diverged. Here are some features that are not uniformly supported across services:\n\n* Authentication with auth token.\n* Automatic re-authentication upon token expiration.\n* Support for internal service URLs.\n* Persistent connections.\n* Rackspace-specific exception handling.\n\nIt would be great to have all these features available across services and provide a common module where all request-related work can occur in the future. My work-in-progress is available at https://github.com/bradgignac/fog/tree/unify_rackspace_requests.'
1037,'',"Don't stop all instances when mocking\nFilter out the instances for only the ones specified."
1036,'','Private IP in the AWS mocks should be an actual private ip\nA private ip has a specific # as the first octet.'
1035,'','[aws|storage] Default to false for persistent connections.\nUsing false provides for a more stable solution by default.\n\n@geemus, this is the pull request discussed in #1021.  Thank you for your help with this issue.'
1034,'',"Fail back to 'json' gem if 'multi_json' is not available\nNewer version of `fog` which requires `multi_json` gem don't work on if a user uses an older version of RubyGem, because `multi_json` requires a newer version (>= 1.3.6). Good example of this is Ubuntu 10.04 where the latest RubyGem version available in the official APT repo is `1.3.5`.\n\nMy solution is probably not the best and the final one, but I just want to start the discussion so we can figure out a best solution for this together."
1033,'',"zerigo dns fails for large domains\nWhen using a Zerigo zone, if the domain has more than 300 records, the zerigo api no longer returns the host list, so zone.records.all fails with:\n\n    /Users/mconway/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/core/collection.rb:91:in `load': undefined method `each' for nil:NilClass (NoMethodError)\n        from /Users/mconway/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/zerigo/models/dns/zones.rb:20:in `get'\n        from /Users/mconway/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/zerigo/models/dns/records.rb:16:in `all'\n"
1032,'','SSH connections don\'t seem to use passed SSH keys first\nI have a Jenkins server which runs on an .ssh/config file, looking like this:\n\n    Host *\n        PreferredAuthentications publickey,keyboard-interactive,password\n        StrictHostKeyChecking no\n        UserKnownHostsFile /dev/null\n        CheckHostIP no\n    IdentityFile /var/lib/jenkins/.ssh/id_rsa\n    IdentityFile /var/lib/jenkins/keys/something/ssh/default\n    IdentityFile /var/lib/jenkins/keys/something2/ssh/default\n    IdentityFile /var/lib/jenkins/keys/something3/ssh/default\n    IdentityFile /var/lib/jenkins/keys/something4/ssh/default\n    IdentityFile /var/lib/jenkins/keys/something5/ssh/default\n\n\nBunch of identity files, but it really shouldn\'t matter because I explicitly pass the SSH key to fog:\n\n\n\n    Fog.credential = \'project_qa_key\'\n    <stuff>\n    Fog.credentials = Fog.credentials.merge(\n    {\n        :private_key_path => "./keys/project_qa_id_rsa", \n        :public_key_path => "./keys/project_qa_id_rsa.pub"\n    })\n    <stuff>\n    connection.import_key_pair(\'project_qa_key\', IO.read(\'./keys/project_qa_id_rsa.pub\')) if connection.key_pairs.get(\'project_qa_key\').nil?\n    <stuff>\n     server_attributes = {\n      :flavor_id => instance_size,\n      :tags => tags_for_the_server,\n      :image_id => chosen_image_id,\n      :key_name => \'project_qa_key\',\n      :groups => [\'bla_dev\']\n    }\n    server = connection.servers.bootstrap(server_attributes)\n\nThe strange part, if I have too many "IdentityFile" entries, I will end up with this error:\n\n    disconnected: Too many authentication failures for ubuntu (2)\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/transport/session.rb:176:in `poll_message\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/transport/session.rb:166:in `loop\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/transport/session.rb:166:in `poll_message\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/transport/session.rb:151:in `next_message\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/session.rb:94:in `next_message\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/session.rb:93:in `loop\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/session.rb:93:in `next_message\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/methods/publickey.rb:53:in `authenticate_with\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/methods/publickey.rb:20:in `authenticate\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/key_manager.rb:121:in `each_identity\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/key_manager.rb:118:in `each\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/key_manager.rb:118:in `each_identity\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/methods/publickey.rb:19:in `authenticate\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/session.rb:78:in `authenticate\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/session.rb:65:in `each\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh/authentication/session.rb:65:in `authenticate\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/net-ssh-2.5.2/lib/net/ssh.rb:190:in `start\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/core/ssh.rb:58:in `run\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/compute/models/server.rb:37:in `ssh\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/compute/models/server.rb:45:in `sshable?\'\n    /usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/compute/models/server.rb:45:in `sshable?\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/aws/models/compute/server.rb:214:in `setup\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/core/model.rb:64:in `instance_eval\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/core/model.rb:64:in `wait_for\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/core/wait_for.rb:6:in `wait_for\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/core/model.rb:55:in `wait_for\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/aws/models/compute/server.rb:214:in `setup\'\n    /vol/ebs1/jenkins/jobs/project-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.4.0/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap\'\n\n\nIf I comment out 3-4 of them, the bootstrap will be successful.\nIn http://net-ssh.rubyforge.org/ssh/v2/api/classes/Net/SSH.html#M000002 , there is a parameter to the start() method called:\n\n> :keys_only => set to true to use only private keys from keys and key_data parameters, even if ssh-agent offers more identities. This option is intended for situations where ssh-agent offers many different identites.    \n\nI think adding this to https://github.com/fog/fog/blob/master/lib/fog/core/ssh.rb#L51 might solve the problem, but I\'m still thinking through this, so feel free to add comments :)    '
1031,'',"added PeopleAdmin to list of users\nI use it every day. We've used it to automate dynamically spinning up and down 20+ instances at a time that we use for migrating customers from our legacy platform to our new platform."
1030,'','As discussed in #991, this converts the readme from SimpleMarkup to Markdown\nShould be painless.'
1029,'','[openstack|compute] Add filters to list servers details\nAdd filters to list servers details.\n\nSee issue #1007 for discussion history.'
1028,'','[openstack] Fix Authentication for OpenStack v1.1 Authentication\nIn relation to https://github.com/fog/fog/issues/1015'
1027,'','Fix :path pollution after re-authentication \ncorrect in compute.rb\nhttps://github.com/fog/fog/commit/5c6ca0ee22ece7e86f798e2fa862258c99ad64ef\nbut not in storage.rb\n\n'
1026,'','Fog User-Agent Header\nI\'d be curious to know how people feel about adding a user-agent string of "Fog/X.X.X" to all requests by default. Of course, it should be able to be turned on/off and changed by end users. Thoughts?\n\n**Edit:** Perhaps it should be off by default at first. It might be a mean trick to turn this on by default right out of the gate.'
1025,'','[fix-ephemeral-naming] Typo in ephemeral naming\nTypo in IBM Compute create instance request'
1024,'',"allocate_address usage\nIs there a proper way to allocate a new elastic ip address without dealing with the low level `Excon::Response` object?\n\nRight now I'm doing the following:\n\n```\naddress = connection.allocate_address\nconnection.associate_address(server.id, address.body['publicIp'])\n```"
1023,'','Fix bug in local storage #copy_object.\nWe should mkdir_p on the target directory path instead of the source.'
1022,'',"fix not pulling InstanceProtocol from the xml\nparser wasn't picking up the InstanceProtocol element"
1021,'',"Excon::Errors::Timeout in Heroku\nCrazy error in Heroku with carrierwave+fog(depends excon (0.14.2))\n\nRuby: 1.9.3\n\n    â¦undle/ruby/1.9.1/gems/excon-0.14.2/lib/excon/socket.rb: 124:in `rescue in write'\n    â¦undle/ruby/1.9.1/gems/excon-0.14.2/lib/excon/socket.rb: 115:in `write'\n    â¦e/ruby/1.9.1/gems/excon-0.14.2/lib/excon/connection.rb: 249:in `request_kernel'\n    â¦e/ruby/1.9.1/gems/excon-0.14.2/lib/excon/connection.rb: 101:in `request'\n    â¦ndler/gems/fog-5f6a21a253f3/lib/fog/core/connection.rb:  20:in `request'\n    â¦1/bundler/gems/fog-5f6a21a253f3/lib/fog/aws/storage.rb: 392:in `request'\n    â¦f6a21a253f3/lib/fog/aws/requests/storage/put_object.rb:  43:in `put_object'\n    â¦ms/fog-5f6a21a253f3/lib/fog/aws/models/storage/file.rb: 133:in `save'\n    â¦ndler/gems/fog-5f6a21a253f3/lib/fog/core/collection.rb:  50:in `create'\n    â¦/gems/carrierwave-0.6.2/lib/carrierwave/storage/fog.rb: 250:in `store'\n    â¦/gems/carrierwave-0.6.2/lib/carrierwave/storage/fog.rb:  84:in `store!'\n    â¦ms/carrierwave-0.6.2/lib/carrierwave/uploader/store.rb:  59:in `block in store!'\n    â¦arrierwave-0.6.2/lib/carrierwave/uploader/callbacks.rb:  17:in `with_callbacks'\n    â¦ms/carrierwave-0.6.2/lib/carrierwave/uploader/store.rb:  58:in `store!'\n    â¦/1.9.1/gems/carrierwave-0.6.2/lib/carrierwave/mount.rb: 345:in `store!'\n    â¦/1.9.1/gems/carrierwave-0.6.2/lib/carrierwave/mount.rb: 217:in `store_photo!'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 471:in `_run__4428550732847088090__save__3433293938273105555__callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 405:in `__run_callback'\n     â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 385:in `_run_save_callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb:  81:in `run_callbacks'\n    â¦gems/activerecord-3.2.6/lib/active_record/callbacks.rb: 264:in `create_or_update'\n    â¦ms/activerecord-3.2.6/lib/active_record/persistence.rb:  84:in `save'\n    â¦ms/activerecord-3.2.6/lib/active_record/validations.rb:  50:in `save'\n    â¦ord-3.2.6/lib/active_record/attribute_methods/dirty.rb:  22:in `save'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 241:in `block (2 levels) in save'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 295:in `block in with_transaction_returning_status'\n    â¦rd/connection_adapters/abstract/database_statements.rb: 192:in `transaction'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 208:in `transaction'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 293:in `with_transaction_returning_status'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 241:in `block in save'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 252:in `rollback_active_record_state!'\n    â¦s/activerecord-3.2.6/lib/active_record/transactions.rb: 240:in `save'\n              /app/app/controllers/photos_controller.rb:  95:in `block in create'\n    â¦ack-3.2.6/lib/action_controller/metal/mime_responds.rb: 270:in `call'\n    â¦ack-3.2.6/lib/action_controller/metal/mime_responds.rb: 270:in `retrieve_collector_from_mimes'\n    â¦ack-3.2.6/lib/action_controller/metal/mime_responds.rb: 194:in `respond_to'\n              /app/app/controllers/photos_controller.rb:  94:in `create'\n    â¦k-3.2.6/lib/action_controller/metal/implicit_render.rb:   4:in `send_action'\n    â¦/gems/actionpack-3.2.6/lib/abstract_controller/base.rb: 167:in `process_action'\n    â¦ionpack-3.2.6/lib/action_controller/metal/rendering.rb:  10:in `process_action'\n    â¦/actionpack-3.2.6/lib/abstract_controller/callbacks.rb:  18:in `block in process_action'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 437:in `block in _run__4383138304010497824__process_action__3780903005377931191__callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 215:in `block in _conditional_callback_around_833'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 326:in `around'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 310:in `_callback_around_679'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 214:in `_conditional_callback_around_833'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 425:in `_run__4383138304010497824__process_action__3780903005377931191__callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 405:in `__run_callback'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 385:in `_run_process_action_callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb:  81:in `run_callbacks'\n    â¦/actionpack-3.2.6/lib/abstract_controller/callbacks.rb:  17:in `process_action'\n    â¦actionpack-3.2.6/lib/action_controller/metal/rescue.rb:  29:in `process_action'\n    â¦k-3.2.6/lib/action_controller/metal/instrumentation.rb:  30:in `block in process_action'\n    â¦ctivesupport-3.2.6/lib/active_support/notifications.rb: 123:in `block in instrument'\n    â¦3.2.6/lib/active_support/notifications/instrumenter.rb:  20:in `instrument'\n    â¦ctivesupport-3.2.6/lib/active_support/notifications.rb: 123:in `instrument'\n    â¦k-3.2.6/lib/action_controller/metal/instrumentation.rb:  29:in `process_action'\n    â¦ck-3.2.6/lib/action_controller/metal/params_wrapper.rb: 206:in `process_action'\n    â¦3.2.6/lib/active_record/railties/controller_runtime.rb:  18:in `process_action'\n    â¦/gems/actionpack-3.2.6/lib/abstract_controller/base.rb: 121:in `process'\n    â¦/actionpack-3.2.6/lib/abstract_controller/rendering.rb:  45:in `process'\n    â¦1/gems/actionpack-3.2.6/lib/action_controller/metal.rb: 203:in `dispatch'\n    â¦k-3.2.6/lib/action_controller/metal/rack_delegation.rb:  14:in `dispatch'\n    â¦1/gems/actionpack-3.2.6/lib/action_controller/metal.rb: 246:in `block in action'\n    â¦ionpack-3.2.6/lib/action_dispatch/routing/route_set.rb:  73:in `call'\n    â¦ionpack-3.2.6/lib/action_dispatch/routing/route_set.rb:  73:in `dispatch'\n    â¦ionpack-3.2.6/lib/action_dispatch/routing/route_set.rb:  36:in `call'\n    â¦le/ruby/1.9.1/gems/journey-1.0.4/lib/journey/router.rb:  68:in `block in call'\n    â¦le/ruby/1.9.1/gems/journey-1.0.4/lib/journey/router.rb:  56:in `each'\n    â¦le/ruby/1.9.1/gems/journey-1.0.4/lib/journey/router.rb:  56:in `call'\n    â¦ionpack-3.2.6/lib/action_dispatch/routing/route_set.rb: 600:in `call'\n    â¦uby/1.9.1/gems/omniauth-1.1.0/lib/omniauth/strategy.rb: 177:in `call!'\n    â¦uby/1.9.1/gems/omniauth-1.1.0/lib/omniauth/strategy.rb: 157:in `call'\n    â¦uby/1.9.1/gems/omniauth-1.1.0/lib/omniauth/strategy.rb: 177:in `call!'\n    â¦uby/1.9.1/gems/omniauth-1.1.0/lib/omniauth/strategy.rb: 157:in `call'\n    â¦ruby/1.9.1/gems/omniauth-1.1.0/lib/omniauth/builder.rb:  48:in `call'\n    â¦1/gems/hirefireapp-0.0.8/lib/hirefireapp/middleware.rb:  27:in `call'\n    â¦dle/ruby/1.9.1/gems/warden-1.2.1/lib/warden/manager.rb:  35:in `block in call'\n    â¦dle/ruby/1.9.1/gems/warden-1.2.1/lib/warden/manager.rb:  34:in `catch'\n    â¦dle/ruby/1.9.1/gems/warden-1.2.1/lib/warden/manager.rb:  34:in `call'\n    â¦b/action_dispatch/middleware/best_standards_support.rb:  17:in `call'\n    â¦dor/bundle/ruby/1.9.1/gems/rack-1.4.1/lib/rack/etag.rb:  23:in `call'\n    â¦/ruby/1.9.1/gems/rack-1.4.1/lib/rack/conditionalget.rb:  35:in `call'\n    â¦ctionpack-3.2.6/lib/action_dispatch/middleware/head.rb:  14:in `call'\n    â¦9.1/gems/remotipart-1.0.2/lib/remotipart/middleware.rb:  30:in `call'\n    â¦-3.2.6/lib/action_dispatch/middleware/params_parser.rb:  21:in `call'\n    â¦tionpack-3.2.6/lib/action_dispatch/middleware/flash.rb: 242:in `call'\n    â¦/1.9.1/gems/rack-1.4.1/lib/rack/session/abstract/id.rb: 205:in `context'\n    â¦/1.9.1/gems/rack-1.4.1/lib/rack/session/abstract/id.rb: 200:in `call'\n    â¦onpack-3.2.6/lib/action_dispatch/middleware/cookies.rb: 338:in `call'\n    â¦ms/activerecord-3.2.6/lib/active_record/query_cache.rb:  64:in `call'\n    â¦record/connection_adapters/abstract/connection_pool.rb: 473:in `call'\n    â¦pack-3.2.6/lib/action_dispatch/middleware/callbacks.rb:  28:in `block in call'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 405:in `_run__2215179173472973290__call__3433293938273105555__callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 405:in `__run_callback'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb: 385:in `_run_call_callbacks'\n    â¦ms/activesupport-3.2.6/lib/active_support/callbacks.rb:  81:in `run_callbacks'\n    â¦pack-3.2.6/lib/action_dispatch/middleware/callbacks.rb:  27:in `call'\n    â¦pack-3.2.6/lib/action_dispatch/middleware/remote_ip.rb:  31:in `call'\n    â¦2.6/lib/action_dispatch/middleware/debug_exceptions.rb:  16:in `call'\n    â¦.2.6/lib/action_dispatch/middleware/show_exceptions.rb:  56:in `call'\n    â¦uby/1.9.1/gems/railties-3.2.6/lib/rails/rack/logger.rb:  26:in `call_app'\n    â¦uby/1.9.1/gems/railties-3.2.6/lib/rails/rack/logger.rb:  16:in `call'\n    â¦ack-3.2.6/lib/action_dispatch/middleware/request_id.rb:  22:in `call'\n    â¦/ruby/1.9.1/gems/rack-1.4.1/lib/rack/methodoverride.rb:  21:in `call'\n    â¦/bundle/ruby/1.9.1/gems/rack-1.4.1/lib/rack/runtime.rb:  17:in `call'\n    â¦dor/bundle/ruby/1.9.1/gems/rack-1.4.1/lib/rack/lock.rb:  15:in `call'\n    â¦ionpack-3.2.6/lib/action_dispatch/middleware/static.rb:  62:in `call'\n    â¦by/1.9.1/gems/rack-cache-1.2/lib/rack/cache/context.rb: 136:in `forward'\n    â¦by/1.9.1/gems/rack-cache-1.2/lib/rack/cache/context.rb: 143:in `pass'\n    â¦by/1.9.1/gems/rack-cache-1.2/lib/rack/cache/context.rb: 155:in `invalidate'\n    â¦by/1.9.1/gems/rack-cache-1.2/lib/rack/cache/context.rb:  71:in `call!'\n    â¦by/1.9.1/gems/rack-cache-1.2/lib/rack/cache/context.rb:  51:in `call'\n    â¦dle/ruby/1.9.1/gems/railties-3.2.6/lib/rails/engine.rb: 479:in `call'\n    â¦uby/1.9.1/gems/railties-3.2.6/lib/rails/application.rb: 220:in `call'\n    â¦/gems/railties-3.2.6/lib/rails/railtie/configurable.rb:  30:in `method_missing'\n    â¦by/1.9.1/gems/unicorn-4.3.1/lib/unicorn/http_server.rb: 531:in `process_client'\n    â¦by/1.9.1/gems/unicorn-4.3.1/lib/unicorn/http_server.rb: 606:in `worker_loop'\n    â¦by/1.9.1/gems/unicorn-4.3.1/lib/unicorn/http_server.rb: 487:in `spawn_missing_workers'"
1020,'',"Rackspace Cloud Database (Ready for Review)\nMessed up the last pull request. Let's try this again.\n\n---\n\nSee issue #812."
1019,'','ELB Listener instance_protocol always show HTTP\nHello,\n\nI have ELBs listeners configured with elbProtocol SSL(443) and instanceProtocol TCP(80). \n\nWhile making fog API calls, it always returns instanceProtocol as "HTTP" instead of "TCP".\n\nBelow is the response:\n\n  <Fog::AWS::ELB::LoadBalancers\n    [\n      <Fog::AWS::ELB::LoadBalancer\n        id="ID",\n        availability_zones=["us-east-1b", "us-east-1a"],\n        created_at=Fri May 19 09:20:33 UTC 2012,\n        dns_name="ID-NUMBER.us-east-1.elb.amazonaws.com",\n        health_check={"HealthyThreshold"=>3, "Timeout"=>5, "UnhealthyThreshold"=>3, "Interval"=>6, "Target"=>"HTTP:80/index.html"},\n        instances=["INSTANCEID", "INSTANCEID"],\n        source_group={"OwnerAlias"=>"amazon-elb", "GroupName"=>"amazon-elb-sg"},\n        hosted_zone_name="ID-IDNUMBER.us-east-1.elb.amazonaws.com",\n        hosted_zone_name_id="ZONEID"\n      >\n    ]\n  >\n\n    [\n      <Fog::AWS::ELB::Listener\n        policy_names=[],\n        instance_port=80,\n        instance_protocol="HTTP",\n        lb_port=443,\n        protocol="SSL",\n        ssl_id="arn:aws:iam::002200220000:server-certificate/sslcert"\n      >\n    ]\n  >\n\nThe "instance_protocol" is actually TCP, but its showing HTTP.\n\nIf i recall it correct, it was not there in v1.1.2, it started happening after v1.3.1.\n\nThe same behavior may be true for elbProtocol (i will update this thread once i test it)\n\n\n-Tuj'
1018,'','Mock for filter ec2 instance by security group name\n'
1017,'','Updated changelog for release v1.4.0\n'
1016,'','add us-east-1e to mock\nFor #describe_availability_zones.'
1015,'','Fog 4.0 openstack support cannot connect to trystack.org\nCongratulations on fog it is a big step forward in a generic way to access and script cloud computing environments.  \nthe only way i could get Fog 1.4 to work with trystack using v1.1 authentication is to change openstack/compute.rb.\n\nchange\n @identity_connection = Fog::Connection.new(\n             @openstack_identity_public_endpoint,\n            false, @connection_options)\nto \n@identity_connection = Fog::Connection.new(\n            @openstack_management_url,\n            false, @connection_options)\n\nI suspect that the latest openstack/compute.rb has issues using v1.1 authentication. Maybe the code should test if   @openstack_identity_public_endpoint is empty and if so then use  @openstack_management_url but i am not an expert on the openstack api. \n\nNeill Turner\nhttp://ec2dream.blogspot.com '
1014,'','Bugfix in Fog::DNS::AWS::Records.all!\nIf we have more than 100 AWS records, this method returns different\nresults if called twice. So we should reset attributes before each call.\n\nRelated to https://github.com/fog/fog/issues/826'
1013,'',"Support for serverlove cloud services\nThis is the beginning of our implementation of the serverlove API.\n\nhttp://www.serverlove.com/support/api-questions/\n\nIt's not finished by any means but we'd love feedback on what we have so far so that we can fix any broken assumptions and keep moving in the right direction.\n\nThanks!"
1012,'','Fix some of the failing tests\nThis pull request fixes several of the issues mentioned in #1002 - hope you like it :) I may get to fixing more during next week.'
1011,'','Fog support for Google Compute\nHello,\nIt would be awesome if Fog could support Google Compute\nSee https://developers.google.com/compute/\n\nThanks in advance'
1010,'','Rackspace Cloud Database\nSee issue #812.'
1009,'','[rackspace|identity] Better checking around hash/array responses.\nPreviously, the Identity API request methods simply checked for the existence of a key in the response to determine whether a single object or an array was returned. Using type checking should be a less fragile approach. Tests still pass.\n\n/cc @brianhartsock '
1008,'','[libvirt] minor updates\n* fixed incorrect mock method signature\n* ensure Fog volumes do not raise on LVM based volumes'
1007,'','[openstack|compute] Add find_by methods to servers\nAdd find_by_[attribute] method to OpenStack Servers.'
1006,'','Rackspace ssl termination\nSomeone want to give a quick sanity check?  All tests are passing.'
1005,'','fix subnet tests in mocking mode\nquotes an integer to bring it inline with the strings returned by aws.'
1004,'',"AWS AutoScaling\nI've added a lot of code around AWS Auto Scaling and Cloud Watch. In particular, I fleshed out models for scaling policies and alarms. I also improved the api around group creation. Unfortunately, I really don't know much about how to test this stuff, so my tests are somewhat lacking. I have at least exercised all this code through my own applications. It all works so far :-)"
1003,'','fixes elb test in mocking mode\nParser was missing some of the newer VPC related features.'
1002,'',"Test failures on Fedora Rawhide\nHi, I'm experiencing quite a lot of test failures on fedora rawhide, here is the complete test output: [1]\nIs anyone experiencing something similar or is this a failure on my side?\n\nThanks.\n\n[1] https://gist.github.com/2987130"
1001,'','[openstack] Fix create snapshot\n'
1000,'',"Rackspace Temp/Expiring URLs\nHi,\n\nThis series of patches adds support for expiring URLs to the rackspace storage adapter.\n\nI've tried to copy the style of specs for other Rackspace storage requests, but I'm new to fog and expect you might want some changes.\n\nThe spec for Rackspace::Storage#get_object_https_url requires ~/.fog to include the :rackspace_temp_url_key option. It also doesn't spec the signature itself is correct, as the signature will change depending on the value of rackspace_temp_url_key. Is that OK?"
999,'','Rackspace Identity v2.0\nAdds support for the Rackspace Identity v2.0 API. API documentation is available at http://docs.rackspace.com/auth/api/v2.0/auth-client-devguide/content/QuickStart-000.html.'
998,'','Fog::Compute::AWS bootstrap timeouts: No route to host - connect(2)\nHi,\n\nWe are currently using Fog to automate our instance setup on AWS. Unfortunately, the bootstap process currently fais every few tries.\n\nOur setup looks like this:\n\n```ruby\nconnection = Fog::Compute.new(credentials_ec2)\nserver_attributes = {\n  :flavor_id => instance_size,\n  :tags => tags_for_the_server,\n  :image_id => chosen_image_id,\n  :key_name => \'ourkey\',\n  :groups => [\'ourgroup\']\n}\n\nputs "Launching an on-demand instance"\nserver = connection.servers.bootstrap(server_attributes)\n```\n\nThis setup is working most of the time, but currently fails multiple times a day. It\'s executed by our Jenkins installation which itself is hosted on EC2:\n\n```\n\nNo route to host - connect(2)\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `open\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize\'\n/usr/lib/ruby/1.8/timeout.rb:67:in `timeout\'\n/usr/lib/ruby/1.8/timeout.rb:101:in `timeout\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh.rb:186:in `new\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh.rb:186:in `start\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/core/ssh.rb:52:in `run\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:209:in `setup\'\n/usr/lib/ruby/1.8/timeout.rb:67:in `timeout\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:208:in `setup\'\n/usr/lib/ruby/1.8/timeout.rb:67:in `timeout\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:206:in `setup\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/Rakefile:113\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:205:in `call\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:205:in `execute\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:200:in `each\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:200:in `execute\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:158:in `invoke_with_call_chain\'\n/usr/lib/ruby/1.8/monitor.rb:242:in `synchronize\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:151:in `invoke_with_call_chain\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/task.rb:144:in `invoke\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:116:in `invoke_task\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:94:in `top_level\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:94:in `each\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:94:in `top_level\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:133:in `standard_exception_handling\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:88:in `top_level\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:66:in `run\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:133:in `standard_exception_handling\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/lib/rake/application.rb:63:in `run\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/gems/rake-0.9.2.2/bin/rake:33\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/bin/rake:19:in `load\'\n/vol/ebs1/jenkins/jobs/fog-stage-setup/workspace/system-tests/instance-setup-fog/vendor/bundle/ruby/1.8/bin/rake:19\n```\n\nCould this be some find of race condition that fails only under special circumstances?\n\n--\nCheers,\npfleidi'
997,'','Add ssh_port to Fog::Compute::Server\nThis is for when a server may not be listening for ssh on port 22'
996,'','Support for iam roles\nAWS: ability to grab credentials from the instance metadata service & new IAM requests for manipulating roles\n'
995,'',"Fixed non-persistent connections handling with AWS DNS\nThere are many places like this:\n`@persistent = options[:persistent]  || false`\n\nSo  there is no way to set `@persistent` to false.\nSeems like other backends have the same issues too.\n\nI don't know the best way to fix, so just notice you about the bug."
994,'','[AWS | IAM ] Feature/add iam get group mocking\nhi @geemus,\n\nThis pull requests adds mocking for aws/iam/get_group.\n\nThanks,\n\nRodrigo Estebanez'
993,'','add some more explanation to the server creation process\n'
992,'','AWS/VPC fix: Subnets and Security groups can co-exist now.\nThis statement is no longer true.\n  # If subnet is defined we are working on a virtual private cloud.\n  # subnet & security group cannot co-exist. I wish VPC just ignored\n  # the security group parameter instead, it would be much easier!\n\n'
991,'','Prevents yard from trying to interpret the README.rdoc as a ruby source file\nWhen installing, YARD produces a non-threatening error:\n\n```\nBuilding YARD (yri) index for fog-1.3.1...\n[error]: ParserSyntaxError: syntax error in `README.rdoc`:(3,47): syntax error, unexpected tIDENTIFIER, expecting keyword_do or \'{\' or \'(\'\n[error]: Stack trace:\n\t/Users/michael/.rvm/gems/ruby-1.9.3-p194@10genchef/gems/yard-0.7.5/lib/yard/parser/ruby/ruby_parser.rb:517:in `on_parse_error\'\n\t/Users/michael/.rvm/gems/ruby-1.9.3-p194@10genchef/gems/yard-0.7.5/lib/yard/parser/ruby/ruby_parser.rb:49:in `parse\'\n\t/Users/michael/.rvm/gems/ruby-1.9.3-p194@10genchef/gems/yard-0.7.5/lib/yard/parser/ruby/ruby_parser.rb:49:in `parse\'\n\t/Users/michael/.rvm/gems/ruby-1.9.3-p194@10genchef/gems/yard-0.7.5/lib/yard/parser/ruby/ruby_parser.rb:15:in `parse\'\n\t/Users/michael/.rvm/gems/ruby-1.9.3-p194@10genchef/gems/yard-0.7.5/lib/yard/parser/source_parser.rb:438:in `parse\'\n\t/Users/michael/.rvm/gems/ruby-1.9.3-p194@10genchef/gems/yard-0.7.5/lib/yard/parser/source_parser.rb:361:in `parse_in_order\'\n```\n\nAccording to [Yard setup](https://rubydoc.tenderapp.com/kb/getting-started-with-rubydocinfo/setting-up-a-yardopts-file), moving the file behind a "-" will prevent it from being compiled as ruby source code.\n\nSo it\'s either move this there, or edit the README to not terminate lines with colons. This seems easier.'
990,'','Fix up describe_volume_status to work with THE ARRAYZ.\nReported by @adelcambre at Nordic Ruby.\n\n![](http://farm9.staticflickr.com/8010/7376127066_150d6bc741_m.jpg)\n\n:hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings: :hotsprings:\n\n![](http://webster.cs.ucr.edu/AoA/Windows/HTML/images/Arrays6.gif)\n\n![](http://myphpscriptz.com/wp-content/uploads/2010/10/twodim-array.png)\n\n![](http://www.qscaudio.com/images/products/WL8/array_variations.jpg)\n\n![](http://personalpages.manchester.ac.uk/staff/p.dudek/projects/scamp/array.gif)\n\n![](http://i.msdn.microsoft.com/dynimg/IC145002.gif)\n\n![](http://charm.cs.uiuc.edu/tutorial/images/ArrayProxyIndexing.jpg)'
989,'','fix describe_volume_status parser\n'
988,'','describe_volume_status broken\nCompute[:AWS].describe_volume_status("volume-status.status" => "impaired")\nExcon::Errors::SocketError: EndTag: \'</\' not found\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/nokogiri-1.5.2/lib/nokogiri/xml/sax/push_parser.rb:47:in `native_write\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/nokogiri-1.5.2/lib/nokogiri/xml/sax/push_parser.rb:47:in `write\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/lib/fog/core/connection.rb:16:in `block in request\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/excon-0.13.4/lib/excon/response.rb:43:in `call\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/excon-0.13.4/lib/excon/response.rb:43:in `parse\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/excon-0.13.4/lib/excon/connection.rb:249:in `request_kernel\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/excon-0.13.4/lib/excon/connection.rb:97:in `request\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/lib/fog/core/connection.rb:20:in `request\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/lib/fog/aws/compute.rb:349:in `request\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/lib/fog/aws/requests/compute/describe_volume_status.rb:25:in `describe_volume_status\'\n\tfrom (irb):2:in `<top (required)>\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/bin/fog:50:in `block in <top (required)>\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/bin/fog:50:in `catch\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bundler/gems/fog-50faf88393cf/bin/fog:50:in `<top (required)>\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bin/fog:23:in `load\'\n\tfrom /Users/edwardam/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/bin/fog:23:in `<main>\''
987,'',"Nexenta Support\nHello,\n\nI'd like to ask if Nexenta fits in nicely to be one of the providers fog should support?"
986,'',"Ec2 security groups fixes\nChanges to security groups authorize_ingress as discussed earlier.\n\nSorry, I'm sick and didn't have time to send this patch earlier.\n\nFeedback welcome!"
985,'','fix attribute name\nAccidentally committed wrong attribute with the last route53 mock pull request. This fixes it.'
984,'','Feature/aws iam tests\nThis pull request adds two tests for previously untested requests in Fog::AWS::IAM.\n\n*Potentially Breaking Change*\n\nIt also changes one of the requests, get_user, to take a String username as its first argument, which is more compliant with the way the rest of the methods in this service module work.\n'
983,'','fix response-cache-control typo for AWS signed urls\nI fixed a typo that I found while creating a AWS signed URLs using the `response-cache-control` query parameter.\n'
982,'',"regularize examples showing use of AWS access keys\nUse the same order of keys and and same names of variables in the examples showing use of AWS access keys.\n\nMinor documentation update.\n\nIt was a stupid mistake (https://github.com/fog/fog/issues/978) but I probably wouldn't have made it with these changes."
981,'','[ecloud|compute] Adding multiple disks at once was not working properly\nFixed adding more than 1 disk at a time'
980,'','Fix multiple disk add.\nAdding multiple disks to an instance was not working properly.  Fixed.'
979,'','Attaching Volume to Instance does not update EC2 Metadata\nGood morning,\n\nI am using FOG to create some instances based on a configuration file.\n\nThe machines create OK and the any additional volumes that are attached are detected by the OS, in this case Centos.  The following is output from \'fdisk\':\n\n```\nDisk /dev/sdc: 21.4 GB, 21474836480 bytes\n255 heads, 63 sectors/track, 2610 cylinders\nUnits = cylinders of 16065 * 512 = 8225280 bytes\n```\n\nI am creating a 20Gb volume and attaching it to the machine on /dev/sdc:\n\n```\n   attributes = {:image_id => "ami-12345678",\n                      :flavor_id => "m1.medium",\n                      :availability_zone => "eu-west-1b"}\n                      \n        new_instance = fog.servers.new attributes\n\n        # Create the new machine\n        new_instance.save\n\n        # Wait for the instance\n        new_instance.wait_for { ready? }\n\n        # Create the volume object\n        volume_attrs = {\n          :size => 20,\n          :availability_zone => "eu-west-1b",\n          :device => "/dev/sdc",\n          :delete_on_termination => true\n        }\n        instance_volume = fog.volumes.new volume_attrs\n        \n        instance_volume.server = new_instance\n\n        # Now actually create the volume\n        # to get the id so that it can be assigned to the\n        # instance that we are creating\n        instance_volume.save\n```        \n\nHowever I use Chef to configure and install the necessary software and format partitions.  To do this it uses the EC2 metadata of the instance to work out the EBS volumes.  Unfortunately the metadata for \'block-device-mapping\' does not not contain the \'/dev/sdc\' device that I have attached and can see in \'fdisk\'.\n\n```\nblock-device-mapping: \n\t ami: /dev/sda1\n\t ephemeral0: /dev/sdb\n\t root: /dev/sda1\n```\n\nIf I create the machine using the AWS command line tools the metadata is set correctly.\n\nIs there anything I can do to force the update of the metadata or is this a potential bug?\n\nThanks,\n\nRussell'
978,'','AWS AuthFailure, perhaps due to account managed with IAM??\nI am getting authentication errors right from the start trying to use fog with AWS -- but I AM able to use the Amazon ec2-api-tools.\n\nI\'m wondering if the fact that my account is managed as part of "AWS Identity and Access Management (IAM)" for our company is part of the problem ???\n\n---- details ----\n\nFollowing these instructions: http://fog.io/1.3.1/compute/\n\nI installed fog and created this simple program to test the connection (copyingmy actual access key credentials from the AWS Management Console):\n\n    require \'fog\'\n\n    # create a connection\n    connection = Fog::Compute.new({\n      :provider                 => \'AWS\',\n      :aws_secret_access_key    => YOUR_SECRET_ACCESS_KEY,\n      :aws_access_key_id        => YOUR_SECRET_ACCESS_KEY_ID\n    })\n\n    puts connection.servers.length\n\nRunning it generates this error:\n\n    /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/excon-0.13.4/lib/excon/connection.rb:266:in `request_kernel\': AuthFailure => AWS was not able to validate the provided access credentials (Fog::Compute::AWS::Error)\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/excon-0.13.4/lib/excon/connection.rb:97:in `request\'\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/core/connection.rb:20:in `request\'\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/aws/compute.rb:320:in `request\'\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/aws/requests/compute/describe_instances.rb:75:in `describe_instances\'\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/aws/models/compute/servers.rb:64:in `all\'\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/core/collection.rb:131:in `lazy_load\'\n    \tfrom /Users/stephen/.rvm/gems/ruby-1.9.3-p194/gems/fog-1.3.1/lib/fog/core/collection.rb:18:in `length\'\n    \tfrom connect.rb:9:in `<main>\'\n\nI then followed the instructions here to generate sbannasch.crt and sbannasch.key, put them in ~/.ec2 (setting permissions correctly), and uploaded sbannasch.crt to the Signing Certificates section of my account.\n\n  http://michaelnovi.com/2011/prerequisites-preparing-to-work-with-amazon-ec2/\n\nThen I modified ~/.bash_profile to setup some EC2 environmental variables:\n\n    export EC2_HOME=/Users/stephen/dev/bin/ec2-api-tools-1.5.5.0\n    export PATH=$PATH:$EC2_HOME/bin\n    export EC2_PRIVATE_KEY=~/.ec2/sbannasch.key\n    export EC2_CERT=~/.ec2/sbannasch.crt\n\nAnd downloaded the ec2-api-tools-1.5.5.0 from here and put them on my path:\n\n  http://aws.amazon.com/developertools/351\n\nRunning the EC2 CLI/API commands works. For example: ec2-describe-instances shows all of our running instances.'
977,'','Updated create_load_balancer to support internal ELBs \nAmazon recently introduced support to [create internal ELBs in a VPC](http://aws.typepad.com/aws/2012/06/internal-elastic-load-balancers.html). These changes enable fog to do the same. '
976,'','Updated create_load_balancer to support internal ELBs \nAmazon recently introduced support to [create internal ELBs in a VPC](http://aws.typepad.com/aws/2012/06/internal-elastic-load-balancers.html). These changes enable fog to do the same. '
975,'','Specify image_ref rather than trying to instantiate object.\nResolves #974, which is causing the test suite to crash in mocked mode.'
974,'',"Test suite failing in mocked mode\nLooks like some dependency between cloudstack and openstack is causing the test suite to crash, rather than skip the tests due to lacking credentials.\n\n```\n  Fog::Compute[:cloudstack] | volume requests (cloudstack) /Users/cmeiklejohn/Repositories/fog/lib/fog/core/service.rb:188:in `validate_options': Missing required arguments: openstack_auth_url (ArgumentError)\n\tfrom /Users/cmeiklejohn/Repositories/fog/lib/fog/core/service.rb:59:in `new'\n\tfrom /Users/cmeiklejohn/Repositories/fog/lib/fog/compute.rb:62:in `new'\n\tfrom /Users/cmeiklejohn/Repositories/fog/lib/fog/compute.rb:5:in `[]'\n\tfrom tests/compute/helper.rb:26:in `compute_providers'\n\tfrom tests/compute/models/flavors_tests.rb:1:in `<top (required)>'\n\tfrom /Users/cmeiklejohn/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `load'\n\tfrom /Users/cmeiklejohn/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread'\n\tfrom /Users/cmeiklejohn/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `each'\n\tfrom /Users/cmeiklejohn/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `block in run_in_thread'\n```"
973,'','Fix typo.\nThis typo is causing a syntax error and the entire test suite to fail when running mocked.'
972,'','Fog not working woth eucalyptus 3\nHi,\n\nIt seems that fog is not working with eucalyptus 3 (where it was working fine with version 2)\n\n```\nPOST /services/Eucalyptus HTTP/1.1\nContent-Type: application/x-www-form-urlencoded\nHost: 10.0.42.165:8773\nContent-Length: 224\n\nAWSAccessKeyId=AccessKey&Action=DescribeInstances&SignatureMethod=HmacSHA256&SignatureVersion=2&Timestamp=2012-06-11T09%3A16%3A59Z&Version=2012-03-01&Signature=Signature\n\nHTTP/1.1 200 OK\nContent-Length: 1940\nContent-Type: application/xml; charset=UTF-8\n\n<euca:DescribeInstancesResponseType xmlns:euca="http://ec2.amazonaws.com/doc/2012-03-01/"><euca:VmControlMessage><euca:EucalyptusMessage><euca:_return>true</euca:_return><euca:_services/><euca:_disabledServices/><euca:_notreadyServices/></euca:EucalyptusMessage></euca:VmControlMessage><euca:reservationSet><euca:item><euca:reservationId>r-C6D24017</euca:reservationId><euca:ownerId>843187190042</euca:ownerId><euca:groupSet><euca:item><euca:entry>default</euca:entry></euca:item></euca:groupSet><euca:instancesSet><euca:item><euca:instanceId>i-131C401F</euca:instanceId><euca:imageId>emi-96A03CA2</euca:imageId><euca:stateCode>80</euca:stateCode><euca:stateName>stopped</euca:stateName><euca:privateDnsName>192.168.0.110</euca:privateDnsName><euca:dnsName>192.168.0.110</euca:dnsName><euca:reason>USER_STOPPED: User stopped. -- []</euca:reason><euca:keyName>login</euca:keyName><euca:amiLaunchIndex>0</euca:amiLaunchIndex><euca:productCodes/><euca:instanceType>c1.medium</euca:instanceType><euca:launchTime>2012-06-08T15:05:15.106Z</euca:launchTime><euca:placement>PART00</euca:placement><euca:platform>linux</euca:platform><euca:monitoring>false</euca:monitoring><euca:disableApiTermination>false</euca:disableApiTermination><euca:instanceInitiatedShutdownBehavior>true</euca:instanceInitiatedShutdownBehavior><euca:ipAddress>192.168.0.110</euca:ipAddress><euca:privateIpAddress>192.168.0.110</euca:privateIpAddress><euca:rootDeviceType>ebs</euca:rootDeviceType><euca:rootDeviceName>/dev/sda1</euca:rootDeviceName><euca:blockDevices><euca:item><euca:deviceName>/dev/sda1</euca:deviceName><euca:ebs><euca:volumeId>vol-03F94128</euca:volumeId><euca:status>attached</euca:status><euca:attachTime>2012-06-08T15:05:15.247Z</euca:attachTime><euca:deleteOnTermination>true</euca:deleteOnTermination></euca:ebs></euca:item></euca:blockDevices></euca:item></euca:instancesSet></euca:item></euca:reservationSet></euca:DescribeInstancesResponseType>\n```'
971,'',"Don't leak secrets\nArguably this could be generalized more, but this is what I need for now.\n\nStill leaks the access key, but that's generally considered the public part\n(more or less)."
970,'','Copied auth token reauthentication from rackspace|compute\nThis makes Rackspace storage reauthenticate when the auth token expires. Otherwise an auth token will be held onto for the lifetime of the process, causing connection failures when the auth token eventually expires.'
969,'',"Ecloud Syntax Error in Ruby 1.8\nLooks like yesterday's round of commits broke fog for Ruby 1.8: https://gist.github.com/2898228\n\nI'm using this in Foreman's nightly builds, which pull in the head from master."
968,'','openstack create_server doesn\'t handle security groups\nPassing in security_groups isn\'t working, looking at http://api.openstack.org/ shows "security_group" and openstack/models/compute/server.rb has "security_groups". Didn\'t have time to properly debug and solve the issue so I figured I\'d at least note it.'
967,'','Mock aws route53\nmocking route53 commands, feedback welcome!'
966,'','Change gemspec to depend on excon >= 0.13.0\nrefs #958'
965,'',"[xenserver] Added missing Server.tags attribute, minor fixes\nAdded support for Array parameters to Connection.request:\n\n    server = connection.server.create :name => 'fooserver',\n                                      :template_name => 'debian-squeeze'\n    server.wait_for { ready? }\n    server.set_attribute 'tags', ['tagfoo', 'tagbar']\n\nAdded required shindo test for set_attribute request."
964,'','New ecloud provider\nMerged the code with the most recent code from the master branch, to allow for easier merging.  Also removing non-functioning Mock classes.'
963,'','New ecloud provider.\nRemoved Ecloud provider and replaced it with a new version in preparation for Terremark turning off the old version of their API on Saturday.  This version has been fairly extensively tested and seems to be working, but currently has no automated tests.  It is essentially still beta, but I believe it is ready for prime time.'
962,'','Rackspace Temporary/Expiring URLs\nRackspace has added the ability to create temporary urls and expiring urls, among other features. Think would be good to add to compete with S3.\n\nhttp://www.rackspace.com/blog/rackspace-cloud-files-adds-new-control-features/'
961,'',"Ecloud v2\nTerremark is turning off the Ecloud API version that the Ecloud provider currently uses this Saturday (06/09/12).  This version has been tested working, but is not backwards compatible and has no tests, so for the time being I've made it a separate provider (Ecloudv2).  It is basically beta at this point, but I've extensively tested it, and it doesn't seem to have any glaring issues that should prevent it from pushed out."
960,'','Fog::AWS::AutoScaling::Group.instances is unscoped\nIf I call\n\nrequire \'rubygems\'; require \'fog\';\nas = Fog::AWS::AutoScaling.new(:aws_access_key_id => "xxx",:aws_secret_access_key => "xxx")\nas.groups.first.instances\n\nI get all of the autoscaling instances on my account... not those belonging just to the first group.\n\nIt seems that the Fog::AWS::AutoScaling::Instances.all method needs to take a parameter to filter\n\nbut how do I get that parameter in there?\n\nseems we need to make a change something like this to Fog::AWS::AutoScaling::Group.\n\n        def instances\n          requires :id\n          connection.instances(:group => self)\n          # Fog::AWS::AutoScaling::Instances.new({\n          #   :data => attributes[\'Instances\'],\n          #   :connection => connection\n          # })\n        end\n\nBut that alone is not enough.\n\nJust need a bit more guidance to put together a patch'
959,'',"[AWS|IAM] users, access_keys and policies models implemented\nHi @geemus\n\nI've implemented three models for AWS::IAM: users, access_keys and policies. In order to make proper shindo testing i had to implement mocking for **get_user** and **get_user_policy** request methods.\n\nA bug already [reported] (https://github.com/fog/fog/pull/189) about the formatting of the document policy was [fixed] (https://github.com/restebanez/fog/blob/0bc0bd45860d44394b4e1477c9a6bb8d1c99b382/lib/fog/aws/parsers/iam/get_user_policy.rb#L18-22).\n\nYou can find the requests to models mapping in this [document](https://gist.github.com/2836309). You can disregard the [Agifog](https://github.com/restebanez/agifog) parts. In case you're interested Agifog turns fog into a restful API.\n\nThis is my first time doing fog models so I'd appreciate any feedback to improve this pull request.\n\nThis shindo tests look like this:\n\n    Fog::Compute[:iam] | access_keys (aws, iam)\n      #all (there are no access keys for a new user) + succeeds\n      #create (an access key) + succeeds\n      #all (there are two access keys) + succeeds\n      #get\n        a valid access key id + succeeds\n        an invalid access key + succeeds\n      #destroy (decrease by one the number of access keys) + succeeds\n    \n    Fog::Compute[:iam] | policies (aws, iam)\n      #all (there is no policies) + succeeds\n      #create\n        a valid policy + succeeds\n      #all (there are two policies) + succeeds\n      #get\n        a valid policy + succeeds\n        an invalid policy + succeeds\n      #destroy + succeeds\n    \n    Fog::Compute[:iam] | users (aws, iam)\n      #create + succeeds\n      #all (there is only one user) + succeeds\n      #all (the only user should match) + succeeds\n      #create (a second user) + succeeds\n      #all (there are two users) + succeeds\n      #get (an existing user) + succeeds\n      #get (returns nil if the user doesn't exists) + succeeds\n      #policies (it has no policies) + succeeds\n      #access_keys (it has no keys) + succeeds\n      #destroy (an existing user) + succeeds\n      #destroy (clean up remaining user) + succeeds\n    \n    23 succeeded in 0.975087 seconds\n\nThanks,\n\nRodrigo Estebanez"
958,'','Change gemspec to depend on excon >= 0.13.0\nexcon is at version 0.14.0 right now'
957,'','Request Mocks for AWS R53 create_hosted_zone and change_resource_record_sets\n'
956,'',"Don't duplicate effort\n"
955,'','forgot to commit dhcp_options tests\n'
954,'','Dhcp options\n'
953,'','Dhcp options\nthis adds the Dhcp options object for managing a vpc.'
952,'','this adds the dhcp_options object and associated operations\nthis adds the dhcp_options object and associated operations'
951,'',"Catch Errno::ETIMEDOUT timeout for new EC2 machines\nIs it possible that we should also catch Errno::ETIMEDOUT somewhere in here:\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/models/compute/server.rb#L213\n\nBecause I've been running into this little bugger:\n\n````ruby\nConnection timed out - connect(2)\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `open'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize'\n/usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout'\n/usr/local/lib/ruby/1.8/timeout.rb:101:in `timeout'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh.rb:186:in `new'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh.rb:186:in `start'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/core/ssh.rb:52:in `run'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:209:in `setup'\n/usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:208:in `setup'\n/usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:206:in `setup'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap'\n````"
950,'',"Timeout on AWS server bootstraps\nIs it possible that we should also catch Errno::ETIMEDOUT somewhere in here:\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/models/compute/server.rb#L213\n\nBecause I've been running into this little bugger:\n\n````ruby\nConnection timed out - connect(2)\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `open'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize'\n/usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout'\n/usr/local/lib/ruby/1.8/timeout.rb:101:in `timeout'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh/transport/session.rb:66:in `initialize'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh.rb:186:in `new'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/net-ssh-2.3.0/lib/net/ssh.rb:186:in `start'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/core/ssh.rb:52:in `run'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:209:in `setup'\n/usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:208:in `setup'\n/usr/local/lib/ruby/1.8/timeout.rb:67:in `timeout'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/server.rb:206:in `setup'\n/something/instance-setup-fog/vendor/bundle/ruby/1.8/gems/fog-1.3.1/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap'\n````"
949,'','Openstack attributes\n- Added new details attributes for Openstack\n- Added all_tenant parameter to list_servers and list_servers_detail Openstack requests'
948,'','Make aws compute server retry SSH on EHOSTUNREACH\nWhen bootstraping an EC2 server from a Heroku instance an EHOSTUNREACH exception is thrown. This makes bootstraping from Heroku impossible. I can\'t reproduce this from another EC2 instance or any other machine; only directly from Heroku.\n\nHere are the steps I used to reproduce this problem on Heroku:\n\nFirst setup the app (replace the AWS ENVs with your own):\n```\nmkdir -p fog-test && cd fog-test && git init .\nheroku apps:create fog-test-$RANDOM -s cedar\nbundle init && echo "gem \'fog\'" >> Gemfile && bundle install\nheroku config:add AWS_KEY=abc123 AWS_SECRET=def456\nssh-keygen -f id_rsa -P \'\'\ngit add . && git commit -m \'Initial commit with fog\' && git push heroku\n```\n\nThen in a ```heroku run irb``` session I ran the following commands\n```\nrequire \'bundler/setup\' # Needed for testing my patch\nrequire \'fog\'\nkey_name = \'fog-test\'\n\nconnection = Fog::Compute.new(\n               provider:              \'AWS\',\n               aws_access_key_id:     ENV[\'AWS_KEY\'],\n               aws_secret_access_key: ENV[\'AWS_SECRET\']\n             )\n\nconnection.key_pairs.get(key_name).destroy if connection.key_pairs.get(key_name)\nconnection.import_key_pair(key_name, IO.read(\'id_rsa.pub\')) if connection.key_pairs.get(key_name).nil?\nserver = connection.servers.bootstrap(\n  username:          \'ubuntu\',\n  key_name:          key_name,\n  private_key_path:  \'id_rsa\',\n  public_key_path:   \'id_rsa.pub\'\n)\n\n### FAILS HERE ###\n\n# And don\'t forgot to cleanup the server and key:\nserver.destroy # Might not work if it failed to connect -- cleanup manually\nconnection.key_pairs.get(key_name).destroy if connection.key_pairs.get(key_name)\n```\n\nWith my patched version this runs with no problem. Without it I get a ```Errno::EHOSTUNREACH: No route to host - connect(2)```\n\nBtw, I opened heroku ticket #53434 for this.'
947,'','Add missining non-minified .js files\nAs stated in #939 some minified .js files are missing their non-minified counter parts\n\nThis patch add them'
946,'','Mock implementations for SCP upload and download\nSimple mocks for SCP upload and download, as per SSH examples'
945,'','Mock aws compute start_instances\n'
944,'','Mock stop_instances\nNot perfect, but looks like it works for me'
943,'','more robust resource pool discovery for cloning in vsphere\nchecking if the template has a pool associated with it is a sane default that covers more possible use cases without making any obscurely implied assumptions'
942,'','[AWS|Autoscale] Fixing Parameters notes for autoscale create_launch_configuration for InstanceMonitoring.\n*NO REAL CODE COMMIT, ONLY MOCK AND COMMENTS*\n\nSo pretty much the notes for using create_launch_configuration are wrong for InstanceMonitoring as it seems either AWS changed or their was some plan to use the Hash in some different way but pretty much all you need to do is what I described in the notes and the mock has the example.  Credit goes to boto, https://github.com/boto/boto/blob/develop/boto/ec2/autoscale/__init__.py, for having it correct but this caused me a lot of pain as AWS API spec was not very clear.\n\nZuhaib'
941,'','Fix user-data attribute name for OpenStack\n'
940,'',"Added offeringType value in the response for the describe_reserved_instances function.\nThe issue was that the response for the describe_reserved_instances function didn't contain the offeringType for the reservations made. Managed to fix it by modifying line 16 in fog-1.3.1/lib/fog/aws/parsers/compute/describe_reserved_instances.rb from:\nwhen 'availabilityZone', 'instanceType', 'productDescription', 'reservedInstancesId', 'state'\nto:\nwhen 'availabilityZone', 'instanceType', 'productDescription', 'reservedInstancesId', 'state', 'offeringType'"
939,'','Please include unminified javascript files\nHi,\n\nThis is related to bug #914.\n\nCould you please ship the unminified version of the javascripts files for both yahoo-profiling and modernizr, it seems that you are already doing so for jquery\n\nThanks!'
938,'',"RDS reservations not being shown\nThe issue consists in an empty request when calling the describe_db_reserved_instances function. Although the request is generated correctly, same issue persists if the request is generated like described in the AWS api documentation with Signature version 2 but works if is being done with Signature version 4 - thus this is more an issue on the AWS side but can be fixed if Signature version 4 is used instead of 2 when doing the API call. Unfortunately couldn't find how to fix this in the code."
937,'',"offeringType not shown in the describe_reserved_instances function\nThe issue was that the response for the describe_reserved_instances function didn't contain the offeringType for the reservations made. Managed to fix it by modifying line 16 in fog-1.3.1/lib/fog/aws/parsers/compute/describe_reserved_instances.rb from:\n            when 'availabilityZone', 'instanceType', 'productDescription', 'reservedInstancesId', 'state'\nto:\n            when 'availabilityZone', 'instanceType', 'productDescription', 'reservedInstancesId', 'state', 'offeringType'"
936,'','Idempotent Dynect calls. :v:\nThe only call I am unsure of currently is put_zone.\n\n```\n=> #<Excon::Response:0x00000004709cd0 @body={"status"=>"success", "data"=>{"zone_type"=>"Primary", "serial_style"=>"increment", "serial"=>1234, "zone"=>"..."}, "job_id"=>1234, "msgs"=>[{"INFO"=>"changeset: No changes to apply.", "SOURCE"=>"BLL", "ERR_CD"=>nil, "LVL"=>"INFO"}, {"INFO"=>"publish: Could not publish .... No changes to apply.", "SOURCE"=>"BLL", "ERR_CD"=>nil, "LVL"=>"INFO"}]}, @headers={"Server"=>"nginx/0.7.67", "Date"=>"Mon, 28 May 2012 14:22:39 GMT", "Content-Type"=>"application/json", "Transfer-Encoding"=>"chunked", "Connection"=>"keep-alive"}, @status=200>\n```\n\nThe delete_record call should also work fine for `Fog.mock!` too.'
935,'',"Default to false for persistent connections. You can't pass in false.\nThis now behaves like other connections in fog. :v: :cloud:"
934,'','Update the terremark driver to work with the latest vcloud express 0.8-ext1.6\nThe Pull request, add supports for the following items:\n\n1. Ability to list templates, SSH keys\n2. Ability to configure VM - SSH Keys, CPU, Memory and Disks\n3. Ability to create and delete internet and node services for multiple ports.\n4. Support for rake to package and install fog '
933,'',"OpenStack Compute addresses['internet'] and public and private_ip_address fixed\nThe private_ip_address only returned nil. Some OpenStack providers do not have 'public' and 'private', they have 'internet' for their addresses. The assumption is to use that for both public and private then. Also only returns the first entry until I see an OpenStack deployment with more than 1 private and public network."
932,'',"catch passing an invalid openstack_tenant\nPassing an invalid openstack_tenant throws a \nException: NoMethodError: undefined method `[]' for nil:NilClass \nfrom \nmgmt_url = svc['endpoints'].detect{|x| x[@endpoint_type]}[@endpoint_type]\nbecause you get an empty serviceCatalog."
931,'','Fog::Storage::AWS::Real#http_url is not working.\n```ruby\n> file\n =>   <Fog::Storage::AWS::File\n    key="22/content/119258/593249-0d360f10-6cd5-012f-2d0e-12313d00d151.mov",\n    cache_control=nil,\n    content_disposition=nil,\n    content_encoding=nil,\n    content_length=4745616,\n    content_md5=nil,\n    content_type="video/quicktime",\n    etag="c9441821afac6def58f3b86e538ed6d1",\n    expires=nil,\n    last_modified=2012-04-20 05:10:25 +0000,\n    metadata={},\n    owner=nil,\n    storage_class=nil,\n    encryption=nil,\n    version=nil\n  > \n\n> aws\n => #<Fog::Storage::AWS::Real:0xba622b8 @aws_access_key_id="AKIAILQ7QPDWKJSCR6FA",\n# <snip the rest since it\'s long and has the secret>\n\n# neither this...\n\n> aws.http_url({host: \'s3.amazonaws.com\', path: [file.directory.key, file.key].join(\'/\')}, 1.year.from_now)\n => "http://s3.amazonaws.com/videos.realgravity.com/22/content/119258/593249-0d360f10-6cd5-012f-2d0e-12313d00d151.mov?AWSAccessKeyId=AKIAILQ7QPDWKJSCR6FA&Signature=ZCMMDmK8PqI9GAFpY%2FU%2BUA3LTF8%3D&Expires=1369515889"\n\n# or this...\n\n> aws.http_url({host: file.directory.key, path: file.key}, 1.year.from_now)\n => "http://videos.realgravity.com/22/content/119258/593249-0d360f10-6cd5-012f-2d0e-12313d00d151.mov?AWSAccessKeyId=AKIAILQ7QPDWKJSCR6FA&Signature=aXHb9bZ0Ox5cjcnAw5JR2HGcpZw%3D&Expires=1369515689" \n\n# produce URLs that work.\n\n```\n\nThere\'s a lot more information I can provide, but I\'m not sure what would be useful.\n\nThis issue is in some fairly complicated code that I\'m only somewhat familiar with (i.e., the S3 signing code).  I\'ve been unable to track down what the problem really is.\n\n\n\n'
930,'','ensure that nil objects are not added to the array in case of search failure\n'
929,'','Circular References Found\nRunning Fog with Ruby\'s "-w" flag indicates that circular references are found throughout the code base. These are considered harmful and should be resolved. As per discussion on #905, this ticket is opened to devise a strategy to resolve this issue.'
928,'','Content-MD5 header results in error when md5 sum is correct\nI\'m trying to upload to s3 using fog and the Content-MD5 option to verify the file was uploaded correctly.   But when I use that header I get the following error:\n\n1.9.2p290 :034 > connection.put_object("imchat_development_logs","ready/logmover.conf",File.read("logmover.conf"),options = { \'Content-MD5\' => \'f81a724a1bf0a87f3fe7ef3995f3dd62\' })\n\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\n--snip--\n  response => #<Excon::Response:0xb770640 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>InvalidDigest</Code><Message>The Content-MD5 you specified was invalid.\n--snip--\n\nBut when I remove that option and upload it works fine and the resulting etag matches the md5 I\'m putting in the option:\n\n1.9.2p290 :035 > connection.put_object("imchat_development_logs","ready/logmover.conf",File.read("logmover.conf"))\n => #<Excon::Response:0xb8400e8 @body="", @headers={"x-amz-id-2"=>"/WDlMfWsoePvdkNWGe4i57p/hxvOkZyJY8bB0hdzRLLxw3UfzAu9gahc4RTbT2CS", "x-amz-request-id"=>"53103479B5A3E849", "Date"=>"Thu, 24 May 2012 00:20:29 GMT", "ETag"=>"\\"f81a724a1bf0a87f3fe7ef3995f3dd62\\"", "Content-Length"=>"0", "Server"=>"AmazonS3"}, @status=200>\n\nHere\'s the gems that are active:\n\naws-sdk (1.5.2)\nbuilder (3.0.0)\nbundler (1.0.21)\nexcon (0.13.4)\nfog (1.3.1)\nformatador (0.2.3)\nhttparty (0.8.3)\njruby-pageant (1.0.2)\njson (1.7.3)\nmime-types (1.18)\nmulti_json (1.3.5)\nmulti_xml (0.5.1)\nnet-scp (1.0.4)\nnet-ssh (2.4.0)\nnokogiri (1.5.2)\nruby-hmac (0.4.0)\nuuidtools (2.1.2)\n\nand...\n\nruby 1.9.2p290 (2011-07-09 revision 32553) [i686-linux]'
927,'','Revert "Add debug option to Fog::Compute::Server#ssh"\nThis reverts commit 1cf33ccc7acc1c68eba23c9fa4556571f67c175f.\n\nConflicts:\nlib/fog/core/ssh.rb\n\nUse a block when you care about getting streaming output, this way you\ncan decide to puts it, store it somewhere, etc, etc, etc.'
926,'','ssh/run optionally takes a block\nand yields [STDOUT, STDERR]\n\nUseful if you need real-timeish output'
925,'','Fog::Compute::Server#sshable?\nwait_for { ready? && sshable? }\n...Do your automation...'
924,'','Fog::Compute::Server#private_key=\nUseful for automation purposes where you have the private key stored in a\ndatabase and not on disk.'
923,'','[rackspace|storage|file] copy method now use the options hash and apply content-type\nhttps://github.com/fog/fog/issues/921'
922,'','[rackspace|storage|files] fix iteration method\nFix bug in the each method of [rackspace|storage|files], which only allow iteration over first 10k items.\n\nhttps://github.com/fog/fog/issues/917'
921,'','[rackspace|storage|file] file copy change content_type \nIf i copy a image file on Rackspace Cloud Files the content_type change to application/json.\n\n```ruby\nf = dir.files.get("original.jpeg")\n=>   <Fog::Storage::Rackspace::File\n    key="original.jpeg",\n    content_length=23378,\n    content_type="image/jpeg",\n    etag="95ac64e518130b273c348002757fa603",\n    last_modified=2012-05-23 15:06:23 +0200\n  \nx = f.copy(\'test\',\'new_file.jpg\')\n=>   <Fog::Storage::Rackspace::File\n    key="new_file.jpg",\n    content_length=23378,\n    content_type="application/json",\n    etag="95ac64e518130b273c348002757fa603",\n    last_modified=2012-05-23 15:11:13 +0200\n  >\n```'
920,'','[cloudstack|compute] volumes and volume tests for everyone\n* Add volume abstraction support for cloudstack\n* Add volume tests for models, collections, and attach/detach'
919,'','Elb2\nI took dilliards commits from https://github.com/fog/fog/issues/856\n"Lists all of the cipher policies that are valid, defaulting to the ELB defaults. Also includes changes for VPC support, but the lack of VPC support in fog makes testing difficult. This could use some manual testing and automated tests, but it is working for me and supports all the current features of the ELB API.\n"\n\nadded the ability to create VPC ELBs, Tests, and the introduction of the InternetGateway object'
918,'','Vpc elb\nI\'ve taken dilliards changes in https://github.com/fog/fog/issues/856  \n"Lists all of the cipher policies that are valid, defaulting to the ELB defaults. Also includes changes for VPC support, but the lack of VPC support in fog makes testing difficult. This could use some manual testing and automated tests, but it is working for me and supports all the current features of the ELB API."\n\nI\'ve added VPC testing for the ELB. Implemented the creation of ELBs in a VPC, and added the InternetGateway object (which I needed for VPC ELB creation testing).'
917,'','[rackspace|storage|files] each method only iterate over first 10000 items\nI have about 23000 files in my Rackspace Cloud Files Container, but the each methode stop after 10000 items.\n\nFor example: \n\n```ruby\nconnection = Fog::Storage.new(<credentials>)\ndir = connection.directories.get("test_dir")\ni = 0\ndir.files.each {|f| puts i; i+=1 }    \n\n```\nOutput:\n```ruby\n0\n...\n999\n```\n\n'
916,'','[cloudstack|compute] support async jobs\ncloudstack will now pass\n\n```bash\nFOG_MOCK=true shindo tests/ +cloudstack\n```\n\nand\n\n```bash\nshindo tests/ +cloudstack\n```\n'
915,'','Cannot control RackSpace Load Balancers\n>> Rackspace[:load_balancers].list_load_balancers\nFog::Rackspace::LoadBalancers::ServiceError: Invalid authentication token. Please renew\n\tfrom /usr/lib64/ruby/gems/1.8/gems/excon-0.13.4/lib/excon/connection.rb:266:in `request_kernel\'\n\tfrom /usr/lib64/ruby/gems/1.8/gems/excon-0.13.4/lib/excon/connection.rb:97:in `request\'\n\tfrom /usr/lib64/ruby/gems/1.8/gems/fog-1.3.1/lib/fog/core/connection.rb:20:in `request\'\n\tfrom /usr/lib64/ruby/gems/1.8/gems/fog-1.3.1/lib/fog/rackspace/load_balancers.rb:121:in `request\'\n\tfrom /usr/lib64/ruby/gems/1.8/gems/fog-1.3.1/lib/fog/rackspace/requests/load_balancers/list_load_balancers.rb:15:in `list_load_balancers\'\n\tfrom (irb):4\n\tfrom /usr/lib64/ruby/gems/1.8/gems/fog-1.3.1/bin/fog:40\n\tfrom /usr/bin/fog:19:in `load\'\n\tfrom /usr/bin/fog:19\n\nHowever:\n\n\n>> Rackspace[:compute].list_servers\n#<Excon::Response:0x2ab087e79840 @headers={"X-PURGE-KEY"=>"/10006121/servers", "X-Varnish"=>"329415808", "Last-Modified"=>"Wed, 18 Apr 2012 14:31:38 GMT", "Via"=>"1.1 varnish", "Date"=>"Mon, 21 May 2012 22:39:18 GMT", "Content-Type"=>"application/json", "Content-Length"=>"825", "Server"=>"Apache-Coyote/1.1", "Age"=>"0", "Cache-Control"=>"s-maxage=1800", "vary"=>"Accept, Accept-Encoding, X-Auth-Token", "Connection"=>"keep-alive"}, @status=200, @body={"servers"=>[{"name"=> "xxx"... etc'
914,'','Missing licence for some .js files\nHi,\n\nIn docs/public/js/ directory, you can find some .js files that have a different license/copyright holders.\n\nIt could be interesting to list these into the README file or in a dedicated LICENCE file.'
913,'','Modify url regexp to handle periods in bucket names\nIt looks like this was fixed by #835, but was ditched when the get object handling was centralized.'
912,'','Adding network interface information and security group ids\nUpdating describe_instances call.\n\nAmazon API return the following:\n\n```xml\n<item>\n    <instanceId>i-XXXXX</instanceId>\n    <imageId>ami-XXXXX</imageId>\n    <instanceState>\n        <code>16</code>\n        <name>running</name>\n    </instanceState>\n    <privateDnsName/>\n    <dnsName/>\n    <reason/>\n    <keyName>key</keyName>\n    <amiLaunchIndex>0</amiLaunchIndex>\n    <productCodes/>\n    <instanceType>c1.medium</instanceType>\n    <launchTime>2012-05-06T19:32:29.000Z</launchTime>\n    <placement>\n        <availabilityZone>us-west-2a</availabilityZone>\n        <groupName/>\n        <tenancy>default</tenancy>\n    </placement>\n    <kernelId>aki-XXXXXX</kernelId>\n    <monitoring>\n        <state>disabled</state>\n    </monitoring>\n    <subnetId>subnet-XXXXXX</subnetId>\n    <vpcId>vpc-XXXXX</vpcId>\n    <privateIpAddress>111.111.111.111</privateIpAddress>\n    <ipAddress>222.222.222.222</ipAddress>\n    <sourceDestCheck>false</sourceDestCheck>\n    <groupSet>\n        <item>\n            <groupId>sg-XXXXXXX</groupId>\n            <groupName>prd-vpn</groupName>\n        </item>\n    </groupSet>\n    <architecture>x86_64</architecture>\n    <rootDeviceType>ebs</rootDeviceType>\n    <rootDeviceName>/dev/sda1</rootDeviceName>\n    <blockDeviceMapping>\n        <item>\n            <deviceName>/dev/sda1</deviceName>\n            <ebs>\n                <volumeId>vol-XXXXXXX</volumeId>\n                <status>attached</status>\n                <attachTime>2012-05-06T19:33:01.000Z</attachTime>\n                <deleteOnTermination>true</deleteOnTermination>\n            </ebs>\n        </item>\n    </blockDeviceMapping>\n    <virtualizationType>paravirtual</virtualizationType>\n    <clientToken/>\n    <tagSet>\n        <item>\n            <key>Name</key>\n            <value>vpc-vpn2</value>\n        </item>\n    </tagSet>\n    <hypervisor>xen</hypervisor>\n    <networkInterfaceSet>\n        <item>\n            <networkInterfaceId>eni-XXXXXX</networkInterfaceId>\n            <subnetId>subnet-XXXXXX</subnetId>\n            <vpcId>vpc-XXXXXX</vpcId>\n            <description>Primary network interface</description>\n            <ownerId>XXXXXXXXXX</ownerId>\n            <status>in-use</status>\n            <privateIpAddress>111.111.111.111</privateIpAddress>\n            <sourceDestCheck>false</sourceDestCheck>\n            <groupSet>\n                <item>\n                    <groupId>sg-XXXXXXXX</groupId>\n                    <groupName>prd-vpn</groupName>\n                </item>\n            </groupSet>\n            <attachment>\n                <attachmentId>eni-attach-XXXXXX</attachmentId>\n                <deviceIndex>0</deviceIndex>\n                <status>attached</status>\n                <attachTime>2012-05-06T19:32:29.000Z</attachTime>\n                <deleteOnTermination>false</deleteOnTermination>\n            </attachment>\n            <association>\n                <publicIp>222.222.222.222</publicIp>\n                <ipOwnerId>XXXXXXXX</ipOwnerId>\n            </association>\n        </item>\n    </networkInterfaceSet>\n</item>\n```\n\nThis pull request adds parsing of the networkInterfaceSet tag and elements.\nThis pull request also moves security GroupIds into an array.\n\nOn a practical side, knife ec2 output before the patch:\n\n```\n\nknife ec2 server list\nInstance ID  Public IP       Private IP     Flavor     Image         SSH Key  Security Groups                State  \ni-XXXXXXXX   111.111.111.111   111.111.111.111  m1.large   ami-XXXXXXXX           sg-XXXXXXXX, web               running\ni-XXXXXXXX   111.111.111.111   111.111.111.111  m1.large   ami-XXXXXXXX           sg-XXXXXXXX, web               running\ni-XXXXXXXX   111.111.111.111   111.111.111.111  c1.medium  ami-XXXXXXXX  artem                                   running\n                                            t1.micro                                                         [{}]   \ni-XXXXXXXX                   111.111.111.111     c1.medium  ami-XXXXXXXX  artem                                   running\n                                            t1.micro                                                         [{}]   \ni-XXXXXXXX                   111.111.111.111    c1.medium  ami-XXXXXXXX  artem                                   running\n                                            t1.micro                                                         [{}]   \ni-XXXXXXXX   111.111.111.111  111.111.111.111    c1.medium  ami-XXXXXXXX  artem                                   running\n                                            t1.micro                                                         [{}]   \n\n```\n\nNotice the empty "t1.micro  [{}]" instance objects created because of parsing failures for VPC instances.\n\nThe pull request addresses this issue.'
911,'','use kernel_id for mocked kernel, not stackscript_id\nThis commit fixes a bug I found in the Linode mocks.'
910,'','fix auto-discovery for HP Cloud by fog bin [for #909]\nIssue was:\n\n```ruby\n>> HP.class_for(:compute)\nNameError: uninitialized constant Fog::HP::Compute\n\n>> AWS.class_for(:compute)\nFog::Compute::AWS\n```\n\nNow:\n\n```ruby\n$ bundle exec bin/fog hp\n  Welcome to fog interactive!\n  :bosh-hp provides HP, VirtualBox and Vmfusion\n```'
909,'',"HP not discovered by fog bin\n```ruby\n>> HP.class_for(:compute)\nNameError: uninitialized constant Fog::HP::Compute\n\n>> AWS.class_for(:compute)\nFog::Compute::AWS\n```\n\nI think the bug is at https://github.com/fog/fog/blob/master/lib/fog/bin/hp.rb#L6-12, which is referencing invalid classes. I guess there was a refactoring an these didn't get ported."
908,'',"add Linode Mock classes to request primitives\nI added Mock implementations to most of the Linode request primitives. I'm writing tests for the Opscode Chef knife-linode plugin, and I wanted to be able to put Fog into mock mode."
907,'','add a method to IPAddr instead of breaking a useful one\nThe monkey patch to `IPAddr#mask` in the [ecloud compute provider](https://github.com/fog/fog/blob/master/lib/fog/ecloud/compute.rb#L4-8) unnecessarily removes functionality from IPAddr in both [1.8.7](http://ruby-doc.org/stdlib-1.8.7/libdoc/ipaddr/rdoc/IPAddr.html#method-i-mask) and [1.9](http://www.ruby-doc.org/stdlib-1.9.3/libdoc/ipaddr/rdoc/IPAddr.html#method-i-mask). This pull request adds a method to IPAddr instead of breaking a useful one.'
906,'','[cloudstack|compute] server abstraction and mocks\ncreate server abstraction and mock server support for cloudstack'
905,'',"Remove more warnings\nThis branch is *not* done. I'm simply making it available to show some visibility into some work I'm doing on removing warnings in Fog, especially since this work touches so many files.\n\nThe biggest remaining problem is a circular dependency issue mentioned in issue #904.\n\nWould someone mind looking over what's done so far to see if anything is out of sorts?"
904,'',"Interesting Comment in Code\nI'm doing some work on removing a circular require warning in Fog, and I noticed an interesting comment here: https://github.com/fog/fog/blob/master/lib/fog.rb#L11-13.\n\nIt seems to be suggesting that [fog/providers.rb](https://github.com/fog/fog/blob/master/lib/fog/providers.rb) and that the user (???) be forced to use Fog::Providers interface. Is this a correct interpretation of the comment?\n\nThe circular reference problem is in the [Fog::Providers#service method](https://github.com/fog/fog/blob/master/lib/fog/core/provider.rb#L27).\n\nIt be nice to put this warning to bed, and I'm willing to help make any changes required :)"
903,'',"add support for HP availability zone az-3.region-a.geo-1\nmissing from the 'HP' provider in Fog."
902,'','replace hp_account_id with hp_access_key to match HP\'s description\nOn HP\'s API Keys page, it\'s called the "Access Key ID". I\'ve already had a confused user trying to use the account ID from their login, so let\'s make it match HP\'s own description.'
901,'',"Missing require 'rubygems' in several files\nHi,\r\n\r\nlib/fog/bin/libvirt.rb, lib/fog/bin/virtual_box.rb and lib/fog/bin/vmfusion.rb are using rubygems without explicitly require it.\r\n\r\nPlease add the needed require 'rubygems'"
900,'','Rackspace love\n* Fix Integer vs String hash key comparisons in the Compute mock\r\n* Add default Rackspace images\r\n* Fix Fog::Compute::Rackspace::Images#all returning nil without a server filter'
899,'','implement Fog::SSH::Mock#run\nStore instance variables and command in data.\r\n\r\nObviously not complete but better than raising unimplemented error.'
898,'','[AWS|Auto Scale] Delete notifications created by put_notification_configuration.\nDelete notifications created by put_notification_configuration.  I should have created this when I committed the put_notification_configuration.'
897,'','[libvirt] Fix SSH keyfile being pulled from wrong param\nAccording to the libvirt docs ( http://libvirt.org/remote.html#Remote_URI_parameters ) the ssh keyfile should be pulled from the keyfile param not the command param. Without this Fog was unable to SSH into the newly provisioned VM to get the IP. '
896,'','Tag generated model tests with string not symbol\nFix for issue #895'
895,'','Shindo not running model tests by default and issue with tags\nIf I run `shindo` then the following "core" tests aren\'t getting run:\r\n\r\n```\r\ntests/compute/models/flavors_tests.rb\r\ntests/compute/models/server_tests.rb\r\ntests/compute/models/servers_tests.rb\r\n```\r\n\r\nIf I run `shindo tests/compute` they are run.\r\n\r\nIf I run `shindo tests/compute +brightbox` to limit the run to our provider they are no longer ran! The tests do appear to be tagged.\r\n\r\n```\r\n  Fog::Compute[:brightbox] | flavors (brightbox)\r\n  \r\n  Fog::Compute[:brightbox] | server (brightbox)\r\n  \r\n  Fog::Compute[:brightbox] | servers (brightbox)\r\n\r\n0 succeeded in 0.355904 seconds\r\n```\r\n\r\nThis has covered up a couple of missing methods on the Brightbox provider because these tests have not been included in our testing.\r\n\r\nI would expect `shindo +brightbox` to run these core tests as well as the request tests and not be excluded when we are using a \'+\' tag.'
894,'',"[openstack] Add Public Identity URL to parameters to enable tenant auto detection\nThis is a followup to Pull Request #890\r\n\r\n@rubiojr @xtoddx what do you think?\r\n\r\nAuto-detection of tenant won't work on my environment on port 35357 (Admin URL) giving me authentication errors and must be port 5000 (Public URL)."
893,'','ensure apiKey and command are included in parameter sorting for Ninefold\nWhen creating a new VM on Ninefold and an account is required, the secret generation was incorrect because apiKey was always at the beginning of the request string. In this case, the account parameter should be sorted to the start.\r\n'
892,'','SSL Certificates for Rackspace load balancer\nI added this feature several weeks ago for my own purpose and realized it could benefit the community at large. Unfortunately, I\'m having a bit of trouble writing te tests. Can anyone help me with that part of it? \r\n\r\nThe use of it should look like this:\r\nlb = connection.create_load_balancer("new-balancer", "HTTP", 80, [{type: "PUBLIC"}],[{address:"x.x.x.x", port:80, condition: "ENABLED"}])\r\n\r\nlb.enable_ssl_termination(443, private_key, certificate)\r\n'
891,'',"Nested Credentials with Array gets flattened; restrict flatten to 1L\nThis is mainly to take into account credentials which has a structure wherein when flattened would result into an odd number of elements. For example:\r\n\r\n```\r\n{ :token => 'abcdefg',\r\n  :roles => [{:id => 1, :name => 'admin'}, {:id => 2, :name => 'netadmin'}]\r\n}\r\n```\r\n\r\n@redzebra The other thing I'm concerned about is that if this works with ruby 1.8.5. I wanted to try it myself but currently rvm is giving me compilation errors whenever I try to install 1.8.5... I think I'm missing something."
890,'','[openstack|compute] authenticate_v2 fixes\n* Add connection_options to Fog::Connection when\r\nauthenticating so we can disable SSL cert verification for example.\r\n* Do not use hardcoded keystone 5000 port\r\n\r\nSample code:\r\n\r\n    conn = Fog::Compute.new({\r\n      :provider => \'OpenStack\',\r\n      :openstack_api_key => "changeme",\r\n      :openstack_username => "user@bvox.net",\r\n      :openstack_auth_url => "https://auth-server/v2.0/tokens",\r\n      :connection_options => { :ssl_verify_peer => false }\r\n    })'
889,'','ArgumentError (acl must be one of [private, public-read, public-read-write, authenticated-read])\nUpdating to the latest version of Fog has caused file uploads to S3 (via Carrierwave) to fail. It looks like I\'m setting the *acl* incorrectly (or perhaps I\'m not setting it at all?) - but I can\'t figure out what to fix exactly.\r\n\r\nThis is a bit outside my element, so I\'d appreciate any help.\r\n\r\n```\r\n2012-05-03T22:08:05+00:00 app[web.1]: Started POST "/documents" for 174.70.56.37 at 2012-05-03 22:08:05 +0000\r\n2012-05-03T22:08:06+00:00 app[web.1]: \r\n2012-05-03T22:08:06+00:00 app[web.1]: ArgumentError (acl must be one of [private, public-read, public-read-write, authenticated-read]):\r\n2012-05-03T22:08:06+00:00 app[web.1]:   app/controllers/documents_controller.rb:39:in `block in create\'\r\n2012-05-03T22:08:06+00:00 app[web.1]:   app/controllers/documents_controller.rb:38:in `create\'\r\n2012-05-03T22:08:06+00:00 app[web.1]: \r\n2012-05-03T22:08:06+00:00 app[web.1]: \r\n2012-05-03T22:08:06+00:00 app[web.1]: Processing by DocumentsController#create as JS\r\n2012-05-03T22:08:06+00:00 app[web.1]:   Parameters: {"utf8"=>"â", "authenticity_token"=>"F5qftHl+rMmuKwbvW2uzs6aQWWLynZuclr/npxgbaBU=", "form_id"=>"upload_new_document_form", "form_container"=>"upload_new_document", "file_req"=>"DefaultReq---12", "document"=>{"generated_on(2i)"=>"", "generated_on(3i)"=>"", "generated_on(1i)"=>"", "illustration_type"=>"", "vendor"=>"", "multiplier"=>"", "length"=>"", "uploaded_version"=>"1", "insured_id"=>"794", "policy_id"=>"967", "file_req_type"=>"DefaultReq", "file_req_id"=>"12", "status"=>"new", "document"=>#<ActionDispatch::Http::UploadedFile:0x0000000687e668 @original_filename="small.png", @content_type="image/png", @headers="Content-Disposition: form-data; name=\\"document[document]\\"; filename=\\"small.png\\"\\r\\nContent-Type: image/png\\r\\n", @tempfile=#<File:/tmp/RackMultipart20120503-1-1aeuemg>>}}\r\n```'
888,'','Refactor AWS Directory\n* Silence warnings regarding uninitialized instance variable @location\r\n* Tidy up memoization\r\n* Extensive use of getters instead of instance variables\r\n\r\nFixes #884'
887,'','Fix Ecloud Specs\nMade computePool an optional parameter, specs now pass without issue.'
886,'kevinykchan','[joyent|compute] Support for DSA keys for auth\n'
885,'','undefined method \'s3_headers=\'\nI\'m getting the following error, which I thought might be fog related.\r\n\r\n```\r\nconfig/initializers/fog.rb:14:in `block in <top (required)>\': undefined method `s3_headers=\' for CarrierWave::Uploader::Base:Class (NoMethodError)\r\n```\r\n\r\nI updated my gems, but nothing else change so far as I\'m aware. Older/working version in [ brackets ].\r\n\r\nfog (1.3.1)  [0.9.0]\r\ncarrierwave (0.6.2)  [0.5.8]\r\n\r\nHere\'s my fog.rb contents...\r\n```\r\nCarrierWave.configure do |config|\r\n  config.fog_credentials = {\r\n    :provider               => \'AWS\',       # required\r\n    :aws_access_key_id      => \'XXXXXXXXXXXX\',       # required\r\n    :aws_secret_access_key  => \'XXXXXXXXXXXXX\'    # required\r\n    # :region                 => \'eu-west-1\'  # optional, defaults to \'us-east-1\'\r\n  }\r\n  config.fog_directory  = \'s3-bucket-name\'                     # required\r\n  \r\n  config.cache_dir = "#{Rails.root}/tmp/uploads"    # \r\n  # config.fog_host       = \'https://assets.example.com\'            # optional, defaults to nil\r\n  config.fog_public     = false                                   # optional, defaults to true\r\n  config.fog_attributes = {\'Cache-Control\'=>\'max-age=315576000\'}  # optional, defaults to {}\r\n  config.s3_headers = {"Content-Disposition" => "attachment;"}\r\nend\r\n```'
884,'',"Uninitialized Instance Variable @location\nWhen running a script using Fog with the warnings flag for Ruby (i.e. `ruby -w myscript.rb`), I'll see the following warning occasionally in my log when uploading to S3:\r\n\r\n`/Users/james/.rvm/gems/ruby-1.9.2-p318/gems/fog-1.3.1/lib/fog/aws/models/storage/directory.rb:110: warning: instance variable @location not initialized`\r\n\r\nIt looks like the logic for determining the [location during save](https://github.com/fog/fog/blob/master/lib/fog/aws/models/storage/directory.rb#L110-113) accesses the `@location` instance variable, and does a little manipulation of it, something I'd think should be wrapped up either in `AWS::Directory#location`, or some private method.\r\n\r\nThough this is not a show stopper, it'd be nice to clean up the code such that the warning is not emitted."
883,'','Rackspace Cloud Database Support (Not Ready)\n'
882,'',"Correct docs for change_resource_record_sets\nI came across errors in the docs for the change_resource_record_sets\r\nmethod. I've updated the docs for the method and provided an example of\r\nusing it."
881,'','ecloud tests fail\nI added TRMK ecloud credentials to my .fog and when I run the specs the ecloud specs fail as below:\r\n\r\n```\r\nexport FOG_MOCK=true && bundle exec spec spec\r\n..***.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF................................................\r\n\r\nPending:\r\n\r\nEcloud should == "192.168.0.1" (TODO)\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/bin_spec.rb:5:in `block in <top (required)>\'\r\n\r\nEcloud when indexing it like an array with a service that exists should return something when indexed with a configured service (TODO)\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/bin_spec.rb:14:in `block (3 levels) in <top (required)>\'\r\n\r\nEcloud when indexing it like an array with a service that does not exist should raise an ArgumentError (TODO)\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/bin_spec.rb:21:in `block (3 levels) in <top (required)>\'\r\n\r\n1)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data should respond to #instantiate_vapp_template\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:37:in `block (2 levels) in <top (required)>\'\r\n\r\n2)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data should respond to #instantiate_vapp_template\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:38:in `block (2 levels) in <top (required)>\'\r\n\r\n3)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data should respond to #instantiate_vapp_template\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:39:in `block (2 levels) in <top (required)>\'\r\n\r\n4)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data should respond to #instantiate_vapp_template\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:40:in `block (2 levels) in <top (required)>\'\r\n\r\n5)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data should respond to #instantiate_vapp_template\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:41:in `block (2 levels) in <top (required)>\'\r\n\r\n6)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data should respond to #instantiate_vapp_template\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:35:in `block (4 levels) in <top (required)>\'\r\n\r\n7)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data updates the mock data properly\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:38:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:38:in `block (4 levels) in <top (required)>\'\r\n\r\n8)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data body should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:42:in `block (2 levels) in <top (required)>\'\r\n\r\n9)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data headers should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:32:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:43:in `block (2 levels) in <top (required)>\'\r\n\r\n10)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n11)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n12)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n13)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n14)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data name should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n15)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data memory should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n16)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data added mock data cpus should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:42:in `block (5 levels) in <top (required)>\'\r\n\r\n17)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data server based on added mock data name should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:60:in `block (5 levels) in <top (required)>\'\r\n\r\n18)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:69:in `block (5 levels) in <top (required)>\'\r\n\r\n19)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:79:in `block (5 levels) in <top (required)>\'\r\n\r\n20)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body xmlns should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:133:in `block (2 levels) in <top (required)>\'\r\n\r\n21)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body xmlns_xsi should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:137:in `block (2 levels) in <top (required)>\'\r\n\r\n22)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body xmlns_xsd should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:141:in `block (2 levels) in <top (required)>\'\r\n\r\n23)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body href should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:73:in `block (5 levels) in <top (required)>\'\r\n\r\n24)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body type should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:74:in `block (5 levels) in <top (required)>\'\r\n\r\n25)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body name should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:75:in `block (5 levels) in <top (required)>\'\r\n\r\n26)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body status should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:76:in `block (5 levels) in <top (required)>\'\r\n\r\n27)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body size should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:67:in `block (5 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:77:in `block (5 levels) in <top (required)>\'\r\n\r\n28)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body Link should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:82:in `block (6 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:84:in `block (6 levels) in <top (required)>\'\r\n\r\n29)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body Link rel should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:82:in `block (6 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:86:in `block (6 levels) in <top (required)>\'\r\n\r\n30)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body Link type should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:82:in `block (6 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:87:in `block (6 levels) in <top (required)>\'\r\n\r\n31)\r\nArgumentError in \'Fog::Ecloud, initialized w/ the TMRK Ecloud module#instantiate_vapp_template with a valid data#body Link href should change #result\'\r\nRequired data missing: :computePool\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:10:in `validate_instantiate_vapp_template_options\'\r\n/Users/drnic/Projects/gems/fog/lib/fog/ecloud/requests/compute/instantiate_vapp_template.rb:105:in `instantiate_vapp_template\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:31:in `block (4 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:82:in `block (6 levels) in <top (required)>\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/spec_helper.rb:14:in `block (2 levels) in its\'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/requests/instantiate_vapp_template_spec.rb:89:in `block (6 levels) in <top (required)>\'\r\n\r\nFinished in 10.236514 seconds\r\n```'
880,'',"Dynect DNS Problem while parsing JSON\nI didn't install any additional engines (json, yajl, ...) and ran into this when trying to deal with dynect DNS requests:\r\n\r\n\r\n\r\n    stack level too deep\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/core/json.rb:36:in `decode'\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/core/json.rb:36:in `decode'\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/dynect/dns.rb:96:in `request'\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/dynect/requests/dns/post_session.rb:15:in `post_session'\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/dynect/dns.rb:78:in `auth_token'\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/dynect/dns.rb:89:in `request'\r\n    /instance-setup-fog/vendor/bundle/ruby/1.8/bundler/gems/fog-a816990270e1/lib/fog/dynect/requests/dns/get_record.rb:19:in `get_record'"
879,'','[aws|address] fixes release_address for VPC EIPs\nthere doesn\'t seem to be any documentation on ReleaseAddress for this requirement, but attempts to release an EIP allocated within VPC bomb without providing the AllocationId. further, the API will error if PublicIp is passed in addition to AllocationId, lord only knows why.\r\n\r\nwasn\'t sure where to slot in tests for VPC EIPs. here\'s a before and after anyway. \r\n\r\n```\r\n>> compute.release_address "107.21.53.97"\r\nFog::Compute::AWS::Error: InvalidParameterValue => You must specify an allocation id when releasing a VPC elastic IP address\r\n\tfrom gems/excon-0.13.4/lib/excon/connection.rb:266:in `request_kernel\'\r\n\tfrom gems/excon-0.13.4/lib/excon/connection.rb:97:in `request\'\r\n\tfrom bundler/gems/fog-a816990270e1/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom bundler/gems/fog-a816990270e1/lib/fog/aws/compute.rb:331:in `request\'\r\n\tfrom bundler/gems/fog-a816990270e1/lib/fog/aws/requests/compute/release_address.rb:22:in `release_address\'\r\n>> compute.release_address "107.21.53.97", "eipalloc-946c29fc"\r\nFog::Compute::AWS::Error: InvalidParameterCombination => You may specify public IP or allocation id, but not both in the same call\r\n\tfrom gems/excon-0.13.4/lib/excon/connection.rb:266:in `request_kernel\'\r\n\tfrom gems/excon-0.13.4/lib/excon/connection.rb:97:in `request\'\r\n\tfrom bundler/gems/fog-a816990270e1/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom bundler/gems/fog-a816990270e1/lib/fog/aws/compute.rb:331:in `request\'\r\n        from bundler/gems/fog-a816990270e1/lib/fog/aws/requests/compute/release_address.rb:22:in `release_address\'\r\n```\r\n\r\n```\r\n>> compute.release_address "107.21.53.97", "eipalloc-946c29fc"\r\n=> #<Excon::Response:0x007fed16f1fc60 @body={"requestId"=>"a4e3d6a0-0629-4ca5-a6e6-98cbbdad81c1", "return"=>true}, @headers={"Content-Type"=>"text/xml;charset=UTF-8", "Transfer-Encoding"=>"chunked", "Date"=>"Thu, 26 Apr 2012 01:50:11 GMT", "Server"=>"AmazonEC2"}, @status=200>\r\n```'
878,'',"vcloud configure_vm.rb has a YAML configuration at the top\nThis file has some YAML at the top that looks unneeded and out of place. Its not causing a bug but its definitely ugly, for both the code and the person's company who has data listed there. \r\n\r\nThe fix would be to remove this private data."
877,'',"Fixed #875: Loosen multi_json version.\nIf I could get another set of eyes to either review the code or at least verify it works, I'd appreciate that.  I ran the tests with multi_json 1.2.0 and 1.3.2 and didn't seem to have any problems.\r\n\r\nOne change introduced that I'm not wild about is we use to lazy require 'multi_json'.  I now require it optimistically in 'fog/core/json.rb', but this file gets loaded everywhere, so we effectively always load multi_json.  We could relax that, but I liked caching the results of the `:respond_to?` call, since introspecting on every call would incur considerably more overhead than requiring once.  I'm open to suggestions if anyone has a way to blend the two approaches."
876,'',"Excon::Errors::SocketError: write would raise \nI'm getting the above error... here's a simple repro: https://gist.github.com/2489522\r\n\r\nAbove is just IRB, require 'fog' so shouldn't be an environment issue.\r\n\r\nOnly happens in jruby (I'm on 1.6.7) \r\n\r\nfog (1.3.1)\r\nexcon (0.13.4)\r\n"
875,'','Loosen multi_json version\nI commented on the merge that brought multi_json up to 1.3.2, here:\r\n\r\nhttps://github.com/fog/fog/commit/56403ea5f40fc76582d23abfdabe45c8ee7c23f5\r\n\r\nBut, I think this is something that really should be relaxed.  fog shouldn\'t force an entire dependency chain upgrade on any app.  It certainly shouldn\'t do that in a point release (this change was introduced in 1.3.1).  Granted, multi_json put us in a very odd position here.  But, I think the proper thing to do is drop the dependency version back to "~> 1.0" and use `:respond_to?` to choose between the two APIs.  Or, we should go back to the deprecated API and cope with the messages.  Flat out changing the API though is akin to multi_json 2.0 upgrade -- it breaks anything still using a 1.x version.'
874,'','Adds Support for AWS DynamoDB batch_put_item\nCurrently, the ruby aws sdk has a "batch_put_item" method, but fog doesn\'t have this functionality yet.\r\n\r\nI forked fog, implemented batch_put_item, wrote a test, and would like someone to review / merge this pull request\r\n\r\nCode available here : git@github.com:adgaudio/fog.git\r\n\r\nPlease review my tests, as I copied the format for batch_get_item.\r\n\r\nThanks!\r\n\r\nAlex'
873,'','No Support for AWS DynamoDB batch_put_item\nCurrently, the ruby aws sdk has a "batch_put_item" method, but fog doesn\'t have this functionality yet.\r\n\r\nI forked fog, implemented batch_put_item, wrote a test, and would like someone to review / merge this "pull request"\r\n\r\nCode available here :  git@github.com:adgaudio/fog.git\r\n\r\nCode awaiting review.\r\n\r\nThanks!\r\n\r\nAlex'
872,'','OS API was renamed to 2 from 1.1.\n'
871,'','Add support for ports in AWS storage URLs\n* Introduce put_object_http_url request\r\n  This is useful for when using fake S3 implementations\r\n* Automatically detect default scheme based on the connection'
870,'','[aws|dns] fix get, all, and all!\nget and all returned AWS error responses about empty values being specified.  Existing shindo\r\ntests already covered these cases as this:\r\n\r\nFOG_MOCK=false bundle exec shindont tests/aws/models/dns/records_tests.rb\r\n\r\nwas reporting 6 failures before this fix.\r\n\r\nTests (and apps) pass after fix.'
869,'','[AWS|Auto Scale] Add support for PutNotificationConfiguration\n[AWS|Auto Scale] Add support for put_notification_configuration and change AWS API for Autoscale to use 01-01-2011 version which support PutNotificationConfiguration, http://docs.amazonwebservices.com/AutoScaling/latest/APIReference/API_PutNotificationConfiguration.html\r\nLikely more things to add for 01-01-2011 version but will add as we hit them.'
868,'kevinykchan',"Use MultiJSON #dump and #load rather than #encode and #decode\nIn version 1.3.0 MultiJSON replaced the methods encode and decode with dump and load. The commit also deprecated the encode and decode methods (https://github.com/intridea/multi_json/commit/e90fd6cb1b0293eb0c73c2f4eb0f7a1764370216).\r\n\r\nIn version 2.0 of MultiJSON encode and decode will be removed entirely. This commit replaces the methods throughout fog for every provider. It also updates the gemspec to ~> 1.3 to ensure that 1.3.0 or higher is required so that the new methods are availible.\r\n\r\nThe changes are pretty simple and I've tested them on the Brightbox Cloud but I don't have the ability to test all the other providers."
867,'','Allow for stringified options keys in Fog::Service#new\nFog::Service#validate_options fails in case of using HashWithIndifferentAccess ( or Hash with stringified keys ) as options'
866,'xtoddx','OpenStack Update\nIn relation to: https://github.com/fog/fog/issues/848'
865,'','* [xenserver|compute] set_attribute request now accepts var args\n- added new tests\r\n\r\n* [xenserver|compute]  VBD fixes and cleanup\r\n  - VBD.metrics now returns nil when VBD not attached\r\n  - VBD tests fixes and cleanup\r\n\r\n* [xenserver|compute] cleanup tests and add new helpers'
864,'','Fog::Compute::AWS::Address#server -> assigned Server (fixes #862)\n'
863,'',"Missing tests/vcloud/models/compute/conn_helper during test run\nThis error appears throughout the specs:\r\n\r\n```\r\n$ bundle exec rake\r\n...\r\n Fog::Compute[:slicehost] | slice requests (slicehost) tests/vcloud/models/compute/network_tests.rb:1:in `require': cannot load such file -- tests/vcloud/models/compute/conn_helper.rb (LoadError)\r\n\tfrom tests/vcloud/models/compute/network_tests.rb:1:in `<top (required)>'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p125/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `load'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p125/gems/shindo-0.3.4/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p125/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `each'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p125/gems/shindo-0.3.4/lib/shindo/bin.rb:58:in `block in run_in_thread'\r\n```\r\n"
862,'',"Address#server missing\n`Fog::Compute::[SomeCloud]::Address#server=` exists; though there isn't `Address#server` getter method. Can I add one to the appropriate models; or is this missing for a good reason?"
861,'',"Add flush option which is available to Fog::Compute::Server#ssh\nWe needed more visibility into our ssh commands for long-running ssh sessions when provisioning chef nodes. I tried to make the most minimal optional change that would allow this. This allows a user to see stdout and stderr in the middle of the command instead of at the end:\r\n\r\n```ruby\r\nserver = Fog::Compute::Server.new\r\nserver.ssh 'long_running_command', :flush => true\r\n```\r\n\r\nI chose :flush since :verbose is already being used by [Net::SSH.start](http://rdoc.info/gems/net-ssh/Net/SSH.start), which Net::SSH::Real passes its options to.\r\n\r\nI'm open to adding tests (though I didn't see any related ones in tests/core) and a different option name. Would love to get this in so we don't have to rely on monkeypatching Fog :(. Feedback?"
860,'',"Local::Files#each out of sync\nHi, I'm new to Fog so apologies if this is due to a misunderstanding on my part...\r\n\r\nI find that Local::Files#each can get out of sync.  I'm seeing it yield files that were deleted (admittedly not via fog) and simultaneously not yield files that were actually created via Local::Files#create.   Using #all syncs it back up:\r\n\r\n     directory.files.each { |model| pp model }   # out of sync\r\n     directory.files.all.each { |model| pp model } # in sync\r\n\r\nis that intended behavior or a bug?     \r\n\r\nIn particular I'm interested in having consistent behavior with AWS::Files.  If using #all.each is the right thing to do for Local::Files, would it also be OK to do that for AWS::Files?  Or would AWS::Files#all.each subvert the paging that AWS::Files#each does?\r\n\r\n\r\n(Trolling through the code, I notice that AWS::Files#each seems to call #all internally, but Local::Files#each inherits from Array without calling #all, so that seems inconsistent.    OTOH since AWS::Files#each calls #all that seems to imply that it'd be harmless to do #all.each but I could imagine there's a penalty for doing essentially #all.all ...?)\r\n\r\nThanks.\r\n\r\n"
859,'','reserved instance hourly cost was empty\nHi,\r\n\r\nAWS has changed the result set for describe reserved instances call. UsagePrice is always 0 while amount gives the correct hourly cost of a reserved instances.\r\n\r\nbest wishes,\r\nOz'
858,'','Add new HP providers for Object Storage, Compute and CDN services.\nWes,\r\n  Please review and let me know if I missed anything. Thanks for your help in this matter.\r\n\r\nThanks,\r\nRupak Ganguly\r\nHP Cloud Services\r\nrupak.ganguly@hp.com\r\n'
857,'','[aws|storage] Make get_object_http_url use correct S3 host in returned URL\nThis fixes a previous typo in get_object_http_url to correctly use the\r\nconfigured AWS S3 host name in the URL and adds a test for the default case\r\nwhere the bucket name can be used as a DNS CNAME.\r\n    \r\nFor example, a bucket company-testbucket would translate into:\r\n    \r\n  http://company-testbucket./company-testbucket./fog_object?AWSAccessKeyId=...\r\n    \r\nWhich is now fixed into:\r\n    \r\n  http://company-testbucket.s3.amazonaws.com/fog_object?AWSAccessKeyId=...\r\n\r\nPlease let me know how to improve this patch if necessary, since this is my first contribution to fog. For example, I can also add more shindo tests for the get_object_http_url method since they are nonexistent at this moment.\r\n\r\nThis pull request, however fixes the case above.'
856,'','VPC and Policy Changes\nLists all of the cipher policies that are valid, defaulting to the ELB defaults.  Also includes changes for VPC support, but the lack of VPC support in fog makes testing difficult.  This could use some manual testing and automated tests, but it is working for me and supports all the current features of the ELB API.'
855,'','[oVirt] volume size in GB accessor\n'
854,'',"fog.io down\nDoes anyone know why the fog.io website is down? I can't access it."
853,'','describe_instances parser always returns false\nHi,\r\n\r\nBased on AWS documentation monitoring-state is either disabled or enabled. Parser was checking if it is true or false.\r\n              <monitoring>\r\n                <state>enabled</state>\r\n              </monitoring>\r\n\r\nbest wishes,\r\nOz '
852,'','us-west-2 default ami\nCloses fog/fog#851'
851,'',"Add a default ubuntu image to us-west-2\n```ruby\r\n\r\nconnection = Fog::Compute.new({\r\n   :provider => 'AWS', \r\n   :region => 'us-west-2' # Oregon (same cheap price as us-east-1 Virginia, but better coffee)\r\n })\r\n\r\nserver = connection.servers.bootstrap({\r\n  :public_key_path => '~/.ssh/id_rsa.pub',\r\n  :private_key_path => '~/.ssh/id_rsa',\r\n  :flavor_id => 'm1.large', # 64 bit, normal large\r\n  :username => 'ubuntu'\r\n})\r\n\r\nFog::Compute::AWS::Error: MissingParameter => The request must contain the parameter ImageId\r\n```\r\n\r\nCan someone please add a default AMI to Oregon region? https://github.com/fog/fog/blob/master/lib/fog/aws/models/compute/server.rb#L54-64"
850,'','add cc2.8xlarge AWS flavor\n'
849,'','Support for Compute Pools in Ecloud\nAdded the models and requests necessary to grab a list of available compute pools in a vDC.  Also added support to Servers.create to be able to specify the compute pool at server creation.'
848,'',"OpenStack Update\nGood Day,\r\n\r\nWe have a quite a hefty amount of changes on Fog's OpenStack interface in: https://github.com/MorphGlobal/fog\r\n\r\nWe'd like to have this pulled into Fog, but since it's is pretty big I would like to know what you guys think.\r\n\r\nWe did quite a number of tests but it doesn't cover all the changes we made.\r\n\r\nIn any case if you have any questions, I'll gladly answer them.\r\n\r\nThanks!\r\nNelvin"
847,'','Connection Sharing with Fog and Carrierwave\ni can\'t seem to find the "best practices" to sharing a fog connection with Carrierwave as I need to pull files from S3 besides just the carrier wave images, but would be connecting to the same bucket.  I hope I didn\'t miss this anywhere cause I don\'t want to waste your time.  Thanks!'
846,'','Fix for Issue #845 - Parsing error for EC instances with networkInterfaceSet tag\nFixes a problem parsing the AWS describe_instances request when the response includes content within a networkInterfaceSet element.'
845,'benton','Parsing error for EC instances with networkInterfaceSet tag\nHello, all.\r\n\r\nI am working on a problem I\'m having with Fog that manifests as "empty" (that is, with no "instanceID" identity field) instances. If the following code produces anything other than an empty Array, then the bug is present:\r\n\r\n    no_ids = Fog::Compute[:aws].servers.select {|s| s.id == nil}\r\n\r\nI can\'t tell if it\'s related to any of the other open issues, but it seems not. But here\'s a running history, and a fix.\r\n\r\n\r\nFog EC2 Server Collection Parsing Error\r\n===\r\n\r\nFirst, I noticed that some of our EC2 server instances were returning with no IDs.\r\nThe following code should always produce an empty array, but for fog >= 1.2, I kept getting entries in the following Array:\r\n\r\n    no_ids = Fog::Compute[:aws].servers.select {|s| s.id == nil}\r\n\r\n\r\nUpon further investigation, found that the ID-less instances do not actually correspond to running instances. Here I compare the output of the EC2 command-line utility against Fog:\r\n\r\n    â­â@Diderot.local ~/projects/fog â¹ruby-1.9.3âº â¹masterâº\r\n    â°â ec2-describe-instances | grep INSTANCE | wc -l\r\n         115\r\n    â­â@Diderot.local ~/projects/fog â¹ruby-1.9.3âº â¹masterâº\r\n    â°â bundle exec fog\r\n     Welcome to fog interactive!\r\n     :default provides AWS, VirtualBox and Vmfusion\r\n    >> Fog::Compute[:aws].servers.count\r\n    117\r\n\r\nHmmmm, something\'s wrong with the Fog Collection `Compute[:aws].servers`. Here\'s the Fog code that parses the response body from Excon (from `lib/fog/aws/models/compute/servers.rb`):\r\n\r\n    data = connection.describe_instances(filters).body\r\n    load(\r\n      data[\'reservationSet\'].map do |reservation|\r\n        reservation[\'instancesSet\'].map do |instance|\r\n          instance.merge(:groups => reservation[\'groupSet\'])\r\n        end\r\n      end.flatten\r\n    )\r\n\r\nSo, we\'ve got 2 XML structures that wrap our instances: `reservationSet` and `instancesSet`. Each gets a call to `map`, so as long as the outer call returns the correct count, all is well. Let\'s try this code in IRB to confirm that we\'ve located the problem...\r\n\r\n    â­â@Diderot.local ~/projects/fog â¹ruby-1.9.3âº â¹masterâº\r\n    â°â bundle exec ./bin/fog\r\n      Welcome to fog interactive!\r\n      :default provides AWS, VirtualBox and Vmfusion\r\n    >> (Fog::Compute[:aws].describe_instances.body[\'reservationSet\'].map {|r| r[\'instancesSet\']}).flatten.count\r\n    117\r\n\r\nThere\'s the incorrect count. What if we eliminate parsing of the inner XML and just count `reservationSet`?\r\n\r\n    >> Fog::Compute[:aws].describe_instances.body[\'reservationSet\'].flatten.count\r\n    115\r\n\r\nThere\'s our correct number.\r\nAt least one of these `reservationSet`s must have more than one `instancesSet`...\r\n\r\n    >> fat_sets = Fog::Compute[:aws].describe_instances.body[\'reservationSet\'].select {|r| r[\'instancesSet\'].count > 1}\r\n      [...]\r\n    >> fat_sets.count\r\n    2\r\n    >> fat_sets.map {|set| set[\'instancesSet\'].count}\r\n    [2, 2]\r\n    >> fat_sets.first[\'instancesSet\'][0]\r\n    {"blockDeviceMapping"=>[{"deviceName"=>"/dev/sda1", "volumeId"=>"vol-1b8c2672", "status"=>"attached", "attachTime"=>2011-03-24 19:38:20 UTC, "deleteOnTermination"=>true}], "instanceState"=>{"code"=>80, "name"=>"stopped"}, "monitoring"=>{"state"=>false}, "placement"=>{"availabilityZone"=>"us-east-1c", "groupName"=>nil, "tenancy"=>"default"}, "productCodes"=>[], "stateReason"=>{"code"=>0}, "tagSet"=>{}, "instanceId"=>"i-0745236c", "imageId"=>"ami-f11ff098", "privateDnsName"=>nil, "dnsName"=>nil, "reason"=>"User initiated (2011-03-24 19:37:49 GMT)", "keyName"=>"CorpIT_NAS", "amiLaunchIndex"=>0, "instanceType"=>"m1.small", "launchTime"=>2011-03-21 19:58:07 UTC, "platform"=>"windows", "subnetId"=>"subnet-b78544de", "vpcId"=>"vpc-b28544db", "privateIpAddress"=>"10.225.50.8", "architecture"=>"i386", "rootDeviceType"=>"ebs", "clientToken"=>nil}\r\n    >> fat_sets.first[\'instancesSet\'][1]\r\n    {"blockDeviceMapping"=>[], "instanceState"=>{}, "monitoring"=>{}, "placement"=>{}, "productCodes"=>[], "stateReason"=>{}, "tagSet"=>{}}\r\n\r\nThere it is -- an empty item in `instancesSet`. There\'s one in both the `fat_sets`.\r\n\r\n\r\nThe Fix\r\n===\r\n\r\nOK, so our extra instances are being caused by an empty `instancesSet`. \r\nWhat if we just filter those out?\r\n\r\n    >> (Fog::Compute[:aws].describe_instances.body[\'reservationSet\'].map do |r| \r\n    ?>   r[\'instancesSet\'].select {|i| i[\'instanceId\'] != nil}\r\n    >> end).flatten.count\r\n    117\r\n\r\nWorks just fine. The code fix goes into line 59 of the relevant parser,\r\n`lib/fog/aws/parsers/compute/describe_instances.rb`:\r\n\r\n    if @instance[\'instanceId\'] != nil\r\n      @reservation[\'instancesSet\'] << @instance\r\n    end\r\n\r\n(The existing code is just the middle line, without the test for nil identity.)\r\n\r\n---\r\n\r\nI will try to answer the following questions before submitting a pull request:\r\n\r\n  * Why is this happening in the first place? \r\n    Does the XML response from Amazon have some empty tags? \r\n    Or is there some other bug in the parser that I\'m missing?\r\n  * Under what conditions does this problem manifest?\r\n  * How can I write a test for it?\r\n\r\nDoes anyone know how I  can easily look at the whole response body (pre-parsing) when parsing with SAX?\r\n\r\n- benton\r\n\r\n'
844,'','[oVirt] Added volumes to vm and template\nAdded vm and template volumes list, get, add and destroy.'
843,'','Libvirt minor updates\n* expose node hostname\r\n* added display attributes and allowed to change display of a running server\r\n* fixed incorrect device names for multiple storage volumes\r\n* improved libvirt on debian'
842,'','Add Capabilities to describe_stacks parser\nFix for stacks that have capabilities. Without this the parser misinterprets an aws response with capabilities set as the capabilities are contained in <member>'
841,'','Fix SpotRequest loading and Private/Public key setting.\nThis code reloads when checking for a started spot instance (fixing one bug) and also adds private/public key options into spot_requests, then set those on the server when loaded, fixing another bug.'
840,'','Booting EC2 Spot instance failing\nI\'m trying to bootstrap an ec2 spot instance, if I do the following it works (I\'m using a real ami id, just removing it below):\r\n\r\nserver = connection.servers.bootstrap(:private_key_path => \'~/.ssh/id_rsa\', :public_key_path => \'~/.ssh/id_rsa.pub\', :username => \'ubuntu\', :image_id => "---myami---", :flavor_id => "t1.micro")\r\n\r\nBut if I change it to:\r\n\r\nserver = connection.spot_requests.bootstrap(:price => "1", :private_key_path => \'~/.ssh/id_rsa\', :public_key_path => \'~/.ssh/id_rsa.pub\', :username => \'ubuntu\', :image_id => "---myami---", :flavor_id => "t1.micro")\r\n\r\nI get the following error:\r\n\r\n/Users/ryanstout/.rvm/gems/ruby-1.9.2-p290@dating/bundler/gems/fog-341d012f6a07/lib/fog/aws/models/compute/spot_requests.rb:76:in `bootstrap\': undefined method `wait_for\' for nil:NilClass (NoMethodError)\r\n\r\nAbove this in the stack trace is the line where it calls bootstrap.  This error happens a little while after the server actually boots.\r\n\r\nAny help here would be appreciated.  Also great work on Fog.'
839,'','[rackspace|lb] Support setting algorithm when creating a load balancer\nPretty straightforward.  Let me know if there is any feedback before I merge.\r\n\r\nAll tests pass.'
838,'','Libvirt mock\nAdded mock to Libvirt.\r\nNow all test are passing both in real and in mock. '
837,'','[compute|aws] Apply tags to volume at creation\nSame approach as used for server tags for issue #366\r\n\r\n---\r\n\r\nI need a bit of guidance to add tests for this.'
836,'',"Creating an S3 signed URL without downloading the object\nI'm using `fog` to generate signed URLs for S3, like this:\r\n\r\n````ruby\r\ns3.directories.get(BUCKET).files.get(object).url(expiry)\r\n````\r\n\r\nThis causes `fog` to download the entire object, which I don't need to do.\r\n\r\nIs there any way to create the signed URL without downloading the object?"
835,'','Adjusts regex to fix issues with S3 paths that include periods\nSee [Issue #834 for discussion](https://github.com/fog/fog/issues/834#issuecomment-4894086).'
834,'','Upgrading to Fog 1.1.2 -> 1.3 breaks S3 bucket URLs\nWe were previously on Fog 1.1.2. We upgraded to Fog 1.3. This broke a number of integration tests which check that the right S3 URL is being returned.\r\n\r\nIn my app, I have a test that checks that a specific URL is returned when a file is finished being uploaded:\r\n\r\n```\r\n  1) UserExport.perform sends out an email to the requester\r\n     Failure/Error: described_class.perform user.id\r\n       <UserMailer (class)> received :export_done with unexpected arguments\r\n         expected: (482, /^https:\\/\\/s3\\.amazonaws\\.com\\/exports\\.test\\.example\\.com\\/users-1333422499\\.csv\\?AWSAccessKeyId=...&Signature=foo&Expires=\\d{10}$/)\r\n              got: (482, "https://exports.test.example.com.s3.amazonaws.com/users-1333422499.csv?AWSAccessKeyId=...&Signature=foo&Expires=1334027299")\r\n     # ./app/jobs/export_job.rb:15:in `perform\'\r\n     # ./spec/jobs/user_export_spec.rb:21:in `block (3 levels) in <top (required)>\'\r\n```\r\n\r\nEssentially, the test expects a URL like `https://s3.amazonaws.com/<bucket>/...`, but Fog is returning `https://<bucket>.s3.amazonaws.com/...`.\r\n\r\nNo code changed in between the Fog dependency update except our Gemfile. What caused this change in Fog, and how do I return to the more desirable original behavior?'
833,'',"All directories.create on us-east-1\nPull request for comment...\r\n\r\nw/o this you can't do directories.create(key: <name>) in us-east-1.\r\n"
832,'','Rackspace Monitoring API suppot\nHi,\r\n\r\nis anyone working on this beta feature from the people in Rackspace?\r\n\r\nThanks'
831,'','XenServer provider\n[xenserver|compute] Citrix XenServer Compute Service Provider, initial release\r\n\r\n\r\n\r\n'
830,'','the old parser was not working properly\nCloses #829'
829,'',"describe_instance_status parser broken\nAt the very least there aren't ever any 'events' in an instanceStatusSet."
828,'','Status next token\nCloses #800'
827,'','[aws|dns] Reimplemented #get\n#get was not working correctly.  It was not using the :identity\r\nattribute of the record as its argument and was calling #get_change which\r\ndoes not return a record.\r\n\r\n#get now takes a record name as its first argument and returns the\r\nfirst matching argument or nil.  It also take two optional arguments,\r\ntype and identifier, which allow one to select a specific record as\r\nneeded, without iterating through multiple records.\r\n\r\nSubmitted as a pull request to review before committing, as this changes behavior from the prior version.\r\n '
826,'',"Fog:DNS:AWS has no method to ask for the next 100 records\nlib/fog/aws/requests/dns/list_resource_record_sets.rb\r\n\r\nThe above doesn't appear to use the 'IsTruncated'<true> response to request the next set of records. \r\n\r\nI think for the default case when max_items isn't set it should keep cycling through by 100 records. If max_items isn't the default then of course stop at that number of records. \r\n\r\n"
825,'','CloudStack template calls\nAdded all of the remaining API calls for CloudStack templates.'
824,'','"Broken pipe" error from S3\nThere are numerous reports of this error, but there doesn\'t seem to be any agreement about what causes it. I see it when uploading largish (~20M) files to eu-west-1. I see the error about half the times I do the upload. I have never seen it for much smaller files.\r\n\r\nI think I can rule out three frequently reported causes: wrong endpoint (I\'m setting the region explicitly and creating the bucket immediately before use); files too big (this problem is reported only for multi-gigabyte files); wrong bucket name (I\'m creating the bucket and then immediately using the object returned.\r\n\r\nHere\'s the code I\'m using.\r\n\r\n````ruby\r\nconnection = Fog::Storage.new(:provider => :aws,\r\n                              :region => \'eu-west-1\',\r\n                              :aws_access_key_id => \'<redacted>\',\r\n                              :aws_secret_access_key => \'<redacted>\')\r\ndirectory = connection.directories.create(:key => \'<redacted>\')\r\n\r\nDir.glob(\'out/*\').each do |file|\r\n  File.open(file) { |f| directory.files.create(:key => File.basename(file), :body => f) }\r\nend\r\n````\r\n\r\nI wonder, looking at that now, whether it\'s possible that the region is not getting propagated correctly to the directory object. But I assume that it just holds a copy of the original connection object with the region set.\r\n\r\n(It\'s worth pointing out that the version of `fog` I\'m using includes #818, which was necessary to get the bucket creation working.)\r\n\r\nI\'ve put in logging of the URL, request params and response to see exactly what\'s going on.\r\n\r\n````\r\nhttps://s3-eu-west-1.amazonaws.com:443/\r\n\r\n{:method=>"PUT", \r\n :headers=>{"Date"=>"Thu, 29 Mar 2012 16:46:13 +0000", "Authorization"=>"<redacted>"}, \r\n :idempotent=>true, \r\n :body=>"  <CreateBucketConfiguration>\\n    <LocationConstraint>eu-west-1</LocationConstraint>\\n  </CreateBucketConfiguration>\\n", \r\n :host=>"<redacted>.s3-eu-west-1.amazonaws.com", \r\n :expects=>200}\r\n\r\n#<Excon::Response:0x7f1009e2e558 \r\n   @status=200, \r\n   @headers={"Date"=>"Thu, 29 Mar 2012 16:46:15 GMT", \r\n             "Content-Length"=>"0", \r\n              "Location"=>"http://<redacted>.s3.amazonaws.com/", \r\n              "x-amz-request-id"=>"<redacted>", \r\n              "Server"=>"AmazonS3", \r\n              "x-amz-id-2"=>"<redacted>"}, \r\n   @body="">\r\n\r\n{:method=>"PUT", \r\n :headers=>{"Date"=>"Thu, 29 Mar 2012 16:46:15 +0000", "Content-Type"=>"<redacted>", "Authorization"=>"<redacted>", "Content-Length"=>25958650}, \r\n :idempotent=>true, \r\n :body=>#<File:<redacted>>, \r\n :path=>"<redacted>", \r\n :host=>"<redacted>.s3-eu-west-1.amazonaws.com", \r\n :expects=>200}\r\n````\r\n\r\nAny thoughts what might be causing this, or ideas of things I could try?\r\n\r\nThanks\r\n-Ben\r\n'
823,'','[libvirt] refactored libvirt entire code\n* moved to using requests\r\n* added vm nic/nics\r\n* kept compatability with the existing interfaces\r\n* moved util classes into util subdir\r\n* added support for vm boot order\r\n* added tests'
822,'','[vpc-fixes] AWS security group model + VPC\n- Drop AWS security group name when id is provided\r\n- Security group id must be used when dealing w/ VPC\r\n- "authorize_port_range" (AuthorizeSecurityGroupIngress) must use IpPermissions in order to work w/ VPC\r\n- Adjusted security group tests, as group id can be used instead of group name\r\n- Added a few tests for nil group name and nil group id\r\n\r\nLooking for feedback, as deleting a key in a method intend for parsing is a bit odd.\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-AuthorizeSecurityGroupIngress.html\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-RevokeSecurityGroupIngress.html'
821,'',"AWS.collections => :beanstalk unrecognized service\nI'm new to fog.  I installed 1.3.0 and just upgraded to 1.3.1, and run into the following error.\r\nNot blocking me but it's in the 'first time user' path, following the online docs for fog.\r\n\r\nRunning AWS.collections results in an ArgumentError (:beanstalk unrecognized service).\r\n\r\nneilmachome:~ neils$ fog\r\n  Welcome to fog interactive!\r\n  :default provides AWS\r\n>> AWS.collections\r\n[WARNING] AWS[:cdn] is not recommended, use CDN[:aws] for portability\r\n[WARNING] AWS[:compute] is not recommended, use Compute[:aws] for portability\r\nArgumentError: Unrecognized service: :beanstalk\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin/aws.rb:98:in `[]'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin/aws.rb:101:in `call'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin/aws.rb:101:in `default'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin/aws.rb:101:in `[]'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin/aws.rb:101:in `[]'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin.rb:47:in `collections'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin.rb:47:in `map'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/lib/fog/bin.rb:47:in `collections'\r\n\tfrom (irb):1\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.3.1/bin/fog:40\r\n\tfrom /usr/bin/fog:19:in `load'\r\n\tfrom /usr/bin/fog:19\r\n>> \r\n\r\nEnvironment: Mac OSX 10.7.3\r\n$ uname -a\r\nDarwin neilmachome.nsds.local 11.3.0 Darwin Kernel Version 11.3.0: Thu Jan 12 18:47:41 PST 2012; root:xnu-1699.24.23~1/RELEASE_X86_64 x86_64\r\n\r\n$ ruby -v\r\nruby 1.8.7 (2010-01-10 patchlevel 249) [universal-darwin11.0]\r\n\r\n$gem list --local\r\nneilmachome:~ neils$ gem list --local\r\n\r\n*** LOCAL GEMS ***\r\n\r\naaronh-chronic (0.3.9)\r\nabstract (1.0.0)\r\nactionmailer (3.2.2, 3.0.3)\r\nactionpack (3.2.2, 3.0.3)\r\nactivemodel (3.2.2, 3.0.3)\r\nactiverecord (3.2.2, 3.0.3)\r\nactiveresource (3.2.2, 3.0.3)\r\nactivesupport (3.2.2, 3.0.3)\r\nandand (1.3.1)\r\narel (3.0.2, 2.0.7)\r\naws-s3 (0.6.2)\r\nbuilder (3.0.0, 2.1.2)\r\nbundler (1.0.22)\r\nbunny (0.7.4)\r\ncapistrano (2.5.19)\r\nchef (0.10.8)\r\nchildprocess (0.2.0)\r\ncoffee-script (2.2.0)\r\ncoffee-script-source (1.2.0)\r\ncronedit (0.3.0)\r\ndiff-lcs (1.1.2)\r\nerubis (2.7.0, 2.6.6)\r\nexcon (0.13.2, 0.12.0, 0.6.6)\r\nexecjs (1.3.0)\r\nfacter (1.6.0)\r\nffi (1.0.9)\r\nfog (1.3.1, 1.3.0, 0.8.2)\r\nforeigner (0.9.1)\r\nformatador (0.2.1)\r\nhighline (1.6.1)\r\nhike (1.2.1)\r\ni18n (0.6.0, 0.5.0)\r\nisolate (3.0.0)\r\njourney (1.0.3)\r\njson (1.6.1, 1.5.0)\r\njson_pure (1.5.3)\r\nknife-ec2 (0.5.10)\r\nlibxml-ruby (2.2.2)\r\nlinecache (0.43)\r\nmail (2.4.1, 2.2.14)\r\nmechanize (1.0.0)\r\nmime-types (1.17.2, 1.16)\r\nmixlib-authentication (1.1.4)\r\nmixlib-cli (1.2.0)\r\nmixlib-config (1.1.2)\r\nmixlib-log (1.3.0)\r\nmoneta (0.6.0)\r\nmulti_json (1.1.0)\r\nmysql (2.8.1)\r\nmysql2 (0.3.11)\r\nnet-scp (1.0.4)\r\nnet-sftp (2.0.5)\r\nnet-ssh (2.1.4, 2.1.0)\r\nnet-ssh-gateway (1.0.1)\r\nnet-ssh-multi (1.1, 1.0.1)\r\nnokogiri (1.5.2, 1.4.4)\r\nohai (0.6.4)\r\npolyglot (0.3.3, 0.3.1)\r\nrack (1.4.1, 1.2.1)\r\nrack-cache (1.1)\r\nrack-mount (0.6.13)\r\nrack-ssl (1.3.2)\r\nrack-test (0.6.1, 0.5.7)\r\nrails (3.2.2, 3.0.3)\r\nrailties (3.2.2, 3.0.3)\r\nrake (0.9.2.2, 0.8.7)\r\nrdoc (3.12)\r\nRedCloth (4.2.3)\r\nrest-client (1.6.3)\r\nrspec (2.6.0)\r\nrspec-core (2.6.4)\r\nrspec-expectations (2.6.0)\r\nrspec-mocks (2.6.0)\r\nruby-debug-base (0.10.5.jb2, 0.10.4)\r\nruby-debug-ide (0.4.15)\r\nruby-hmac (0.4.0)\r\nrubygems-update (1.4.2)\r\nrubyzip (0.9.4)\r\nselenium-webdriver (2.1.0)\r\nsprockets (2.1.2)\r\nsystemu (2.2.0)\r\nthor (0.14.6)\r\ntilt (1.3.3)\r\ntreetop (1.4.10, 1.4.9)\r\ntzinfo (0.3.31, 0.3.24)\r\nuuidtools (2.1.2)\r\nvalidatable (1.6.7)\r\nwhenever (0.6.2)\r\nxml-simple (1.1.1)\r\nyajl-ruby (0.8.2)\r\n"
820,'','Incorrect Host Set by #get_object_https_url\nIt seems that `Fog::Storage::AWS::GetObjectHttpsUrl#get_object_https_url` sets the incorrect value for `host`.\r\n\r\nIf you have a bucket on AWS that includes periods, and you want to access a file in that bucket using SSL, you need to call:\r\n\r\n    https://s3.amazonaws.com/my-bucket.example.com/file.pdf\r\n    \r\ninstead of this:\r\n\r\n    https://my-bucket.example.com.s3.amazonaws.com/file.pdf\r\n    \r\nIf you call the latter, you\'ll get a browser SSL warning (this won\'t happen if your bucket name is just one word--see [here][1] for more information). This is the URL form that `#get_object_https_url` returns, which is called by `Fog::Storage::AWS::File#url`.\r\n\r\nSo when I do this:\r\n\r\n    dir  = connection.directories.get("my-bucket.example.com")\r\n    file = dir.files.new(key: \'file.pdf\')\r\n    file.url\r\n\r\nI get this:\r\n\r\n    https://my-bucket.example.com.s3.amazonaws.com/file.pdf?<query-params>\r\n\r\nThis gives me a browser warning. To get around that, I\'m doing this:\r\n\r\n    connection.https_url({\r\n      headers: {},\r\n      method:  \'GET\',\r\n      path:    \'my-bucket.example.com\',\r\n      host:    \'s3.amazonaws.com\'\r\n    }, 0)\r\n\r\nWhich gives me this:\r\n\r\n    https://s3.amazonaws.com/my-bucket.example.com/file.pdf?<query-params>\r\n\r\nThe reason this seems to happen is because of the Regex matching in `Fog::Storage::AWS::GetObjectHttpsUrl#get_object_https_url`. Interestingly enough, there\'s a very similar (but different) Regex in `Fog::Storage::AWS::File#public_url` that would behave correctly, at least as far as this situation is concerned. The regular expressions in question:\r\n\r\n    get_object_https_url: => /^(?:[a-z]|\\d(?!\\d{0,2}(?:\\.\\d{1,3}){3}$))(?:[a-z0-9]|\\.(?![\\.\\-])|\\-(?![\\.])){1,61}[a-z0-9]$/\r\n    public_url:           => /^(?:[a-z]|\\d(?!\\d{0,2}(?:\\.\\d{1,3}){3}$))(?:[a-z0-9]|\\-(?![\\.])){1,61}[a-z0-9]$/\r\n\r\nI\'m sure there\'s a reason these regular expressions are different, I just can\'t work out what that reason is. Can someone explain?\r\n\r\n[1]: https://wincent.com/wiki/HTTPS_access_to_Amazon_S3_buckets'
819,'','Enhance Fog vSphere Adaptor \nHello Jeff.  Thanks a lot for your kind help :)  I rebased my pull request on latest fog-1.3.1. Please take a look!\r\n\r\nThese patches are created when we use Fog vSphere to talk to vSphere 5.0 API (with Ruby 1.8.7). Please see more details in the commit log and code changes.\r\n\r\nUnit test is not included. All are manually tested and it works fine.\r\n'
818,'',"Store the region for S3.\nThis is a fix for #654: can't create S3 buckets in regions other than the default. S3 complains that the location constraint doesn't match the specified region.\r\n\r\nI couldn't see any obvious way to test this (other than manually), so there is no test included.\r\n\r\nI don't think this fix will work in the case where the `:endpoint` option is provided. I suspect that you would need to parse the region out of the URL in that case. But this is progress, anyway.\r\n\r\n"
817,'','vsphere enchancements\n1. expose memory / cpu information\r\n2. allow to force shutdown when vmware tools are not installed\r\n3. add support to manipulate vnc display'
816,'','docs: fix link to EngineYard logo (broken in /storage, /compute, ...)\n'
815,'',"[aws|dns] Support for checking record sync status.\n\r\nAWS Route 53 takes some time to propagate zone record modifications to all DNS servers.  The status of the update can be determined via the get_change API call.  This commit adds support to check the sync status of a newly created or modified zone record on the record model directly.\r\n\r\nOne can now write code like:\r\n\r\n```ruby\r\nrecord = zone.records.create({ ... })\r\n\r\nrecord.wait_for { insync? }\r\n\r\n```\r\n\r\nReview requested as this is implemented via overriding the reload method to support fog's standard wait_for call.\r\n"
814,'','excon ~> 0.12.0 \nHello,\r\n\r\nI have failed deps in my app because Fog is tried to excon ~> 0.12.0  and a few of my gems in my app require excon ~> 0.13.0.'
813,'','IBM SmartCloud Vlan class\nMinor enhancement to the IBM SmartCloud implementation to add support for a Vlan class'
812,'',"Rackspace CloudDB Support\nRackspace has introduced a CloudDB service in a private beta, I just got access today. Has anyone worked on building support for this? I'm going to start on it today, but I was curious to see if anyone had something up already that I could take a look at or help out with.\r\n\r\nCheck out [my fork](https://github.com/cwoodcox/fog/tree/rackspace-clouddb) later today for progress. Maybe."
811,'',"Ibm enhancements\nA few things that did not make in into the initial ibmsmartcloud merge, including tests for the Image model. Not merging immediately because I'm sure I'll think of something else before the day is out :-)"
810,'','Added support for Elastic Network Interfaces\nThe code supports all the documented network interface API calls.\r\nMockups and unit tests are included.\r\n\r\nI have tried to run all unit tests (in mocking mode) and I do get some errors, but I do not think they are related to this patch.'
809,'','[ibm] avoid using constants (Rails loads files multiple times, issue #807)\n'
808,'',"Enhance Fog vSphere Adaptor \nHello Fog vSphere Adaptor maintainer,  I'm from VMware and would like to contribute some patch to Fog. These patch is created when we use Fog vSphere to talk to vSphere 5.0 API.  The following enhancement are contained in this Pull Request:\r\n\r\n1) enable creating a VM in vSphere by cloning from a VM template or VM instance using Fog.servers.create\r\n2) add vsphere_templates_folder as a param for setting the full path of the folder containing VM templates to be cloned from\r\n3) rename param 'path' to more meaningful 'template_path'.\r\n4) allow wait until ip address is ready when creating a VM (use options[:wait] to specify whether wait or not)\r\n\r\nUnit test is not included. All are manually tested and it works fine.\r\n\r\nPlease take a look and give some comments. Thanks :)"
807,'',"Already Initialized Constant - In ibm.rb\nSo this happens in a rails 3.2 application.\r\n\r\n```\r\n/Users/kencollins/.rbenv/versions/ree/lib/ruby/gems/1.8/gems/fog-1.3.0/lib/fog/ibm.rb:13: warning: already initialized constant TIMEOUT\r\n/Users/kencollins/.rbenv/versions/ree/lib/ruby/gems/1.8/gems/fog-1.3.0/lib/fog/ibm.rb:17: warning: already initialized constant ENDPOINT\r\n```\r\n\r\nI believe it is due to the way you require fog by using a mixed method of requires. Rails will hook into require and base weather it has loaded a file or not based on that as a key. So I am assuming that the initial `require 'fog/ibm'` in `providers.rb` will do the initial load. Then as things like `fog/ibm/compute.rb` and `fog/ibm/storage.rb` are loaded, the require at the top looks like this.\r\n\r\n```\r\nrequire File.expand_path(File.join(File.dirname(__FILE__), '..', 'ibm'))\r\n```\r\n\r\nI am sure that changing this to a simple `require 'fog/ibm'` will fix the issue. Thoughts? Would you like a pull request?\r\n"
806,'',"Fog::Server#groups is just a list of nils\nWhen I call #groups, I get a list of nils, ie:\r\n\r\neg.\r\n\r\nI have 2 groups on a node: default, web server\r\n\r\nWhen I retrieve that server via connection.servers, the #groups for the node is [nil, nil]\r\n\r\nSame goes for any number of groups. It'll always be a list of nils when I retrieve the servers.\r\n\r\n"
805,'','Allow custom headers in Storage#put_object_url\nIt would be very nice to allow custom headers when generating put URLs. In particular, this would allow supplying a `Content-Type` which is part of the signature for AWS S3.'
804,'','wrangled security tests into working\nThis fixes the security group tests which were not working in non-mocking mode, and brings the mock returns inline with the non-mocking returns.  Also removed a line of debugging from the subnet functionality.'
803,'','simpledb broken for us-east-1 region (1.2.0)\nWhen creating a connection like:\r\n\r\nFog::AWS::SimpleDB.new(:aws_access_key_id => @aws_access_key, :aws_secret_access_key => @aws_secret_key)\r\n\r\nIt sets the host value to "sdb.us-east-1.amazonaws.com", which does not resolve.  The host value should be "sdb.amazonaws.com" if region is us-east-1.  This was working fine in the 1.1.2 release and is broken in 1.2.0.\r\n\r\n'
802,'','in `tests\': wrong number of arguments (2 for 1) (ArgumentError)\nI am fresh to fog and just installed its related gems. Trying to shindo "/tests/vsphere" but got below attached error. Please suggest and help point out  where I did wrong or something mist for me to do with shindo or fog\r\n\r\nC:/Documents and Settings/Administrator/fog/tests/vsphere/compute_tests.rb:1:in\r\n`tests\': wrong number of arguments (2 for 1) (ArgumentError)\r\n        from C:/Ruby187/lib/ruby/gems/1.8/gems/shindo-0.0.2/bin/shindo:27:in `jo\r\nin\'\r\n        from C:/Ruby187/lib/ruby/gems/1.8/gems/shindo-0.0.2/bin/shindo:27:in `ru\r\nn_in_thread\'\r\n        from C:/Ruby187/lib/ruby/gems/1.8/gems/shindo-0.0.2/bin/shindo:34\r\n        from C:/Ruby187/bin/shindo:19:in `load\'\r\n        from C:/Ruby187/bin/shindo:19\r\n\r\nI also write a ruby test and can successfully build connection with my vcserver by username/pass/hashkey'
801,'','Make the security group object work with VPC groups\nThis patch fixes a couple of issues when managing VPC security groups in AWS.\r\n* CreateSecurityGroup now includes the group id in the reply, this\r\n  patch makes the model store this\r\n* The patch also changes the delete call to use the group id if\r\n  present (since you must use the id when deleting VPC groups)'
800,'',"describe_instance_status does not support nextToken\nMostly filing this for myself unless someone else get's to it first."
799,'','Excon 0.10 dep downgrade breaks rackspace storage file uploads?\nI noticed this while using master from today. This code no longer works:\r\n\r\n    connection = Fog::Storage.new({\r\n        :provider                => \'Rackspace\',\r\n        :rackspace_auth_url      => "http://my-swift-server/foo/bar",\r\n        :rackspace_username      => \'admin:admin\',\r\n        :rackspace_api_key       => \'ADMIN\'\r\n\r\n    })\r\n    #Create a test bucket\r\n    dir = connection.directories.create :key => "test-bucket2"\r\n\r\n    print "Uploading #{FSIZE}MB file..."\r\n    dir.files.create( :key => temp_file,\r\n                      :body => File.open(temp_file))\r\n\r\nBacktrace:\r\n\r\n    Uploading 1MB file.../home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/excon-0.10.0/lib/excon/connection.rb:211:in `request_kernel\': undefined method `empty?\' for #<File:/home/rubiojr/swift-ha-test-file> (Excon::Errors::SocketError)\r\n            from /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/excon-0.10.0/lib/excon/connection.rb:92:in `request\'\r\n            from /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/core/connection.rb:20:in `request\'\r\n            from /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/rackspace/storage.rb:107:in `request\'\r\n            from /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/rackspace/requests/storage/put_object.rb:23:in `put_object\'\r\n            from /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/rackspace/models/storage/file.rb:66:in `save\'\r\n            from /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/core/collection.rb:50:in `create\'\r\n            from swift-ha-test:39:in `block in <main>\'\r\n            from swift-ha-test:36:in `loop\'\r\n            from swift-ha-test:36:in `<main>\'\r\n\r\n\r\nChanging the Excon dependency to use 0.11 works as expected.'
798,'','AWS Beanstalk support for fog\nThis is a re-submitted pull request that adds support for AWS ElasticBeanstalk to fog.\r\n\r\nThe following models/collections are supported:\r\n\r\n* applications\r\n* versions (Application Versions)\r\n* environments\r\n* templates (Configuration Templates)\r\n* events\r\n\r\nUnit tests have been provided for the all models/collections.\r\n\r\nDesign follows the other AWS services in fog, with the exception of the parsers which use a common base class and declarative tag definition per parser to simplify the code.\r\n\r\nQuestions/Comments?\r\n'
797,'','Someone check my thinking about security group tests\nI have a feeling that tests like these\r\n\r\n    tests("#describe_security_groups(\'group-name\' => \'fog_security_group\')").returns([]) do\r\n      array_differences(expected_permissions, Fog::Compute[:aws].describe_security_groups(\'group-name\' => \'fog_security_group\').body[\'securityGroupInfo\'].first[\'ipPermissions\'])\r\n    end\r\n\r\nin  tests/aws/requests/compute/security_group_tests.rb\r\n\r\nshould be wrapped in an if Fog.mocking\r\nas when I run them in non-mocked mode \r\n      #describe_security_groups(\'group-name\' => \'fog_security_group\') - returns []\r\n        expected => []\r\n        returned => [{"groups"=>[{"userId"=>"... etc\r\n\r\nI think generally these tests would be done with .formats() instead of returns.\r\n\r\nif that is the case I\'ll change the test around.'
796,'',"DescribeVolumeStatus\nI know I could commit this...\r\n\r\nbut the thing that worries me is the bump to the Amazon Compute API version to '2012-03-01', so hence a pull request for now. "
795,'','Vpc security group\nThe test code now creates a vpc before trying to create a security group in it.'
794,'','Added Elastic Beanstalk support to fog\nThis is initial support for AWS Elastic Beanstalk for fog. Currently includes implementations for all API operations and models/collections for applications, environments, and versions.\r\n\r\nImplementation follows pattern of other AWS services with the exception of parsers which are implemented using a base parser class with a declarative-style tag declaration per parser class.  Note, this technique could be useful in other AWS services as it simplifies the code significantly.\r\n\r\nStill needs some follow-on work to build out more functional models/collections as well as unit tests. \r\n'
793,'',"undefined method `empty?' for #<File:0x007fd1e74e3958>\nI'm using Rails, asset_sync which in turn does use Fog, which in turn installed Excon 0.10.0\r\n\r\nCurrent Gemfile:\r\n\r\n```ruby\r\ngem 'asset_sync', '>= 0.2.12'\r\ngem 'fog', :git => 'git://github.com/fog/fog.git'\r\ngem 'excon', '>= 0.9.6'\r\n```\r\n\r\nYesterday I `bundle update` and excon 0.10.0 was installed (f39baa6120270a2e9655748a06ea23c7d8c3a8f1), I get an exception during assets precompile:\r\n\r\n```\r\n\r\nrake aborted!\r\nundefined method `empty?' for #<File:0x007fd1e74e3958>\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/excon-0.10.0/lib/excon/connection.rb:211:in `request_kernel'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/excon-0.10.0/lib/excon/connection.rb:92:in `request'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bundler/gems/fog-0fbd9a3a3330/lib/fog/core/connection.rb:20:in `request'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bundler/gems/fog-0fbd9a3a3330/lib/fog/aws/storage.rb:359:in `request'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bundler/gems/fog-0fbd9a3a3330/lib/fog/aws/requests/storage/put_object.rb:43:in `put_object'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bundler/gems/fog-0fbd9a3a3330/lib/fog/aws/models/storage/file.rb:133:in `save'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bundler/gems/fog-0fbd9a3a3330/lib/fog/core/collection.rb:50:in `create'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/asset_sync/storage.rb:121:in `upload_file'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/asset_sync/storage.rb:133:in `block in upload_files'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/asset_sync/storage.rb:131:in `each'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/asset_sync/storage.rb:131:in `upload_files'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/asset_sync/storage.rb:140:in `sync'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/asset_sync/asset_sync.rb:29:in `sync'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/asset_sync-0.3.1/lib/tasks/asset_sync.rake:3:in `block in <top (required)>'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:205:in `call'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:205:in `block in execute'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:200:in `each'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:200:in `execute'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:158:in `block in invoke_with_call_chain'\r\n/Users/kain/.rvm/rubies/ruby-1.9.3-p125/lib/ruby/1.9.1/monitor.rb:211:in `mon_synchronize'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:151:in `invoke_with_call_chain'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/task.rb:144:in `invoke'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:116:in `invoke_task'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:94:in `block (2 levels) in top_level'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:94:in `each'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:94:in `block in top_level'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:133:in `standard_exception_handling'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:88:in `top_level'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:66:in `block in run'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:133:in `standard_exception_handling'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/lib/rake/application.rb:63:in `run'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/gems/rake-0.9.2.2/bin/rake:33:in `<top (required)>'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bin/rake:19:in `load'\r\n/Users/kain/.rvm/gems/ruby-1.9.3-p125/bin/rake:19:in `<main>'\r\nTasks: TOP => assets:precompile:nondigest\r\n```\r\n\r\nAny idea?"
792,'','Fix sync_clock method, only rescue Excon::Errors::HTTPStatusError that a...\n...re known to have a #response method, let all other exceptions bubble up\r\n\r\nDiscussion in #789'
791,'','Check if exception has a #response method before calling it, otherwise call #message\nAs discussed in #789'
790,'','Updated excon to version ~>0.10.0. Closes #781\n'
789,'',"undefined method `response' for #<Excon::Errors::SocketError:0x0000001044da08>\nI'm getting this error when trying to use the backup gem. I updated the gem to a new version, so it may very well be that my configuration is incorrect and causes this error in the first place, but it seems to be a bug in fog because it tries to call `response` on a `Excon::Errors::SocketError` which doesn't have a `response` method.\r\nFog seems to expect a `HTTPStatusError` or a descendent thereof, which has a `response` method.\r\nThe errors are defined in https://github.com/geemus/excon/blob/master/lib/excon/errors.rb\r\nA simple `respond_to?(:response)` call should fix this...?\r\n\r\n\r\nBacktrace:\r\n```\r\n.../gems/fog-1.1.2/lib/fog/aws/requests/storage/sync_clock.rb:12:in `rescue in sync_clock'\r\n.../gems/fog-1.1.2/lib/fog/aws/requests/storage/sync_clock.rb:9:in `sync_clock'\r\n.../gems/backup-3.0.23/lib/backup/storage/s3.rb:61:in `transfer!'\r\n.../gems/backup-3.0.23/lib/backup/storage/base.rb:33:in `perform!'\r\n.../gems/backup-3.0.23/lib/backup/model.rb:245:in `each'\r\n.../gems/backup-3.0.23/lib/backup/model.rb:245:in `block in perform!'\r\n.../gems/backup-3.0.23/lib/backup/model.rb:243:in `each'\r\n.../gems/backup-3.0.23/lib/backup/model.rb:243:in `perform!'\r\n.../gems/backup-3.0.23/lib/backup/cli/utility.rb:74:in `block in perform'\r\n.../gems/backup-3.0.23/lib/backup/cli/utility.rb:65:in `each'\r\n.../gems/backup-3.0.23/lib/backup/cli/utility.rb:65:in `perform'\r\n.../gems/thor-0.14.6/lib/thor/task.rb:22:in `run'\r\n.../gems/thor-0.14.6/lib/thor/invocation.rb:118:in `invoke_task'\r\n.../gems/thor-0.14.6/lib/thor.rb:263:in `dispatch'\r\n.../gems/thor-0.14.6/lib/thor/base.rb:389:in `start'\r\n.../gems/backup-3.0.23/bin/backup:11:in `<top (required)>'\r\n.../bin/backup:19:in `load'\r\n.../bin/backup:19:in `<main>'\r\n```\r\n"
788,'',"Added PrivateIpAddress to the list of valid parameters for instance creation\nSimple one-line addition, allows specifying the IP when creating an instance within a VPC.\r\n\r\nPlease let me know if there's additional work that needs to be done to get this accepted -- not exactly sure how/were to test this one, but it works when creating actual instances at least :)\r\n"
787,'','Handle multiple instances with spot request\nPreviously (current HEAD) you could instantiate many spot requests by using instance_count, but only the first was added to the SpotRequests collection and returned.\r\n\r\nThis pull request updates Fog::Compute::AWS::SpotRequest#save so that it initializes and adds all newly created spot requests to the Fog::Compute::AWS::SpotRequests collection.  If instance_count is 1 (which is the default) it returns the generated spot_request.  If instance_count is greater than 1 it will return an array of the newly created spot requests.  \r\n\r\n(Please note: this does not change the result of spot_requests.create because Fog::Collection#create automatically returns the object created when SpotRequest.new is called (not the result of SpotRequest#save).\r\n\r\nThis pull request also updates Fog::Compute::AWS::SpotRequests#bootstrap to allow it to bootstrap multiple servers at once if instance_count is more than one.  Fog::Compute::AWS::SpotRequests#bootstrap will then return an array of Fog::Compute::AWS::Server objects (when instance_count == 1) or it will return the first Fog::Compute::AWS::Server (when instance_count == 1).\r\n\r\nI do not see any tests specific to Fog::Compute::AWS::SpotRequests or Fog::Compute::AWS::SpotRequest, but I certainly can try to add some testing with a bit of direction.\r\n\r\nIn the default case of instance_count == 1 both Fog::Compute::AWS::SpotRequests#bootstrap and Fog::Compute::AWS::SpotRequest#save return the same value as current HEAD.\r\n'
786,'',"Removed mutual exclusion between subnet and security group\nIn the AWS::Server class there were a few lines that made the assumption that security groups and subnets were somehow mutually exclusive. This is in fact not true and both can be used at once, and they cooperate quite nicely.\r\n\r\nA setup with both subnets and security groups is integral to our production configuration so I'm submitting a request to remove the restriction.\r\n\r\nThanks!\r\nrusty\r\n"
785,'','Made it possible to specify security group via ID as well as name\nThis patch makes it possible to specify GroupID in the options hash to the\r\naws computre requests operating on security groups. This is needed since\r\nwhen working with VPC you must use GroupID instead of name.\r\n'
784,'','[aws]Add in subnets for VPCs \nThis patch add subnets functionality to AWS VPCs'
783,'','support alias records in the route53 models\nthis adds support for creating Route53 Alias records into the record model.'
782,'','Fix cloudstack warning\nOn ruby 1.8.7 or REE, I get warnings like this whenever I require fog:\r\n\r\n    lib/fog/cloudstack.rb:11: warning: already initialized constant DIGEST\r\n\r\nThis patch fixes the warning by using a module variable instead of a constant. The mocked cloudstack tests pass.'
781,'',"Update Excon to 0.10.0\nBundler tried to force me on fog 0.7.2 because I had excon 0.10.0 in the Gemfile.\r\nApparently fog 0.7.2 didn't have properly locked down versioning for the excon dependency.\r\n\r\n    In Gemfile:\r\n      fog (~> 1.1.2) ruby depends on\r\n        excon (~> 0.9.0) ruby\r\n\r\n\r\nAny reason why we wouldn't want to update 0.10.0?"
780,'',"Fixing typo\nI've corrected `retreive` misspelling to `retrieve`."
779,'','[aws][auto_scaling] Bug fixed: configurations.get(launch-configuration) always shows the first element\nBelow is the proof of the bug, the original code didn\'t take into account that you can query one or many passing an array.\r\n\r\n[agifog] fog                                           \r\n  Welcome to fog interactive!\r\n  :default provides AWS\r\n>> Fog.mock!\r\ntrue\r\n>> \r\n?> def as\r\n>>   @as ||= Fog::AWS::AutoScaling.new\r\n>> end\r\nnil\r\n>> \r\n?> def compute\r\n>>   @compute ||= Fog::Compute::AWS.new\r\n>> end\r\nnil\r\n>> \r\n?> @image = compute.register_image(\'image\', \'image\', \'/dev/sda1\').body\r\n{"requestId"=>"cff532df-ae60-49e6-ba21-ffe46e3d4155", "imageId"=>"ami-6471279a"}\r\n>> @image_id = @image[\'imageId\']\r\n"ami-6471279a"\r\n>> \r\n?> first = as.configurations.create(:id => "first-configuration", :image_id => @image_id, :instance_type => \'t1.micro\')\r\n  <Fog::AWS::AutoScaling::Configuration\r\n    id="first-configuration",\r\n    arn="arn:aws:autoscaling:eu-west-1:000000000000:launchConfiguration:00000000-0000-0000-0000-000000000000:launchConfigurationName/first-configuration",\r\n    block_device_mappings=[],\r\n    created_at=2012-03-06 14:04:10 UTC,\r\n    image_id="ami-6471279a",\r\n    instance_monitoring=true,\r\n    instance_type="t1.micro",\r\n    kernel_id=nil,\r\n    key_name=nil,\r\n    ramdisk_id=nil,\r\n    security_groups=[],\r\n    user_data=nil\r\n  >\r\n>> second = as.configurations.create(:id => "second-configuration", :image_id => @image_id, :instance_type => \'t1.micro\')\r\n  <Fog::AWS::AutoScaling::Configuration\r\n    id="first-configuration",\r\n    arn="arn:aws:autoscaling:eu-west-1:000000000000:launchConfiguration:00000000-0000-0000-0000-000000000000:launchConfigurationName/first-configuration",\r\n    block_device_mappings=[],\r\n    created_at=2012-03-06 14:04:10 UTC,\r\n    image_id="ami-6471279a",\r\n    instance_monitoring=true,\r\n    instance_type="t1.micro",\r\n    kernel_id=nil,\r\n    key_name=nil,\r\n    ramdisk_id=nil,\r\n    security_groups=[],\r\n    user_data=nil\r\n  >\r\n>> as.configurations.get(\'second-configuration\')\r\n  <Fog::AWS::AutoScaling::Configuration\r\n    id="first-configuration",\r\n    arn="arn:aws:autoscaling:eu-west-1:000000000000:launchConfiguration:00000000-0000-0000-0000-000000000000:launchConfigurationName/first-configuration",\r\n    block_device_mappings=[],\r\n    created_at=2012-03-06 14:04:10 UTC,\r\n    image_id="ami-6471279a",\r\n    instance_monitoring=true,\r\n    instance_type="t1.micro",\r\n    kernel_id=nil,\r\n    key_name=nil,\r\n    ramdisk_id=nil,\r\n    security_groups=[],\r\n    user_data=nil\r\n  >'
778,'','basic VPC creation\nthis patch adds the ability to create, delete, and list vpcs'
777,'','Support for rds parameter groups mocking\nShindo tests now pass in mocking mode. \r\n\r\n[fog] export FOG_MOCK=true ;bundle exec shindo tests/aws/requests/rds/parameter_group_tests.rb\r\n  \r\n  AWS::RDS | parameter group requests (aws, rds)\r\n    success\r\n      #create_db_parameter_groups + returns "mysql5.1"\r\n+ returns "fog-group"\r\n+ returns "Some description"\r\n+ has proper format\r\n      #describe_db_parameter_groups + returns 4\r\n+ has proper format\r\n      #describe_db_parameter_groups(\'fog-group) + returns 1\r\n+ returns "mysql5.1"\r\n+ returns "fog-group"\r\n+ returns "Some description"\r\n+ has proper format\r\n      delete_db_parameter_group + raises Fog::AWS::RDS::NotFound\r\n+ has proper format\r\n    failures\r\n      + raises Fog::AWS::RDS::NotFound\r\n      + raises Fog::AWS::RDS::NotFound\r\n      creating second group with same id\r\n        + raises Fog::AWS::RDS::IdentifierTaken\r\n  \r\n  16 succeeded in 0.564274 seconds'
776,'',"Simple multipart S3 uploads\nTo upload files larger than 5GB to S3, you must use multipart uploads.\r\n\r\nThis is a complicated process of:\r\n1. initializing the upload (keeping track of the upload_id)\r\n2. uploading each part (keeping track of each part's ETag)\r\n3. completing the upload\r\n\r\nThis adds simple support for multipart uploads to the File model by passing the :multipart_chunk_size parameter.\r\n\r\nE.g.\r\n    chunk_size = 5242880 # 5mb\r\n    directory.files.create(:key => 'large_file', :body => File.open('large_file'), :multipart_chunk_size => chunk_size)\r\n\r\nConsiderations: each chunk must be read into memory, so small chunk sizes are preferable. Multipart uploads cannot have more than 10k parts, so a 1TB file would need at least a 100MB chunk size.\r\n\r\n(I couldn't see how to avoid reading the whole chunk into memory w/out changing Excon's internals to take a file handle w/ a byte offset to start reading.)\r\n\r\nCurrently each part is uploaded serially. Some applications would benefit from uploading parts in parallel."
775,'','Fog::Compute::AWS::SecurityGroups ip_permissions - variance\nI am pretty sure that there is a reason for this it may even be the expected behaviour and a result of how the EC2 API returns the data.\r\n\r\nWhen I query AWS eu-west-1 using `security.groups.all` with the following:\r\n\r\n<pre>\r\n#AWS.security_groups.get("default")\r\n# Get a list of the zpf EC2 security groups\r\nzpf_security_groups = connection.security_groups.all\r\n\r\n# If this is not run in the zpf shell context, it is in a script context, so\r\n# return in format <name, ip_permission> so that the data can be used in the shell\r\n# script context.\r\nif $script_call == \'1\'\r\n  zpf_security_groups.each { |i| puts "#{i.name}, #{i.ip_permissions}" };nil\r\nend\r\n</pre>\r\n\r\nI get the results back on the `zpf_security_groups.each { |i| puts "#{i.name}, #{i.ip_permissions}" };nil` with varying order in the structure of the ip_permissions strings.  Sometimes the ip_permissions string begins with `ipProtocol` metadata, sometimes it is the `toPort`, etc.\r\n\r\nTo highlight this here is an example:\r\n\r\nThis is 3 different `security_groups.all ` executions I have just highlighted the one security group and anonymised the IP strings.\r\n\r\n<pre>\r\ngary@mc9:~$ cat /home/gary/admin/rm/bug5785/zpf-controller-dev-1.fog.ip_permissions.variance.txt | sed -e \'s/\\([0-9]\\{1,3\\}\\.\\)\\{3\\}[0-9]\\{1,3\\}/123\\.124\\.125\\.126/g\'\r\n[root@zpf-controller-dev-1-10g-ruk ~]# cat $CURRENT_PERMISSIONS_FILE.raw.20120302071000 | grep "zpf-controller-dev"\r\nzpf-controller-dev, toPort22ipProtocoltcpfromPort22ipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/26groupstoPort6163ipProtocoltcpfromPort6163ipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32groupstoPort6164ipProtocoltcpfromPort6164ipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32groupstoPort8140ipProtocoltcpfromPort8140ipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32groupstoPort6166ipProtocoltcpfromPort6166ipRangescidrIp123.124.125.126/32groupstoPort162ipProtocoludpfromPort161ipRangescidrIp123.124.125.126/32groups\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n[root@zpf-controller-dev-1-10g-ruk ~]# cat $CURRENT_PERMISSIONS_FILE.raw | grep "zpf-controller-dev"\r\nzpf-controller-dev, ipProtocoltcpfromPort22toPort22groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/26ipProtocoltcpfromPort6163toPort6163groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32ipProtocoltcpfromPort6164toPort6164groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32ipProtocoltcpfromPort8140toPort8140groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32ipProtocoltcpfromPort6166toPort6166groupsipRangescidrIp123.124.125.126/32ipProtocoludpfromPort161toPort162groupsipRangescidrIp123.124.125.126/32\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n[root@zpf-controller-dev-1-10g-ruk ~]# /opt/zpf/scripts/fog/fog.check.ec2.security.groups.permission.rb $i_region $SECURITY_GROUP script > $CURRENT_PERMISSIONS_FILE.raw.20120302073032\r\n[root@zpf-controller-dev-1-10g-ruk ~]# cat $CURRENT_PERMISSIONS_FILE.raw.20120302073032 | grep "zpf-controller-dev"\r\nzpf-controller-dev, fromPort22groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/26ipProtocoltcptoPort22fromPort6163groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32ipProtocoltcptoPort6163fromPort6164groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32ipProtocoltcptoPort6164fromPort8140groupsipRangescidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32cidrIp123.124.125.126/32ipProtocoltcptoPort8140fromPort6166groupsipRangescidrIp123.124.125.126/32ipProtocoltcptoPort6166fromPort161groupsipRangescidrIp123.124.125.126/32ipProtocoludptoPort162\r\n[root@zpf-controller-dev-1-10g-ruk ~]#\r\n</pre>'
774,'','Rename from NewServers to BareMetalCloud\nAn effort to address the needed name changes for :octocat:  #773\r\n\r\nThis request includes changing from:\r\n\r\n* NewServers to BareMetalCloud\r\n* new_servers to bare_metal_cloud\r\n* newservers to baremetalcloud\r\n\r\nThe changelog.txt change is probably not needed.\r\n\r\nVerified the tests are passing via `bundle exec rake` in comparison with master branch.'
773,'','New Servers provider is now Bare Metal Cloud\nhttp://www.baremetalcloud.com/index.php/en/'
772,'',"* [dreamhost|dns] initial import\nImplementation of Dreamhost DNS API commands: http://wiki.dreamhost.com/API/Dns_commands\r\n\r\nKind of simple but since it's my first Fog provider, better to have an easy start I guess :)\r\n\r\nCreated a small cheatsheet: https://gist.github.com/1944277\r\n\r\nI've implemented some shindo tests and I'm still trying to digest the Mock thing in Fog. Dreamhost does not have an API test account with RW operations enabled so testing has been done in my own account...\r\n\r\nhttp://troll.me/i-dont-always-test-my-code-but-when-i-do-i-do-it-in-production/  \r\n"
771,'','Scan sort of acts like a GET request, which are idempotent\n'
770,'','When Exists boolean is not specified, this request is not idempotent\n'
769,'',"Excon is now by default verifying HTTPS connections with certificates an...\n...d it's failing on our site for AWS. Don't know where to add this so I'm using general place fog.rb. Hope you can make sense of this. If not write me back and I'll give u more info. Thank you"
768,'','Remove require rubygems line from core.rb\nI think this can be safely removed, when used via gem - rubygems is already available and it creates problem in non gem environments. '
767,'','strip arn\nPer AWS staff description:\r\n\r\nhttps://forums.aws.amazon.com/message.jspa?messageID=320808#320808\r\n\r\nAWS will reject a request that uses a ARN with whitespace/cr/lf'
766,'','this patch adds host based vmotion to the vsphere provider\nthis patch adds host based vmotion to the vsphere provider'
765,'','make fog/cloudstack support "servers.create" style server CRUD\ne.g. compute.servers.create(options)\r\ncompute.servers.get server_id\r\nserver.destroy'
764,'','[aws|rds] Add mock support for DB snapshots\nContinue @restebanez excellent work on RDS mocks to support snapshots.\r\n\r\nRelevant tests were changed from pending to active, and pass.\r\n\r\nAlso cleanup up some whitespace.'
763,'','[aws|dns] Add Record#modify method (and tests)\nSee https://github.com/fog/fog/pull/626 for original pull request.\r\n\r\nThis branch now includes model & collection tests for AWS Route53 zones and records, particularly for the new Record#modify method.'
762,'',"[aws|storage|test] Use the MD5 of the file as the ETag for put_object to match S3's behavior.\nI'm not sure why the ETag was mocked originally, but it seems to make sense to continue mocking for multi-part stores.  For simple put_object, the docs specify what the format of the ETag should be.\r\n\r\nThe value is a bit more important now that objects can have multiple versions.  E.g., I'm trying to write a job to clean up duplicate versioned data in S3 and need the mock framework to better match S3."
761,'',"fog and carrierwave\nI'm using carrierwave and fog to upload documents to s3 storage. Would anone know anything about how I can add additional headers, in particularly \r\n\r\nx-amz-server-side-encryption=AES256 \r\n\r\nto a fog configuration with carrierwave. See this stacks overflow for more info:\r\nhttp://stackoverflow.com/questions/9106115/adding-additional-headers-to-carrierwave-for-amazon-s3-encryption"
760,'','fixed some whitespace issues in auto_scaling.  Fixed auto_scaling test format.\nfixed some whitespace issues in auto_scaling.  Fixed auto_scaling test format.'
759,'','fixes the object returned by auto_scaling describe_scheduled_actions.\nfixes the object returned by describe_scheduled_actions.'
758,'','update autoscaling scheduled actions to allow recurrence, end and start times\nupdates autoscaling scheduled actions to allow recurrence, end and start times also initializes @activity explicitly to fix an issue in ruby 1.8'
757,'','multi_json 1.1.0 is out\n```\r\nBundler could not find compatible versions for gem "multi_json":\r\n  In snapshot (Gemfile.lock):\r\n    multi_json (1.1.0)\r\n\r\n  In Gemfile:\r\n    fog (>= 1.1.2) ruby depends on\r\n      multi_json (~> 1.0.3) ruby\r\n```\r\n\r\nUsually gems relying on multi_json specify a `~> 1.0` version dep.'
756,'','associate EIPs in a vpc\nThis patch allows the association of EIPs in a VPC '
755,'','Manage floating ips in openstack 2.0\nAdd some methods for managing floating ips in openstack v2'
754,'',"Slow uploading for S3\nI seem to have a very interesting issue with fog.\r\nI was searching for an answer, but failed to find one.\r\n\r\nOur application uses Amazon EC2 and that application needs to upload/download files from S3.\r\nWe're using fog to handle that process which generally works great.\r\nWe do really appreciate everyone's effort on this gem.\r\n\r\nHowever, the uploading seems to be a lot slower than when I'm using aws-s3 gem.\r\nIt took about 15 minutes to upload using fog, but it took only 5 seconds with aws-s3 when uploading 100MB file.\r\nWhile I'm surprised that it took only 5 seconds to upload it from EC2 to S3, I don't understand why using fog makes it a lot slower.\r\nI've tried curl based bash script that does the same thing and it took pretty much the same time as aws-s3.\r\n\r\nIt looks to me that the request via fog is considered to be the request outside of Amazon's private network or something.\r\n\r\nAnyone has any idea on this?\r\nAny kind of input would very much be appreciated.\r\n\r\nThanks,\r\n"
753,'',"SNS region unknown or method unknown\n In Fog 1.1.2:\r\n\r\n    opts = {:region => ...., <keys>} \r\n    ::Fog::AWS::SNS::Real.new( opts )\r\n\r\nWill init OK but not know anything about SNS methods (e.g `list_topics`):\r\n\r\n    NoMethodError: undefined method `list_topics' for #<Fog::AWS::SNS::Real:0x00000004e73bd8>\r\n\r\nOn the other hand:\r\n\r\n    ::Fog::AWS::SNS.new( opts )\r\n    ArgumentError: Unrecognized arguments: region\r\n    /src/project/ttinit/vendor/ruby/1.9.1/gems/fog-1.1.2/lib/fog/core/service.rb:193:in `validate_options'\r\n    /src/project/ttinit/vendor/ruby/1.9.1/gems/fog-1.1.2/lib/fog/core/service.rb:58:in `new'\r\n\r\nThere is a little too much magic happening in the test suite to be able to tell why this doesn't show up as a failure there.\r\n\r\n"
752,'',"missing raise\nMissed a raise, so it's returning this in the mock, not raising it."
751,'','[bluebox|compute] Add support for locations\nThis adds support for Blue Box locations. Can now create instances in Seattle or Ashburn.'
750,'',"[storage] Add copy method to {Local,Ninefold,Rackspace}::File\nThese changes add tests for File#copy and implements the copy method in `Local::File`, `Ninefold::File`, and `Rackspace::File`, which didn't have the functionality before.\r\n\r\nI implemented the `copy_object` method and request Local and Rackspace, but couldn't find a proper API call for copying in Ninefold. For Ninefold, I essentially used `files.create(:body => original.body)`, which has the additional overhead of downloading and uploading the body.\r\n\r\nI would have attached this to #735, but because this implements more than just `Local::File`, it belongs in its own pull request."
749,'','[storage|test] Run storage tests on a file in a subdirectory.\nRunning the storage tests prior to fog/fog#746 in Ruby 1.8 succeeded\r\nbecause the current tests do not run empty parent tree deletion. After\r\nthe addition of this test, running the storage tests will fail if an\r\nexception occurs while deleting the parent directories.\r\n\r\nThis essentially runs the same tests as above, but with `:public => true` as a constant and the file key set to `:key => "fog/storageobject"` instead of `:key => "fogstorageobject"`.\r\n\r\nI have tested this against `Local`, `AWS`, and `Google`: all three succeeded. I don\'t have accounts with the other storage providers Fog supports (`Rackspace` and `Ninefold`).'
748,'',"Added Fog.find_credentials which supports checking parent directories for the .fog file.\n* Fog.credentials_path now uses Fog.find_credentials.\r\n* Fog.find_credentials checks:\r\n  1. `ENV['FOG_RC']`\r\n  2. Each parent directory\r\n  3. `ENV['HOME']`"
747,'',"Use Faraday for HTTP connections\nWould it be accepted, if done, to use Faraday for the HTTP connections?\r\n\r\nIt can still use Excon as the main adapter. It was just make it so much easier to use fog with other adapters and environments that Excon does support.\r\n\r\nFor example, EventMachine or JRuby.\r\n\r\nI'm willing to put the time in to do the conversion."
746,'',"[local|storage] Fix Local::File deletion for Ruby 1.8.\nRuby 1.8 doesn't have a Dir.exists? method, which causes an exception and\r\nprevents empty parent directories from being deleted. These changes use\r\nFile.exists? and File.directory? in place of Dir.exists?. Fixes\r\nfog/fog#707.\r\n\r\nI'm not sure how to test for this. I tested locally by running the following in IRB.\r\n\r\n```ruby\r\n`mkdir test1`\r\n`mkdir test1/test2`\r\n`mkdir test1/test2/test3`\r\n`mkdir test1/test2/test3/test4`\r\n`touch test1/test2/test3/test4/file1`\r\n`touch test1/test2/file2`\r\n\r\nFile.exists?('test1/test2/test3/test4/file1') # => true\r\n\r\ndirectory = Fog::Storage.new(:provider => 'Local', :local_root => '.').directories.get('.')\r\nfile = directory.files.get('test1/test2/test3/test4/file1')\r\nfile.destroy\r\n\r\nFile.exists?('test1/test2/test3/test4/file1') # => false\r\nFile.exists?('test1/test2/test3/test4') # => false\r\nFile.exists?('test1/test2/test3') # => false\r\nFile.exists?('test1/test2/file2') # => true\r\nFile.exists?('test1/test2') # => true\r\n```\r\n\r\nI'll see if I create some shindo test for Local::File to make sure that this doesn't break anything - but that still doesn't test for 1.8/1.9 compatibility."
745,'',"Remove coverage Rake task.\nRCov isn't in the gemspec anymore, and doesn't work when added.\r\n\r\nWe could add support for RCov/SimpleCov, but it looks like this hasn't been used in awhile."
744,'','Check for .fog file in the current directory\nIt would be useful if the `fog` console could check for a `.fog` file in the current directory, or even ascend each parent directory. This would allow per-project `fog` console configurations.'
743,'',"public_url and bucket names with periods\nThis is more of a problem with S3 than with fog, but I thought I'd point it out.\r\n\r\nThere seems to be no tests for the public_url methods, but it contains a regex match to detect wether to use the sub domain method of accessing a bucket or the directory method. I can't really read the regex (write only format), so this is an assumption.\r\n\r\nHowever, if you have periods in your bucket name (which is valid: http://docs.amazonwebservices.com/AmazonS3/latest/dev/BucketRestrictions.html), and then use SSL to access it via the sub domain (which fog does), then you get a certificate failure, which causes all sorts of niggly problems down the line.\r\n\r\nI would offer a patch, but I'm not comfortable editing that regex without more info about it. For now, we've just renamed our buckets, but a fix would be better."
742,'','make eips useable in a VPC\nThis patch allows the creation of Elastic IPs in a VPC. '
741,'','[Compute|OpenStack] match auth response to stable/diablo keystone\nTested with latest devstack running master keystone, should work for Essex as well.'
740,'',"Move fission from reg dependency to dev dependency per #736\nThis is what you'd prefer, yes?"
739,'','GH-690 Joyent Cloud Provider\nThis implements GH-690 Joyent CloudAPI provider support\r\n\r\nAPI Documentation: https://us-west-1.api.joyentcloud.com/docs\r\n\r\nMethods implemented (everything in the docs except those under Analytics and Datacenters)\r\n\r\n```\r\nadd_machine_tags\r\ncreate_key\r\ncreate_machine\r\ncreate_machine_snapshot\r\ndelete_all_machine_metadata\r\ndelete_all_machine_tags\r\ndelete_key\r\ndelete_machine\r\ndelete_machine_metadata\r\ndelete_machine_snapshot\r\ndelete_machine_tag\r\nget_dataset\r\nget_key\r\nget_machine\r\nget_machine_metadata\r\nget_machine_snapshot\r\nget_machine_tag\r\nget_package\r\nlist_datasets\r\nlist_keys\r\nlist_machine_snapshots\r\nlist_machine_tags\r\nlist_machines\r\nlist_packages\r\nreboot_machine\r\nresize_machine\r\nstart_machine\r\nstart_machine_from_snapshot\r\nstop_machine\r\nupdate_machine_metadata\r\n```\r\n\r\nModels provided (and their corresponding vocabulary in CloudAPI terms):\r\n\r\n```\r\nFlavor # Machine\r\nImage # Dataset\r\nKey # Key\r\nServer # Machine\r\nSnapshot # Snapshot\r\n```'
738,'',"Fog::AWS::CloudFormation.new results in SignatureDoesNotMatch\nUsing fog successfully to hit EC2 and S3 with no problems in the same app with the same exact keys.\r\n\r\nDoing everything exactly the same way for this request:\r\n\r\ncf = Fog::AWS::CloudFormation.new({\r\n      :aws_access_key_id     => current_user.access_key_id,\r\n      :aws_secret_access_key => current_user.secret_access_key\r\n    })\r\n\r\ncf.create_stack('xxxxxxxxxxxxxxxxx', 'TemplateURL' => 'https://s3.amazonaws.com/xxxxxxxxxxxxxxx/xxxxxxxxxxxxxxx', 'Parameters' => parameters )"
737,'','OutOfMemory when trying to transfer files from one storage to the other\nHi,\r\n\r\nI try to transfer all files from a bucket on AWS to the S3 compatible cloud storage at Hosteurope.\r\n\r\nThis is what I try, but it eats up all my memory as it adds all created files to the files collection I guess...\r\n\r\n\r\n    s3_dir.files.each do |s3_file|\r\n      he_file = he_dir.files.select{|f| f.key == s3_file.key}[0]\r\n      if he_file && he_file.content_length == s3_file.content_length\r\n        puts "Skipping #{s3_file.key}, because it\'s already there"\r\n      else\r\n        puts "Transferring #{s3_file.key} with size #{s3_file.content_length/1024} kB"\r\n        he_dir.files.create(\r\n          :key => s3_file.key,\r\n          :body => s3_file.body,\r\n          :public => false\r\n        )\r\n      end\r\n    end\r\n\r\nWhat is a better way which avoids to load _all_ files into memory? Writing to disk?\r\n\r\nThanks,\r\nMatthias\r\n'
736,'','include fission gem?\n"bundle exec rake" was crapping out for us because vmfusion/compute.rb was requiring it.  The obvious fix was adding fission to the gemspec, but the require inside a method suggests that there are more subtle forces at work.  \r\n\r\nIs this the right way to fix the problem?'
735,'',"Local::File doesn't have a copy method\n`Fog::Storage::Local::File` doesn't have a `#copy` method similar to those found in `Fog::Storage::AWS::File` and `Fog::Storage::Google::File`. These methods can be implemented using `FileUtils.copy_file`."
734,'','Fog::Storage::AWS::Directory#files includes directories\nHi,\r\n\r\nWe are seeing directories returned when we call Fog::Storage::AWS::Directory#files:\r\n\r\n    ruby-1.9.2-p180 :010 > b.class\r\n     => Fog::Storage::AWS::Directory \r\n    ruby-1.9.2-p180 :011 > b.files.last(2)\r\n     => [  <Fog::Storage::AWS::File\r\n        key="this/is/directory/504/",\r\n        cache_control=nil,\r\n        content_disposition=nil,\r\n        content_encoding=nil,\r\n        content_length=0,\r\n        content_md5=nil,\r\n        content_type=nil,\r\n        etag="abcdef",\r\n        expires=nil,\r\n        last_modified=2011-06-08 08:08:05 UTC,\r\n        metadata={},\r\n        owner={:display_name=>nil, :id=>nil},\r\n        storage_class="STANDARD"\r\n      >,   <Fog::Storage::AWS::File\r\n        key="this/is/directory/504/an_actual_file.jpg",\r\n        cache_control=nil,\r\n        content_disposition=nil,\r\n        content_encoding=nil,\r\n        content_length=345312,\r\n        content_md5=nil,\r\n        content_type=nil,\r\n        etag="1234567",\r\n        expires=nil,\r\n        last_modified=2011-06-08 08:08:05 UTC,\r\n        metadata={},\r\n        owner={:display_name=>nil, :id=>nil},\r\n        storage_class="STANDARD"\r\n      >] \r\n\r\nNote that the first result is a directory (ends in /, has `content_length` 0), while the second result is a file in this directory. We are expecting only files to be returned.'
733,'','IAM mocks\nIAM mocks, so I can test my code w/o stubs.\r\n\r\nThe only thing that deviates from that is where I cleaned up a bunch of s/key.include? something/has_key? something/\r\n\r\n'
732,'','[aws|storage|test] Make sure tests pass with both mocking enabled and disabled.\nSo, I think I may have only run the request tests with mocking disabled and the model tests with mocking enabled.  I\'m not 100% sure, but it seems the likely scenario.\r\n\r\nSummary of changes:\r\n\r\n* Fixed ordering of versions in mocks.  The S3 docs make no explicit guarantee on order, so I didn\'t worry about it, but the differences between mock & real were fixed by reversing the sort order.  This may break in the future if results truly are sorted in a nondeterministic order, in which case we\'d have to compare Sets instead of Arrays.\r\n\r\n* There were some issues delineating between AccessDenied & NotFound, depending on the bucket name used.  If anyone ever creates the bucket "fognonbucket" and doesn\'t tear it down, we\'re going to have a lot of failures.\r\n\r\n* There may be sporadic failures doing the request tests un-mocked.  It seems with versioning in particular it can take S3 several seconds to update the bucket configuration.  I\'m open to suggestions on how to fix this.  Sleeping for 15s seems to be the safest way, but that\'s quite annoying and still not even guaranteed to pass.'
731,'',"Added check if Fog.mock! should be used in AWS tests\nWithout the check all tests were assumed mocked regardless of the user's environment setting.\r\n\r\nI don't have the accounts to confirm the specs are now running with mocking disabled so would appreciate a second opinion."
730,'','Added idempotent => true to create_tags\nThis appears to fix an issue when launching many instance from cluster_chef, which tags servers on the way up.'
729,'',"[aws|compute] Update API version and support new DescribeInstanceStatus format.\nOpening a PR for this because I'm not sure what the protocol is for the DescribeInstanceStatus body changing. I'm probably missing something obvious from the past but I couldn't immediately find a case where an AWS parser changed due to a breaking change in response.\r\n\r\nIn this case, `systemStatus` and `instanceStatus` items were added and `eventsSet` changed to just a single `event`, according to the sample [here](http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeInstanceStatus.html). I also used the sample to verify the parser.\r\n\r\nThe current format was made public in fog 1.1.2 with the initial implementation of the DescribeInstanceStatus request and parser.\r\n\r\nHalp?"
728,'',"Don't hardcode regions\nAWS has added and will add more regions. Apart from few early special cases (S3 & SQS have distinct us-east-1 endpoints), region name is simply part of API endpoint DNS name.\r\n\r\nHaving the knowledge of regions hardcoded, makes Fog fragile to future changes in AWS. Some projects tend to pick up new versions of Fog conservatively. Users of such sluggish projects tend to get stuck with whatever regions that Fog supported a year ago or more. That is because Fog had regions hardcoded. I know this pull request won't help these poor souls. But it will avoid this class of problems in future.\r\n\r\nHope this helps.\r\n\r\nPlease let me know if anything needs to be added or fixed or undone in this pull request."
727,'','Add 2.8 support\nThe difference between 2.6 and 2.8 are a few additional api calls but the\r\nexisting calls are still backwards compatible, and we need the version bump\r\nto be able to continue to use.'
726,'','[cloudstack|compute] added update resource count action\n'
725,'','fixed a typo in vm_power_on_tests.rb\ntest was powering off rather than powering on a VM.'
724,'','Migration to rspec 2\nHi, are you planning to migrate your specs to rspec 2? I think rspec 1.3.1 are getting quite old and obsoleted.\r\nThank you.'
723,'','Adds Supprt for oVirt (http://ovirt.org).\nSigned-off-by: Ohad Levy <ohadlevy@gmail.com>'
722,'','add subnet and vpc info to instance gets\nadd in subnet_id and vpc_id info when running an Fog::Compute[:aws].servers.get(i-name)  '
721,'','add vm reconfiguration functions for memory cpu / generic spec for vsphere\nThis patch adds the ability to perform a reconfigVmTask on a VM given its UUID.  The patch includes two specific functions for modifying memory and cpu, and a generic hardware modification spec. '
720,'','Rackspace create_image request - pass all options\nPass in all options provided on a Rackspace create_image request.  We needed to pass in undocumented flags.\r\n\r\nSorry, this is based on v1.1.2 release tag.'
719,'','Removing duplicates from reservation\'s groupSet\nFog::Compute::AWS::Server objects produced from describe_instances contain duplicates in the group\'s array.\r\n\r\nAs a result, tools built on Fog e.g <a href="https://github.com/opscode/knife-ec2">knife-ec2</a> produce confusing output:\r\n\r\n<pre>\r\n# knife ec2 server list\r\nInstance ID  Name        Zone        Public IP  Private IP  Flavor    Image         SSH Key  Sec Group                                   State  \r\ni-XXXXXXXX   mastertest  us-west-2a                         t1.micro  ami-XXXXXXXX  artem    [webservers, webservers]                    stopped\r\ni-XXXXXXXX   grouptest   us-west-2a                         t1.micro  ami-XXXXXXXX  artem    [webservers, default, webservers, default]  stopped\r\n</pre>\r\n\r\nThis patch fixes the describe_instances parser and eliminates duplicates.\r\n\r\n\r\nHere are the details.\r\n\r\nA sample AWS response to describe_instances request:\r\n<pre>\r\n&lt;?xml version="1.0" encoding="UTF-8"?&gt;\r\n&lt;DescribeInstancesResponse xmlns="http://ec2.amazonaws.com/doc/2011-11-01/"&gt;\r\n    &lt;requestId&gt;51b74328-d2d7-4b02-867d-818fec883f7d&lt;/requestId&gt;\r\n    &lt;reservationSet&gt;\r\n        &lt;item&gt;\r\n            &lt;reservationId&gt;XXXXXX&lt;/reservationId&gt;\r\n            &lt;ownerId&gt;XXXXXX&lt;/ownerId&gt;\r\n --&gt;        &lt;groupSet&gt;  &lt;-- reservation groupSet\r\n                &lt;item&gt;\r\n                    &lt;groupId&gt;XXXXXX&lt;/groupId&gt;\r\n                    &lt;groupName&gt;webservers&lt;/groupName&gt;\r\n                &lt;/item&gt;\r\n            &lt;/groupSet&gt;\r\n            &lt;instancesSet&gt;\r\n                &lt;item&gt;\r\n                    &lt;instanceId&gt;XXXXXX&lt;/instanceId&gt;\r\n                    &lt;imageId&gt;XXXXXX&lt;/imageId&gt;\r\n                    &lt;instanceState&gt;\r\n                        &lt;code&gt;80&lt;/code&gt;\r\n                        &lt;name&gt;stopped&lt;/name&gt;\r\n                    &lt;/instanceState&gt;\r\n                    &lt;privateDnsName/&gt;\r\n                    &lt;dnsName/&gt;\r\n                    &lt;reason&gt;User initiated (2012-01-30 05:44:47 GMT)&lt;/reason&gt;\r\n                    &lt;keyName&gt;artem&lt;/keyName&gt;\r\n                    &lt;amiLaunchIndex&gt;0&lt;/amiLaunchIndex&gt;\r\n                    &lt;productCodes/&gt;\r\n                    &lt;instanceType&gt;t1.micro&lt;/instanceType&gt;\r\n                    &lt;launchTime&gt;2012-01-30T05:00:34.000Z&lt;/launchTime&gt;\r\n                    &lt;placement&gt;\r\n                        &lt;availabilityZone&gt;us-west-2a&lt;/availabilityZone&gt;\r\n                        &lt;groupName/&gt;\r\n                        &lt;tenancy&gt;default&lt;/tenancy&gt;\r\n                    &lt;/placement&gt;\r\n                    &lt;kernelId&gt;aki-ace26f9c&lt;/kernelId&gt;\r\n                    &lt;monitoring&gt;\r\n                        &lt;state&gt;disabled&lt;/state&gt;\r\n                    &lt;/monitoring&gt;\r\n --&gt;                &lt;groupSet&gt; &lt;-- instance groupSet\r\n                        &lt;item&gt;\r\n                            &lt;groupId&gt;XXXXXX&lt;/groupId&gt;\r\n                            &lt;groupName&gt;webservers&lt;/groupName&gt;\r\n                        &lt;/item&gt;\r\n                    &lt;/groupSet&gt;\r\n                    &lt;stateReason&gt;\r\n                        &lt;code&gt;Client.UserInitiatedShutdown&lt;/code&gt;\r\n                        &lt;message&gt;Client.UserInitiatedShutdown: User initiated shutdown&lt;/message&gt;\r\n                    &lt;/stateReason&gt;\r\n                    &lt;architecture&gt;x86_64&lt;/architecture&gt;\r\n                    &lt;rootDeviceType&gt;ebs&lt;/rootDeviceType&gt;\r\n                    &lt;rootDeviceName&gt;/dev/sda1&lt;/rootDeviceName&gt;\r\n                    &lt;blockDeviceMapping&gt;\r\n                        &lt;item&gt;\r\n                            &lt;deviceName&gt;/dev/sda1&lt;/deviceName&gt;\r\n                            &lt;ebs&gt;\r\n                                &lt;volumeId&gt;XXXXXX&lt;/volumeId&gt;\r\n                                &lt;status&gt;attached&lt;/status&gt;\r\n                                &lt;attachTime&gt;2012-01-30T05:45:08.000Z&lt;/attachTime&gt;\r\n                                &lt;deleteOnTermination&gt;true&lt;/deleteOnTermination&gt;\r\n                            &lt;/ebs&gt;\r\n                        &lt;/item&gt;\r\n                    &lt;/blockDeviceMapping&gt;\r\n                    &lt;virtualizationType&gt;paravirtual&lt;/virtualizationType&gt;\r\n                    &lt;clientToken/&gt;\r\n                    &lt;tagSet&gt;\r\n                        &lt;item&gt;\r\n                            &lt;key&gt;Name&lt;/key&gt;\r\n                            &lt;value&gt;mastertest&lt;/value&gt;\r\n                        &lt;/item&gt;\r\n                    &lt;/tagSet&gt;\r\n                    &lt;hypervisor&gt;xen&lt;/hypervisor&gt;\r\n                &lt;/item&gt;\r\n            &lt;/instancesSet&gt;\r\n        &lt;/item&gt;\r\n        &lt;item&gt;\r\n            &lt;reservationId&gt;XXXXXX&lt;/reservationId&gt;\r\n            &lt;ownerId&gt;XXXXXX&lt;/ownerId&gt;\r\n --&gt;        &lt;groupSet&gt; &lt;-- reservation groupSet\r\n                &lt;item&gt;\r\n                    &lt;groupId&gt;XXXXXX&lt;/groupId&gt;\r\n                    &lt;groupName&gt;webservers&lt;/groupName&gt;\r\n                &lt;/item&gt;\r\n                &lt;item&gt;\r\n                    &lt;groupId&gt;XXXXXX&lt;/groupId&gt;\r\n                    &lt;groupName&gt;default&lt;/groupName&gt;\r\n                &lt;/item&gt;\r\n            &lt;/groupSet&gt;\r\n            &lt;instancesSet&gt;\r\n                &lt;item&gt;\r\n                    &lt;instanceId&gt;XXXXXX&lt;/instanceId&gt;\r\n                    &lt;imageId&gt;XXXXXX&lt;/imageId&gt;\r\n                    &lt;instanceState&gt;\r\n                        &lt;code&gt;80&lt;/code&gt;\r\n                        &lt;name&gt;stopped&lt;/name&gt;\r\n                    &lt;/instanceState&gt;\r\n                    &lt;privateDnsName/&gt;\r\n                    &lt;dnsName/&gt;\r\n                    &lt;reason&gt;User initiated (2012-01-30 12:01:57 GMT)&lt;/reason&gt;\r\n                    &lt;keyName&gt;artem&lt;/keyName&gt;\r\n                    &lt;amiLaunchIndex&gt;0&lt;/amiLaunchIndex&gt;\r\n                    &lt;productCodes/&gt;\r\n                    &lt;instanceType&gt;t1.micro&lt;/instanceType&gt;\r\n                    &lt;launchTime&gt;2012-01-30T10:44:32.000Z&lt;/launchTime&gt;\r\n                    &lt;placement&gt;\r\n                        &lt;availabilityZone&gt;us-west-2a&lt;/availabilityZone&gt;\r\n                        &lt;groupName/&gt;\r\n                        &lt;tenancy&gt;default&lt;/tenancy&gt;\r\n                    &lt;/placement&gt;\r\n                    &lt;kernelId&gt;aki-ace26f9c&lt;/kernelId&gt;\r\n                    &lt;monitoring&gt;\r\n                        &lt;state&gt;disabled&lt;/state&gt;\r\n                    &lt;/monitoring&gt;\r\n--&gt;                 &lt;groupSet&gt;  &lt;-- instance groupSet\r\n                        &lt;item&gt;\r\n                            &lt;groupId&gt;XXXXXX&lt;/groupId&gt;\r\n                            &lt;groupName&gt;webservers&lt;/groupName&gt;\r\n                        &lt;/item&gt;\r\n                        &lt;item&gt;\r\n                            &lt;groupId&gt;XXXXXX&lt;/groupId&gt;\r\n                            &lt;groupName&gt;default&lt;/groupName&gt;\r\n                        &lt;/item&gt;\r\n                    &lt;/groupSet&gt;\r\n                    &lt;stateReason&gt;\r\n                        &lt;code&gt;Client.UserInitiatedShutdown&lt;/code&gt;\r\n                        &lt;message&gt;Client.UserInitiatedShutdown: User initiated shutdown&lt;/message&gt;\r\n                    &lt;/stateReason&gt;\r\n                    &lt;architecture&gt;x86_64&lt;/architecture&gt;\r\n                    &lt;rootDeviceType&gt;ebs&lt;/rootDeviceType&gt;\r\n                    &lt;rootDeviceName&gt;/dev/sda1&lt;/rootDeviceName&gt;\r\n                    &lt;blockDeviceMapping&gt;\r\n                        &lt;item&gt;\r\n                            &lt;deviceName&gt;/dev/sda1&lt;/deviceName&gt;\r\n                            &lt;ebs&gt;\r\n                                &lt;volumeId&gt;XXXXXX&lt;/volumeId&gt;\r\n                                &lt;status&gt;attached&lt;/status&gt;\r\n                                &lt;attachTime&gt;2012-01-30T12:02:17.000Z&lt;/attachTime&gt;\r\n                                &lt;deleteOnTermination&gt;true&lt;/deleteOnTermination&gt;\r\n                            &lt;/ebs&gt;\r\n                        &lt;/item&gt;\r\n                    &lt;/blockDeviceMapping&gt;\r\n                    &lt;virtualizationType&gt;paravirtual&lt;/virtualizationType&gt;\r\n                    &lt;clientToken/&gt;\r\n                    &lt;tagSet&gt;\r\n                        &lt;item&gt;\r\n                            &lt;key&gt;Name&lt;/key&gt;\r\n                            &lt;value&gt;grouptest&lt;/value&gt;\r\n                        &lt;/item&gt;\r\n                    &lt;/tagSet&gt;\r\n                    &lt;hypervisor&gt;xen&lt;/hypervisor&gt;\r\n                &lt;/item&gt;\r\n            &lt;/instancesSet&gt;\r\n        &lt;/item&gt;\r\n    &lt;/reservationSet&gt;\r\n&lt;/DescribeInstancesResponse&gt;\r\n</pre>\r\n\r\nThe above request produces the following Fog::Compute::AWS::Server objects:\r\n\r\n<pre>\r\n  &lt;Fog::Compute::AWS::Server\r\n    id="XXXXXX",\r\n    ami_launch_index=0,\r\n    availability_zone="us-west-2a",\r\n    block_device_mapping=[{"deviceName"=&gt;"/dev/sda1", "volumeId"=&gt;"XXXXXX", "status"=&gt;"attached", "attachTime"=&gt;2012-01-30 05:45:08 UTC, "deleteOnTermination"=&gt;true}],\r\n    client_token=nil,\r\n    dns_name=nil,\r\n    groups=["XXXXXX", "webservers", "XXXXXX", "webservers"],\r\n    flavor_id="t1.micro",\r\n    image_id="XXXXXX",\r\n    kernel_id="aki-ace26f9c",\r\n    key_name="artem",\r\n    created_at=2012-01-30 05:00:34 UTC,\r\n    monitoring=false,\r\n    placement_group=nil,\r\n    platform=nil,\r\n    product_codes=[],\r\n    private_dns_name=nil,\r\n    private_ip_address=nil,\r\n    public_ip_address=nil,\r\n    ramdisk_id=nil,\r\n    reason="User initiated (2012-01-30 05:44:47 GMT)",\r\n    root_device_name=nil,\r\n    root_device_type="ebs",\r\n    security_group_ids=nil,\r\n    state="stopped",\r\n    state_reason={"code"=&gt;0},\r\n    subnet_id=nil,\r\n    tenancy="default",\r\n    tags={"Name"=&gt;"mastertest"},\r\n    user_data=nil\r\n  &gt;,\r\n   &lt;Fog::Compute::AWS::Server\r\n    id="XXXXXX",\r\n    ami_launch_index=0,\r\n    availability_zone="us-west-2a",\r\n    block_device_mapping=[{"deviceName"=&gt;"/dev/sda1", "volumeId"=&gt;"XXXXXX", "status"=&gt;"attached", "attachTime"=&gt;2012-01-30 12:02:17 UTC, "deleteOnTermination"=&gt;true}],\r\n    client_token=nil,\r\n    dns_name=nil,\r\n    groups=["XXXXXX", "webservers", "XXXXXX", "default", "XXXXXX", "webservers", "XXXXXX", "default"],\r\n    flavor_id="t1.micro",\r\n    image_id="XXXXXX",\r\n    kernel_id="aki-ace26f9c",\r\n    key_name="artem",\r\n    created_at=2012-01-30 10:44:32 UTC,\r\n    monitoring=false,\r\n    placement_group=nil,\r\n    platform=nil,\r\n    product_codes=[],\r\n    private_dns_name=nil,\r\n    private_ip_address=nil,\r\n    public_ip_address=nil,\r\n    ramdisk_id=nil,\r\n    reason="User initiated (2012-01-30 12:01:57 GMT)",\r\n    root_device_name=nil,\r\n    root_device_type="ebs",\r\n    security_group_ids=nil,\r\n    state="stopped",\r\n    state_reason={"code"=&gt;0},\r\n    subnet_id=nil,\r\n    tenancy="default",\r\n    tags={"Name"=&gt;"grouptest"},\r\n    user_data=nil\r\n  &gt;\r\n</pre>\r\n\r\nThe current parse code simply double counts groupSet by not distinguishing between the groupSet field in the reservation and the groupSet field in the item.\r\n\r\nA simple fix is to ignore the groupSet field if the context is instancesSet.\r\n\r\nWith the applied patch duplicates are removed.\r\n\r\n<pre>\r\nInstance ID  Name        Zone        Public IP  Private IP  Flavor    Image         SSH Key  Sec Group              State  \r\ni-XXXXXXXX   mastertest  us-west-2a                         t1.micro  ami-XXXXXXXX  artem    [webservers]           stopped\r\ni-XXXXXXXX   grouptest   us-west-2a                         t1.micro  ami-XXXXXXXX  artem    [webservers, default]  stopped\r\n</pre>'
718,'','Vcloud 1.5\nHi\r\n\r\nthese commits add vmWare vCloud 1.5 compatibility and also clean up some other parts of the vCloud resources.\r\n\r\nThis has been tested against a vCloud 1.0 and vCloud 1.5.\r\n\r\nAs I had no idea how you think that multi-api-version suport should be implemented in fog, I took the straight forward way and added here and there some little fixes for the versions.\r\n\r\nI added tests for both supported API versions and as you can see there is not much difference between the two versions.\r\n\r\nIf you have any comments, please let me know.\r\n\r\nthanks for merging\r\n\r\nduritong'
717,'','fix list_virtual_machines when using :folder\nfix list_virtual_machines when using :folder  assigning instead of evaluating.'
716,'','Ecloud on 1.9.2 fails but passes on 1.8.7\nThe current implementation of ecloud fails on 1.9.X but passes on 1.8.7:\r\n\r\n<pre>\r\n\r\n     @vcloud = ::Fog::Compute.new(:provider => \'ecloud\',\r\n                                    :ecloud_username => \'user@domain.com\',\r\n                                    :ecloud_password => \'PASSWORD\',\r\n                                    :ecloud_version => \'0.8b-ext2.6\',\r\n                                    :ecloud_versions_uri => \'https://services.enterprisecloud.terremark.com/api/versions\')\r\n   @vcloud.vdcs.each do |v|\r\n            puts "Processing #{v.name}..."\r\n            v.servers.each do |s|\r\n              puts s.name\r\n            end\r\n    end\r\n\r\n</pre>\r\n'
715,'','flavor list should be queried from ec2 endpoint\nCurrently, flavors are maintained as a hard coded list.\r\n\r\nThis is find if the endpoint is aws (since for aws it is a hard coded list)\r\n\r\nIf the aws::compute is intended to support other ec2 compatible apis (like openstack where flavors are customizable), then the\r\nflavor list should be determined by querying the api endpoint.'
714,'',"AWS.collections fails with ArgumentError\nI've just fired up fog for the first time with the `fog` command line tool.  The structure page on the fog website suggests that I run `AWS.collections` to see what's available.  This command fails with the following output:\r\n\r\n>> AWS.collections\r\n[WARNING] AWS[:cdn] is not recommended, use CDN[:aws] for portability\r\n[WARNING] AWS[:compute] is not recommended, use Comptue[:aws] for portability\r\n[WARNING] AWS[:dns] is not recommended, use DNS[:aws] for portability\r\nArgumentError: Unrecognized service: :sts\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin/aws.rb:90:in `block in []'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin/aws.rb:93:in `yield'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin/aws.rb:93:in `default'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin/aws.rb:93:in `[]'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin.rb:47:in `block in collections'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin.rb:47:in `map'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/lib/fog/bin.rb:47:in `collections'\r\n\tfrom (irb):1:in `<top (required)>'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/bin/fog:52:in `block in <top (required)>'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/bin/fog:52:in `catch'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/gems/fog-1.1.2/bin/fog:52:in `<top (required)>'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/bin/fog:19:in `load'\r\n\tfrom /root/rds_db_tool/vendor/bundle/ruby/1.9.1/bin/fog:19:in `<main>'"
713,'','Security Group vs. Subnet on VPC instance\nI was just reviewing the code for fog, and came across this comment:\r\n\r\n          # If subnet is defined we are working on a virtual private cloud.\r\n          # subnet & security group cannot co-exist. I wish VPC just ignored\r\n          # the security group parameter instead, it would be much easier!\r\n          if subnet_id\r\n            options.delete(\'SecurityGroup\')\r\n          else\r\n            options.delete(\'SubnetId\')\r\n          end\r\n\r\n\r\nI\'m currently working on implementing VPC, and when I output the instance, I get this:\r\n\r\n\r\n  <Fog::Compute::AWS::Server\r\n    id="i-c09fe289",\r\n    ami_launch_index=0,\r\n    availability_zone="eu-west-1c",\r\n    block_device_mapping=[],\r\n    client_token=nil,\r\n    dns_name=nil,\r\n\r\n    groups=["sg-4168742d", "WebServerSG"],\r\n\r\n    flavor_id="m1.small",\r\n    image_id="ami-f60e3c82",\r\n    kernel_id="aki-4deec439",\r\n    key_name="KEY",\r\n    created_at=Thu Jan 26 10:47:50 UTC 2012,\r\n    monitoring=false,\r\n    placement_group=nil,\r\n    platform=nil,\r\n    product_codes=[],\r\n    private_dns_name=nil,\r\n    private_ip_address="PRIVATE IP",\r\n    public_ip_address="PUBLIC IP",\r\n    ramdisk_id=nil,\r\n    reason=nil,\r\n    root_device_name=nil,\r\n    root_device_type="instance-store",\r\n    state="running",\r\n    state_reason={},\r\n\r\n    subnet_id=nil,\r\n\r\n    tenancy="default",\r\n    tags={"Name"=>"region-20120126-1052-13", "Project"=>"region", "Roles"=>"region"},\r\n    user_data=nil\r\n\r\n\r\nThis server is a VPC server, has an SG defined, and subnet_id set to nil. It appears that this is something that fog is doing, because if I look at the subnet ID in the EC2 Instances GUI, I see this:\r\n\r\nSubnet ID: subnet-<RANDOM ID>\r\n\r\nIt looks like Amazon has changed the API so that SGs and subnets can coexist. Does Fog need to be updated?\r\n\r\n--Noah'
712,'',"[aws|elb] Updated Load Balancers and Listeners to support the InstanceProtocol attribute\nAdded the ability to specify a protocol to use when sending traffic to ELB registered instances as described in:\r\nhttp://docs.amazonwebservices.com/ElasticLoadBalancing/latest/APIReference/API_Listener.html\r\n\r\nMy changes work for my app's purposes and the updated mocked ELB tests still pass. If I've missed anything please let me know."
711,'','[cloudstack|compute] Rounded out SSH Key and Snapshot Policy support\nAdded additional actions for ssh keys and snapshot policies. Ignore previous pull request.\r\n\r\n'
710,'','Rounded out SSH key and Snapshot Policy support\n'
709,'','another fix to the fix\n'
708,'','minor cleanup and a couple of bugs\n'
707,'',"Cannot Destroy Local::File\n    NoMethodError: undefined method `exists?' for Dir:Class\r\n    from /usr/lib/ruby/gems/1.8/gems/fog-1.1.2/lib/fog/local/models/storage/file.rb:53:in `destroy'\r\n    from /usr/lib/ruby/gems/1.8/gems/fog-1.1.2/lib/fog/local/models/storage/file.rb:43:in `times'\r\n    from /usr/lib/ruby/gems/1.8/gems/fog-1.1.2/lib/fog/local/models/storage/file.rb:43:in `destroy'\r\n\r\n`Dir.exist?` and `Dir.exists?` are not present in ruby-1.8.7.\r\n"
706,'','added support for server-side encryption on s3\nAdds an "encryption" attribute to Fog::Storage::AWS::File to enable S3\'s server-side encryption.'
705,'',"Caching with signature in url\nI may not 100% understand the issue here, so I'm posting in hopes of either a resolution, or maybe better understanding.\r\n\r\nI've got a photo site, that needs to protect uploaded data stored on S3. This is done with carrierwave/fog. \r\n\r\n```ruby\r\nCarrierWave.configure do |config|\r\n  \r\n  # Store the files locally for development\r\n  config.storage = (Rails.env.development? or Rails.env.test?) ? :file : :fog\r\n  config.fog_credentials = {\r\n    :provider               => 'AWS',\r\n    :aws_access_key_id      => 'xxxxxxxxxxxxxx',\r\n    :aws_secret_access_key  => 'xxxxxxxxxxxxxx',\r\n    :region                 => 'us-east-1'\r\n  }\r\n  config.fog_public     = false\r\n  config.fog_directory  = 'xxxxxxxxxxxxxx'\r\n  config.fog_attributes = { 'Cache-Control'=>'max-age=315576000', 'Expires' => 1.week.from_now.httpdate }\r\n\r\nend\r\n```\r\n\r\nThe issue is that when I set fog_public to false, images are no longer cached, because the signature in the url changes. The signature appears to be generated for every request regardless of time in between. For example, you can hit a page with 50 images all images are downloaded, refresh immediately, still downloaded... This can be verified with chromes inspector, or firebug in firefox. Status code should be 304 Not Modified, but instead is 200 OK.\r\n\r\nSo, my question is: Is caching supported on private urls with s3 using fog, or should I work out other means for serving protected urls, or am I just plain doing it wrong?\r\n\r\nThanks!"
704,'',"This patch allows the ability to create 'blank' vms in vsphere\nThis patch allows the ability to create 'blank' vms in vsphere"
703,'','first cleanup of libvirt fog code\n'
702,'','[aws|storage] Add bucket lifecycle / object expiration requests.\n'
701,'','Security groups parser fix\nthe security groups parser was not handling groupid correctly.  It seems it never has :/'
700,'',"[aws|storage] Fix put bucket website test, request returns not found whe...\n...n the bucket does not exist.\r\n\r\nFailing:\r\n\r\n```\r\n$ bundle exec shindo tests/aws/requests/storage/ +aws\r\n      #put_bucket_website('fognonbucket', 'index.html') - raises Excon::Errors::Forbidden\r\n      Expected(200) <=> Actual(404 Not Found)\r\n```"
699,'','One more typo fix.\n'
698,'','AWS PUT Bucket lifecycle support\nAre there any plans to support the Object Expiration feature in AWS S3?\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/RESTBucketPUTlifecycle.html\r\n\r\nShould the addition of this feature be similar to the proposed changes to add versioning?\r\nhttps://github.com/fog/fog/pull/681 (i.e. should these changes be used as a good example of how to code the lifecycle feature)\r\n\r\n'
697,'jeffmccune','[vsphere] Add the ability to create linked clones in vsphere\nAdd the ability to create linked clones in vsphere'
696,'',"enable_metrics_collection requires a granularity argument\nThe request requires a granularity argument, but the corresponding model method doesn't supply one. Defaulting it to  '1Minute' because that is currently the only legal value"
695,'','Fixed a typo in the warning.\n'
694,'','[ibm] Initial IBM SmartCloud support\nHi, this is my first contribution to Fog so any pointing out of things that need to be fixed first would be appreciated. I\'ve added a module for the IBM SmartCloud REST API -- I don\'t think I can link to the actual API if you\'re not logged in, but general information is here: https://www-147.ibm.com/cloud/enterprise/support/ I\'ve called the module "IBM". There are compute and storage providers.\r\n\r\nWork is still needed and documentation needs to be added (I pulled out the mocks because I wasn\'t quite sure what I was doing, but I intend to fill them out), but we are currently successfully using it to provision instances with a Fog-based tool that previously only supported AWS, and wanted to get some early feedback.\r\n\r\nThanks!'
693,'','implement respond_to? corresponding to method_missing\n'
692,'jeffmccune','Feature/master/robustness and similar to vsphere\n This patch has several purposes.  Firstly this patch brings the Fog vmfusion provider in line with the recently released v0.4.0 version of the Fission project by aligning various method names.  During this sync up servers.rb was modified to obtain all VM states and passing them to the raw object instead of doing so when attributes are obtained inside server.rb.  This improves performance a lot since it reduces the need to run vmrun for every VM on the system.  Other changes being made to the provider are so that it returns data and acts more similar to the vsphere provider while still keeping backward compatibility with the original implementation; which was to be more similar to various cloud providers.'
691,'jeffmccune',"[vsphere] this patch allows the ability to create 'blank' vms in vsphere rather than cloning\nthis patch allows the ability to create 'blank' vms in vsphere rather than cloning"
690,'',"Add Joyent Cloud support\nJoyent's Cloud API support is missing from Fog.io.\r\nThe public API documentation is available here: https://us-west-1.api.joyentcloud.com/docs\r\n\r\n-Trevor"
689,'','fix a typo in the vsphere vm_clone.rb file\ngit commit -a -m "fixed a conditional that was assigining = rather than evaluating == in vsphere clone routine.  This resulted in cloning from folders always failing"'
688,'','Simple doc change\nThe usual order is ID/Secret, so I swapped them in the doc.'
687,'','[aws|storage] Add mock for Fog::Storage::AWS#put_bucket_website\n'
686,'','[aws|storage] Delete multiple objects\nThis adds support for S3 "Delete multiple objects" as described in\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/multiobjectdeleteapi.html'
685,'','Fixed SQS :receive_message mock bug\nThere is a bug in the SQS mock... line 40:\r\n```keys = queue[:messages].keys[0, max_number_of_messages]```\r\n\r\nThe problem is that this limits the messages that it iterates over to only the first N... but if all of those N messages turn out to be "invisible", then it returns [].  Instead, it should return the first N _visible_ messages.\r\n\r\nI reworked the logic to make that happen.'
684,'','Add support for the new Terremark eCloud API\nSince July 2011 there is a new Terremark "Enterprise Cloud API Version 2011-07-01".\r\nURL: http://support.theenterprisecloud.com/kb/default.asp?id=984&Lang=1&SID=\r\nThis one also works with API keys.\r\nCan or will support for this API be added to a next version of fog? I\'m not much of a programmer...\r\nTIA!'
683,'','Fixes the rackspace_cdn_ssl public_url method\nWhen a directory is initially saved, it was defaulting to the X-CDN-URI instead of the X-CDN-SSL-URI.\r\n\r\nThis fixes my issues noted on #223.'
682,'','Correct an error with long keys where Base64.encode64 adds "\\n" at 60 chars\n'
681,'',"S3 versioning models\nThis is based off pull request #672.  It adds S3 model support for versioning.  Since most of the model methods already allowed passing of an options hash, we can just pass through the 'versionId' value, which limited the number of changes necessary.\r\n\r\nFeedback on the Versions model would be appreciated it.  I tried to come up with a natural API.  The tricky part is a version could be an object deletion, which would be a nil file with metadata.  The Version model encapsulates the metadata with a corresponding method for fetching the file for a given version."
680,'',"Change to only do a 'head' on the file that we've copied directly in S3\nI operate on files of several gigabytes in size, and it's not good if my server tries to load all that stuff into RAM, so a 'head' is much better then a 'get'."
679,'','[aws|rds] Rds security group mocking. shindo security group.\nRDS security groups are fully mocked. Shindo tests were also implemented. They pass in mocking and non-mocking mode.\r\n\r\nFIX: RDS db instances mocking are improved so now they pass shindo tests.\r\n\r\n'
678,'',"security_groups.all crashes\nUsing 1.1.2:\r\n\r\n    Compute[:aws].security_groups.all\r\n    Excon::Errors::SocketError: EndTag: '</' not found\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/nokogiri-1.5.0/lib/nokogiri/xml/sax/push_parser.rb:47:in `native_write'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/nokogiri-1.5.0/lib/nokogiri/xml/sax/push_parser.rb:47:in `write'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/core/connection.rb:16:in `block in request'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/excon-0.9.4/lib/excon/response.rb:45:in `parse'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/excon-0.9.4/lib/excon/connection.rb:215:in `request_kernel'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/excon-0.9.4/lib/excon/connection.rb:89:in `request'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/core/connection.rb:20:in `request'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/aws/compute.rb:324:in `request'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/aws/requests/compute/describe_security_groups.rb:43:in `describe_security_groups'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/aws/models/compute/security_groups.rb:64:in `all'\r\n      from (irb):1:in `<top (required)>'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/bin/fog:52:in `block in <top (required)>'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/bin/fog:52:in `catch'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/bin/fog:52:in `<top (required)>'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/bin/fog:19:in `load'\r\n      from /Users/jay/.rvm/gems/ruby-1.9.3-p0/bin/fog:19:in `<main>'"
677,'',"Inconsistent API: :flavor vs :image\nThere's some inconsistency when creating a server on EC2, and it smells like the solution could be generalized. In 1.1.2, when calling `Compute[:aws].servers.create`:\r\n\r\n* `:flavor` wants a `Fog::Compute::AWS::Flavor` object, and will raise an error if it gets a string\r\n* `:flavor_id` wants a `String` (e.g. `'m1.large'`), and will raise an error if it gets an object\r\n* `:image` doesn't exist and gets ignored\r\n* `:image_id` wants a string, and will raise an error if it gets an object\r\n\r\nWhat is the general mechanism that relates `:flavor` to `:flavor_id`, if any? It seems to me that an ideal API would:\r\n\r\n* Raise an error if you call `create` with an attribute that doesn't exist\r\n* Support both `<attribute>` and `<attribute_id>` versions whenever possible\r\n* Either raise a specific error or coerce if you call it with the wrong object type (and I'd argue for coercion in this case, since the API is inherently large, confusing, and unstable due to the problem scope; the smarter it can be, the more discoverable it is)\r\n\r\nWhat do you think?  I'd be happy to submit a patch to the attribute handler but I'm not sure where to start looking. Actually, I have a suspicion the `flavor` magic happens here in `fog/aws/models/compute/server.rb`:\r\n\r\n\r\n        remove_method :flavor_id\r\n        def flavor_id\r\n          @flavor && @flavor.id || attributes[:flavor_id]\r\n        end\r\n\r\n        def flavor=(new_flavor)\r\n          @flavor = new_flavor\r\n        end\r\n\r\n        def flavor\r\n          @flavor ||= connection.flavors.all.detect {|flavor| flavor.id == flavor_id}\r\n        end\r\n\r\nbut I'm not sure where it should more properly go."
676,'','s3 encryption\nIs there currently a way to request that values be encrypted in s3 (i.e. server-side encryption)?  If not, will this feature be added soon?'
675,'',"[rackspace/compute] Add 30GB (30720) compute size\nRackspace has [30GB compute nodes][1]. If you've got these nodes on your\r\naccount and try to do a flavor.cores you an exception like:\r\n\r\n```\r\nTypeError: nil can't be coerced into Fixnum\r\n\tfrom /Users/philkates/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/rackspace/models/compute/flavor.rb:37:in `*'\r\n\tfrom /Users/philkates/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.2/lib/fog/rackspace/models/compute/flavor.rb:37:in `cores'\r\n\tfrom (irb):6:in `<main>'\r\n\tfrom ./bin/fog:52:in `block in <main>'\r\n\tfrom ./bin/fog:52:in `catch'\r\n\tfrom ./bin/fog:52:in `<main>'\r\n```\r\n\r\nThis is my incredibly simplistic fix.\r\n\r\n[1]: http://www.rackspace.com/cloud/cloud_hosting_products/servers/pricing/"
674,'','This patch add the ability to create a new security group in a VPC in ec2 by specifying the VPC ID.\nThis patch add the ability to create a new security group in a VPC in ec2 by specifying the VPC ID.'
673,'','Zerigo DNS - update_host fails with some options\nThere is a bug in the updae_host which says host_type not found.\r\n\r\nThe reason is :\r\n\r\n<pre>\r\n   optional_tags= \'\'\r\n          options.each { |option, value|\r\n            case option\r\n            when :host_type\r\n              optional_tags+= "<host-type>#{host_type}</host-type>" - Here it should say value instead of host_type\r\n            when :data\r\n              optional_tags+= "<data>#{data}</data>" - Same here.. it should say value instead of data\r\n            \r\n            end\r\n          }\r\n</pre>'
672,'',"S3 versioning improvements\nI implemented S3 versioning mocking in all the necessary requests (at least I think so).  This is a rather large changeset, so I'd appreciate feedback.  I held off on the model changes for now so I didn't end up tossing work in the event this gets rejected."
671,'','[docs] Update GitHub repository references from geemus/fog to fog/fog.\nWhile the URLs were updated in e3dfde84, references to the GitHub repository still say geemus/fog while linking to fog/fog.\r\n\r\nThis commit updates those references to the new fog/fog repository.'
670,'',"ELB policies\nAllow policies to be set on ELB. This takes the ELB API up to 2011-11-15. One issue to note is that passing a valid SSH public key to the public key policy doesn't work. Using the SERVER_CERT_PUBLIC_KEY does. :("
669,'',"save the region in a instance variable\nHi,\r\n\r\nI've added a instance variable for @region similar to this issue https://github.com/fog/fog/issues/654\r\n\r\nBest Regards,\r\nDaniel"
668,'','Invalid date format in gemspec\nHello\r\n\r\nI see a problem when trying to use the Fog gem:\r\n\r\n    Invalid gemspec in [.gems/ruby/1.8/specifications/fog-1.1.2.gemspec]: invalid date format in specification: "2011-12-18 00:00:00.000000000Z"\r\n\r\nI am using\r\n* Ubuntu 11.10\r\n* Ruby 1.8.7\r\n* Rubygems 1.7.2\r\n\r\nI can fix the problem by manually editing the gemspec after installing the gem, removing the time portion of the `s.date` entry.\r\n\r\nFrom looking around on Google, it appears that this may be a problem with building the gem with Ruby 1.9 and then trying to run it on 1.8.\r\n\r\n(However, I do not see the problem on Ubuntu 10.10, Ruby 1.8.7, Rubygems 1.3.7.)\r\n\r\nAny ideas?\r\n-Ben\r\n'
667,'',"fix for free choice of region\nHi,\r\n\r\nI've fixed the :region option similarly to the other aws services.\r\n\r\nBest Regards,\r\nDaniel"
666,'',"Concurrency (with Carrierwave)\nHi there.\r\n\r\nI submitted a ticket over at Carrierwave's issues page and was wondering if you could take a look.\r\n\r\nhttps://github.com/jnicklas/carrierwave/issues/564\r\n\r\nIt's about trying to gain more concurrency (using Threads) when transferring files to Cloud Files. I have listed the details in the above mentioned ticket. It seems to keep throwing `Excon::Errors::SocketError: getaddrinfo: nodename nor servname provided, or not known` exceptions whenever I use threads to transfer files.\r\n\r\nThanks!"
665,'','100% CPU when used with awesome_print\nHi there,\r\n\r\nJust wanted to request your help do debug https://github.com/michaeldv/awesome_print/issues/68\r\n\r\nThanks!\r\nMichael\r\n'
664,'','Allow use of sa-east-1 as a valid region in the EC2 mock.\n'
663,'','Rails Carrier Wave/fog and JQuery Uploader to Amazon S3\nGooday...\r\n\r\nI am trying to implement the multiple uploading to Amazon S3 (https://github.com/jnicklas/carrierwave/blob/master/README.md) (under Using Amazon S3)\r\n\r\nBut I got an error inside log file:\r\n```\r\nStarted POST "/images?project_id=18" for 124.106.90.29 at Wed Dec 14 19:11:47 -0600 2011\r\n  Processing by ImagesController#create as JS\r\n  Parameters: {"project_id"=>"18", "authenticity_token"=>"9z0CzTtMwxgfdsyFLCNzx44qqRDT8F7+6F/RsVzUe4=", "utf8"=>"â", "image"=>{"carimage"=>#<ActionDispatch::Http::UploadedFile:0x6eab8de86708 @content_type="image/jpeg", @headers="Content-Disposition: form-data; name=\\"image[carimage]\\"; filename=\\"stroke_holding.jpg\\"\\r\\nContent-Type: image/jpeg\\r\\n", @tempfile=#<File:/tmp/RackMultipart20111214-5354-1b4qtl7-0>, @original_filename="stroke_holding.jpg">, "project_id"=>"18"}}\r\n  [1m[35mProject Load (0.2ms)[0m  SELECT `projects`.* FROM `projects` WHERE `projects`.`id` = 18 LIMIT 1\r\n  [1m[36m (0.1ms)[0m  [1mBEGIN[0m\r\n  [1m[35mSQL (1.2ms)[0m  INSERT INTO `images` (`caption`, `carimage`, `created_at`, `proj_photo_content_type`, `proj_photo_file_name`, `proj_photo_file_size`, `proj_photo_updated_at`, `project_id`, `updated_at`) VALUES (NULL, \'stroke_holding.jpg\', \'2011-12-15 01:11:48\', NULL, NULL, NULL, NULL, 18, \'2011-12-15 01:11:48\')\r\n  [1m[36m (1.7ms)[0m  [1mROLLBACK[0m\r\nCompleted 500 Internal Server Error in 2635ms\r\n\r\nExcon::Errors::MovedPermanently (Expected(200) <=> Actual(301 Moved Permanently)\r\n  request => {:port=>"443", :method=>"PUT", :idempotent=>true, :body=>#<File:/home/ngtv2/activedesigns/public/uploads/tmp/20111214-1911-5354-1557/stroke_holding.jpg>, :headers=>{"Authorization"=>"AWS XXXXXXXXXXXXXXXXXXXXXXXXXXXXX:XXX/XXXXXXXXXXXXXXXXXXX=", "x-amz-acl"=>"public-read", "Date"=>"Thu, 15 Dec 2011 01:11:48 +0000", "Content-Type"=>"image/jpeg", "Content-Length"=>64387, "Host"=>"sample.s3-eu-west-1.amazonaws.com:443"}, :host=>"sample.s3-eu-west-1.amazonaws.com", :query=>nil, :connect_timeout=>60, :expects=>200, :read_timeout=>60, :scheme=>"https", :write_timeout=>60, :path=>"/stroke_holding.jpg", :mock=>nil}\r\n  response => #<Excon::Response:0x6eab8c663f18 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>PermanentRedirect</Code><Message>The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint.</Message><RequestId>2990AE131EF6DCE2</RequestId><Bucket>sample</Bucket><HostId>q+XXXXXXXXXXXXXXXXXXX/XXXXXXXXXXXXXXXXXXXXXXXXXXXXX</HostId><Endpoint>s3.amazonaws.com</Endpoint></Error>", @status=301, @headers={"x-amz-id-2"=>"q+XXXXXXXXXXXXXXXXXXXXXXXXXXXXX/XXXXXXXXXXXXXXXXXXX", "Transfer-Encoding"=>"chunked", "Date"=>"Thu, 15 Dec 2011 01:11:49 GMT", "Content-Type"=>"application/xml", "x-amz-request-id"=>"2990AE131EF6DCE2", "Server"=>"AmazonS3", "Connection"=>"close"}>):\r\n  app/controllers/images_controller.rb:37:in `create\'\r\n\r\nRendered vendor/bundle/ruby/1.8/gems/actionpack-3.1.1/lib/action_dispatch/middleware/templates/rescues/_trace.erb (1.4ms)\r\nRendered vendor/bundle/ruby/1.8/gems/actionpack-3.1.1/lib/action_dispatch/middleware/templates/rescues/_request_and_response.erb (1.0ms)\r\nRendered vendor/bundle/ruby/1.8/gems/actionpack-3.1.1/lib/action_dispatch/middleware/templates/rescues/diagnostics.erb within rescues/layout (4.4ms)\r\n```\r\nHere is my line 37 in images controller:\r\n```\r\n def create\r\n    @image = Image.new(params[:image])\r\n    if @image.save                                                                   #line 37\r\n\t  render :json => [@image.to_jq_upload].to_json\r\n    end\r\nend\r\n```\r\n\r\nI also get something like this in error console:\r\n\r\n```\r\nError: not well-formed\r\nSource File: https://s3-console-us-standard.console.aws.amazon.com/DeliverHttp\r\nLine: 1, Column: 1\r\nSource Code:\r\n{\r\n```\r\n\r\n## I also posted this on [stackoverflow](http://stackoverflow.com/questions/8514247/rails-carrier-wave-and-jquery-uploader-to-amazon-s3)'
662,'','Added sa-east-1 region\n'
661,'','Add SÃ£o Paulo Brazil  Region to S3\n'
660,'','Do you need to hard code EC2 regions?\n    aws = Fog::Compute.new(ec2credentials.merge({:provider=>\'AWS\'}))\r\n    @regions = aws.describe_regions.body["regionInfo"].map {|region| region["regionName"]}\r\n    @compute = {}\r\n    @regions.each do |region|\r\n      @compute.merge!(region => Fog::Compute.new(ec2credentials.merge({:provider=>\'AWS\',:region=>region})))\r\n    end\r\n\r\nI use the above code to create a connection to each region and put them in a hash keyed by region name but it breaks whenever amazon release a new region. Can we not make amazon the source of truth for what regions exist instead of hard coding them in fog?\r\n\r\nThanks.\r\nTom Hall'
659,'','Add new elasticache endpoints\n'
658,'',"Fixing Rackspace's lack of integer-as-string support \nas per https://github.com/fog/fog/pull/657#issuecomment-3145337"
657,'',"Rackspace does not accept integer-like strings, need to cast before send...\nRackspace doesn't accept integer-strings. Since imageId and flavorId isn't being validated before being included into the model, fog should probably cast them into integers before sending them on."
656,'',"1.1.2 Artifacts\nIt looks like 1.1.2 is available on RubyGems, but there's no tag and no changelog entry for the release."
655,'','Simple bug in saving metric_statistic model\nBug fix is removing this line ... looks like a WIP:\r\n\r\n          put_opts.merge!(\'Timestamp\' => dimensions) if timestamp\r\n\r\nIt sends a bad request to the API, the \'Timestamp\' key is replaced with dimensions. The test for this is marked as \'pending\', but it\'s easy to show it is broken in fog/master and that this one liner fixes it:\r\n\r\nSymptom with fog master:\r\n\r\nfog#> instanceid = "i-xxxxxxx"\r\nfog#> params = { :timestamp => Time.now.iso8601, :minimum => 0, :maximum => 60, :sum => 100, :average => 3, :sample_count => 10, :namespace => "hom_custom", :metric_name => "PassengerQueue", :value => 10, :unit => \'None\', \'Dimensions\' => [{\'Name\' => \'InstanceId\', \'Value\' => instanceid}]}\r\nfog#> Fog::AWS::CloudWatch.new(:region => "us-west-1").metric_statistics.new(params).save\r\n\r\nresponse => #<Excon::Response:0x000008046d28b8 @body="<ErrorResponse xmlns=\\"http://monitoring.amazonaws.com/doc/2010-08-01/\\">\\n  <Error>\\n    <Type>Sender</Type>\\n    <Code>MalformedInput</Code>\\n    <Message>timestamp must follow ISO8601</Message>\\n  </Error>\\n  <RequestId>d47bdedf-25c8-11e1-bbe6-419fabbfd753</RequestId>\\n</ErrorResponse>\\n", @headers={"x-amzn-RequestId"=>"d47bdedf-25c8-11e1-bbe6-419fabbfd753", "Content-Type"=>"text/xml", "Content-Length"=>"281", "Date"=>"Tue, 13 Dec 2011 20:27:08 GMT"}, @status=400>'
654,'','Creating a EU S3 bucket through region on connection not working\nThe feature introduced in 49b7c122ab95b2037fb38d3f9cac58a1074e8ed1 has since broken:\r\n\r\n```\r\nirb(main):008:0> connection.directories.create :key => "fog-demo-#{Time.now.to_i}"\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)                                                                                                                                     \r\n  request => {:query=>nil, :method=>"PUT", :expects=>200, :connect_timeout=>60, :headers=>{"Authorization"=>"", "Date"=>"Tue, 13 Dec 2011 22:27:49 +0000", "Content-Length"=>0, "Host"=>"fog-demo-1323815269.s3-eu-west-1.amazonaws.com:443"}, :body=>nil, :read_timeout=>60, :mock=>nil, :port=>"443", :write_timeout=>60, :idempotent=>true, :host=>"fog-demo-1323815269.s3-eu-west-1.amazonaws.com", :path=>"/", :scheme=>"https"}                                                                                                                                 \r\n  response => #<Excon::Response:0xb6dac1c0 @status=400, @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>IllegalLocationConstraintException</Code><Message>The unspecified location constraint is incompatible for the region specific endpoint this request was sent to.</Message><RequestId></RequestId><HostId></HostId></Error>", @headers={"x-amz-id-2"=>"", "Transfer-Encoding"=>"chunked", "Date"=>"Tue, 13 Dec 2011 22:28:07 GMT", "Content-Type"=>"application/xml", "x-amz-request-id"=>"", "Server"=>"AmazonS3", "Connection"=>"close"}>                                                                                                  \r\n        from /home/betelgeuse/.gem/ruby/1.8/gems/excon-0.7.12/lib/excon/connection.rb:197:in `request\'\r\n        from /home/betelgeuse/.gem/ruby/1.8/gems/fog-1.1.1/lib/fog/core/connection.rb:20:in `request\' \r\n        from /home/betelgeuse/.gem/ruby/1.8/gems/fog-1.1.1/lib/fog/aws/storage.rb:375:in `request\'\r\n        from /home/betelgeuse/.gem/ruby/1.8/gems/fog-1.1.1/lib/fog/aws/requests/storage/put_bucket.rb:39:in `put_bucket\'  \r\n        from /home/betelgeuse/.gem/ruby/1.8/gems/fog-1.1.1/lib/fog/aws/models/storage/directory.rb:92:in `save\'   \r\n        from /home/betelgeuse/.gem/ruby/1.8/gems/fog-1.1.1/lib/fog/core/collection.rb:50:in `create\'\r\n```'
653,'',"MaxItems in Fog::DNS::AWS::Records\nI'm trying to list more than 100 records with Fog::DNS::AWS, and it appears it's ignoring the max_items, (or MaxItems) field\r\nHere, I've loaded a zone that has 140 records.  On the off chance that I should use the MaxItems vs max_items, I've tried both.\r\n\r\n\r\nruby-1.9.2-p136 :037 > @zone.records.all('max_items'=>999).count\r\n => 98 \r\n\r\nruby-1.9.2-p136 :039 >   @zone.records.all('MaxItems'=>999).count\r\n => 98 \r\n\r\nIf it's just a usage issue, updating the docs would be most appreciated!\r\n\r\n\r\n"
652,'','Adds the ability to specify security groups by SecurityGroupId which is needed for VPC Security Groups\nThis patch adds the ability to specify security groups by security group id, rather than group name.  This is a required feature to use security groups within a VPC'
651,'',"Example of using fog from the cli\nThis looks like it's possible. I've sorta figured it out by looking at the source and piecing things together. It would really help to have some documentation or even a short example. That is, if it is indeed possible to provision from the cli. I haven't gotten it to actually work yet."
650,'','rackspace load balancer attribute connection logging unexpectedly returns nil\nHi,\r\n\r\n  Right after I enabled the connection logging attribute, when I access fog_lb.connection_logging, it returned true. \r\n\r\n  But after I re-established the connection, it seems always return nil. However, when I use the real version to get it, I can see {"enabled"=>true}. \r\n\r\n  I\'ve used the real version to get around it, but please have a check. \r\n\r\nThanks,\r\nKenson\r\n\r\nPS:\r\n > fog_lb.reload \r\n > fog_lb.connection_logging \r\n => nil    # set as true in last connection or on rackspace console\r\n\r\n > fog_lb.attributes[:connection_logging]\r\n => nil \r\n\r\n > fog_lb.disable_connection_logging \r\n => false \r\n > fog_lb.connection_logging \r\n => false\r\n\r\n > fog_lb.enable_connection_logging \r\n => true \r\n > fog_lb.connection_logging \r\n => true \r\n \r\n > fog_lb.connection.get_connection_logging(fog_lb.id)\r\n => #<Excon::Response:0x1b63e50 @status=200, @body={"connectionLogging"=>{"enabled"=>true}}, @headers={"Content-Type"=>"application/json", "Date"=>"Mon, 12 Dec 2011 06:17:57 GMT", "Content-Length"=>"38", "Server"=>"Rackspace Cloud Load Balancer API v1.7.17"}> \r\n'
649,'',"When I bootstrap an AWS instance it is timing out when trying to setup my keys\nWhen I bootstrap an AWS instance it is timing out when trying to setup my keys:\r\n\r\n```\r\n>> server = connection.servers.bootstrap({\r\n?>   :public_key_path => '~/.ssh/id_rsa.pub',\r\n?>   :private_key_path => '~/.ssh/id_rsa',\r\n?>   :flavor_id => 'c1.xlarge', # 64 bit, high CPU\r\n?>   :username => 'ubuntu'\r\n>> })\r\nTimeout::Error: execution expired\r\n...\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/aws/models/compute/server.rb:204:in `block in setup'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/aws/models/compute/server.rb:202:in `setup'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap'\r\n```\r\n\r\nHow do I debug what is going on/not going on? Suggestions?"
648,'',"NoMethodError: undefined method `match' for nil <-- key_factory.rb:48:in `load_data_private_key`\nAnyone know what causes this? I wasn't having this issue last night but its happening in 1.8.7/1.9.3 and various different bootstrap/create attempts:\r\n\r\n```\r\n>> hdb = connection.servers.bootstrap\r\nNoMethodError: undefined method `match' for nil:NilClass\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/key_factory.rb:48:in `load_data_private_key'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/key_manager.rb:218:in `load_identities'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/key_manager.rb:207:in `map'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/key_manager.rb:207:in `load_identities'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/key_manager.rb:100:in `each_identity'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/methods/publickey.rb:19:in `authenticate'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/session.rb:73:in `authenticate'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/session.rb:65:in `each'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh/authentication/session.rb:65:in `authenticate'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/net-ssh-2.2.1/lib/net/ssh.rb:190:in `start'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/fog-1.1.1/lib/fog/core/ssh.rb:52:in `run'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/fog-1.1.1/lib/fog/aws/models/compute/server.rb:205:in `setup'\r\n\tfrom /Users/drnic/.rvm/rubies/ruby-1.8.7-p352/lib/ruby/1.8/timeout.rb:67:in `timeout'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/fog-1.1.1/lib/fog/aws/models/compute/server.rb:204:in `setup'\r\n\tfrom /Users/drnic/.rvm/rubies/ruby-1.8.7-p352/lib/ruby/1.8/timeout.rb:67:in `timeout'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/fog-1.1.1/lib/fog/aws/models/compute/server.rb:202:in `setup'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/fog-1.1.1/lib/fog/aws/models/compute/servers.rb:102:in `bootstrap'\r\n\tfrom (irb):5\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/gems/fog-1.1.1/bin/fog:40\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/bin/fog:19:in `load'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.8.7-p352/bin/fog:19\r\n```"
647,'',"implement #scp_download method to allow downloads in addition to uploads...\ntitle says it all. if you are interested, i'm going to look into accompanying tests before you pull :)\r\n\r\nhope you like it!"
646,'','add query options for s3 to support response headers overwriting\nHi guys,\r\n\r\nWe are using your library (together with Carrierwave gem) in our project and I would like to thanks for that. Great job!\r\n\r\nCarrierwave uses Fog::Storage::AWS::File#url, Fog::Storage::AWS::Files#get_https_url and Fog::Storage::AWS#get_object_https_url methods to get url. Unfortunately those methods do not support query params such as "response-content-disposition". I have to added that.\r\n\r\nIt was quite difficult for me to follow your test convention on this project and I had not found any unit test for those methods. Another problem is that tests were not passing on my local before I\'ve changed anything, but that can be related with some missing configuration on my side. Therefore I have not added tests for that.\r\n\r\nIn the same time I am creating a pull request for carrierwave project to accept my change to "url" method. Carrierwave would require first changes on fog to work correctly, that\'s why I have left in carrierwave\'s Gemfile dependency to fog forked on autohaus24.\r\n\r\nPlease let me know if the changes are on acceptable level or there is anything that could be done better\r\n\r\nBest regards,\r\nMateusz Juraszek\r\nautohaus24.de'
645,'','Small typo in documentation on DNSMadeEasy\nDoes this mean I am a contributor now? :P '
644,'','Failed to enable a HTTP health monitor in rackspace load balancer\nWhen I call lb.enable_health_monitor("CONNECT", 10, 5, 2), it can enable the health monitor in rackspace load balancer, but when I tried to enable a HTTP one, it failed with error message "Fog::Rackspace::LoadBalancers::BadRequest: Updating to HTTP/HTTPS monitor. Please provide all required fields".\r\n \r\nWhen I examined the function connection.set_monitor with same parameters, it succeeded. \r\nWe expect the two function should be able to achieve the same job, don\'t we? \r\nPlease kindly have a check.\r\n\r\nThanks.\r\n\r\n\r\nQuotes:\r\nirb(main):054:0> lb.enable_health_monitor("HTTP", 10, 5, 2, {:status_regex => "^[234][0-9][0-9]$", :path=>"/", :body_regex=>" "})\r\n\r\nFog::Rackspace::LoadBalancers::BadRequest: Updating to HTTP/HTTPS monitor. Please provide all required fields.\r\n\tfrom /home/kc/.rvm/gems/ree-1.8.7-2011.03@cloudengine/gems/excon-0.7.6/lib/excon/connection.rb:194:in `request\'\r\n\tfrom /home/kc/.rvm/gems/ree-1.8.7-2011.03@cloudengine/gems/fog-1.0.0/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /home/kc/.rvm/gems/ree-1.8.7-2011.03@cloudengine/gems/fog-1.0.0/lib/fog/rackspace/load_balancers.rb:117:in `request\'\r\n\tfrom /home/kc/.rvm/gems/ree-1.8.7-2011.03@cloudengine/gems/fog-1.0.0/lib/fog/rackspace/requests/load_balancers/set_monitor.rb:25:in `set_monitor\'\r\n\tfrom /home/kc/.rvm/gems/ree-1.8.7-2011.03@cloudengine/gems/fog-1.0.0/lib/fog/rackspace/models/load_balancers/load_balancer.rb:97:in `enable_health_monitor\'\r\n\tfrom (irb):54:in `require\'\r\n\tfrom ./test/elbtest_rackspace.rb:78:in `require\'\r\n\tfrom /home/kc/.rvm/rubies/ree-1.8.7-2011.03/lib/ruby/1.8/irb.rb:54:in `start\'\r\n\tfrom /home/kc/.rvm/rubies/ree-1.8.7-2011.03/bin/irb:17\r\n\r\nirb(main):073:0> connection.set_monitor(lb.id, "HTTP", 10, 5, 2, {:status_regex => "^[234][0-9][0-9]$", :path=>"/", :body_regex=>" "})\r\n=> #<Excon::Response:0x1e2ff08 @body="", @headers={"Content-Type"=>"text/xml", "Date"=>"Thu, 08 Dec 2011 02:27:47 GMT", "Content-Length"=>"0", "Server"=>"Rackspace Cloud Load Balancer API v1.7.17"}, @status=202>\r\n\r\nirb(main):074:0> lb.health_monitor \r\n=> {"statusRegex"=>"^[234][0-9][0-9]$", "timeout"=>5, "delay"=>10, "type"=>"HTTP", "path"=>"/", "attemptsBeforeDeactivation"=>2, "bodyRegex"=>" "}\r\n'
643,'','Fixing rds mocking bug: It always shows the first instance when using servers.get\n'
642,'','[aws|dns] Add support for aliasing records to Elastic Load Balancers\nAdd support for fetching, creating, and deleting A record that can alias to an elastic load balancer.'
641,'',"AWS DNS (Route 53) - Support AliasTarget for Elastic Load Balancers\nRoute 53 API version 2011-05-05 added support for mapping A records to an Elastic Load Balancer CNAME via a special AliasTarget setting.\r\n\r\nDocs are here:\r\nhttp://docs.amazonwebservices.com/Route53/latest/APIReference/\r\n\r\nAliasTarget should be a hash that can be passed with `change_resource_record_sets` or fetched with `list_resource_record_sets`.  It requires a DNSName and a HostedZoneId.\r\n\r\nI spent a bunch of time trying to figure out how to add this, but just couldn't get it -- currently implemention of Route53 is a bit confusing.  Would appreciate help implementing it!"
640,'','Add implementation of DescribeInstanceStatus.\nAdded support for DescribeInstanceStatus for AWS against ec2 api version 2011-11-01.'
639,'',"Document AWS key pair handling\nAs described in #636, using multiple ssh keys on AWS can be really confusing for beginners.\r\n\r\nTo fix this, I've written a few paragraphs to describe the most common use cases.\r\n\r\nCheers,\r\npfleidi"
638,'',"vcloud tests broke other tests\nHi!\r\n\r\nSems like changes in vcloud subtree introduce issue with running other providers tests.\r\n\r\nWhen I run shindo tests/clodo from command lin, I get backtraces like this:\r\n\r\n  Fog::Compute[:clodo] | server requests (clodo)\r\n    No such file or directory - /home/mine/W/code/ruby/fog/tests/vcloud/data/v1.0 (Errno::ENOENT)\r\n      ./tests/vcloud/models/compute/conn_helper.rb:8:in `read'\r\n      ./tests/vcloud/models/compute/conn_helper.rb:8:in `request'\r\n      /home/mine/W/code/ruby/fog/lib/fog/clodo.rb:18:in `authenticate'\r\n      /home/mine/W/code/ruby/fog/lib/fog/clodo/compute.rb:136:in `authenticate'\r\n      /home/mine/W/code/ruby/fog/lib/fog/clodo/compute.rb:85:in `initialize'\r\n      /home/mine/W/code/ruby/fog/lib/fog/core/service.rb:67:in `new'\r\n...\r\n\r\nRunning rm tests/vcloud/models/compute/conn_helper.rb solve the problem (but not for vcloud, I think)\r\n\r\nProblem is introduced by commit with id 750fb59f2505955b33d8183511e2f467b626f7fb\r\n\r\nIt will be great, if somebody who work on vcloud subtree can move problem code in vcloud own namespace.\r\n\r\nThank you!\r\n"
637,'','basic RDS mocking\nHi,\r\n  this request contains basic rds mocking for create, describe, modify, delete and reset.\r\n\r\nThanks,\r\n\r\nRodrigo Estebanez'
636,'','Document SSH key management\nHello everyone,\r\n\r\nsome days ago I was using Fog to bootstrap a virtual machine using Compute::AWS. I was running into some strange timeout errors until I discovered, that these errors are caused by a failed SSH authentication.\r\n\r\nAs it turns out, a colleague of mine was using [bootstrap](https://github.com/fog/fog/blob/master/lib/fog/aws/models/compute/servers.rb#L74) with the same AWS credentials but different SSH keys. So the fog_default public key was already registered to the public key of my colleague and the attempts to log in with my key pair failed.\r\n\r\nIt took me quite a bit of time to grep through the fog source to figure out what I was doing wrong. While reading through the fog code, I found two ways to work around this problem:\r\n\r\n1. Use connection.import_key_pair() to register a custom key and pass in :key_name to bootstrap()\r\n2. Set Fog.credential to a custom name so the SSH public key gets registered using fog_#{custom_name}\r\n\r\n\r\nUsing the first workaround my code looked like:\r\n\r\n```ruby\r\nFog.credentials = Fog.credentials.merge({\r\n  :private_key_path => "./keys/my_custom_key",\r\n  :public_key_path => "./keys/my_custom_key.pub"\r\n})\r\n\r\nif connection.key_pairs.get(\'my_custom_key\').nil?\r\n  public_key = IO.read(\'./keys/my_custom_key.pub\')\r\n  connection.import_key_pair(\'my_custom_key\', public_key)\r\nend\r\n\r\nserver = connection.servers.bootstrap(\r\n  :key_name =>  \'my_custom_key\',\r\n  ...\r\n)\r\n```\r\nUsing the second, the code got much simpler code:\r\n\r\n```ruby\r\nFog.credential = \'my_custom_key\'\r\n\r\nconnection.servers.bootstrap(\r\n  :private_key_path => \'./keys/my_custom_key\',\r\n  :public_key_path => \'./keys/my_custom_key.pub\',\r\n  ...\r\n)\r\n```\r\n\r\n\r\nIt would be really great if this behavior was documented somewhere, so people wouldn\'t run into strange errors caused my wrong key management.'
635,'','Not possible to add priority to DNS record on Rackspace, making impossible to add MX records\nSeems that the Fog::Rackspace::Model::record.create ignores a :priority parameter.'
634,'','Chunked file uploads in Rackspace\nWas just wondering if fog supports/will support the ability to send chunked files to rackspace?\r\n\r\nhttp://docs.rackspace.com/files/api/v1/cf-devguide/content/Chunked_Transfer_Encoding-d1e2092.html'
633,'','Fix regression in Rakefile introduced in 70e7ea1\nCommit 70e7ea133b5be629ec54bd26b2a456cb45abfd89 changed the format of Fog.providers from an array to a hash using symbols as keys and strings as values.  Thus Fog.providers.each yielded two-element arrays rather than a string scalar as it did before.  The tests themselves were fine but portions of the Rakefile were expecting the old format.  \r\n\r\nWith this pach "bundle exec rake" works once again.'
632,'','Auto-Retry for All Operations\nAll operations should have an auto-retry mechanism to handle ephemeral failures.\r\n\r\nE.g., `#put_object` (storage) should accept some additional option parameters specifying an optional auto-retry mechanism, including enabled/disabled, number of attempts, delay strategy such as exponential backoff, etc.\r\n'
631,'','[core] Cast Fog.wait_for interval to float.\nsleep() is strict. Allow more liberal values like\r\nActiveSupport::Durations:\r\n\r\n   Fog.wait(1.hour, 10.seconds) { â¦ }'
630,'','* implement :destroy_volumes in Server.destroy (libvirt provider)\n'
629,'','* Add server_name environment variable to ip_command\n'
628,'','* Add missing recognized :libvirt_ip_command\n'
627,'','* remove unnecessary debugging\n'
626,'',"[aws|dns] Add Record#modify method\nAllow modifying a Route 53 dns record. It generates a single BatchRequest that deletes the current record and creates a record with the new attributes.\r\n\r\nE.g.:\r\n\r\n    # Create a record\r\n    record = zone.records.create(:name => 'example.tld', :value => 1.1.1.1, :ttl => 60, type => 'A')\r\n\r\n    # Change the value and ttl\r\n    record.modify(:value => 2.2.2.2, :ttl => 300)"
625,'',"parse SQS timestamps as milliseconds\nFixes #623\r\n\r\nI don't see many other focussed tests, and this is just a test of the SQS Parser class for receiving messages. Would be interested to see how to implement the test in Shindo, if that's suitable.\r\n\r\nApologies for two requests, this one has more readable test output."
624,'',"parse SQS timestamps as milliseconds\nFixes #623\r\n\r\nI don't see many other focussed tests, and this is just a test of the SQS Parser class for receiving messages. Would be interested to see how to implement the test in Shindo, if that's suitable."
623,'','bignum too big to convert into `long\'\nHi there,\r\n\r\nOn a 32-bit REE system, when I receive a message with AWS::SQS, I get the aforementioned exception. It\'s choking [when trying to convert timestamps to Time objects](https://github.com/fog/fog/blob/master/lib/fog/aws/parsers/sqs/receive_message.rb#L27).\r\n\r\nIn my particular case, the @value variable had this string in it: "1322229918740".\r\n\r\nWill try to submit a test case / patch shortly.'
622,'','Issue/602/callback errors\nFix for #602.  Callbacks in an error state should now throw an error (when accessed through models).'
621,'',"Address family not supported by protocol - connect(2)\ncarrierwave seems to have updated their rackspace support to interface through fog, and I'm getting the above error whenever interacting with rackspace on my server. anyone seen this before?"
620,'','FOG / Excon - EOFError\nI was trying to upload a few (about 50) images using Paperclip + fog.io + Rackspace and I got this error after a few uploads (usually between 10o and 20o upload):\r\n\r\n    EOFError\r\n     /home/dals/.rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/openssl/buffering.rb:190:in `readline\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/excon-0.7.6/lib/excon/response.rb:22:in `parse\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/excon-0.7.6/lib/excon/connection.rb:178:in `request\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.1.1/lib/fog/core/connection.rb:20:in `request\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.1.1/lib/fog/rackspace.rb:59:in `authenticate\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.1.1/lib/fog/rackspace/storage.rb:87:in `initialize\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.1.1/lib/fog/core/service.rb:67:in `new\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.1.1/lib/fog/core/service.rb:67:in `new\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/fog-1.1.1/lib/fog/storage.rb:25:in `new\'\r\n     /home/dals/.rvm/gems/ruby-1.9.2-p290/gems/paperclip-2.4.5/lib/paperclip/storage/fog.rb:155:in `connection\'\r\n     ...\r\nfull stack: https://gist.github.com/1383745\r\n\r\nLooking around I found I could mitigate this error by providing :persistent => false on fog_credentials, but it is not working for me.\r\n\r\nPaperclip options:\r\n\r\n```ruby\r\nPaperclip::Attachment.default_options.update({\r\n  :path => "images/:class/:id/:style/:hash/:basename",\r\n  :hash_secret => "blablabla",\r\n  :storage => :fog,\r\n  :fog_credentials => {\r\n    :provider           => \'Rackspace\',\r\n    :rackspace_username => \'blablabla\',\r\n    :rackspace_api_key  => \'blablabla\',\r\n    :persistent => false\r\n  },\r\n  :fog_directory => \'blablabla\',\r\n  :fog_public => true,\r\n  :fog_host => \'http://blablabla.rackcdn.com\'\r\n})\r\n```\r\n\r\nGems versions:\r\n\r\n    Using rake (0.9.2.2) \r\n    Using abstract (1.0.0) \r\n    Using activesupport (3.0.11) \r\n    Using builder (2.1.2) \r\n    Using i18n (0.5.0) \r\n    Using activemodel (3.0.11) \r\n    Using erubis (2.6.6) \r\n    Using rack (1.2.4) \r\n    Using rack-mount (0.6.14) \r\n    Using rack-test (0.5.7) \r\n    Using tzinfo (0.3.31) \r\n    Using actionpack (3.0.11) \r\n    Using mime-types (1.17.2) \r\n    Using polyglot (0.3.3) \r\n    Using treetop (1.4.10) \r\n    Using mail (2.2.19) \r\n    Using actionmailer (3.0.11) \r\n    Using arel (2.0.10) \r\n    Using activerecord (3.0.11) \r\n    Using activeresource (3.0.11) \r\n    Using bcrypt-ruby (3.0.1) \r\n    Using bundler (1.0.21) \r\n    Using cocaine (0.2.0) \r\n    Using orm_adapter (0.0.5) \r\n    Using warden (1.1.0) \r\n    Using devise (1.5.0) \r\n    Using excon (0.7.6) \r\n    Using formatador (0.2.1) \r\n    Using multi_json (1.0.3) \r\n    Using net-ssh (2.2.1) \r\n    Using net-scp (1.0.4) \r\n    Using nokogiri (1.5.0) \r\n    Using ruby-hmac (0.4.0) \r\n    Using fog (1.1.1) \r\n    Using json (1.6.1) \r\n    Using rdoc (3.11) \r\n    Using thor (0.14.6) \r\n    Using railties (3.0.11) \r\n    Using jquery-rails (1.0.18) \r\n    Using mysql2 (0.2.17) \r\n    Using newrelic_rpm (3.3.0) \r\n    Using paperclip (2.4.5) \r\n    Using rails (3.0.11) \r\n    Using rails-i18n (0.1.11) \r\n    Using sqlite3 (1.3.4) '
619,'','Rackspace DNS does not work for London Datacenter\nIn order to use London datacenter it is necessary to pass :rackspace_dns_endpoint to the contructor. However, this is not allowed.\r\n\r\nThis may be fixed with a recognize instruction in fog/rackspace/dns.rb'
618,'','Fixes for issues 616 and 617\n'
617,'',"Exception listing nodes using the libvirt provider\n<snip>\r\nc = Fog::Compute.new(  { :provider => 'Libvirt', :libvirt_uri => 'xen+ssh://foobarstuff' }  )\r\ncompute.nodes.all\r\n</snip>\r\n\r\n/home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/libvirt/compute.rb:98:in `method_missing': undefined method `connection' for #<Fog::Compute::Libvirt::Real:0x00000001f53290> (NoMethodError)\r\n\tfrom /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/libvirt/models/compute/nodes.rb:29:in `all'\r\n\tfrom test.rb:25:in `<main>'\r\n\r\n\r\nThis little patch fixes the issue for me:\r\n\r\n--- libvirt/models/compute/nodes.rb.orig\t2011-11-18 16:22:07.206508066 +0100\r\n+++ libvirt/models/compute/nodes.rb\t2011-11-18 16:23:33.148579634 +0100\r\n@@ -26,7 +26,7 @@\r\n               node_info[param]=nil\r\n             end\r\n           end\r\n-          node_info[:uri]=connection.connection.uri\r\n+          node_info[:uri]=connection.uri\r\n           data << { :raw => node_info }\r\n           require 'pp'\r\n           pp node_info\r\n"
616,'','libvirt provider missing libvirt_username and libvirt_password as "recognized" parameters?\nHiya!\r\n\r\nI\'m trying to connect to an ESX 4 (using the libvirt fog provider) that needs user/pass but it raises an exception if the little patch below is not applied:\r\n\r\n/home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/core/service.rb:193:in `validate_options\': Unrecognized arguments: libvirt_username, libvirt_password (ArgumentError)\r\n\tfrom /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/core/service.rb:58:in `new\'\r\n\tfrom /home/rubiojr/.rvm/gems/ruby-1.9.3-p0/gems/fog-1.1.1/lib/fog/compute.rb:31:in `new\'\r\n\tfrom fog_libvirt_esx_info.rb:37:in `<main>\'\r\n\r\nNot sure if it\'s the right thing to do so I\'m not submitting a pull request.\r\n\r\n--- libvirt/compute.rb.orig\t2011-11-18 15:45:44.157356945 +0100\r\n+++ libvirt/compute.rb\t2011-11-18 15:45:59.619547859 +0100\r\n@@ -8,6 +8,7 @@\r\n     class Libvirt < Fog::Service\r\n \r\n       requires :libvirt_uri\r\n+      recognizes :libvirt_username, :libvirt_password\r\n \r\n       model_path \'fog/libvirt/models/compute\'\r\n       model       :server\r\n'
615,'','Fix exceptions from nil credential value\n'
614,'','[core] `@credential` should always be a symbol\nSimilar to #504, say your ~/.fog had multiple stanzas:\r\n\r\n```yaml\r\n:default:\r\n  :aws_access_key_id: aaa\r\ntest:\r\n  :aws_access_key_id: bbb\r\n:prod:\r\n  :aws_access_key_id: ccc\r\n```\r\n\r\nBy default, fog will look for either the credential *symbol* `:default` or for the *string* stored in `FOG_CREDENTIAL` (in `lib/fog/core/credentials.rb` method `self.credential`). When the fog credentials file given above is read in, itâs passed through `self.symbolize_credentials` which makes *symbols* out of all the keys (so `prod`, `test`, and `default` will all be symbols) and saves the list to credentials then looks for `credentials[credential]` which is indexing a string in a hash of symbols.\r\n\r\nAny value that `@credential` is set to should be a symbol, because the hash keys will only be symbols.'
613,'jeffmccune','vsphere provider should create blank VMs\nThe vsphere provider should have a method to create blank VMs. This would support the provisioning model where you create a blank VM and PXE boot into a kickstart or preseed install. '
612,'','Broken pipe on upload to eu s3 bucket\nI suspect that this issue is caused by:\r\n\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/index.html?RESTObjectPUT.html\r\n\r\n"To configure your application to send the request headers prior to sending the request body, use the 100-continue HTTP status code . For PUT operations, this helps you avoid sending the message body if the message is rejected based on the headers (e.g., authentication failure or redirect). For more information on 100-continue HTTP status code, go to Section 8.2.3 of http://www.ietf.org/rfc/rfc2616.txt."\r\n\r\nMore info:\r\nhttp://davidjrice.co.uk/2010/10/26/amazon-s3-european-bucket-issues-paperclip-attachment_fu.html\r\nhttps://github.com/jnicklas/carrierwave/issues/203\r\nhttps://github.com/jnicklas/carrierwave/issues/161\r\n\r\nWe get it with one of our customers\' buckets every single time we try to upload to it using fog, and this didn\'t happen with right-aws. We\'ve even figured out how to locate which region their bucket is in on the fly and we\'re specifying it in the request. I\'ve tried it sans https, I\'ve tried manually specifying the host and region, I\'ve tried just about everything one could try to get this to work (except modifying fog and excon to detect what I suspect is happening and behave accordingly).\r\n\r\nAny help would be appreciated, or advice on how to fix this in excon and/or fog.\r\n'
611,'','get_object_https?_url for s3 is generating urls with the bucket in the path\nThis may be intentional, and in some cases it\'s necessary, but you don\'t always know which region a bucket is in, so it\'s useful to generate the url with the bucket in the subdomain. If it doesn\'t work as a subdomain then it\'s in us-east, so you can just use s3.amazonaws.com and put the bucket in the path.\r\n\r\nHere\'s how it works now:\r\n\r\n```ruby\r\nconnection.get_object_https_url("foo_bar", "baz") # => "https://s3.amazonaws.com/foo_bar/baz?..."\r\nconnection.get_object_https_url("foo.bar", "baz") # => "https://s3.amazonaws.com/foo.bar/baz?..."\r\nconnection.get_object_https_url("foo",     "bar") # => "https://s3.amazonaws.com/foo/bar?..."\r\n```\r\n\r\nHere\'s how I would expect it to work:\r\n\r\n```ruby\r\nconnection.get_object_https_url("foo_bar", "baz") # => "https://s3.amazonaws.com/foo_bar/baz?..."\r\nconnection.get_object_https_url("foo.bar", "baz") # => "https://foo.bar.s3.amazonaws.com/baz?..."\r\nconnection.get_object_https_url("foo",     "bar") # => "https://foo.s3.amazonaws.com/bar?..."\r\n```\r\n\r\nThoughts? Ideas?'
610,'',"[AWS] Fix S3 get acl mocks \nWhen mocking is enabled I noticed that ```get_object_acl``` and ```get_bucket_acl``` returns a XML string if the ACL had been set previously with ```set_object_acl```/```set_bucket_acl```. The real version of these get methods returns the ACL as a hash.\r\n \r\nI have added a helper method for the mocks that parses the acl xml (using the AWS::AccessControlList parser) and returns a hash of if it, so the mock result is more similar to the real one. However this won't work when setting the acl with e-mail as aws resolves the email into a id (not really sure how to mock this..), so the tests for setting the acl with a email are still marked as pending.\r\n\r\nLet me know what you think! =)"
609,'',"Federated IAM\nAdd support for generation of temporary security tokens via Amazon's STS. "
608,'',"[vsphere] (#10644) Add servers filter to improve clone performance\nThe behavior without this patch is that the performance of the vm_clone\r\noperation in unacceptably slow for VMware vCenter deployments with\r\nmultiple hundreds of virtual machines.\r\n\r\nPerformance is unacceptable because the vm_clone operation makes\r\nmultiple API calls to list _all_ of the VM's in the inventory.  This\r\npatch eliminates the need to list all VM's by adding path and folder\r\nfilters to limit our API calls to subtrees of the VMware inventory.\r\n\r\n= API Changes =\r\n\r\n * New datacenters request that caches the Datacenter objects for the\r\n   life of the process.\r\n * New clone() method on the server model that returns a server model of\r\n   the new VM even if it is not yet done cloning.\r\n * Ability to limit collections to inventory paths by passing the\r\n * 'folder' filter to the servers collection.  For example:\r\n   `conn = Fog::Compute[:vsphere];\r\n    conn.servers('path' => '/Datacenters/DC1/vm/Templates')`\r\n   this filter will greatly reduce the number of SOAP API calls by\r\n   limiting the server models in the collection to only those in the\r\n   Templates inventory folder.  Note, this is not recursive yet.\r\n\r\n= Tests =\r\n\r\nTests have been updated.  The vm_clone request no longer takes an\r\ninstance_uuid because we cannot actually use this to search the\r\ninventory efficiently.  Instead, the vm_clone request now requires a\r\npath attribute to allow Fog to search only a subset of the inventory."
607,'','Loosen net/ssh version dependency\nIs there any reason for the strict 2.2.1 net/ssh dependency?\r\n\r\nThis makes Fog 1.1.0 incompatible with the current (0.10.4) and pre (0.10.6.beta) versions of Chef.'
606,'','excon dependency too pessimistic?\nHey guys,\r\n\r\nI just added fog as a dependency in my Gemfile. I\'m getting the following error after a bundle install:\r\n\r\n    Bundler could not find compatible versions for gem "excon":\r\n      In snapshot (Gemfile.lock):\r\n        excon (0.7.6)\r\n    \r\n      In Gemfile:\r\n        fog (>= 0) ruby depends on\r\n          excon (~> 0.6.1) ruby\r\n    \r\n    Running `bundle update` will rebuild your snapshot from scratch, using only\r\n    the gems in your Gemfile, which may resolve the conflict.\r\n    \r\n\r\nMaybe the excon dependency should be a little more optimistic than ~> 0.6.1? :-)\r\n\r\nI\'m actually surprised that Bundler installed 0.7.6, though. I have nothing else that depends on excon.\r\n\r\nMat'
605,'','[rackspace|load_balancers] made lb endpoint configurable\nSee #604'
604,'','Rackspace load_balancers can not switch the end_point when initializing the connection\nIn lib/fog/rackspace/load_balancers.rb, Line 18\r\n\r\nThere should be a line recognizes :rackspace_lb_endpoint, \r\notherwise this option cannot be recognized and thus the end point will be hardcoded as DFW_ENDPOINT.\r\n'
603,'brianhartsock',"[rackspace|dns] DNS Records failure test breaks\nThis is probably a bug in the Rackspace API, but the failure test on records is not working.\r\n\r\nGET /v1.0/389090/domains/2959812/records/k-6543282 is returning 500 from the API.  I'll email the Rackspace DNS API team, but I wanted to make sure we documented it in case other people saw the same issue."
602,'brianhartsock','[rackspace|dns] Callback errors should thrown on ERROR status\n<code>\r\n{"request"=>"{\\"domains\\":[{\\"name\\":\\"fogzonetests.com\\",\\"emailAddress\\":\\"fog@example.com\\"}]}", "error"=>{"message"=>"The object already exists.", "code"=>409, "details"=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n\\n  Hash: Zone label conflicts with the existing zone because parent/sub domain of fogzonetests.com belongs to another owner\\n\\n"}, "status"=>"ERROR", "verb"=>"POST", "jobId"=>"1af8bd49-4860-4a3b-9256-8f6eb9467dd8", "callbackUrl"=>"https://dns.api.rackspacecloud.com:443/v1.0/<redact>/status/1af8bd49-4860-4a3b-9256-8f6eb9467dd8", "requestUrl"=>"http://dns.api.rackspacecloud.com:443/v1.0/<redact>/domains"}\r\n</code>\r\n\r\nThe above callback status response should trigger an exception.'
601,'',"[dns] Made model tests use uniq domain names\nNot using unique hostnames could cause conflicts across accounts if names aren't cleaned up appropriately.  This was done because of how the Rackspace provider works, so I don't know how it might affect other providers"
600,'','New AWS region us-west-2 not working\nAll AWS commands fail for region us-west-2 with the following error:\r\n\r\nUnknown region: us-west-2'
599,'',"Removed puts of element name\nFound this ``puts`` call in ``Fog::Parsers::CDN::AWS::GetInvalidationList``. I removed it as I guess it's some debug stuff thats been accidentally left in there? Kinda annoying when doing command line utils =)\r\n\r\nLet me know what you think."
598,'','Feature/unmocking\nAdding a method to unmock Fog which addresses issue #594. Includes tests and documentation.'
597,'',"Change response parameter\nThe StormOnDemand API is a moving target since it's in Beta. These changes will correctly list certain resources (balancers, configs, images, servers, and templates)."
596,'',"AWS::Files::each not called for Enumerable methods\nI have a bucket that contains 5000 files. Here's the problem:\r\n\r\n```ruby\r\nconnection = Fog::Storage.new(:provider => 'AWS', ...)\r\ndirectory = connection.directories.get('mybucket')\r\nfiles = []\r\ndirectory.files.each { |f| files << f.key }\r\nputs files.count\r\nfiles = directory.files.map { |f| f.key }\r\nputs files.count\r\n```\r\n\r\nThis outputs:\r\n\r\n```\r\n5000\r\n1000\r\n```\r\n\r\nThis causes [AssetSync](https://github.com/rumblelabs/asset_sync), which calls AWS::Files::map, to fail when there are more than 1000 files in a bucket."
595,'','Slicehost dns fixes\nHiya guys,\r\n\r\nThe Slicehost DNS API was not working properly.\r\n\r\ndns.zones returned a list of zones correctly.  However, trying to get the records for a particular zone would return a list of records for all zones, because the Slicehost API returned "zone-id" but the Fog internals were matching against "zone_id".  I did some minor tweakage to the parser to address this and, relatedly, squash a bug where "record-type" would not match "record-type".\r\n\r\nI also fixed a doc bug in the Slicehost records request.\r\n\r\nApologies for the feature branch being a wee bit on the unclean side -- my git-fu is weak, so there\'s a lot of "Whoopsie, didn\'t want to actually do that" in there.'
594,'','Add a way to unmock\nFog really needs a way to unmock and to clear the mock data.'
593,'','Nokogiri dependency is incompatible with Blather\nTrying to use fog and blather together causes this rubygems error:\r\nUnable to activate fog-1.0.0, because nokogiri-1.4.7 conflicts with nokogiri (~> 1.5.0) (Gem::LoadError)\r\n\r\nIt looks like nokogiri 1.5.0 has some serious regressions in it that prevent blather from updating its dependency. See this issue for details: https://github.com/sprsquish/blather/issues/55\r\n\r\nCan fog use a nokogiri dependency of >= 1.4.0 so it can be used with blather?\r\n\r\n'
592,'',"vSphere usability improvements \ncommit b53416abce6eb9de2d358e9516540d50a58f8e87\r\nAuthor: Carl Caum <carl@carlcaum.com>\r\nDate:   Fri Oct 28 09:03:02 2011 -0400\r\n\r\n    (#10055) Search vmFolder inventory vs children\r\n    \r\n    This patch changes how the `list_all_virtual_machine_mobs` method\r\n    searches for virtual machines. Previously the search was based on\r\n    children of the `dc.vmFolder` object. This makes the false assumption\r\n    that all children are virtual machines.\r\n    \r\n    Now the search is based on the entire inventory of the `dc.vmFolder`\r\n    object, which gives us more control over what we consider a virtual\r\n    machine.\r\n    \r\n    This patch also adds a new `find_all_in_inventory` method; a generic\r\n    method that can be used to search an inventory for any VMware object\r\n    exposed by RbVmomi. Using `find_all_in_inventory` we are able to\r\n    traverse VMware folders and pickout specific VMware object, in this case\r\n    `RbVmomi::VIM::VirtualMachine`\r\n\r\ncommit 762aa624ac07f76d774bc852e4737637273cea30\r\nAuthor: Carl Caum <carl@carlcaum.com>\r\nDate:   Fri Oct 28 10:10:37 2011 -0400\r\n\r\n    Adding a path attribute to the vm_mob_ref hash\r\n    \r\n    This patch adds a new `path` attribute to the vm_mob_ref hash returned\r\n    by the `convert_vm_mob_ref_to_attr_hash` method. In order to support the\r\n    new `path` attribute, this patch also adds a new `get_folder_path` method\r\n    to the `list_virtual_machines` vsphere module.\r\n\r\ncommit bc74e06d128ba2cdef60534eecb27174af388219\r\nAuthor: Kelsey Hightower <kelsey@puppetlabs.com>\r\nDate:   Mon Nov 7 07:08:54 2011 -0500\r\n\r\n    (#10570) Use nil in-place of missing attributes\r\n    \r\n    Without this patch, `Fog::Compute::Vsphere#convert_vm_mob_ref_to_attr_hash`\r\n    method produces unhandled exceptions during VMware cloning and listing\r\n    operations. The root cause of these exceptions are based on the fact\r\n    that some VMware virtual machine attributes: hypervisor name, and\r\n    macaddress, are not available until the cloning process has finished.\r\n    \r\n    These exceptions can be triggered when external events take place within\r\n    the VMware infrastructure such as end-users cloning machines via some\r\n    other VMware management tool.\r\n    \r\n    This patch solves the problem by catching any exceptions that occur\r\n    during attribute lookups for both the hypervisor name and the virtual\r\n    machine macaddress, and setting them to nil.\r\n    \r\n    This patch also removes the host attribute from the hash generated by\r\n    the `Fog::Compute::Vsphere#convert_vm_mob_ref_to_attr_hash` method. The\r\n    hypervisor attribute is added instead, which is an alias to host.\r\n    \r\n    This patch changes the behaviour of the\r\n    `Fog::Compute::Vsphere#convert_vm_mob_ref_to_attr_hash` method by\r\n    catching exceptions for missing attributes, and setting them to nil.\r\n\r\ncommit a65db7f594c6c5fde37d4c393e6438e1d0f71163\r\nAuthor: Kelsey Hightower <kelsey@puppetlabs.com>\r\nDate:   Tue Nov 8 00:47:27 2011 -0500\r\n\r\n    (#10570) Update `Fog::Compute::Vsphere` tests\r\n    \r\n    Update `Fog::Compute::Vsphere` tests to reflect the way the\r\n    `Fog::Compute::Vsphere#convert_vm_mob_ref_to_attr_hash` method currently\r\n    converts a `RbVmomi::VIM::ManagedObject` object to a hash.\r\n    \r\n    Without this patch, tests related to converting an instance of\r\n    `RbVmomi::VIM::ManagedObject` to a hash will raise an exception:\r\n    NoMethodError: undefined method `collect!' for Hash; causing the test to\r\n    fail.\r\n    \r\n    This patch solves the problem by mocking `RbVmomi::VIM::ManagedObject`\r\n    with a new `MockManagedObject` class, which provides a `collect!`\r\n    method, and the `_ref` and `parent` attributes.\r\n    \r\n    This patch renames fake_vm to fake_vm_mob_ref in order to provide a\r\n    more descriptive name for what's actually being tested.\r\n    \r\n    The `Fog::Compute::Vshpere::Mock` class has been updated to require the\r\n    rbvmomi library, which prevents an `NameError` exception from being raised\r\n    due to the `Fog::Compute::Vsphere::Shared::RbVmomi` constant not being\r\n    initialized.\r\n    \r\n    The `Fog::Compute::Vshpere::Mock` class has been updated with a\r\n    `get_folder_path` method, which prevents a `NoMethodError` exception\r\n    from being raised due to the `get_folder_path` method being undefined."
591,'','tag assignment for ec2 spot instances is broken\nCreating spot instances doesn\'t seem to work:\r\n    \r\n    MissingParameter => The request must contain the parameter resourceIdSet\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/gems/excon-0.7.6/lib/excon/connection.rb:194:in `request\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/core/connection.rb:20:in `request\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/aws/compute.rb:316:in `request\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/aws/requests/compute/create_tags.rb:35:in `create_tags\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/aws/models/compute/tag.rb:27:in `save\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/core/collection.rb:50:in `create\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/aws/models/compute/spot_requests.rb:69:in `bootstrap\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/aws/models/compute/spot_requests.rb:68:in `each\'\r\n    /vol/ebs1/jenkins/jobs/commons-stage-setup/workspace/instance_setup/vendor/bundle/ruby/1.8/bundler/gems/fog-e3dfde84c7c5/lib/fog/aws/models/compute/spot_requests.rb:68:in `bootstrap\'\r\n\r\n\r\n\r\n\r\nThose are the parameters I passed in:\r\n\r\n    {\r\n    :tags=>{:type=>"commons_qa_server", :company_dns=>"some.url.com", :creation_time=>"Thu Nov 03 15:05:43 +0000 2011", :build_tag=>"jenkins-commons-stage-setup-148"},\r\n    :private_key_path=>"./keys/commons_qa_id_rsa",\r\n    :flavor_id=>"m1.small",\r\n    :public_key_path=>"./keys/commons_qa_id_rsa.pub",\r\n    :image_id=>"ami-91579af8",\r\n    :groups=>["our_dev_group"],\r\n    :price=>"1"\r\n    }'
590,'','[dnsmadeeasy|dns] Fix Fog::DNS::DNSMadeEasy::Record#save \nThe update code path of `#save` was not passing the required parameters into the update request.'
589,'',"AWS#hash_to_acl - add support for EmailAddress and URI grantee types.\nAside: Don't assume there will always be a DisplayName.\r\n"
588,'',"hash_to_acl for AWS has a bug and lacks support for other grantee types\nThe bug is that it supposes there will be a DisplayName even though DisplayName isn't required.\r\n\r\nThe grantee types it doesn't support are EmailAddress and URI.\r\n"
587,'','TypeError when trying to get_object_https?_url when credentials not configured\nThese errors happen in the signing step of these methods (hmac.rb).\r\n\r\n```ruby\r\nconnection = Fog::Storage.new(:provider => "AWS", :aws_access_key_id => nil, :aws_secret_access_key => nil)\r\nconnection.get_object_https_url("bucket", "key", Time.now) # => TypeError: can\'t convert nil into String\r\nconnection.get_object_http_url("bucket", "key", Time.now) # => TypeError: can\'t convert nil into String\r\n```\r\n\r\nSince it\'s acceptable to pass nil for aws_access_key_id and aws_secret_access_key, these methods should return a Fog::Errors::Error and not a TypeError error. Libraries should return predictable errors wherever possible. It looks like this particular issue has been around for a while.\r\n'
586,'redzebra','Auto Scaling Group object contains All instances and not just the member ones\nHello,\r\n\r\nI have got an object of my AutoScaling group and all the attributes of it are correct, however the the instances property contains all instances from all groups and not just the one I have selected.\r\n\r\n\t# Create a connection to the required cloud service\r\n\tcf = Fog::AWS::CloudFormation.new(\r\n\t\t:aws_access_key_id => "somekey",\r\n\t\t:aws_secret_access_key => "secret",\r\n\t\t:region => "eu-west-1" \r\n\t  )\r\n\r\n\tresources = cf.describe_stack_resources("StackName" => "MyStack").body[\'StackResources\']\r\n\r\n\t# Now that we have some instance ids get information about each one\r\n\tcompute = Fog::Compute.new(:provider => config["cloud"]["service"],\r\n\t\t\t\t\t\t\t\t:aws_access_key_id => "somekey",\r\n\t\t\t\t\t\t\t\t:aws_secret_access_key => "secret",\r\n\t\t\t\t\t\t\t\t:region => "eu-west-1")  \r\n\t  \r\n\t# loop round the resources that are returned\r\n\tinstances = Array.new\r\n\tresources.each do |resource|\r\n\t  \r\n\t  # determine the type of resource\r\n\t  if (resource[\'ResourceType\'] == "AWS::EC2::Instance")    \r\n\t\t# get the instance id\r\n\t\tinstances << resource[\'PhysicalResourceId\']\r\n\t  elsif (resource[\'ResourceType\'] == "AWS::AutoScaling::AutoScalingGroup")\r\n\r\n\t\t# Create an AutoScaling object\r\n\t\tas = Fog::AWS::AutoScaling.new(:aws_access_key_id => "somekey",\r\n\t\t\t\t\t\t\t\t\t:aws_secret_access_key => "secret",\r\n\t\t\t\t\t\t\t\t\t:region => "eu-west-1")  \r\n\t\t\r\n\t\t\r\n\t\t# use the Fog class to get the machines with the relevant tags\r\n\t\tasgroup = as.groups.get(resource[\'PhysicalResourceId\'])\r\n\r\n\t\tputs asgroup.inspect\r\n\t  end\r\n\tend\r\n\r\nI can parse this list to extract only the instances relevant to the group, but I thought this is what the \'groups.get\' function was meant to provide.  If it is what this is meant to do, is this a bug and if so can it be looked at?\r\n\r\nThanks very much,\r\n\r\nRussell'
585,'',"Initial VPC support\nI've added initial support for EC2 VPCs.  This commit can Describe, Create, and Delete the base VPC.  There are many more features to implement such as Subnets, VPC Elastic IPs, VPC Security Groups, Gateways, VPN Connections, Routing, etc.\r\n\r\nAn argument could be made for putting this functionality into the Compute object, but in this commit I have kept it logically separate.\r\n\r\nImplemented so far:\r\n\r\nmodel       :vpc\r\ncollection  :vpcs\r\n\r\nrequest :create_vpc\r\nrequest :delete_vpc\r\nrequest :describe_vpcs\r\n\r\nLet me know what you think.\r\nThanks,\r\nJason Watson\r\n"
584,'',"AWS::Files `each` method yields incorrect results\nThe custom `each` method for `Fog::Storage::AWS::Files` disregards any filtering applied by calling Array methods such as `reject!` and `select!`\r\n\r\nAssume S3 bucket has 3 files:\r\n\r\n* index.html\r\n* app.js\r\n* styles.css\r\n\r\nThe result is a bit confusing:\r\n\r\n    files = bucket.files.all\r\n\r\n    files.reject! {|f| f.key == 'index.html'}\r\n    files.length # => Returns 2\r\n\r\n    count = 0\r\n    files.each {|f| count += 1}\r\n    count # => Returns 3\r\n\r\n\r\nI'm not sure if this is a bug or intended behavior, but I thought I'd post it anyway. Either way it's _confusing_ and deserves some attention, either with a bugfix or documentation note. (I didn't submit a patch/docs because I wasn't sure if this is the way `each` is supposed to work in this case).\r\n\r\nMy vote is to either make `Files#each` behave as expected for an Array (preferred), or to _not_ have `Fog::Collection` inherit from Array in the first place."
583,'','S3: Signature Does Not Match\nHi,\r\n\r\nI\'m running Fog against an S3 compatible service by German provider Hosteurope. While I can successfully connect to their service using various S3 clients, it fails using Fog :-(\r\n\r\nHere is the exception:\r\n\r\nirb(main):001:0> storage = Fog::Storage.new({:provider => \'AWS\', :aws_access_key_id => "UCNVGEXEVTP5AKFMQ93R", :aws_secret_access_key => "...", :endpoint => \'https://cs.hosteurope.de\'})\r\n=> #<Fog::AWS::Storage::Real:0x10f37aec8 @hmac=#<Fog::HMAC:0x10f373088 @key="...", @digest=#<OpenSSL::Digest::Digest: da39a3ee5e6b4b0d3255bfef95601890afd80709>, @signer=#<Proc:0x000000010a7b6eb0@/Library/Ruby/Gems/1.8/gems/fog-0.7.2/lib/fog/core/hmac.rb:22>>, @aws_secret_access_key="...", @port=443, @scheme="https", @connection=#<Fog::Connection:0x10f35afb0 @excon=#<Excon::Connection:0x10f35aec0 @socket_key="cs.hosteurope.de:443", @connection={:port=>"443", :path=>"", :headers=>{}, :query=>nil, :scheme=>"https", :host=>"cs.hosteurope.de", :mock=>nil}>, @persistent=nil>, @host="cs.hosteurope.de", @path="", @endpoint="https://cs.hosteurope.de", @aws_access_key_id="UCNVGEXEVTP5AKFMQ93R">\r\nirb(main):002:0> storage.get_bucket("helpster-cms-backup")\r\nExcon::Errors::Forbidden: Expected(200) <=> Actual(403 Forbidden)\r\n  request => {:expects=>200, :port=>"443", :path=>"/", :headers=>{"Authorization"=>"AWS UCNVGEXEVTP5AKFMQ93R:xDF89OO+i4dWEaLivctwZM4cO4M=", "Date"=>"Wed, 26 Oct 2011 13:43:03 +0000", "Content-Length"=>0, "Host"=>"helpster-cms-backup.cs.hosteurope.de:443"}, :idempotent=>true, :method=>"GET", :query=>{}, :host=>"helpster-cms-backup.cs.hosteurope.de", :scheme=>"https", :mock=>nil}\r\n  response => #<Excon::Response:0x10f34fc78 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>SignatureDoesNotMatch</Code>\\n<Message></Message>\\n</Error>\\n", @headers={"Content-Type"=>"application/xml", "Date"=>"Wed, 26 Oct 2011 13:43:04 GMT", "Content-Length"=>"110", "Server"=>"RestServer/1.0", "Cache-Control"=>"no-cache", "Connection"=>"close"}, @status=403>\r\n\tfrom /Library/Ruby/Gems/1.8/gems/excon-0.6.3/lib/excon/connection.rb:179:in `request\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.7.2/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.7.2/lib/fog/storage/aws.rb:323:in `request\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.7.2/lib/fog/storage/requests/aws/get_bucket.rb:55:in `get_bucket\'\r\n\tfrom (irb):2\r\n\r\nAny ideas?'
582,'',"Tags for EC2 spot instances don't stick\nWith the new bootstrap() for EC2 spot instances, tags that are passed in as a :tags array in the hash don't seem to be applied properly.\r\nThe final server instance doesn't seem to have any."
581,'','Ninefold implementation missing head_namespace implementation\nI have a class called PlanFile that has the following paperclip configuration:\r\n...\r\n  has_attached_file :pdf,\r\n      :url => "/something",\r\n      :path => "/something",\r\n      :storage => :fog,\r\n      :fog_directory => FOG_DIRECTORY,\r\n      :fog_credentials => {\r\n          :provider => \'Ninefold\',\r\n          :ninefold_storage_token => \'\',\r\n          :ninefold_storage_secret => \'\'\r\n      }\r\n...\r\n\r\nTrying to either delete or overwrite the file I get the following exceptions:\r\n\r\nruby-1.8.7-p334 :005 > p.pdf.destroy       \r\nNoMethodError: undefined method `head_object\' for #<Fog::Storage::Ninefold::Real:0x7fccb99a8b60>\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0.1/lib/fog/ninefold/models/storage/files.rb:54:in `head\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/storage/fog.rb:56:in `exists?\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:445:in `queue_existing_for_delete\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:444:in `map\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:444:in `queue_existing_for_delete\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:187:in `clear\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:197:in `destroy\'\r\n\tfrom (irb):5\r\nruby-1.8.7-p334 :006 > p.pdf = File.new(p.filename)    \r\nNoMethodError: undefined method `head_object\' for #<Fog::Storage::Ninefold::Real:0x7fccb99a8b60>\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0.1/lib/fog/ninefold/models/storage/files.rb:54:in `head\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/storage/fog.rb:56:in `exists?\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:445:in `queue_existing_for_delete\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:444:in `map\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:444:in `queue_existing_for_delete\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:187:in `clear\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip/attachment.rb:104:in `assign\'\r\n\tfrom /home/andrew/.rvm/gems/ruby-1.8.7-p334/gems/paperclip-2.4.5/lib/paperclip.rb:337:in `pdf=\'\r\n\tfrom (irb):6\r\n\r\nFog storage.rb for Ninefold is missing "request :head_namespace" even though the fog/ninefold/models/storage/files.rb (which looks like a cut and paste from Rackspace) calls it (it calls head_object because it is a cut and paste of Rackspace).\r\n\r\nIt just took a bit of pattern matching to get it going.\r\n\r\nPlease ignore the version bump in fog.rb (I set it to 1.0.0.1 as way to push this gem more easily - again don\'t know a better way to do this).\r\n\r\nIt appears that there are no tests covering this code path.  I had a go at adding them to "tests/helpers/collection_helper.rb" but they don\'t seem to be included.  I\'d really like to know how the testing is suppose to work - some code has mocks and others don\'t so I wasn\'t able to easily work out what to do.'
580,'',"Use autoload instead of require in #initialize methods\n`Kernel#require` is quite slow and can be taxing when creating a lot of instances. This patch removes these calls and replace them by adding autoload statements in fog/core.rb. \r\n\r\nThis patch is preliminary as the shindo test suite is badly broken on my computer but I though of at least starting a conversation on that issue. When mocking is disabled, I only have an AWS account and even there some tests are failing. When mocking is enabled, I get some uninplemented issues and halts on the vsphere tests because of malformed YAML (they are indented and shouldn't). I don't have the time right now to fix the test suite unfortunately."
579,'','Clodo 1.0.0\nclodo.ru API plugin, as I promised.\r\nI wonder if you can merge this into fog.\r\nThank you!'
578,'','[aws|compute] Update security group operations.\nChanges and features include:\r\n\r\n* Bulk operations support via indexed params\r\n* Mocking updated for bulk operations\r\n* Mocking updated to reflect more real behavior\r\n* Many more tests'
577,'',"Thanks for the T-shirt ! (+ patch)\nI got it two days ago. Very nice :)\r\n\r\n... and here a little patch to fix the S3 ACL generation.\r\n\r\nThe EmailAddress and URI variants when passing a hash where generating invalid XML. The shindo tests are working with FOG_MOCK=true but I don't have your credentials with the real test. I did some by hand and the stuff seems to work correctly."
576,'','Optimize vSphere convert_vm_mob_ref_to_attr_hash\nThis patch reduces the number of round trips to the vSphere API by\r\nusing the `collect!` method on the ManagedObject, vm_mob_ref, which\r\nretrieves most of the properties in one request.\r\n\r\nFor the remaining properties: hypervisor and mac_addresses, we still\r\nneed to make additional requests.\r\n\r\nOverall this patch provides a nice speed improvement for the\r\n`convert_vm_mob_ref_to_attr_hash` method.'
575,'','Dynect async API calls\nDynect\'s API seems to occasionally operate with an asynchronous API and it will return a 307 status code in that case with the job number.\r\n\r\n```\r\nresponse => #<Excon::Response:0x00000005add108 @body="/REST/Job/35859881", @headers={"Server"=>"nginx/0.7.67", "Date"=>"Wed, 26 Oct 2011 03:02:04 GMT", "Content-Type"=>"text/html", "Transfer-Encoding"=>"chunked", "Connection"=>"keep-alive", "Location"=>"/REST/Job/35859881"}, @status=307>\r\n```\r\n\r\nIt looks like this is very rare, but still an annoyance to anyone using the API. I\'m wondering if we should handle this in the library to wait until the job is completed or return the job number and let the user deal with it.'
574,'',"Send power parameter in GoGrid's grid_server_power request\nThe grid_server_power request fails because it does not send the power command to execute. I have modified it to include it as a parameter, and manually tested it to check it works. \r\n\r\nI know the policy is to make shindo tests for the changes in the project, but I am at a loss at how to start: I am not very familiar with shindo and the tests for existing requests for other providers seem rather complicated.\r\n\r\nI hope this is of use anyway."
573,'',"Rackspace Response seems to have changed\nHey Guys,\r\n\r\nSeems like rackspace now wraps this inside another object. \r\n\r\nThis isn't what's specified at: http://docs.rackspace.com/cdns/api/v1.0/cdns-devguide/content/Add_Records-d1e4895.html#d6e2108. \r\n\r\nApologies for the utter and complete lack of test changes etc. If y'all want to point me in the right direction I'll be only too happy to add them. \r\n\r\nNik"
572,'','Changebatch\nImplemented support for weighted records with Route53 using fog and updated it to use the 2011-05-05 Route53 API'
571,'','ssh support for virtualbox\nCurrently not implemented\r\n\r\nPerhaps specifically, support for vagrant (which has pub/priv keys setup)'
570,'','AWS bootstrap() wants to assign tags before server is available\nFrom time to time, I receive an error with EC2 that says something like: "The instance ID \'i-169c8d76\' does not exist"\r\n\r\n    The instance ID \'i-169c8d76\' does not exist\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/excon-0.7.6/lib/excon/connection.rb:194:in `request\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/core/connection.rb:20:in `request\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/compute.rb:286:in `request\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/requests/compute/create_tags.rb:35:in `create_tags\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/models/compute/tag.rb:27:in `save\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/core/collection.rb:50:in `create\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/models/compute/server.rb:174:in `save\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/models/compute/server.rb:173:in `each\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/models/compute/server.rb:173:in `save\'\r\n    /instance_setup/vendor/bundle/ruby/1.8/gems/fog-1.0.0/lib/fog/aws/models/compute/servers.rb:100:in `bootstrap\'\r\n\r\nIt think during bootstrap, fog tries to add tags to an instance that isn\'t there yet. These instances WILL be started and leak\r\n\r\nI pass the following options to the bootstrap:\r\n\r\n      server_attributes = {\r\n        :flavor_id => instance_size,\r\n        :tags => tags_for_the_server,\r\n        :image_id => chosen_image_id,\r\n        :private_key_path => "./keys/id_rsa",\r\n        :public_key_path => "./keys/id_rsa.pub",\r\n        :groups => [\'something\']\r\n      }'
569,'','I wanted to be able to simply access tags, for use upstream.\nMade tags accessible instance variables. \r\nRemove non alpha-numeric characters from tags before making them accessible'
568,'',"Add CloudFormation UpdateStack API\nThis is basically a direct copy of CreateStack with a few parameters removed to match Amazon's API. I added an appropriate test but was unable to figure out how to run it properly, though it should pass just fine. Let me know if I missed something."
567,'','[vsphere] Get inventory of virtual machines\nGet an inventory of virtual machines instead of listing the contents of the vm folder.'
566,'','Cloudformation CreateStack should accept Capabilities array as option\nUpdateStack should do also, if I get to that ill do a separate pull request.'
565,'','add region option to aws sns service recognizes method\naws sns service should recognize region option during intialization. this was probably left out whilst sns was in beta and only available in a single region'
564,'','[OpenStack|compute] user_data support\nSet user data with OpenStack.  Must be transmitted base64, but can be set as ascii with user_data=, or as pre-encoded data with user_data_encoded=.\r\n\r\nCompacts the way most extra options are added to the request.'
563,'','[aws|storage] generated url not usable\nThe URI generate by Fog::Storage::AWS::GetObjectHttpsUrl is not usable.\r\n\r\nget_object_https_url("foo", "bar", 60)\r\n\r\nApparently S3 would like a URI with the form: "foo.s3.amazonaws.com" instead of "s3.amazonaws.com/foo"\r\n\r\nOtherwise an XML document is returned to the effect: "The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint."\r\n\r\nWhile the status is 301 there is no new location specified thus: "ERROR: Redirection (301) without location."'
562,'',"Broken Pipe when uploading to S3\nExcon::Errors::SocketError - Broken pipe\r\n\r\nUsing fog 1.0.0, backup 3.0.18, ruby 1.9.2p290, I get the following error: \r\n\r\n```ruby\r\nExcon::Errors::SocketError - Broken pipe\r\n===========================================================================\r\n/usr/local/rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/openssl/buffering.rb:292:in `syswrite_nonblock'\r\n/usr/local/rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/openssl/buffering.rb:292:in `write_nonblock'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/excon-0.7.6/lib/excon/socket.rb:81:in `write'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/excon-0.7.6/lib/excon/connection.rb:172:in `request'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/fog-1.0.0/lib/fog/core/connection.rb:20:in `request'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/fog-1.0.0/lib/fog/aws/storage.rb:366:in `request'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/fog-1.0.0/lib/fog/aws/requests/storage/put_object.rb:43:in `put_object'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/lib/backup/storage/s3.rb:82:in `transfer!'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/lib/backup/storage/s3.rb:55:in `perform!'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/lib/backup/model.rb:222:in `block in perform!'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/lib/backup/model.rb:222:in `each'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/lib/backup/model.rb:222:in `perform!'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/bin/backup:130:in `block in perform'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/bin/backup:109:in `each'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/bin/backup:109:in `perform'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/thor-0.14.6/lib/thor/task.rb:22:in `run'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/thor-0.14.6/lib/thor/invocation.rb:118:in `invoke_task'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/thor-0.14.6/lib/thor.rb:263:in `dispatch'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/thor-0.14.6/lib/thor/base.rb:389:in `start'\r\n/usr/local/rvm/gems/ruby-1.9.2-p290@backup_util/gems/backup-3.0.18/bin/backup:288:in `<top (required)>'\r\n```\r\n\r\nSee related post https://github.com/meskyanichi/backup/issues/192 \r\n\r\n@meskyanichi the main developer for Backup was wondering if this was a fog issue and not a backup issue...\r\n\r\n"
561,'',"Update the main website's navigation to put the most important links at the top.\nI recently ran into an issue where I ended up finding documentation that wasn't correct for the current API, and only later realized that the links I did want were at the very bottom of the page. I've taken the links describing the different sections of Fog, as well as Structure and Getting Started and created a top-page navigation structure.\r\n\r\nI also went ahead and updated the example in the documentation that was old to match the current API."
560,'',"[OpenStack|compute] add zone awareness\nNova has a `ZoneScheduler` that can run instances on a particular set of\r\nhardware.  This attribute hasn't been documented in the api spec, but is\r\neffective at setting the availability_zone and letting ZoneScheduler work."
559,'',"[OpenStack|compute] fix v2.0 auth endpoints\nThis fixes how paths and regexps work for less common cases (eg: having\r\nand auth endpoint that is /v2.0/tokens.json).\r\n\r\nSerialization to/from json and setting content-type header are added.\r\n\r\nNo longer silently converts nova api endpoints to 1.1, but errors instead.  You\r\nshould be using keystone's service catalog in conjunction with\r\n@openstack_compute_service_name."
558,'','[OpenStack|compute] default metadata to empy hash\nCalling metadata.each in the `save` method will make a spurious request to\r\nthe nova endpoint, unless metadata has been initialized to an empty hash.'
557,'','Cleanup Attributes#merge_attributes\nResults in better performace and clean code.'
556,'',"S3 documentation fixes\nHi geemus, thanks for getting back to me.\r\n\r\nLet's take the rdoc example because it's a good one. Imagine you are learning the library and wants to known what you can do with S3.\r\n\r\nSearching for S3 on the main rdoc page doesn't give any result.\r\n\r\nThen you learn that it's in fact called Fog::Storage::AWS so you open that class but the doc is empty.\r\n\r\nThen you play a bit with the console and see that the Fog::Storage[:aws] object is in fact an instance of Fog::Storage::AWS::Real. Nice, there is some doc.\r\n\r\nYou look for signed urls. Nothing in the doc. In fact there is, I found `get_object_http_url` by looking in `Fog::Storage[:aws].methods` and asserted it was it.\r\n\r\nIn general, I find it hard to know which methods are available for what.\r\n\r\nThe http://fog.io/1.0.0/storage/ page gives the impression that you could do something like:\r\n`Fog::Storage[:aws].directories('bucket_name').files('file/path').http_url` or something similar but it's not the case. In fact if I remember well it's the first thing I tried.\r\n\r\nCheers,\r\nJonas\r\n\r\n"
555,'',"Really needs documentation\nApart from the examples and the website I didn't find much informations on how to use Fog. Is it just me ?"
554,'','Dynect DNS functionality broken?\nI replaced my data with other values, but this is what I get:\r\n\r\n    ruby-1.8.7-p334 :009 >     dynect = Fog::DNS.new(:provider => "dynect", :dynect_customer => "*******", :dynect_username => dynect_user, :dynect_password => dynect_pass)\r\n    => #<Fog::DNS::Dynect::Real:0x102d4a758 @connection=#<Fog::Connection:0x102d228c0 @excon=<Excon::Connection:0x102d22848 @connection={:path=>"", :mock=>nil, :headers=>{}, :port=>"443", :connect_timeout=>60, :query=>nil, :scheme=>"https", :read_timeout=>60, :host=>"api2.dynect.net", :write_timeout=>60}, @socket_key="api2.dynect.net:443">, @persistent=true>, @scheme="https", @dynect_username="*******", @host="api2.dynect.net", @path="/REST", @dynect_customer="*********", @port=443, @version="2.3.1", @persistent=true, @connection_options={}, @dynect_password="****************"> \r\n\r\n    ruby-1.8.7-p334 :011 >       zone = dynect.zones.get("mydomain.com")\r\n    Excon::Errors::SocketError: Address family not supported by protocol family - connect(2)\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/ssl_socket.rb:10:in `connect\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/ssl_socket.rb:10:in `connect\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/socket.rb:23:in `initialize\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/ssl_socket.rb:22:in `initialize\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/connection.rb:233:in `new\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/connection.rb:233:in `socket\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/excon-0.7.6/lib/excon/connection.rb:80:in `request\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/dynect/dns.rb:88:in `request\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/dynect/requests/dns/post_session.rb:15:in `post_session\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/dynect/dns.rb:78:in `auth_token\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/dynect/dns.rb:86:in `request\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/dynect/requests/dns/get_zone.rb:16:in `get_zone\'\r\n\tfrom /Users/mseeger/.rvm/gems/ruby-1.8.7-p334/gems/fog-1.0.0/lib/fog/dynect/models/dns/zones.rb:20:in `get\'\r\n\tfrom (irb):11\r\n'
553,'','[aws|compute] fixed spot_instance_request reply parsing when the original request contained a device mapping.\nThe spot_instance_requests reply parser failed if the original request contained any block device mappings. This patch fixes that.'
552,'','Fixed an issue whereby saving an existing record in Zerigo would nil out its value.\nFixed an issue whereby saving an existing record in Zerigo would nil out its value.'
551,'','Implemented mocks for Zerigo.\n'
550,'','Added the ability to search Zerigo records for a particular zone.\n'
549,'','Updated DNS docs to use newer arg, rather than the old deprecated one.\n'
548,'',"[aws|compute] Allow mock tagging to work across accounts.\nThis moves tag_sets out of individual resources and up to a top-level item in each mock account's hash. Starting with images, this allows other mock accounts to create and use their own tags on images they have launchPermission on."
547,'',"[aws|compute] Mock modify_image_attribute add/remove users.\nImages can be shared with other accounts/users/owners when mocking.\r\n\r\nWith the way the mock data is structured each access key is effectively an account. I did tweak the `owner_id` generation so it's now unique for each mock compute object but it has no real effect on operation since no previous request mocks go outside their access key-specific data."
546,'','[aws|elb] Missed a change as part of #545.\nMissed a change in removing the `instance` variable.'
545,'','[aws|mock] Dig into mock data instead of instantiating new service object\nUsing things like `IAM.new` and `Compute[:aws]` assumes credentials are available via `Fog.credentials` which might not always be the case.'
544,'nightshade427',"After creating a server, cannot ssh to it\n``>> compute = Fog::Compute.new(:provider => 'Linode')\r\n>> server = compute.servers[0]\r\n>> server.ssh('mkdir -p infrastructure')\r\nNoMethodError: undefined method `public_ip_address' for #<Fog::Compute::Linode::Server:0x00000101350550>\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/lib/fog/core/attributes.rb:181:in `block in missing_attributes'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/lib/fog/core/attributes.rb:180:in `each'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/lib/fog/core/attributes.rb:180:in `missing_attributes'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/lib/fog/core/attributes.rb:161:in `requires'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/lib/fog/compute/models/server.rb:18:in `ssh'\r\n  from (irb):13:in `<top (required)>'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/bin/fog:52:in `block in <top (required)>'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/bin/fog:52:in `catch'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/gems/fog-1.0.0/bin/fog:52:in `<top (required)>'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/bin/fog:19:in `load'\r\n  from ~/.rvm/gems/ruby-1.9.2-p290@infrastructure/bin/fog:19:in `<main>'``\r\n\r\nI'm running ruby 1.9.2 and Fog v1.0"
543,'',"Listing servers on Linode fails\nI currently get the following error using v1.0.0.\r\n\r\n``\r\n>> compute = Fog::Compute.new({:provider => 'Linode', :linode_api_key => 'redacted api key here'})\r\n>> compute.servers\r\nNoMethodError: undefined method `each_with_object' for #<Hash:0x1023a1a08>\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/linode/models/compute/servers.rb:26:in `map_server'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/linode/models/compute/servers.rb:22:in `servers'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/linode/models/compute/servers.rb:22:in `map'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/linode/models/compute/servers.rb:22:in `servers'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/linode/models/compute/servers.rb:11:in `all'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/core/collection.rb:131:in `lazy_load'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/core/collection.rb:11:in `empty?'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/core/collection.rb:75:in `inspect'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/formatador-0.2.1/lib/formatador.rb:92:in `indent'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/lib/fog/core/collection.rb:68:in `inspect'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:302:in `output_value'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:151:in `eval_input'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:263:in `signal_status'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:147:in `eval_input'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:146:in `eval_input'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/bin/fog:52\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/bin/fog:52:in `catch'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-1.0.0/bin/fog:52\r\n\tfrom /usr/bin/fog:19:in `load'\r\n\tfrom /usr/bin/fog:19>> ^Dhelium:infrastructure kushalpisavadia$ ./lib/instance.rb \r\n``"
542,'','Fixed an issue with S3 mocked copy_object command.\n'
541,'',"Mon put metric alarm\nHi wes,\r\n\r\nthis is the pull-request that adds support for put-metric-alarm to AWS Cloudwatch. (Issue #499). I added a mock implementation that verifies the required parameters are set.\r\nHowever I was unable to come up with a simple test as this API-call requires a valid Policy-ARN, which in turn requires a autoscaling-group, etc etc. I'd happy if you would pull without a test. Any suggestion/hint?\r\n\r\nCheers,\r\nJens\r\n"
540,'',"Small improvements\nHi\r\n\r\nthese are the small improvements to the core out of my big changes to the vcloud part. I will provide the vcloud improvements as well if I have them in a state, where I would publish them. So long I think it's better to merge my changes seperately into the core.\r\n\r\nThis time I also integrated @geemus's comments from the other pull request.\r\n\r\n~pete\r\n"
539,'',"Small improvements\nHi\r\n\r\nthese are the small improvements to the core out of my big changes to the vcloud part. I will provide the vcloud improvements as well if I have them in a state, where I would publish them. So long I think it's better to merge my changes seperately into the core.\r\n\r\n~pete"
538,'','Completed support for CloudWatch\nAdded models, parsers, requests and tests for remaining CloudWatch features.'
537,'',"[compute|aws] Error listing images when using JRuby\nConsider the following code (specially the last line):\r\n\r\n```ruby\r\n# list_images.rb\r\naws = Fog::Compute.new({\r\n  :provider                 => 'AWS',\r\n  :aws_access_key_id        => 'ACCESS_KEY',\r\n  :aws_secret_access_key    => 'SECRET_KEY'\r\n})\r\n\r\nputs aws.images.all\r\n```\r\nWhen it is run with MRI 1.9.2, everything works fine. But when I run it using JRuby 1.6.3:\r\n\r\n```shellscript\r\nExcon::Errors::SocketError: can't convert String into Integer\r\n          request at /home/marcelo/.rvm/gems/jruby-1.6.3@padrino/gems/excon-0.7.3/lib/excon/connection.rb:187\r\n          request at /home/marcelo/.rvm/gems/jruby-1.6.3@padrino/gems/fog-1.0.0/lib/fog/core/connection.rb:20\r\n          request at /home/marcelo/.rvm/gems/jruby-1.6.3@padrino/gems/fog-1.0.0/lib/fog/aws/compute.rb:286\r\n  describe_images at /home/marcelo/.rvm/gems/jruby-1.6.3@padrino/gems/fog-1.0.0/lib/fog/aws/requests/compute/describe_images.rb:50\r\n              all at /home/marcelo/.rvm/gems/jruby-1.6.3@padrino/gems/fog-1.0.0/lib/fog/aws/models/compute/images.rb:49\r\n           (root) at aws.rb:10\r\n```"
536,'','[core] treat boolean values as a boolean\nIf an attribute should be of type boolean and the value passed is already a boolean, the value should not be discarded. This fixes this problems and add tests for the boolean type.\r\n\r\n~pete'
535,'','Inconsistent AWS storage directory attributes\n`connection.directories.first` returns \r\n\r\n``` ruby\r\n<Fog::Storage::AWS::Directory key="batch-upload", creation_date=2011-09-27 02:31:58 UTC>\r\n```\r\n`connection.directories.get(\'batch-upload\')` returns\r\n\r\n```ruby\r\n<Fog::Storage::AWS::Directory key="batch-upload", creation_date=nil>\r\n```\r\n\r\nThe directories are in fact the same directory, and contain the same files.'
534,'',"Ruby 1.9.3 Segmentation Fault with S3\nFog or more specifically excon seems to segfault with on ruby 1.9.3-rc1 when using AWS S3\r\n\r\nI post this here as I'm unsure whether it is excon or fog.\r\n\r\nIve posted a sample application here that shows this happening.\r\n\r\nhttps://github.com/arbarlow/fog-193-segmentation\r\n\r\nYou just need to replace the AWS key and bucket in config/initializers/carrierwave.rb\r\n\r\nA sample stacktrace is in the readme also...\r\n\r\n/Users/alex/.rvm/gems/ruby-1.9.3-rc1@93/gems/excon-0.6.6/lib/excon/connection.rb:276: [BUG] Segmentation fault\r\nruby 1.9.3dev (2011-09-23 revision 33323) [x86_64-darwin11.1.0]\r\n\r\n-- Control frame information -----------------------------------------------\r\nc:0102 p:---- s:0576 b:0576 l:000575 d:000575 CFUNC  :connect"
533,'',"Updated the fog.io Index Page to reflect README.md and Truth of Statement.\nRemoved statement about @geemus being only member of collaborators list since it's not true anymore."
532,'','Update gemspec description to mention popular services that are supported\nUpdate gemspec description to mention popular services that are supported.'
531,'','Osapi real tests\nAdditions and updates to the OpenStack API tests.'
530,'','Add Clodo.Ru cloud provider\nAdd support for clodo.ru API'
529,'','Add support for non-strict validations, and nullable arrays/hashes.\nThis branch gives me the ability to do this in my tests:\r\n\r\n\r\n    tests(\'#get_flavor_details(1)\').formats(@flavor_format, false) do\r\n      Fog::Compute[:openstack].get_flavor_details("1").body[\'flavor\']\r\n    end\r\n\r\n** notice the extra \'false\' option on the formats helper call.\r\n\r\nThe issue I\'m having with real tests is that the OpenStack API allows extensions. This seems like a reasonable addition to our formats validation function to validate that core things exist while ignoring the extra data.'
528,'',"AWS[:elasticache] support, API Version 2011-07-15 \n* All API requests are implemented\r\n  http://docs.amazonwebservices.com/AmazonElastiCache/latest/APIReference/\r\n\r\n* AWS::Elasticache Models: CacheCluster, SecurityGroup, ParameterGroup\r\n\r\n* Test with: bundle exec shindo +elasticache\r\n  (full test suite is SLOW; no Mocks are implemented yet)\r\n\r\n* There is 1 pending test, for a request that is not behaving correctly in all cases\r\n  ( '#reset_cache_parameter_group with one parameter')\r\n"
527,'',"Work on vcloud API\nHi\r\n\r\nI started to improve the current implementation of the vCloud part. As I chatted with @lstoll (s)he mentioned that the vCloud implementation was left, because they decided for another product.\r\n\r\nSo I introduced Organizations and vApps, made the lib multi-organization capable and changed some parts of the API. Mainly, those parts that didn't work for me.\r\n\r\nWith the current implementation I'm able to query a whole vCloud, which means, that I can walk through all organizations, their vDCs, the contained catalogs and vApps and the servers contained within the vApps. So for me it's currently pretty usable and fits in my opinion much better the actual way how a vCloud is structured.\r\n\r\nThis is my first usage of and hacking on fog. I'm sure there's plenty of room for improvements, I understood probably a lot of things not as they are actually thought to be used and tests are lacking as well :/. However what I would like to feel with my patch series, is whether the road I started going down is appreciated and I won't have to maintain an own fork of fog.\r\n\r\nWhat do you think?\r\n\r\nThanks\r\n\r\n~pete"
526,'','Fixed a couple of errors in the examples\n'
525,'','Openstack Compute API v1.1 support\nImplement fog support for the Openstack Compute API v1.1. Includes support for legacy v1.0 style auth and v2.0 keystone auth.'
524,'','[aws/sqs] Adding SQS mocking support.\nAdded Mock support to AWS SQS:\r\n\r\n* Queue: create_queue, list_queues, delete_queue, get_queue_attributes\r\n* Message: send_message, receive_message, delete_message, change_message_visibility\r\n\r\nShindo tests for response formats passing for both message and queue.'
523,'',"Schedule Release 0.12\n- I'm wondering with fog 0.11 released,could we bump the version to 0.12 already? \r\n- Also I'm eager of getting the kvm release + maybe the vsphere code as well?\r\n\r\nwhen do think the release will be happening?"
522,'',"[bluebox|compute] Expect correct status code for template create\nAs per our API documentation, a success will return '202': https://boxpanel.bluebox.net/public/the_vault/index.php/Blocks_API#POST_.2Fapi.2Fblock_templates"
521,'','[bluebox|compute] Fix for setting hostname on server save.\n'
520,'',"EMR functionality for AWS\nI've added all EMR functions to the AWS library along with an improved serialization function for creating command line args out of function parameters.  I also added a helper function to start a hive cluster.\r\n\r\nI'm in the middle of writing tests now but I wanted to check out if these additions are welcome or not."
519,'','Tweak to escape the Cloud Files filename before passing to public_url.\nPreviously, a Rackspace Cloud Files storage object with a name like\r\n"my_files/1234/original/picture #1.jpg" would generate a public URL like:\r\n\r\nhttp://c21641.r41.cf1.rackcdn.com/user_files/1313284/thumb/IMG_4034 #1.jpg\r\n\r\nThe # character in the URL would get interpreted by Cloud Files as an\r\nanchor marker, and the file would not load.  This change does the\r\nFog::Rackspace.escape on the key (excluding the / path separator character)\r\nto generate a working URL of the form:\r\n\r\nhttp://c21641.r41.cf1.rackcdn.com/user_files/1313284/thumb/IMG_4034%20%231.jpg\r\n\r\nWhich is correctly interpreted by Cloud Files and pulls up.\r\n\r\nBoth of those URLs are live to demonstrate the issue.'
518,'',"[storage] Fixed broken directory model test\nFixed what appeared to be broken test (I only verified with Rackspace provider).  I noticed this while looking at #516.  I can't see how it could have worked on the other providers either, but I only have experience with Rackspace so I could be missing something."
517,'',"[compute|aws] When mocking, instances don't show up right away.\nThis relates to #491.\r\n\r\nNow that fog uses the possibly eventually consistent filtered-param API in `describe_instances`, there is the chance that initial calls to `describe_instances` with an instance id just returned by `run_instances` might yield a 404.\r\n\r\nThis change mimics that in the `describe_instances` mocking."
516,'',"Exception trying to initialize Rackspace storage\nOdd issue - I'm trying to load up a Rackspace Cloud Files storage object, and getting an error about loading a particular file.\r\n\r\n```\r\nirb(main):001:0> require 'tmp/fog/lib/fog'\r\n=> true\r\nirb(main):002:0> storage = Fog::Storage.new(:provider => 'Rackspace',\r\nirb(main):003:1*          :rackspace_username => 'XXX',\r\nirb(main):004:1*          :rackspace_api_key => 'YYY')\r\nLoadError: no such file to load -- fog/rackspace/models/storage/directories\r\n\tfrom /Library/Ruby/Site/1.8/rubygems/custom_require.rb:36:in `gem_original_require'\r\n\tfrom /Library/Ruby/Site/1.8/rubygems/custom_require.rb:36:in `require'\r\n\tfrom /Users/minter/tmp/fog/lib/fog/core/service.rb:79:in `setup_requirements'\r\n\tfrom /Users/minter/tmp/fog/lib/fog/core/service.rb:78:in `each'\r\n\tfrom /Users/minter/tmp/fog/lib/fog/core/service.rb:78:in `setup_requirements'\r\n\tfrom /Users/minter/tmp/fog/lib/fog/core/service.rb:60:in `new'\r\n\tfrom /Users/minter/tmp/fog/lib/fog/storage.rb:25:in `new'\r\n\tfrom (irb):2\r\n```\r\n\r\nAnd sure enough, there's no directory there.  Any idea what might be going on?  Or has the syntax for creating a storage object changed?  \r\n\r\nThis is using the latest github HEAD as of tonight, and git bisect shows that whatever this is probably popped up with the namespace reorg around commit ff6e4397271eacf0a809bbb141186a563b52e657"
515,'','[core] provide Fog::Provider[:service] type accessors\nI had intended to get these working (and thought they did work already), but it seems I was mistaken.  This should be fixed.  IE Fog::AWS[:sqs] ought to build you a connection with your default credentials.'
514,'','Add snapshot method to aws volume model\nUsed when iterating through volumes\r\n\r\n```ruby\r\nvolumes.each do |v|\r\n  v.snapshot "Batch snapshot"\r\nend\r\n```\r\n\r\nUsing it for nightly snapshots, might be useful to others.'
513,'',"Better URL escaping for Rackspace Cloud Files.\nURI.escape doesn't encode question marks properly, CGI.escape doesn't encode\r\nspaces properly.  So we create an escape class method for Fog::Rackspace that\r\ndoes the CGI.escape methods, only additionally encoding spaces as %20.\r\n\r\nThis makes things work properly with Rackspace Cloud Files."
512,'','[aws|compute] EU Ubuntu AMI\'s not found error\nHi Wesley,\r\n\r\nI\'ve been playing around with EC2 and using Fog, I am for some reason (probably because i\'m doing it wrong) only able spin up the US-EAST Ubuntu AMI\'s found on this page: http://cloud-images.ubuntu.com/releases/10.04/release/\r\n\r\nI would like to try and spin up an AMI in the EU region but failed to do so. I also tried other regions like US-WEST but that doesn\'t work either. It seems that I\'m only able to spin up instances in US-EAST (default?).\r\n\r\nThe code snippet I ran:\r\n\r\n``` rb\r\n\r\nserver = connection.servers.bootstrap(\r\n  :image_id          => "ami-5c417128",\r\n  :availability_zone => "eu-west",\r\n  :flavor_id         => "t1.micro",\r\n  :private_key_path  => "~/.ssh/id_rsa",\r\n  :public_key_path   => "~/.ssh/id_rsa.pub",\r\n  :username          => "ubuntu"\r\n)\r\n```\r\n\r\nI also tried to switch `:availability_zone` to `:region` but it doesn\'t work. I also tried to change the `"eu-west"` to `"eu-west-1"`, `"eu-west-1a"`, `"eu-west-1b"` etc. but I can\'t find anything that works.\r\n\r\nThe error that\'s returned is:\r\n\r\n```\r\n/Users/Michael/.rvm/gems/ruby-1.9.3-preview1/gems/excon-0.6.6/lib/excon/connection.rb:190:in `request\': The AMI ID \'ami-5c417128\' does not exist (Fog::Compute::AWS::NotFound)\r\n\tfrom /Users/Michael/.rvm/gems/ruby-1.9.3-preview1/gems/fog-0.11.0/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /Users/Michael/.rvm/gems/ruby-1.9.3-preview1/gems/fog-0.11.0/lib/fog/compute/aws.rb:280:in `request\'\r\n\tfrom /Users/Michael/.rvm/gems/ruby-1.9.3-preview1/gems/fog-0.11.0/lib/fog/compute/requests/aws/run_instances.rb:113:in `run_instances\'\r\n\tfrom /Users/Michael/.rvm/gems/ruby-1.9.3-preview1/gems/fog-0.11.0/lib/fog/compute/models/aws/server.rb:169:in `save\'\r\n\tfrom /Users/Michael/.rvm/gems/ruby-1.9.3-preview1/gems/fog-0.11.0/lib/fog/compute/models/aws/servers.rb:100:in `bootstrap\'\r\n\tfrom foggy.rb:13:in `<main>\'\r\n```\r\n\r\nWhen I open the amazon web console for EC2 and browse the EU AMI list, and fill in the AMI id `ami-5c417128` it does seem to find the image so it does exist, I assume.\r\n\r\nAny help much appreciated!\r\n\r\nCheers,\r\nMichael'
511,'',"Excon::Errors::NotFound: Expected(200) <=> Actual(404 Not Found)\nI switched from aws to fog, and I'm getting Excon::Errors::NotFound: Expected(200) <=> Actual(404 Not Found) errors intermittently. It's difficult to track down because I can't consistently reproduce it. I'm using ruby 1.9.2-p0.\r\n\r\nThere is an issue on paperclip for this same error: https://github.com/thoughtbot/paperclip/issues/554"
510,'','[vsphere] Fix vm clone problem when a Guid instance is passed as the instance_uuid\nWithout this patch the vm_clone requiest would not find a Managed Object\r\nReference when a UUID that is not a string is passed as the\r\ninstance_uuid option.  This is a problem because an unhelpful "undefined\r\nmethod `parent\' for nil:NilClass" would be thrown to the application.\r\n\r\nThis patch throws a more helpful Fog::Compute::Vsphere::NotFound\r\nexception if the Virtual Machine template is not found.\r\n\r\nThe tests have been updated to reflect this expectation.'
509,'','[vsphere] Add vsphere_server connection attribute\nWithout this patch it was difficult to figure out from the outside what\r\nvSphere server Fog connected to.  The application using Fog should be\r\nable to easily print out the connection information without breaking the\r\nencapsulation Fog provides.\r\n\r\nThis patch makes the connected vSphere server hostname and API username\r\nan attribute of the connection instance.\r\n\r\nThe tests have been updated to validate these attribute accessor\r\nmethods.'
508,'','New AWS ELB API version\nThere is a new ELB version (2011-08-15).  See http://aws.amazon.com/releasenotes/Amazon-EC2/8686150592989962 '
507,'','[ecloud/terremark] Support computePools\nIt would be awesome if fog supported computePools within the ecloud/Terremark environments.  Right now, if you have multiple computerPools available, it is impossible to use fog to instantiate new servers anywhere but in the default computePool.\r\n\r\nHere is some documentation on the XML and API calls.  Search for computePool within the document:\r\n\r\nhttp://support.theenterprisecloud.com/kb/default.asp?id=979&Lang=1&SID=\r\nhttp://support.theenterprisecloud.com/kb/default.asp?id=908&Lang=1&SID=\r\n\r\nPlease let me know if you need more details.\r\n\r\nThanks!\r\nAaron'
506,'','[aws|cloudwatch] Fix whitespace.\nHi wes,\r\nplease pull this whitespace cleanup. While I poke around understanding how shindo and fog work, I came across some them.\r\nCheers,\r\nJens\r\n'
505,'','[vsphere] vsphere provider with tests\nThis change set adds a VMware vsphere provider to Fog.  This initial implementation provides a VirtualMachine server model and collection.  The ability to clone a new VM from a template is the major feature provided.\r\n\r\nIn addition, the server model implements the start, stop, reboot and destroy behavior methods.\r\n\r\nShindo tests are provided for all of the behaviors and each request has a Mocked implementation to facilitate testing and refactoring.\r\n\r\n    >> compute = Fog::Compute[:vsphere]; servers = compute.servers; servers.length\r\n    5\r\n    >> template = servers.find { |s| s.name =~ /centos/ }\r\n      Fog::Compute::Vsphere::Server\r\n        id"50323f93-6835-1178-8b8f-9e2109890e1a",\r\n        name"centos56gm",\r\n        uuid"42322347-d791-cd34-80b9-e25fe28ad37c",\r\n        instance_uuid"50323f93-6835-1178-8b8f-9e2109890e1a",\r\n        hostnamenil,\r\n        operatingsystemnil,\r\n        ipaddressnil,\r\n        power_state"poweredOff",\r\n        tools_state"toolsNotRunning",\r\n        tools_version"guestToolsCurrent",\r\n        mac_addresses{"Network adapter 1"=>"00:50:56:b2:00:a1"},\r\n        hypervisor"gunab.puppetlabs.lan",\r\n        is_a_templatetrue,\r\n        connection_state"connected",\r\n        mo_ref"vm-698"\r\n      \r\n    >> new_vm = compute.vm_clone(\'instance_uuid\' => template.id, \'name\' => \'newvm\')\r\n    {"vm_ref"=>"vm-753", "task_ref"=>"task-1931"}\r\n    >> newvm = servers.reload.find { |s| s.name =~ /newvm/ }\r\n      Fog::Compute::Vsphere::Server\r\n        id"vm-753",\r\n        name"newvm",\r\n        uuidnil,\r\n        instance_uuidnil,\r\n        hostnamenil,\r\n        operatingsystemnil,\r\n        ipaddressnil,\r\n        power_state"poweredOff",\r\n        tools_statenil,\r\n        tools_versionnil,\r\n        mac_addressesnil,\r\n        hypervisornil,\r\n        is_a_templatenil,\r\n        connection_state"connected",\r\n        mo_ref"vm-753"\r\n    >> newvm.wait_for { uuid }\r\n'
504,'','[core] Allow FOG_CREDENTIAL variable for config\nSay your ~/.fog had multiple stanzas:\r\n    :default:\r\n      :aws_access_key_id: aaa\r\n    test:\r\n      :aws_access_key_id: bbb\r\n    prod:\r\n      :aws_access-key_id: ccc\r\n\r\nChoose a stanza with an environment variable:\r\n   $ FOG_CREDENTIAL=prod fog'
503,'','[compute|aws] Fix NameError.\nException handling seems to be been forgotten, when AWS moved in Fog::Compute namespace.'
502,'',"[dynect|dns] expired credentials\nI have run in to an issue with Fog::DNS::Dynect and expired credentials. I am wondering if I should raise a custom error object in fog and have my application handle the reauth or if I should build this in to fog itself (say 4 retries). Wanted to get some feedback before proceeding. Not sure what would be considered worthwhile in fog and what wouldn't be."
501,'','[aws|simpledb] Order discarded by select parser\nThe `SimpleDB::Select` parser discards the order of results returned from sdb by putting the results in a Hash. This makes it impossible to get useful results from a select statement with an `order` specified.\r\n\r\nI have a hacky little patch that will be backwards compatible - pull request forthcoming.'
500,'','[bluebox|compute] Create and destroy images\nAdded the ability to create templates from running instances.\r\nAdded the ability to destroy templates.'
499,'','[aws|cloudwatch] put-metric-alarm missing\nShort story:\r\nAWS CloudWatch misses a function to put a metric alarm. This is needed by AutoScaling, where these alarms trigger creation/destruction of instances.\r\n\r\nLong story:\r\nI currently go through the autoscaling example in the "Programming Amazon EC2" book by O\'Reilly (~page 63).\r\n\r\nTheir example involves the following steps\r\n1) create Autoscaling launch config\r\n2) create Autoscaling group\r\n3) create Autoscaling policy\r\n4) create CloudWatch metric alarm.\r\n\r\nI can do 1-3 using fog\'s API, but the CloudWatch parts seem not have been updated, since Amazon moved to CloudWatch alarms.\r\n(See also this https://forums.aws.amazon.com/thread.jspa?threadID=56141, also ticket #285)\r\n\r\n'
498,'','[compute|aws] DescribeTags mocking\nAdds mocking for DescribeTags. Also fixes a bug in CreateTags mock that prevents servers from being updated with new tags assigned to them via that request.'
497,'','Please pull this tiny documentation update.\nFix documentation. The resulting hash has no entry "PutScalingPolicyResponse", but a "...Result".'
496,'','[storage|aws] Add options to File#copy method\nFile#copy takes similar arguments to the #copy_object request'
495,'','uninitialized constant Fog::Rackspace::Storage::NotFound\nThis is not covered by any existing test, but the namespace is correct now.'
494,'','[bluebox|compute] Fixed instance state\nThis now returns the proper state.'
493,'',"Working status on blocks.\nFixing 'ready?'."
492,'','Dynect mocking\n'
491,'',"DescribeInstances InstanceId param should have index according to AWS Docs\nEven if there is only one InstanceId, the docs seem to indicate we should include an index on the InstanceId param. OpenStack's EC2 API expects the index in all cases so this will fix compatibility there as well.\r\n\r\nTested this against EC2 and OpenStack.\r\n\r\nFWIW, the Boto Python library follows this convention as well.\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/APIReference/index.html?ApiReference-query-DescribeInstances.html\r\n\r\nOpenStack compatibility issues: \r\nhttp://tickets.opscode.com/browse/KNIFE_OPENSTACK-1?focusedCommentId=19336&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-19336\r\n\r\n"
490,'','Fix warning about whitespace before parentheses in dns.rb.\nSaw this on startup of "fog interactive".'
489,'',"[compute|aws] - Change modify_instance_attribute name to match EC2 API me\nThis method doesn't really do anything, so make it work.\r\n\r\nAs well, the EC2 API method is '_attribute', and the filename is '_attribute', and the two other similar methods are '_attribute', but for some reason this method got named '_attributes'.  Fix that, and add a depcrecation warning to the old method."
488,'','uninitialized constant Fog::Rackspace::Storage::NotFound\nWhen trying to use Rackspace Cloudfiles with Paperclip we were getting an uninitialized constant error when our file was not found.  It looks like Fog::Rackspace::Storage::NotFound should be Fog::Storage::Rackspace::NotFound in /fog/lib/fog/rackspace/cdn.rb:82.  Would make this change myself with tests, but am unable to understand the testing structure.'
487,'',"[compute|aws] Don't warn in mock describe_snapshots if RestorableBy is 'self'\nThe AWS snapshots collection defaults the `RestorableBy` filter to `self`. The mock `describe_snapshots` warns if a `RestorableBy` filter is specified, but I believe the spirit of the warning is to say that specifying anything other than `self` is not properly mocked. So, don't warn if it's `self`."
486,'','[rackspace|dns] Rackspace DNS\nFor #415\r\n\r\nBasic DNS function is working and matches the contracts Fog is expecting.  Advanced Rackspace specific functionality is not included but that can probably be subsequent fixes.\r\n\r\nOne big issue I would like you all to weight in on:\r\n - Mutator operations return a callback instead of the actual data\r\n - I added a wait_for_job function that will wait for the completion of the mutator action.\r\n - The only operation this is really really needed for is create (so you can get the ID of the zone).  Update and destroy might be fine without it.\r\n\r\nAlso note, I threw in a couple LB test fixes that I noticed.\r\n\r\nLet me know your feedbac.'
485,'','[openstack|compute] OpenStack API 1.1\nRackspace recently released its OpenStack API 1.1 in an alpha environment.  The new API contains some more operations like editing meta-data and a few other changes.\r\n\r\nhttp://docs.openstack.org/cactus/openstack-compute/developer/openstack-compute-api-1.1/content/index.html\r\n\r\nOne of the openstack devs has voiced interest in adding this functionality to Fog.   Let me know if anyone has already started working on this, otherwise he will probably sign up to tackle it.'
484,'',"Libvirt integration for fog\nHere is a first cut at the integration of libvirt into fog. It's a bit focused on kvm and could probably use some extra features/testing. But I'm using it daily now and it works for my needs.\r\n\r\nAs this is pretty self contained (a separate provider), it will not hurt other providers.\r\n\r\nI've noted people starting to experiment with it, and I think the time has come to integrate it further into the fog master.\r\n\r\nPatrick"
483,'','Pass hostname to create_block request if provided.\nShould be able to specify a hostname as described here under "Optional fields":\r\n\r\nhttps://boxpanel.bluebox.net/public/the_vault/index.php/Blocks_API#POST_.2Fapi.2Fblocks'
482,'',"I'm getting like 300 of these a second in production, please help it's killing my logging\nI'm getting like 300 of these a second in production, please help it's killing my logging"
481,'',"Security group fixes\nWhile I did fuck up yesterday and mistakenly think AWS was fucking me around, I did end up catching some issues with the mocking support for security groups. So not a complete waste.\r\n\r\nThe biggest thing I found is that SourceSecurityGroupOwnerId can be nil and it'll use your owner_id. I made the mocks support this and also make use of the argument if it's passed in.\r\n\r\nRan against real and mocked and both pass fine now. I probably need to test across a different owner_id though and see how that really works."
480,'','[storage|aws] extended put_object_acl and put_bucket_acl to support canned ACLs\nYou can now use `put_object_acl` and `put_bucket_acl` to put a canned ACL.'
479,'',"Various fixes\nVarious fixes for AWS, all but one fixing mock behavior.\r\n\r\nThe other fixes modify_{image,instance,snapshot}_attribute to include the id of the thing they're modifying."
478,'',"AWS::SecurityGroup#revoke_owner_and_group\nI've just noticed something odd about this method. https://github.com/geemus/fog/blob/master/lib/fog/compute/models/aws/security_group.rb#L133\r\n\r\nIt doesn't actually work in the case I thought it would so I was hoping you could shed some light on it's proper use case. I am trying to remove a group from another group, say B from A.\r\n\r\nA.revoke_group_and_owner('B', '12345...'), is that the correct usage? It will call;\r\n\r\nrevoke_security_group_ingress('A', 'SourceSecurityGroupName'  => 'B', 'SourceSecurityGroupOwnerId'  => '12345...')\r\n\r\nThe only way I've gotten this to work is doing;\r\n\r\nrevoke_security_group_ingress('A', { 'IpPermissions.1.Groups.1.UserId' => '12345....', 'IpPermissions.1.Groups.1.GroupName' => 'B', 'IpPermissions.1.IpProtocol' => 'tcp', 'IpPermissions.1.FromPort' => 1024, 'IpPermissions.1.ToPort' => 1024 })\r\n\r\nAlso I can't find anywhere in the EC2 documentation about those particular arguments being used."
477,'','Nil Values\nIf a configuration hash is passed and one of the values is nil, then Fog should treat it as though the corresponding key were not in the hash.\r\n\r\n    storage = Fog::Storage.new({\r\n      :provider             => "Rackspace"\r\n      :rackspace_username   => "username",\r\n      :rackspace_api_key    => "api_key",\r\n      :region               => nil # should be interpreted as though it were not passed\r\n    })\r\n\r\nUse case:\r\n\r\n    storage = Fog::Storage.new({\r\n      :provider             => "Rackspace"\r\n      :rackspace_username   => "username",\r\n      :rackspace_api_key    => "api_key",\r\n      :region               => ENV[\'REGION\'].presence\r\n    })\r\n\r\nWhere `#presence` is from ActiveSupport, and returns `nil` if the recipient is a blank string.\r\n\r\nThis way I do not have to set up a separate `Hash` object, and only set the key `:region` if `ENV[\'REGION\'].presence` is not `nil`, and then pass that `Hash` object into `Fog::Storage.new`, and my code is simpler.\r\n\r\nVersion that I need to write now:\r\n\r\n    fog_credentials = {\r\n      :provider             => "Rackspace"\r\n      :rackspace_username   => "username",\r\n      :rackspace_api_key    => "api_key"\r\n    }\r\n    region = ENV[\'REGION\'].presence\r\n    fog_credentials[:region] = region if region\r\n    storage = Fog::Storage.new(fog_credentials)\r\n'
476,'','[core] service configuration coercion and defaults\nAll Fog configuration parameters should support string keys and string values. Configuration parameters which are expected to be numeric or boolean should be auto-coerced to the expected type if they are strings. Use case: setting configuration parameters correctly simply by looping over the environment variables.\r\n\r\nProviders should also be permitted in any text-case (case-insensitive provider lookup).\r\n\r\nExample:\r\n\r\n    storage = Fog::Storage.new({\r\n      "provider"             => "rackspace", # should be supported (lowercase provider)\r\n      "rackspace_username"   => "username",\r\n      "rackspace_api_key"    => "api_key",\r\n      "rackspace_servicenet" => "true"       # should be supported (boolean value given as a string)\r\n    })\r\n'
475,'','updated the code indenting for proper markdown code block recognition\n'
474,'','added a request to put a canned ACL on an existing object\nYou can use `put_object_acl` to put a specific ACL, but nothing to put a canned `:private` ACL, for example. I thought of extending the existing `put_object_acl`, but they actually share very little code.'
473,'','Split fog up into multiple projects (gems)\nJust an idea (but I think a good one). For me, it would make a lot of sense to manage fog in multiple projects, e.g. "fog-core", "fog-aws", "fog-rackspace", etc, etc. and then have a "fog" meta-gem that installs them all. RSpec is probably the best example for a project which successfully does that: https://github.com/rspec/'
472,'',"Added a fast way to add your current machine to an RDS security group.\nYou can now call #authorize_me on an RDS::SecurityGroup which will add your current machine IP address to the security group.  This makes it very easy to develop against RDS and add new machines to a security group in production. This function depends on Fog::CurrentMachine#ip_address which is a threadsafe way to get the current machine's ip address using amazon's checkip website. I've included a spec file for this function as well. Hopefully others will find this useful!"
471,'','Fix issue 464, add howto for European Rackspace cloud\nMini fix to add info about how to setup the credentials for the European cloud from Rackspace. Should be sufficient to close issue 464'
470,'','[rackspace|load balancers] broken tests\nI noticed a recent namespace change broke some tests.  This should fix most of the issues.  I just did it straight on master since it is only changing some tests.'
469,'','[compute|aws] Allow image mocks to support state (except failed).\nUsing a registered member to track the time so we can have faked state like instances.'
468,'',"VirtualBox/CLI Improvements\nWhen running fog for the first time with no setup, the missing_exception message\r\nwas surrounded above and below with a stack trace, which is not particularly\r\nuser-friendly. Since we've rescuing the LoadError only in bin/fog, we know\r\nwe don't have to worry about higher level libraries not getting the exception,\r\nsince it wouldn't propagate between processes.\r\n\r\nChanging LoadError to Fog::Error::LoadError lets us know that this was\r\nan issue on fog's part, rather than some other library we might be\r\nusing. Since we inherit from the LoadError class, any higher-level\r\nlibraries that were using a rescue based on LoadError will still work.\r\n\r\nWork is being done on getting VirtualBox up to speed as well."
467,'','[compute|glesys] Added Glesys as a provider\nAdded support for the Swedish VPS provider [Glesys](http://glesys.com). Unfortunately it is missing some tests  (maybe more). I will look into it as soon as possible.\r\n\r\nIf you want access to the (currently beta) API, just contact me and I should be able to pull some strings.\r\n\r\nComments and feedback are very welcome, thanks!'
466,'',"Error in bootstrap with Net:SSH?\nI'm curious, it looks like this error may be in Net::SSH, but I'm curious if it could maybe be Fog's fault.\r\n\r\nI'm running the following code:\r\n\r\n\r\n    connection = Fog::Compute.new({\r\n      :provider                 => 'AWS',\r\n      :aws_secret_access_key    => AWS_SECRET,\r\n      :aws_access_key_id        => AWS_KEY\r\n    })  \r\n         \r\n    server = connection.servers.bootstrap(\r\n       :private_key_path => '~/.ssh/id_rsa', \r\n       :public_key_path  => '~/.ssh/id_rsa.pub', \r\n       :region           => 'us-east-1',\r\n       :flavor_id        => 'm1.small',\r\n       :image_id         => 'ami-8c1fece5',\r\n       :username         => 'ec2-user',\r\n       :verbose          => true\r\n    )   \r\n\r\nAnd I get the following error:\r\n\r\n     /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/net-ssh-2.1.4/lib/net/ssh/proxy/command.rb:36:in `open': wrong number of arguments (2 for 3) (ArgumentError)\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/net-ssh-2.1.4/lib/net/ssh/transport/session.rb:65:in `block in initialize'\r\n       from /home/natwelch/.rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/timeout.rb:58:in `timeout'\r\n       from /home/natwelch/.rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/timeout.rb:89:in `timeout'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/net-ssh-2.1.4/lib/net/ssh/transport/session.rb:65:in `initialize'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/net-ssh-2.1.4/lib/net/ssh.rb:183:in `new'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/net-ssh-2.1.4/lib/net/ssh.rb:183:in `start'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/fog-0.10.0/lib/fog/core/ssh.rb:52:in `run'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/fog-0.10.0/lib/fog/compute/models/aws/server.rb:190:in `block (2 levels) in setup'\r\n       from /home/natwelch/.rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/timeout.rb:58:in `timeout'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/fog-0.10.0/lib/fog/compute/models/aws/server.rb:189:in `block in setup'\r\n       from /home/natwelch/.rvm/rubies/ruby-1.9.2-p290/lib/ruby/1.9.1/timeout.rb:58:in `timeout'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/fog-0.10.0/lib/fog/compute/models/aws/server.rb:187:in `setup'\r\n       from /home/natwelch/.rvm/gems/ruby-1.9.2-p290/gems/fog-0.10.0/lib/fog/compute/models/aws/servers.rb:102:in `bootstrap'\r\n\r\nAny ideas? I poked around Net::SSH's code, and it looks like it's just not passing the user down, but I'm unsure."
465,'',"uninitialized constant JSON::ParserError\nOn Rails 3.0.7 ruby 1.9.2 I have this issue when trying to upload or delete a file on Rackspace Cloud Files\r\n\r\n\r\n    NameError (uninitialized constant JSON::ParserError)\r\n\r\n\r\nI can fix it just by requiring this in my Gemfile\r\n\r\n\r\n    gem 'json'\r\n\r\n\r\nMissing dependency?\r\n\r\n"
464,'','Rackspace London UK\nIf you like me are getting\r\n\r\n    Excon::Errors::Unauthorized (Expected([200, 204]) <=> Actual(401 Unauthorized)\r\n\r\nit\'s because you need to point to the london api server. \r\n\r\n    config.fog_credentials = {\r\n      :provider           => \'Rackspace\',\r\n      :rackspace_username => \'test\',\r\n      :rackspace_api_key  => \'456664546565\'\r\n      :rackspace_auth_url => "lon.auth.api.rackspacecloud.com"\r\n      }\r\n\r\nMaybe it would be nice to point it out in the documentation'
463,'',"Improve documentation of model attributes/options\nI've looked at the fog website, browsed through the fog api, and I have no idea how to create a ec2 instance with a specific security group.  Where are the options documented for compute.servers.create?"
462,'','Add force stop functionality to AWS Instance\nAWS allows you to add a force option to the stop request. This performs\r\nthe equivalent of a power off, rather thank asking the OS to shutdown.'
461,'','Small fixes to Local storage\n * Write files as binary (otherwise UTF8 - ASCII errors can occur in ruby 1.9)\r\n * Check if File exists before trying to delete it (paperclip sometimes deletes files twice)\r\n * Check if Directory exists before trying to "cd" into it. (paperclip sometimes deletes files twice)\r\n\r\nI ran the tests, a number of them failed but none seem to be related to the Local storage. I have also verified the changes work in a real world scenario.'
460,'','register_image mocking support.\n'
459,'','[aws|s3] Added basic tests for get_bucket, fixed a bug in get_bucket with delimiter option\n[aws|s3] Added basic tests for get_bucket, fixed a bug in get_bucket with delimiter option, tests succeed for both mocked and real situation'
458,'','[storage|aws] Fixed signature construction in Fog::Storage::AWS::Real#post_object_hidden_fields\nI believe this method is made for building upload form. If so, constructing signature should be done like this.\r\n\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/dev/HTTPPOSTForms.html#HTTPPOSTConstructingPolicySignature'
457,'',"Zerigo dns should recognize options :scheme and :port\nIt doesn't recognize these options and defaults to scheme http and port 80. The initializer checks for these options but the class does not recognize them."
456,'','[compute|cloudstack] added cloudstack support\nIncluded at this time:\r\n\r\nRequests for:\r\n\r\n- Domain management\r\n- Account management\r\n- User management\r\n- Assorted list requests (virtual machines, templates, images, usage records)\r\n\r\n'
455,'',"Link to EBS snapshots blog post\nI wrote a blog post about using Fog with EBS snapshots and included some example code. I've updated the press links to list it."
454,'',"[aws|rds] Allow string or symbol hash keys.\nServer#modify and #create_read_replica allow\r\noptions to be passed as symbols or strings.\r\n\r\nThis allows the same hash of attributes to be used\r\nfor creating & modifying servers.\r\n\r\nFor example, the following lines are equivalent:\r\n  server.modify(true, :allocated_storage => 10)\r\n  server.modify(true, 'AllocatedStorage' => 10)"
453,'','Support for delimiter option in Fog::Storage::AWS::Mock object\nHi,\r\n\r\nI added support for the delimiter option in Fog::Storage::AWS::Mock object'
452,'','Escape source object name for aws copy_object operation\n'
451,'',"Need to escape source object name for aws copy_object\nSerious things will happen if you don't CGI.escape source_object_name in headers for AWS copy_object operation !!"
450,'','[aws|compute] Fixed failing instance tests. \nThis fixes the failing aws instance tests.  There are still two broken tests: volume and address.'
449,'',"[aws|compute] Added missing 'platform' attribute to server model and describe instances request.\nAdded missing 'platform' attribute to server model and describe instances request."
448,'','[aws|compute] Security groups parser fix\n"describe security groups" parser was not taking into account ipPermissionsEgress and therefore returning unexpected results when the account had VPC groups.'
447,'','[aws|cdn] Added commands for streaming distribution lists.\nWhat the title says.  Added commands related to the management of streaming distribution lists in AWS.'
446,'','[AWS|IAM] Add new IAM cert validations and clean up error handling\n'
445,'','Fixed #444 - Unable to squash kvp with false values\n'
444,'','Unable to squash key-value-pairs with a FALSE value\n'
443,'',"[core] Extends SSH and SCP mocks.\nExtends mocking support for SSH and SCP\r\nby adding the respective methods run and\r\nupload.\r\n\r\nI created some rspec tests as well that use the new mock methods, but I was not sure where they would go in the project.\r\n\r\n  it 'should be able to mock ssh run' do\r\n    Fog::SSH.new('address', 'username').run('foo')[0].stdout.should == 'foo'\r\n  end \r\n  it 'should be able to mock scp upload' do\r\n    Fog::SCP.new('address', 'username', {}).upload('local', 'remote').should == ['local', 'remote', {}]\r\n  end"
442,'','[aws|elb] Refactor ELB error handling\n'
441,'',"Add spot requests models\nAs per geemus/fog#334, I added spot_instance models so that I can do, \r\n\r\nspot_request = connection.spot_requests.create(spot_request_def)\r\nspot_request.wait_for { state == 'active' }\r\nserver = connection.servers.get(spot_request.instance_id)\r\n\r\nI am using it in https://github.com/emiddleton/knife-ec2"
440,'',"Rs lb\nThis isn't ready for prime time yet, but I wanted to go ahead and get the discussion going on for this change.  A few questions I have are:\r\n \r\n* Is this the right folder structure (I generally followed AWS::ELB but not 100%)?\r\n* There doesn't seem to be a generally accepted load balancer model yet, and it might be challenging to create so I didn't undertake that yet.  Thoughts? \r\n* I had to follow the AWS::ELB code and create a new convention for sub-collections that feels hacky.  At some point it might be good to create a generalized collection convention for models and not just servies.  Interested to hear feedback on this one.\r\n\r\nOpen to any other feedback.  There is a decent amount more functionality but I didn't want to go too far down the wrong path."
439,'','Raise proper iam error in elb listeners\n[aws|elb] Raise proper IAM error for CertificateNotFound when creating an ELB or creating Listeners.'
438,'','[aws|iam] add get_server_certificate request\n'
437,'','[aws|iam] fix superclass mismatch\nMy bad..'
436,'','[aws|iam] add error handling for common failures resulting from upload_server_certificate\n[aws|iam] add error handling for common failures resulting from upload_server_certificate'
435,'','[compute|aws] #all calls should translate params to proper format\nI\'m not entirely sure this is actually a bug or is working by design, but:\r\n\r\n    >> compute.tags.all(:key => \'Environment\').first\r\n    =>   <Fog::AWS::Compute::Tag\r\n        key="Environment",\r\n        value="fanslam-api-second-demo",\r\n        resource_id="i-c3f35e96",\r\n        resource_type="instance"\r\n      >\r\n\r\nfrom that I would assume that I could do:\r\n\r\n    >> compute.tags.all(:resource_id => "i-c3f35e96", :key => \'Environment\').first\r\n\r\nbut that gives:\r\n\r\n    Fog::Service::Error: InvalidParameterValue => The filter \'resource_id\' is invalid\r\n\r\nthe correct request is:\r\n\r\n    >> Cloud.compute.tags.all(\'resource-id\' => "i-c3f35e96", :key => \'Environment\').first\r\n\r\nI would assume that fog would auto-translate :resource_id in to the AWS friendly \'resource-id\'.\r\n\r\nShould it?'
434,'',"Case sensitivity of ETag header causes an issue for VCR\nI've been using fog on a project and wanted to use VCR for stubbing the HTTP stuff.  The latest Excon addresses a few issues and I've addressed a few more in the the current master branch of VCR, but there's one more issue I'm trying to sort out.\r\n\r\nWhen VCR records an HTTP interaction, it normalizes the casing of the HTTP headers.  `Content-Type` becomes `content-type`, as demonstrated [here](http://relishapp.com/myronmarston/vcr/v/1-10-0/dir/cassettes/cassette-format).  This causes a problem when using VCR to stub fog for S3 stuff because Fog looks for the ETag header with exact casing [here](https://github.com/geemus/fog/blob/843cbc37ac49c2636cf0cd03390aa7cfa58bbb9a/lib/fog/storage/models/aws/file.rb#L120).  When VCR plays back the recorded response, it winds up converting 'etag' to 'Etag', and using that in the stubbed response, but that's not the casing fog expects.  A `NoMethodError` results.\r\n\r\nOverall, I would consider this a bug in VCR, but fixing it is anything but simple.  VCR has the header normalization logic due to the nature of how it was developed: it was initially just a tool for recording Net::HTTP requests with FakeWeb, and it was only later expanded to support other HTTP stubbing libraries and other HTTP client libraries.  `Net::HTTP` normalizes headers to lowercase, and as I added support for new libraries, I preserved this behavior--the idea being that a VCR cassette is an abstraction that should be the same regardless of the HTTP library used.\r\n\r\nLong term, I have plans for some changes to the VCR cassette format that would include changing this behavior so that HTTP headers are preserved exactly-as-is--but that's down the road, probably for 2.0.  In the short term, I'm OK putting in a slightly hacky work-around to treat the `ETag` header differently so that on playback it converts `etag` to `ETag` rather than `Etag`.\r\n\r\nI started working working on this today but have been stumped by the fact that Rack itself normalizes `ETag` to `Etag` (in spite of the fact that it is `ETag` in the RFC).  Check out [this gist](https://gist.github.com/1086910)--it demonstrates this rack behavior.  I use rack (well, Sinatra, really) in my tests but I can't really even create a proper end-to-end test for this since I can't get the rack server to return `ETag`.  Thinking about this some more--if I put in the short-term fix of converting `etag` to `ETag` on playback, that may break some the use of VCR for some other libraries.  Consider the case where there is a library that is an API wrapper for an HTTP API served up by rack--the header will be returned as `Etag`, and if the client logic is case sensitive (as yours is), it will depend upon casing being `Etag`.\r\n\r\nAll that is to say...I'm not sure what the right short-term fix is.  Would you consider changing Fog's logic to be tolerant of different casing for HTTP headers (or at least for ETag)?  i'd definitely consider this a bug in VCR, not in Fog, but given the fact that it's impossible to return an ETag header with some servers (like Rack) making it case-insensitivity would seem to make the Fog logic more robust anyway.\r\n\r\nLong term, I hope to get VCR to the point where it never touches the casing of HTTP headers since there's simply no way to ensure the response is played back the same when it does so.\r\n"
433,'','Use the multi_json gem\nI did run the specs and it seems ok, someone else would like to give it a try to be on the safe side?'
432,'',"[aws|elb] make ELB describe_load_balancers parse the Listener's SSLCertificateId\nAdded test for this bug, fixed it, and also added another test to verify that specifying listeners works when creating an ELB"
431,'','[aws|elb] Listener creation syntax is inconsistent\nListeners created at the same time as the ELB need to be passed in using the `ListenerDescriptions` syntax, whereas when creating them on an existing ELB you create them using the Listener attributes. Examples:\r\n\r\n```ruby\r\napi = Fog::AWS::ELB.new\r\n# before\r\nlb = api.load_balancers.create(:id => \'my-elb\', \'ListenerDescriptions\' => [{\r\n  \'Listener\' => {\'LoadBalancerPort\' => 80, \'InstancePort\' => 80, \'Protocol\' => \'HTTP\'},\r\n}])\r\n\r\n# after\r\nlb.listeners.create(:lb_port => 443, :instance_port => 443, :protocol => \'SSL\')\r\n```\r\n\r\nI made an attempt to fix this but ran into difficulties. I think that we should ideally allow listeners to be specified either way on ELB creation to avoid breaking the existing syntax, but also allow people to use the "after" syntax as an option.'
430,'',"Make Rails' respond_with play nice with to_json.\nHopefully this one should be ok. Cheers"
429,'',"Elb listener cleanup\nI made an effort here to clean up the way that the default listener is created by at least moving the default settings to the Listener model.\r\n\r\nOpen to feedback if this doesn't seem like a good change. However, I also added some useful tests to verify that custom listeners are applied properly, so those tests should still be useful."
428,'',"Fix for Rails' respond_with and to_json\nI screwed up a bit the last pull request, here's the new one. Cheers"
427,'',"to_json in Rails' respond_with\nThis commit should fix an exception thrown when using respond_to and respond_with in Rails."
426,'',"Discrepancy between .fog file & dir\nIt's very possible I missed something, but does Fog expect ~/.fog to be a dir, yet Carrierwave expect ~/.fog to be a credential file?"
425,'','[aws|compute] security groups not showing up\nIn version 0.8.2, when I would ask what security groups my server belonged to using AWS.servers[0].groups, I would get a list of group names.\r\n\r\nIn version 0.9.0 when I do Compute[:aws].servers.groups, I get [nil].\r\n\r\nFor some reason, the aws parser for describe_instances is looking for "groupName" in 0.90, where it was looking for "groupId" in 0.8.2. If I change it back to "groupId", my server security groups are populated correctly.'
424,'','[AWS|ELB] fix bug that was causing availability zones to not parse proper\nBefore this patch, availability zones were always loading to all zones, regardless of how the ELB was created.'
423,'',"Fix ::AWS[] syntax that's only valid in Fog tests when bin/aws.rb is load\nPrevent AWS Undefined exceptions when using Fog Mocks outside of Fog tests."
422,'','[tests] avoid using bin helpers\nThis will help to point out any misuse in actual implementation that might not work outside the bin environment.  So, for instance, instead of AWS[:iam] we should use Fog::AWS[:iam] and the like.  Should be pretty easy, but marking medium since it happens to touch a lot of different things.'
421,'',"[rackspace|openstack] connection X-Auth-Token expiration\nThe Rackspace/OpenStack adapters first retrieve an X-Auth-Token header on connect. Per subsequent service call, the X-Auth-Token is appended, which is cool, except when the token expires 24hrs later and causes my connection singleton to 'splode.\r\n\r\nMy hacky work-around is to attempt a reconnect on error. This is non-intuitive for developers and Fog + AWS does not have the same issue. I hope I'm describing this well enough. I've been working on a project with the cloudbuilders and they should be able to clarify my description if necessary."
420,'','Aws iam additions\nAdded alias support in AWS IAM.\r\nAdded support for pulling the new licensing additions for AWS RDS\r\nBug fixed lots in AWS Autoscaling.'
419,'','Fixes non-absolute exception for File.expand_path\nI believe this should do it. Take a look & let me know?'
418,'',"Reserved instances mocking\nI believe this is good to go, but the purchasing part I am slightly wary of since I couldn't run it against AWS for real as it'd spend my monies on the one-time purchase fee."
417,'',"Fixed the escaping in Fog::AWS.escape\nThe method now correctly escapes multibyte strings and behaves exactly like\r\nCGI.escape except that the tilde char is not escaped. Previously spaces where escaped as '%20' where Amazon requires '+' and multibyte characters were not escaped with their correct byte size.   "
416,'','Clean up timeout and add tests.\n'
415,'','[dns|rackspace] implement dns support from rackspace\nSee: http://www.rackspace.com/cloud/blog/2011/07/07/rackspace-cloud-dns-beta-now-available-for-us-uk-cloud-customers/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+RackspaceCloud+%28The+Rackspace+Cloud+Computing+%26+Hosting%29&utm_content=Google+Reader'
414,'','[aws|elb] Add set_load_balancer_listener_ssl_certificate\n'
413,'',"BETA Ninefold storage - try 2\nRunning through as as pull request, as it's a new item rather than working on something I've already added.\r\n\r\nTry 2 - rebased against current master,"
412,'',"BETA Ninefold storage\nRunning through as as pull request, as it's a new item rather than working on something I've already added."
411,'','[core] service config should be able to pass through connection config\nWhen creating Fog::Storage objects, it\'s not possible to explicitly specify an HTTP proxy for Excon to use.\r\n\r\nHowever, I can work around this by setting the HTTP_PROXY environment variable which Excon respects and "does the right thing" with.\r\n\r\nThis would just be a nice-to-have.'
410,'','Request for issue #404\nhttps://github.com/geemus/fog/issues/404'
409,'',"Fix failures in the simpledb tests.\nFix failures in the simpledb testing due to attribute array option deprecation.\r\n\r\nLet me know if you'd like to see anything else changed!\r\n\r\nThanks."
408,'',"Move the timeout to Mock and stop hardcoding.\nPull request for issue #235.  \r\n\r\nPlease let me know if there's anything you'd like to see changed.\r\n\r\nThank you!"
407,'','AWS test fixes\nTrying to get it 100% and not failing on unmocked items.'
406,'','Fix rubygems warning\n\r\nnothing much to say.. :)'
405,'',"ELB SSL mocking\nGot it running against mocks and real. The errors Im issuing in the mocks aren't 100% inline with that AWS serves, but there's no solid documentation on what the expected response if meant to be for those errors so I might just have to fail them and figure it out."
404,'','AWS S3 Metadata problem\nI think \r\nfog / lib / fog / storage / models / aws / file.rb\r\n\r\nneed to be like this.\r\n\r\n```diff\r\n64c64\r\n<           attributes.reject {|key, value| !(key.to_s =~ /^x-amz-meta-/)}\r\n---\r\n>           attributes.reject {|key, value| !(/^x-amz-meta-/ =~ key.to_s)}\r\n116c116\r\n<           options.merge(metadata)\r\n---\r\n>           options.merge!(metadata)\r\n````\r\nHope this helps.'
403,'',"[core] avoid ArgumentError with Ruby 1.8.5 on CentOS.\nI may be Doing It Wrong as I've not seen anyone else mention this as an issue, but I find symbolize_credentials barfs on CentOS 5 if a config file is present (including config files that work fine on other distros). Rephrasing as attached fixes it."
402,'','Auto scaling 20100801\nModels are a WIP but this is a reasonably functional implementation of AWS Auto Scaling.'
401,'','Remove requirement of basic parsers.\n'
400,'',"ELB model_tests with mocking\nThis includes model_tests.rb with mocking. It also helped me add mocks for a few more requests.\r\n\r\nSo far this just includes what the tests require, but there are probably some edge cases as per the AWS docs. I'll continue working on those."
399,'','ELB mocking support\nThis is just to start the request. It is by no means finished, but it would be good to have any discussion early on rather than later.\r\n\r\nEssentially the first step is getting all of the tests passing and then Im going to go through the AWS documentation for the edge cases, add tests and see how I go from there.'
398,'',"IAM server certificate mocking\nThis only mocks out what is currently tested. I'll add more when I come across them."
397,'',"ArgumentError: non-absolute home\nThis app is running on EngineYard pushing files to S3. I'm able to delete the photo but I get this non-absolute home error. I thought that maybe it was related to 53de3d0 so I created ~/.fog & set HOME=~/.fog and now I do not get this error.\r\n\r\n\r\n    [GEM_ROOT]/gems/fog-0.9.0/lib/fog/core/credentials.rb:23:in `expand_path'\r\n    [GEM_ROOT]/gems/fog-0.9.0/lib/fog/core/credentials.rb:23:in `credentials_path'\r\n    [GEM_ROOT]/gems/fog-0.9.0/lib/fog/core/credentials.rb:37:in `credentials'\r\n    [GEM_ROOT]/gems/fog-0.9.0/lib/fog/core/service.rb:47:in `new'\r\n    [GEM_ROOT]/gems/fog-0.9.0/lib/fog/storage.rb:13:in `new'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/storage/fog.rb:100:in `connection'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/storage/fog.rb:297:in `connection'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/storage/fog.rb:309:in `directory'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/storage/fog.rb:178:in `delete'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/uploader/remove.rb:15:in `remove!'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/uploader/callbacks.rb:17:in `with_callbacks'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/uploader/remove.rb:14:in `remove!'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/mount.rb:342:in `remove!'\r\n    [GEM_ROOT]/gems/carrierwave-0.5.4/lib/carrierwave/mount.rb:202:in `remove_image!'\r\n    [GEM_ROOT]/gems/activesupport-3.0.9/lib/active_support/callbacks.rb:416:in `_run_destroy_callbacks'\r\n    [GEM_ROOT]/gems/activesupport-3.0.9/lib/active_support/callbacks.rb:94:in `send'\r\n    [GEM_ROOT]/gems/activesupport-3.0.9/lib/active_support/callbacks.rb:94:in `run_callbacks'\r\n    [GEM_ROOT]/gems/mongoid-2.0.2/lib/mongoid/persistence.rb:34:in `destroy'\r\n    app/controllers/photos_controller.rb:32:in `destroy'\r\n\r\nI'm not sure if there should be a fix for this, per se, but it should at least be noted for EY customers. Thoughts on how to avoid this?"
396,'','Fog::Time#to_date_header should not return the current time\nThe to_date_header method defined at lib/fog/core/time.rb:22..23 always returns the current time, which seems to be a mistake. Instead, it It should format the time encoded by self:\r\n\r\nself_utc = self.utc\r\nself_utc.strftime(...)\r\n\r\n\r\nWhy not use the standard Time#rfc2822 method instead of this custom version?'
395,'','Changed number of cores reported for rackspace flavors in order to match rackspace documentation\nChanges maximum number of cores reported from 8 to 4.'
394,'','Rackspace flavor reports incorrect number of cores.\nAccording to http://www.rackspace.com/cloud/cloud_hosting_products/servers/faq/: \r\n\r\n> each Cloud Server is assigned four virtual cores and the amount of CPU cycles allocated to these cores is weighted based on the size of the Cloud Server. For example, a 4 GB Cloud Server will have twice the weight of a 2 GB Cloud Server.\r\n\r\nBased on my reading, this means that a server with 15.5GB of memory should have 4 cores, not 8 as is currently reported.  (See also http://help.opscode.com/discussions/problems/690-knife-rackspace-flavor-list-is-not-accurate)'
393,'','Fix for #388\nSmall patch that fixes #388'
392,'','requires_one\nAllows you to require at least one of the specified attributes. As per the AWS documentation snapshot_id and size are both conditional arguments for creating a volume.'
391,'',"conditional get request header time values not formatted properly for AWS S3 get_object\nThe order of the statements are wrong at lib/storage/requests/aws/get_object.rb:42..44. The result is that If-Modified-Since and If-Unmodified-Since headers do not get formatted.\r\n\r\nAlso, if the response is a 304, then no body is included and raises an EOFError. I'd prefer that a no-content/not-modified File object be returned or a not-modified error be raised, rather than the generic EOFError."
390,'','REA vcloud10\nVery basic, generic vcloud 1.0 API implementation. Allows:\r\n* Single VM VApps to be instantiated, powered on/off and destroyed\r\n* VM Memory resized\r\n* VM CPU count changed\r\n* VM Volumes added/removed\r\n\r\nSee tests/compute/models/vcloud/servers_tests.rb for details.'
389,'',"Cloudwatch\nAs asked for, here's a pull request with the methods for AWS Cloudwatch metric API."
388,'',"Call to deprecated get_object_url bombs\nHello,\r\nI'm using DragonFly and it does use Fog for remote S3 storage.\r\n\r\nDragonFly at the moment uses the deprecated call get_object_url, defined here: https://github.com/geemus/fog/blob/master/lib/fog/storage/requests/aws/get_object_url.rb#L21\r\n\r\nProblem is that the Formatador will raise, because of the interpolation without args. I believe this should not be interpolated."
387,'',"Fix for supporting OpenStack swift.\nHey geemus,\r\n\r\nHere is some changes :\r\n\r\n- expect 204 for OpenStack swift.\r\n- Don't always assume there is a CDN  attached to the service.\r\n- Sometime the path have v1.0 and sometime don't.\r\n\r\nLet me know i f that's cool to merge..\r\n\r\nCheers,\r\nChmouel."
386,'',"SimpleDB requests should support ConsistentRead option\nThere should be a way to pass the ConsistentRead option through Fog to SimpleDB requests. It's just a matter of adding the option to the request. For example,\r\n\r\nmodule Fog\r\n  module AWS\r\n    class SimpleDB\r\n      class Real\r\n        def select( select_expression, next_token = nil, **options = {}** )\r\n          request(\r\n            'Action'            => 'Select',\r\n            'NextToken'         => next_token,\r\n            'SelectExpression'  => select_expression,\r\n            **'ConsistentRead'    => options['ConsistentRead'] || 'false',**\r\n            :idempotent         => true,\r\n            :parser             => Fog::Parsers::AWS::SimpleDB::Select.new(@nil_string)\r\n          )\r\n        end\r\n    end\r\n  end\r\nend\r\n"
385,'',"Mock enhancements for Rackspace provider and SSH commands.\nThis is my first commit to fog, so let me know any feedback.  I didn't add any tests because it is just changing the mocks, but I am open to any ideas.\r\n\r\nNotes on the changes:\r\n - Rackspace server model requires JSON, so the mock and real compute implementation need to require it.\r\n - For SSH I figured just printing the commands was enough.  This still allows users to mock the command with mocha or other mocking framework, while making Fog work from the command line as well."
384,'','Adjust the Nokogiri version dep\nApparently nokogiri 1.5.0 hit the streets:\r\n\r\nBundler could not find compatible versions for gem "nokogiri":\r\n  In Gemfile:\r\n    omniauth depends on\r\n      nokogiri (~> 1.4.2)\r\n\r\n    fog depends on\r\n      nokogiri (1.5.0)\r\n\r\nfog does not lock in a specific version: s.add_dependency(\'nokogiri\', \'>=1.4.4\')\r\n\r\nObviously is not a problem related to fog itself, because it may work perfectly with 1.5.0, just reporting to check if something can be done, like a "~> 1.4.4"\r\n\r\nIn the meantime gem "nokogiri", "~> 1.4.4" in Gemfile is a good fix.\r\nCheers'
383,'',"[compute|aws] Default username confusion\nIt's stated at http://fog.io/0.9.0/compute that the default username for a server should be 'root'. However I get 'ubuntu' by default because the AWS Server initializer sets the username to 'ubuntu'. But if i manually set username to nil it defaults to root.\r\n\r\n```ruby\r\n# compute is using AWS as provider\r\nserver = compute.servers.new\r\nserver.username # => 'ubuntu'\r\nserver.username = nil\r\nserver.username # => 'root'\r\n```"
382,'lstoll',"Feature request: automatic retry on AWS 500 or 'throttling' error\nI'm the principal author of dew (https://github.com/playup/dew). Dew contains automated tests which create / destroy AWS resources, and we run a 'stress test' to determine where intermittent failures occur in our scripts.\r\n\r\nOne thing we've found is that AWS will occasionally return an ISE (code 500) or 403 Throttling. We can work around this in our own scripts by retrying, but I'm wondering if it would be a better idea to make this part of Fog or Excon.\r\n\r\nI would imagine that it'd be an option on instantiation, eg :retries => 5, :retrywait => 1000. (retry up to five times, wait 1sec between retries).\r\n\r\nIf the Fog maintainers think this is a good idea I'd be tempted to implement this myself."
381,'','requires with conditionals\nIs there a sane way to handle requiring conditional attributes given that at least one is defined? Or should we just check it outside of the requires helper?\r\n\r\nThe issue at hand is https://github.com/geemus/fog/blob/master/lib/fog/compute/models/aws/volume.rb#L41 should actually just require size || snapshot_id.\r\n\r\nQuick fix at https://github.com/dylanegan/fog/commit/59fc19005db69dfd74436fe5f0843d1ef8a138eb'
380,'',"server method for Fog::Compute::AWS::Volume to easily get the server instance.\nJust a little helper to make it easier to get the server it is attached to. Unless I missed something in the underlying classes, @volume.server wasn't working for me."
379,'','Should actually use the attachment_aliases hash.\nLooks like a copy and paste from describe_security_groups, but forgot to replace the local var name.'
378,'','[compute|aws] add support for dedicated instances\nSee:\r\n\r\nhttp://aws.typepad.com/aws/2011/03/amazon-ec2-dedicated-instances.html\r\nhttp://aws.amazon.com/archives/Amazon-EC2/4898785849311664'
377,'','[compute|aws] update VPC related networking support\nSee:\r\n\r\nhttp://aws.typepad.com/aws/2011/03/new-approach-amazon-ec2-networking.html\r\nhttp://aws.amazon.com/archives/Amazon-EC2/8235632836714390'
376,'','[compute|aws] add support for importing vms\nSee also:\r\n\r\nhttp://aws.typepad.com/aws/2010/12/amazon-vm-import-bring-your-vmware-images-to-the-cloud.html\r\nhttp://aws.amazon.com/archives/Amazon-EC2/0975957552810881'
375,'','Public API for force_detach on Fog::Compute::AWS::Volume.\nThe other possible API is checking if #server = receives more than just a nil value for detachment, but that seems ugly.'
374,'','New changelog didnt make it to gem version 0.9\nThe Changelog file after gem updating to 0.9 is still the 0.8.2 one (though I found the 0.9 in the git repo).'
373,'','Checking path for nil\nHello!\r\nI have a gem for backup files to S3 and I use your gem(thank you for that).\r\nWhen I work with S3, fog raise exception when path equal to nil.\r\n\r\n>gem: https://github.com/reflow/encbs\r\n\r\nBest regards, Timothy.'
372,'','Add support for cluster compute instances\n1) Add instance types for cluster compute instances, or just add them to the docs:\r\n\r\nThere are more types in the code somewhere, but this is what the docs say are available: https://github.com/geemus/fog/blob/master/lib/fog/compute/requests/aws/run_instances.rb#L33\r\n\r\n2) Allow the passing of the placement group when launching an instance:\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?using_cluster_computing.html#using_cluster_computing_launch_instance\r\n\r\n3) Allow the creating, listing, and deleting of placement groups:\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?using_cluster_computing.html#using_cluster_computing_create_placement_group\r\n\r\nhttp://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?using_cluster_computing.html#using_cluster_computing_delete_placement_group\r\n\r\nThere may be more things you can do with cluster compute, but those are the meat of it.\r\n'
371,'','Rescue 404 when fetching zone\n'
370,'',"Fog::Mock.reset doesn't reset all\nCame across a little issue where mocking isn't being reset across all instances. I believe this lays in the change from Fog::<Provider>::<Service> to Fog::<Service>::<Provider> (e.g, Fog::AWS::Compute to Fog::Compute::AWS). I have some code to ensure this works properly now, but it's dealing with hardcoded constants in the Fog::Mock class.\r\n\r\nMy ideal approach would be anything that defines a Mock that can be reset is inserted in to an Array instead of having Fog::Mock.reset actually look up what classes it needs to call out to. Thoughts?"
369,'','Added new blog posting about fog and Carrierwave\n'
368,'','LIES!\nFixing them!'
367,'','Provide mocked console output\nWanted some console output for our local application. Only providing if it the server has been up for greater than the delay. Not sure if that is the proper check or checking the instance state, although as far as I can tell the state is only updated through the same check.'
366,'','[compute|aws] Tags not saved when creating a server\nCreating an EC2 server through Compute with tags provided does not persist the tags on the amazon instance.\r\n\r\n```ruby\r\ncompute = Fog::Compute.new :provider => \'AWS\' # etc...\r\nserver = compute.servers.create :tags => {"Name" => "Awesome", "environment" => "staging"}\r\nserver.tags # => {"Name" => "Awesome", "environment" => "staging"}\r\nserver.wait_for { ready? }\r\nserver.reload.tags # => {}\r\n```'
365,'',"Allow create_volume Mock to support size || snapshot_id || (snapshot_id && size)\nSince the documentation for CreateVolume specifies that size is optional when snapshot_id is passed the Mock should support this.\r\n\r\nRan `rake` twice with no errors, although I did need to tweak the Rakefile to require the right 'lib/fog' file."
364,'','Fog in Mock! mode still contacts AWS\nI\'ve been testing Fog in mock mode with carrier_wave with my AWS Management Console open and although files are not being sent to S3 I get files like this appearing in the bucket while running the tests:\r\n\r\n5fe47345a953b60fe773bc92bddbae76f77bf50d623e742841b79e3002be39be testbucket [19/Jun/2011:12:30:09 +0000] 10.108.133.20 3272ee65a908a7677109fedda345db8d9554ba26398b2ca10581de88777e2b61 CA295D2F4AEB1D61 SOAP.PUT.OBJECT 2011-06-19-12-30-08-8765FDC163EA0260 "POST /soap/ HTTP/1.1" 200 - 797 1854 45 14 "-" "Axis/1.3" -\r\n\r\nIf I disconnect from the Internet and run the tests then they still pass. I already checked that AWS::Storage::Real#put_object is not being called and AWS::Storage::Mock#put_object is being called. I also tried disabling net connect with Fakeweb and Webmock but neither throw an error - probably because Fog uses Excon which uses SSL instead of Net::HTTP.\r\n\r\nAny thoughts?'
363,'',"Add support for specifying a CDN CNAME when getting a Rackspace Cloud Files directory\nThis patch allows you to specify a :cdn_cname => 'http://my.url.com/' option when getting a directory via the Rackspace Cloud Files driver.  Cloud Files allows you to set up a CNAME for the URLs that the Cloud Files CDN normally returns.\r\n\r\nhttp://www.rackspace.com/cloud/blog/2011/04/27/it%E2%80%99s-here-cloud-files-now-supports-cnames-for-cdn-enabled-content/\r\n\r\nIf there's a better way to do this, let me know!"
361,'','[compute|aws] No public_ip_address for DevPay AMIs\nGreetings, and thank you for such an amazing gem!\r\n\r\nI\'ve been using Fog to look up the IP address of various servers. Some of these servers use regular AMIs, and some of these use DevPay AMIs. For regular AMIs, I always receive a valid public_ip_address, but for DevPay AMIs, public_ip_address returns nil.\r\n\r\n    <Fog::AWS::Compute::Server\r\n    id="i-9799def9",\r\n    ami_launch_index=0,\r\n    availability_zone=[{}],\r\n    block_device_mapping=[],\r\n    client_token=nil,\r\n    dns_name="ec2-50-17-112-15.compute-1.amazonaws.com",\r\n    groups=["<REMOVED FROM BUG REPORT>"],\r\n    flavor_id="t1.micro",\r\n    image_id="ami-1622dc7f",\r\n    kernel_id=nil,\r\n    key_name="<REMOVED FROM BUG REPORT>",\r\n    created_at=nil,\r\n    monitoring=[{}],\r\n    product_codes=["AFF1B0F0"],\r\n    private_dns_name="ip-10-88-231-244.ec2.internal",\r\n    private_ip_address=nil,\r\n    public_ip_address=nil,\r\n    ramdisk_id=nil,\r\n    reason=nil,\r\n    root_device_name=nil,\r\n    root_device_type=nil,\r\n    state="running",\r\n    state_reason={},\r\n    subnet_id=nil,\r\n    tags={},\r\n    user_data=nil\r\n    >\r\n\r\nAlso, this instance should be a m1.large, but it claims to be a t1.micro.\r\n\r\nLooking up the IP address using the AWS Console or ec2-describe-images works fine:\r\n\r\n    $ ec2-describe-instances i-9799def9\r\n    RESERVATION\tr-45795e29\t501449412569\t<REMOVED FROM BUG REPORT>\r\n    INSTANCE\ti-9799def9\tami-1622dc7f\tec2-50-17-112-15.compute-1.amazonaws.com\tip-10-88-231-244.ec2.internal\trunning\t<REMOVED FROM BUG REPORT>\t0\tAFF1B0F0\tm1.large\t2011-06-16T14:14:48+0000\tus-east-1d\taki-427d952bmonitoring-disabled\t50.17.112.15\t10.88.231.244\t\t\tinstance-store\t\t\t\t\tparavirtual\t\r\n    BLOCKDEVICE\t/dev/sdi1\tvol-c98a4ca2\t2011-06-16T14:17:27.000Z\t\r\n    TAG\tinstance\ti-9799def9\tManagedBy\t<REMOVED FROM BUG REPORT>\r\n    TAG\tinstance\ti-9799def9\tName\t<REMOVED FROM BUG REPORT>\r\n\r\nHow can I help fix this problem? If you\'d like, I\'m willing to dive into the code, but I may need some pointers in the right direction to get me started.\r\n\r\nThank you for your help, and for such an awesome library!\r\n'
360,'','Updated format tests due to API changes\nFixes to the format tests needed due to changes to the data being exposed.'
359,'',"OpenStack support using Rackspace API\nI've added a couple of things that get fog talking to OpenStack.\r\n\r\nThe first is to allow authentication to happen outside of the normal application flow, so that you can provide an auth token and a management url and skip the authentication step.  It is completely optional, but lets us use out-of-band communication to the integrated authentication project (keystone) that is being worked on for the next OpenStack release.  It also has the side effect of letting authentication credentials be shared between threads, processes, or any other way you may want to auth once, control many, and sharing tokens is more secure since they will expire, whereas the other credentials will not.\r\n\r\nThe other thing that has happened is to include 200 as a valid HTTP status from the create server request.  I'm filing a bug against OpenStack/nova to see if we want to change the api or implement it as 202 as the spec expects.  This may be unnecessary at some point in the future, but it is nice to have now.\r\n\r\nI'm interested in hearing your thoughts about how to implement the 1.1. spec for Rackspace and OpenStack (currently in draft).  I didn't see any knowledge in the client about versions, but it would be great to be able to use fog as a tool to test integration against 1.1 w/o breaking the existing functionality."
358,'',"Added my blog post.\nI've added my blog post to the list."
357,'',"Use multi_json or yajl, and don't depend on json in gemspec\nIs there any reason fog has a hard dependency on the json gem in its gemspec?\r\n\r\nWould it be possible to use yajl or a selector like multi_json, and remove the gemspec dependency on the json gem?"
356,'','add Net::SCP options parameter to Fog::SCP proxy\nHello,\r\n\r\nI have added an additional parameter to the Fog::SCP #upload method which supports passing the options hash parameter to Net::SCP. I primarily needed this to pass :recursive => true so I could upload a folder. \r\n\r\nI added a test to the file under the examples/ directory because that was the only test I could find containing anything related to SCP. I verified that both the test and the library act as expected, but if there is a better way to test this I would be happy to update the commit.\r\n\r\nI hope you find this useful. Thanks for sharing the library.\r\n\r\n\r\n- Phil'
355,'','Edited lib/fog/storage/rackspace.rb via GitHub\nTypo fix'
354,'',"/var/lib/gems/1.8/gems/fog-0.8.2/lib/fog/storage/rackspace.rb:105:in `reload': undefined method `reset' for nil:NilClass (NoMethodError)\nChange this code:\r\ndef reload\r\n  @storage_connection.reset <---\r\nend\r\n\r\nto @connection.reset\r\n\r\nand it worked."
353,'','Segmentation fault in Ruby\nI am getting this in my server logs:\r\n\r\n/app/.bundle/gems/ruby/1.8/gems/fog-0.8.2/lib/fog/core/attributes.rb:143: [BUG] gc_sweep(): unknown data type 0x0(0x7fb466e28660)\r\n2011-06-07T07:03:52+00:00 app[web.1]: ruby 1.8.7 (2010-04-19 patchlevel 253) [x86_64-linux], MBARI 0x6770, Ruby Enterprise Edition 2010.02\r\n2011-06-07T07:03:52+00:00 app[web.1]: \r\n2011-06-07T07:03:52+00:00 app[web.1]: /app/.bundle/gems/ruby/1.8/gems/fog-0.8.2/lib/fog/core/attributes.rb:143: [BUG] Segmentation fault\r\n2011-06-07T07:03:52+00:00 app[web.1]: ruby 1.8.7 (2010-04-19 patchlevel 253) [x86_64-linux], MBARI 0x6770, Ruby Enterprise Edition 2010.02\r\n'
352,'','[storage|aws] clean up multi-region directory creation\nif creating an s3 directory (bucket), one needs to pass in :location as well as have the aws connection set to the correct region...   This fixes that issue'
351,'',"s3 bucket create ignores connection region\nif you create a connection like so\r\n\r\n        connection = Fog::Storage.new(\r\n          :provider               => provider,\r\n          :aws_access_key_id      => access_key_id,\r\n          :aws_secret_access_key  => secret_access_key,\r\n          :region                 => region\r\n        )\r\n\r\nand then call \r\n\r\n        connection.directories.create(\r\n          :key    => bucket,\r\n          :public => false\r\n        )\r\n\r\nit fails.  YOu need to call\r\n\r\n        connection.directories.create(\r\n          :key    => bucket,\r\n          :public => false,\r\n          :location => region\r\n        )\r\n\r\nI would like to change this in the codebase so it defaults to using the location of the connection, but to be honest I can't easily tell where!  If you can point me in the right direction I'll definitely submit a patch.\r\n\r\nthanks!\r\n"
350,'','[aws|simpledb] recognize :region option in SimpleDB.new()\nJust adds :region to recognizes in aws/simpledb.rb'
349,'','Dns made easy\nRecent API update added support for updating records via PUT, previously you had to delete the old record and then re-create it with the required changes.'
348,'','Add recursive argument to server scp methods.\nHave added recursive option to server scp methods so can scp up directories.\r\nIs set to false by default.\r\nHave tested on an AWS server.\r\n\r\n'
347,'','Ninefold\nAs discussed, core implementation for ninefold (http://ninefold.com)'
346,'','[aws|rds] Refactor model tests\nAdded & cleaned up tests for all the RDS models.'
345,'','[storage|aws] Support overriding request parameters\nI was looking to create a signed url that included a `response-content-disposition` request parameter override so that I could change the filename that the browser downloaded. You can see examples of this on Amazon\'s documentation: http://docs.amazonwebservices.com/AmazonS3/latest/API/index.html?RESTObjectGET.html\r\n\r\nâ¦ but I ran into no amount of issues, probably due to my misunderstanding of Fog. But I\'m pretty sure that fog doesn\'t allow this query param.  It would be nice to support request parameter overrides in `get_object_url` or even `url`.\r\n\r\nThe way I was trying (which failed, due to the fact that `params[:query]` was a string that didn\'t have keys â and using a hash mashed my key/value together without a `=` breaking the request):\r\n\r\n``` ruby\r\nstorage = Fog::Storage.new(:provider => \'AWS\', :aws_access_key_id => S3_ACCESS_KEY, :aws_secret_access_key => S3_SECRET)\r\n\r\nexpires = Time.now + 30*24*60*60\r\nurl = storage.url({\r\n            :headers  => {},\r\n            :host     => \'s3.amazonaws.com\',\r\n            :method   => \'GET\',\r\n            :path     => "#{S3_BUCKET}/#{Release.latest_release.guid}.zip",\r\n            :query    => \'response-content-disposition=attachment%3B%20filename%3Dtest.zip\'\r\n          }, expires)\r\n```\r\n\r\nThe end result was that it seemed impossible to get a `&response-content-disposition=attachment%3B%20filename%3Dtest.zip` into the url string to be signed.'
344,'','Fix deprecated public_ip used in AWS Server#setup\nUse #public_ip_address instead of deprecated #ip_address in Server#setup'
343,'','fog.io site is down\nThe fog.io site is down and has been so since yesterday. \r\n\r\nP.S. While it gets back up, is there anywhere else I can get complete documentation?'
342,'',"Fog::Time#to_date_header isn't found under rbx\nWhile running the tests for Paperclip under rbx-head, I kept hitting this error. It didn't show under REE1.8.7.\r\n\r\nIt, of course, makes even less sense because `put_object.rb:71` is `Fog::Time.new.to_date_header`, so not being able to find that method is really weird. I don't know if this is a fog thing or a rubinius thing, but figured I would mention it here first.\r\n\r\n```\r\n  1) Error:\r\ntest: when assigned with a bucket should succeed. (FogTest):\r\nNoMethodError: undefined method `to_date_header' on an instance of Time.\r\n    kernel/delta/kernel.rb:79:in `to_date_header (method_missing)'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/fog-0.8.2/lib/fog/storage/requests/aws/put_object.rb:71:in `put_object'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/fog-0.8.2/lib/fog/storage/models/aws/file.rb:119:in `save'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/fog-0.8.2/lib/fog/core/collection.rb:50:in `create'\r\n    ./lib/paperclip/storage/fog.rb:37:in `flush_writes'\r\n    kernel/common/hash.rb:327:in `each'\r\n    ./lib/paperclip/storage/fog.rb:35:in `flush_writes'\r\n    ./lib/paperclip/attachment.rb:157:in `save'\r\n    ./test/../lib/paperclip.rb:375:in `save_attached_files'\r\n    ./test/../lib/paperclip.rb:368:in `each_attachment'\r\n    kernel/common/hash.rb:327:in `each'\r\n    ./test/../lib/paperclip.rb:367:in `each_attachment'\r\n    ./test/../lib/paperclip.rb:374:in `save_attached_files'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activesupport-2.3.11/lib/active_support/callbacks.rb:178:in `evaluate_method'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activesupport-2.3.11/lib/active_support/callbacks.rb:166:in `call'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activesupport-2.3.11/lib/active_support/callbacks.rb:93:in `run'\r\n    kernel/bootstrap/array.rb:76:in `each'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activesupport-2.3.11/lib/active_support/callbacks.rb:92:in `run'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activesupport-2.3.11/lib/active_support/callbacks.rb:276:in `run_callbacks'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/callbacks.rb:344:in `callback'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/callbacks.rb:251:in `create_or_update (create_or_update_with_callbacks)'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/base.rb:2577:in `save_without_validation (save)'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/validations.rb:1090:in `save_without_dirty (save_with_validation)'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/dirty.rb:79:in `save_without_transactions (save_with_dirty)'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/transactions.rb:229:in `with_transaction_returning_status'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/connection_adapters/abstract/database_statements.rb:136:in `transaction'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/transactions.rb:182:in `transaction'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/transactions.rb:228:in `with_transaction_returning_status'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/transactions.rb:196:in `save_with_transactions'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/transactions.rb:208:in `rollback_active_record_state!'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/activerecord-2.3.11/lib/active_record/transactions.rb:196:in `save (save_with_transactions)'\r\n    ./test/fog_test.rb:60:in `FogTest'\r\n    kernel/common/method.rb:68:in `call'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/shoulda-2.11.3/lib/shoulda/context.rb:382:in `create_test_from_should_hash'\r\n    /Users/jyurek/.rvm/gems/rbx-head/gems/mocha-0.9.12/lib/mocha/integration/test_unit/ruby_version_186_and_above.rb:22:in `run'\r\n    kernel/bootstrap/array.rb:76:in `each'\r\n    kernel/bootstrap/array.rb:76:in `each'\r\n```"
341,'','Typo fix\n'
340,'','Updates for Brightbox representations\nHi,\r\n\r\nA few fixes in the formats for the Shindo tests due to changes in the JSON output of the API\r\n\r\nCheers,\r\n\r\nPaul'
339,'','[aws|elb] 2011-04-05 API update\nAdded the new ELB attributes returned by the DescribeLoadBalancers action in the new ELB API.\r\n\r\nThis branch assumes that the test fix [here](https://github.com/geemus/fog/pull/337) is already applied.'
338,'','DNS Made Easy\nLet me know if I need to do anything further for the Pull Request to be accepted. thanks'
337,'','[aws|elb] Fix failing created_at test caused by Ruby 1.9 changes to Range#include?\nRange#covers? offers the same functionality in 1.9.2 case as Range#include? did in 1.8.7'
336,'',"Fixed Fog::AWS::SimpleDB#delete_attributes in Fog.mock! mode.\nDeleting attributes was not working in mock mode. There were two bugs in this function.The first was that attributes were being deleted from the domain as opposed to the item. The second was that when no attributes were passed, which should delete all attributes, no attributes were actually being deleted. I've written tests that recreate these bugs and I have included a fix as well."
335,'','fixed one small thing in the docs\nIn the docs when setting up the new connections the curly braces were missing, just added them in.\r\n\r\nconnection = Fog::Storage.new({ <params> }) '
334,'','[compute|aws] support for ec2 spot instances\nShould have the same functionality as the ec2-api-tools versions does.\r\n\r\nec2-cancel-spot-instance-requests\r\nec2-create-spot-datafeed-subscription\r\nec2-delete-spot-datafeed-subscription\r\nec2-describe-spot-datafeed-subscription\r\nec2-describe-spot-instance-requests\r\nec2-describe-spot-price-history\r\nec2-request-spot-instances\r\n'
333,'','use correct variable name in test description\n'
332,'',"Add a link to fog's Rubydocs.\nA tiny pull request to add the rdocs to fog's website.\r\n\r\nPlanning on adding some more doco examples on e.g. using fog with EC2, but my brain stopped functioning for tonight I'm afraid."
331,'',"Excon::Errors::Forbidden \nreceiving the above error when using latest version of fog with carrierwave \r\n\r\nexcon (0.6.3) lib/excon/connection.rb:179:in `request'\r\nfog (0.8.1) lib/fog/core/connection.rb:20:in `request'\r\nfog (0.8.1) lib/fog/storage/aws.rb:323:in `request'\r\nfog (0.8.1) lib/fog/storage/requests/aws/put_object.rb:43:in `put_object'\r\nfog (0.8.1) lib/fog/storage/models/aws/file.rb:119:in `save'\r\nfog (0.8.1) lib/fog/core/collection.rb:50:in `create'\r\ncarrierwave (0.5.4) lib/carrierwave/storage/fog.rb:229:in `store'\r\ncarrierwave (0.5.4) lib/carrierwave/storage/fog.rb:79:in `store!'\r\ncarrierwave (0.5.4) lib/carrierwave/uploader/store.rb:59:in `block in store!'\r\ncarrierwave (0.5.4) lib/carrierwave/uploader/callbacks.rb:17:in `with_callbacks'\r\ncarrierwave (0.5.4) lib/carrierwave/uploader/store.rb:58:in `store!'\r\ncarrierwave (0.5.4) lib/carrierwave/mount.rb:324:in `store!'\r\ncarrierwave (0.5.4) lib/carrierwave/mount.rb:214:in `store_pic!'"
330,'',"[aws/elb] Support New API Version 2011-04-05\nCreating this ticket to track the feature. I think I'll take a crack at implementing it this week."
329,'',"Documentation of the head method\nAs we discussed on Twitter, here's some brief docs on the use of the 'head' method to check for the existence of a file, as well as get some metadata without pulling the whole file down.\r\n\r\nThis is actually my first Github pull request, so it's quite likely I didn't do this right. Feel free to set me straight :)\r\n\r\nThanks again for the awesome library."
328,'','Linode\nLet me know if you have any issues. I rebased and all my tests (that I have) still pass and seem to work well on our production servers after the rebase.'
327,'','Upload file to S3: 400 Bad Request\nHi!\r\n\r\nI have problems with upload some files on s3, when content of file is utf-8 string.\r\nPlease look at the following code:\r\n\r\nruby-1.9.2-p180 :211 > Fog::VERSION\r\n => "0.8.1"\r\n\r\nruby-1.9.2-p180 :181 > storage = Fog::Storage.new({ :provider => \'AWS\',  :aws_access_key_id =>\'xxxxx\',  :aws_secret_access_key => \'xxxx\' })\r\n => #<Fog::AWS::Storage::Real:0x00000105b31860 ....>\r\n\r\nruby-1.9.2-p180 :186 > directory = storage.directories.find { |d| d.key == \'mybucket\' }\r\n =>   <Fog::AWS::Storage::Directory\r\n    key="mybucket",\r\n    creation_date=2011-05-17 09:15:55 UTC\r\n  > \r\n\r\nopts = {:key=>"10/abc/test.txt", :content_type=>"text/plain"} \r\n => {:key=>"10/abc/test.txt", :content_type=>"text/plain"} \r\n\r\nSuccessful upload:\r\nruby-1.9.2-p180 :212 > data = ""\r\n => "" \r\nruby-1.9.2-p180 :213 > (1..8000).each do |i|\r\nruby-1.9.2-p180 :214 >     data += "Ð"\r\nruby-1.9.2-p180 :215?>   end\r\n => 1..8000 \r\n\r\nruby-1.9.2-p180 :219 > data.bytesize\r\n => 16000 \r\nruby-1.9.2-p180 :220 > data.size\r\n => 8000 \r\n\r\nruby-1.9.2-p180 :194 > file = directory.files.new(opts)\r\n =>   <Fog::AWS::Storage::File\r\n    key="10/abc/test.txt", ......>\r\n\r\nruby-1.9.2-p180 :195 > file.body = data\r\nruby-1.9.2-p180 :218 > file.save\r\n => true\r\n\r\nBut upload failed for more longer strings:\r\n\r\nruby-1.9.2-p180 :212 > data = ""\r\n => "" \r\nruby-1.9.2-p180 :213 > (1..8500).each do |i|\r\nruby-1.9.2-p180 :214 >     data += "Ð"\r\nruby-1.9.2-p180 :215?>   end\r\n => 1..8500 \r\n\r\nruby-1.9.2-p180 :194 > file = directory.files.new(opts)\r\n =>   <Fog::AWS::Storage::File\r\n    key="10/abc/test.txt", ......>\r\n\r\nruby-1.9.2-p180 :195 > file.body = data\r\nruby-1.9.2-p180 :218 > file.save\r\n\r\nExcon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\n  request => {:headers=>{"Content-Length"=>17000, "Content-Type"=>"text/plain", "Date"=>"Tue, 24 May 2011 10:13:21 +0000", "Authorization"=>"abcd", "Host"=>"mybucket.s3.amazonaws.com:443"}, :host=>"mybucket.s3.amazonaws.com", :mock=>nil, :path=>"/10%2Fabc%2Ftest.txt", :port=>"443", :query=>nil, :scheme=>"https", :body=>"ÐÐ....", :expects=>200, :idempotent=>true, :method=>"PUT"}\r\n\r\n  response => #<Excon::Response:0x00000105b386b0 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>RequestTimeout</Code><Message>Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed.</Message><RequestId>1123</RequestId><HostId123</HostId></Error>", @headers={"x-amz-request-id"=>"123", "x-amz-id-2"=>"I123", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Tue, 24 May 2011 10:13:41 GMT", "Connection"=>"close", "Server"=>"AmazonS3"}, @status=400>\r\n\r\nProbably the reason of this error is wrong content length - https://forums.aws.amazon.com/thread.jspa?messageID=215973&#215973\r\nBut in request header I see content-length and it is right!\r\n\r\nHave you any ideas why upload is not works for long strings?\r\n\r\nRight now I found 2 ways how overcome this issue:\r\n1. Write string to local file first, and then use this file for uploading\r\n2. Convert string to StringIO object.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'
326,'',"How do I discover which DNS providers the user has access to?\nFrom a user's ~/.fog file, how do I figure out which set of (DNS/compute/whatever) providers a fog user has access to?\r\n\r\nFor example, a call to `Fog::DNS.providers` might return [Fog::DNSimple::DNS::Real] if DNSimple is the only DNS provider the user has credentials for."
325,'',"Two known specs failing?\nIn ruby 1.8.7 are there two known specs failing in mock mode? Or have I done something wrong?\r\n\r\n<pre>$ be rake\r\nrake/rdoctask is deprecated.  Use rdoc/task instead (in RDoc 2.4.2+)\r\nexport FOG_MOCK=false && bundle exec shindont examples\r\n  Skipping tests for bluebox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for brightbox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for dnsimple due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for ecloud due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for gogrid due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for google due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for linode due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for local due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for newservers due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for rackspace due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for slicehost due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for stormondemand due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for voxel due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for zerigo due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for bluebox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for brightbox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for dnsimple due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for ecloud due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for gogrid due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for google due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for linode due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for local due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for newservers due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for rackspace due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for slicehost due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for stormondemand due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for voxel due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for zerigo due to lacking credentials (add some to '~/.fog' to run them)\r\n  \r\n  dns tests (dns) ++++++++  \r\n  storage tests (storage) +++++++++++++++++++  \r\n  27 succeeded in 8.798274 seconds\r\n  \r\nexport FOG_MOCK=true  && bundle exec spec spec\r\nF.F.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\r\n\r\n1)\r\n'Ecloud should be available' FAILED\r\nexpected available? to return true, got false\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/bin_spec.rb:4:\r\n\r\n2)\r\nArgumentError in 'Ecloud when indexing it like an array with a service that exists should return something when indexed with a configured service'\r\nMissing required arguments: ecloud_username, ecloud_password, ecloud_versions_uri\r\n/Users/drnic/Projects/gems/fog/lib/fog/core/service.rb:152:in `validate_options'\r\n/Users/drnic/Projects/gems/fog/lib/fog/core/service.rb:50:in `new'\r\n/Users/drnic/Projects/gems/fog/lib/fog/compute.rb:18:in `new'\r\n/Users/drnic/Projects/gems/fog/lib/fog/bin/ecloud.rb:17:in `[]'\r\n/Users/drnic/Projects/gems/fog/lib/fog/bin/ecloud.rb:22:in `call'\r\n/Users/drnic/Projects/gems/fog/lib/fog/bin/ecloud.rb:22:in `default'\r\n/Users/drnic/Projects/gems/fog/lib/fog/bin/ecloud.rb:22:in `[]'\r\n/Users/drnic/Projects/gems/fog/lib/fog/bin/ecloud.rb:22:in `[]'\r\n/Users/drnic/Projects/gems/fog/spec/ecloud/bin_spec.rb:11:\r\n\r\nFinished in 35.196879 seconds\r\n\r\n794 examples, 2 failures\r\nrake aborted!\r\nCommand failed with status (1): [export FOG_MOCK=true  && bundle exec spec ...]\r\n\r\nTasks: TOP => default => test\r\n(See full trace by running task with --trace)\r\n</pre>"
324,'',"Tests failing in ruby 1.9.2 because of nokogiri?!\n<pre>$ ruby -v\r\nruby 1.9.2p180 (2011-02-18 revision 30909) [x86_64-darwin10.6.0]\r\n~/gems/fog[master]$ gem install nokogiri\r\nBuilding native extensions.  This could take a while...\r\nSuccessfully installed nokogiri-1.4.4\r\n1 gem installed\r\n~/gems/fog[master]$ bundle exec rake\r\nrake/rdoctask is deprecated.  Use rdoc/task instead (in RDoc 2.4.2+)\r\nexport FOG_MOCK=false && bundle exec shindont examples\r\n  Skipping tests for bluebox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for brightbox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for dnsimple due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for ecloud due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for gogrid due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for google due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for linode due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for local due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for newservers due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for rackspace due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for slicehost due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for stormondemand due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for voxel due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for zerigo due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for bluebox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for brightbox due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for dnsimple due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for ecloud due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for gogrid due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for google due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for linode due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for local due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for newservers due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for rackspace due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for slicehost due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for stormondemand due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for voxel due to lacking credentials (add some to '~/.fog' to run them)\r\n  Skipping tests for zerigo due to lacking credentials (add some to '~/.fog' to run them)\r\n  \r\n  dns tests (dns) ++++++++  \r\n  storage tests (storage) +++++++++++++++++++  \r\n  27 succeeded in 6.194465 seconds\r\n  \r\nexport FOG_MOCK=true  && bundle exec spec spec\r\n/Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/nokogiri-1.4.4/lib/nokogiri/nokogiri.bundle: [BUG] Segmentation fault\r\nruby 1.8.7 (2009-06-12 patchlevel 174) [universal-darwin10.0]\r\n\r\nsh: line 1: 11578 Abort trap              bundle exec spec spec\r\nrake aborted!\r\nCommand failed with status (134): [export FOG_MOCK=true  && bundle exec spec ...]\r\n\r\nTasks: TOP => default => test\r\n(See full trace by running task with --trace)\r\n</pre>"
323,'','DNSimple to allow dnsimple_site property\nIn the dnsimple-ruby gem, credentials can include a "site" property (for example, point to the test server http://test.dnsimple.com)'
322,'',"[compute|aws] Support new API (since Aug 31, 2010)\nFog currently uses Amazon EC2 API version 2010-08-31\n\nNew API versions have since added several features. The changes in each new API version can be hard to track, so I'm making note of them here.\n\n* 2010-11-15: Support for VM Import (ImportInstance, ImportVolume). See http://aws.typepad.com/aws/2010/12/amazon-vm-import-bring-your-vmware-images-to-the-cloud.html\n* 2011-01-01: New approach to networking (several changes to security groups, like introducing Security group ids, VPC security groups; GroupId is a modifyable attribute for VPC instances). http://aws.typepad.com/aws/2011/03/new-approach-amazon-ec2-networking.html\n* 2011-02-28: Dedicated instances. http://aws.typepad.com/aws/2011/03/amazon-ec2-dedicated-instances.html\n\nSee http://aws.amazon.com/archives/Amazon%20EC2 for version history."
321,'','Documentation fixes (all of them this time)\n:size should be a number in GB, not an instance size (e.g. "t1.micro")'
320,'','Fix Fog::Mock.reset\nUse `const_get` instead of `eval`, symbolize returned constants for 1.8.7/1.9.2 compat.'
319,'','DNSMadeEasy DNS provider feature request\nLooks like DNSmadeEasy has a recently launched REST API. http://www.dnsmadeeasy.com/enterprisedns/api.html\r\n\r\n-Brian'
318,'',"Documentation fix\n:size should be a number in GB, not an instance size (e.g. 't1.micro')"
317,'',"AWS Compute key name not being honored while mocking\nSimilar to #314, it looks like when `:key_name` is specified it's not returned by `describe_instances` when mocking."
316,'',"Add Amazon API reference link to requests' documentation\nI find links back to the amazon api reference useful. YMMV. Generated with a few lines of script, so if you think this is useful but don't like the format it can easily be changed."
315,'','Add reset method to other mock classes in addition to Compute providers\nMore thoroughly added reset methods to provider mock classes in addition to Compute providers along with a reset method for Fog::Mock as described in [Issue #308](https://github.com/geemus/fog/issues/308) and [Pull Request #309](https://github.com/geemus/fog/pull/309)'
314,'','AWS Compute security groups not being honored while mocking\n    server = aws.servers.new(:groups => [\'foo\'])\r\n    server.groups #=> ["foo"]\r\n    server.save\r\n    server.reload.groups #=> ["default"]'
313,'','Better aws tests\nThese commits fix several tests when running:\r\n\r\n    $ shindo tests/compute/*/aws/\r\n\r\n    $ FOG_MOCK=true shindo tests/compute/*/aws/\r\n\r\nBoth commands pass now.'
312,'','Fog.wait_for can slow down tests\nWould be cool if there was a way with `Fog::Mock.delay = 0` to have `Fog.wait_for` be effectively a noop instead of possibly sleeping.'
311,'','CLI\nFog could provide a CLI for simple operations. Example use:\r\n\r\n    $ fog rackspace servers list --format json\r\n    $ fog rackspace servers create --name "test.corp.com" --flavor-id 2 --image-id 69\r\n    $ fog rackspace servers show --name "test.corp.com" --format json\r\n    $ fog rackspace servers ssh --name "test.corp.com" --user root\r\n\r\nThe CLI would provide functionality covering a subset of the API.\r\n'
310,'','Reflavor Instance\nFog should be able to reflavor (resize) an instance on those clouds which support it.\r\n\r\nFor instance: [rackspace](http://docs.rackspacecloud.com/servers/api/v1.0/cs-devguide/content/ch04s03s03.html).\r\n'
309,'','Add reset method to mock classes\nAdded reset methods to provider mock classes along with a reset method for Fog::Mock as described in [Issue #308](https://github.com/geemus/fog/issues/308)'
308,'','add reset method to mock classes\nThis should reset all data for the class, see `/lib/fog/compute/aws.rb` for an example of this.  This makes working with things much easier.  Also, with this done we should add a `reset` method to Fog::Mock that walks through the list of all providers/services and resets them.'
307,'','connections.directories gives TypeError: can\'t convert nil into String\nWith Ruby 1.9.2 p180 & fog 0.8.1 (freshly installed this evening)\r\n\r\n```ruby\r\n>> connection = Fog::Storage.new(:provider => \'AWS\', :aws_access_key_id => ENV[\'AWS_KEY\'], :aws_secret_access_key => ENV[\'AWS_SECRET\'])\r\n=> #<Fog::AWS::Storage::Real:0x00000001d12fd0 @aws_access_key_id=nil, @aws_secret_access_key=nil, @hmac=#<Fog::HMAC:0x00000001d12d28 @key=nil, @digest=#<OpenSSL::Digest::Digest: da39a3ee5exxxxxxxxxxxxafd80709>, signer#<Proc:0x00000001d0b9d8@/home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/hmac.rb:22 (lambda)>, endpointnil, host"s3.amazonaws.com", path"/", port443, scheme"https", connection#<Fog::Connection:0x00000001d0b5f0 @excon=#<Excon::Connection:0x00000001d0b500 @connection={:headers=>{}, :host=>"s3.amazonaws.com", :mock=>nil, :path=>"/", :port=>"443", :query=>nil, :scheme=>"https"}, socket_key"s3.amazonaws.com:443", persistenttrue\r\n>> connection.directories\r\nTypeError: can\'t convert nil into String\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/hmac.rb:23:in `digest\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/hmac.rb:23:in `block in setup_sha1\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/hmac.rb:15:in `call\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/hmac.rb:15:in `sign\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/storage/aws.rb:309:in `signature\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/storage/aws.rb:317:in `request\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/storage/requests/aws/get_service.rb:32:in `get_service\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/storage/models/aws/directories.rb:13:in `all\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/collection.rb:123:in `lazy_load\'\r\n\tfrom (eval):3:in `empty?\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/collection.rb:70:in `block in inspect\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/formatador-0.1.3/lib/formatador.rb:92:in `indent\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/fog-0.8.1/lib/fog/core/collection.rb:63:in `inspect\'\r\n\tfrom /home/jesse/.rvm/gems/ruby-1.9.2-p180@cookes/gems/wirble-0.1.3/lib/wirble.rb:432:in `output_value\'\r\n\tfrom /home/jesse/.rvm/rubies/ruby-1.9.2-p180/bin/irb:16:in `<main>\'\r\n```\r\n'
306,'','Excon::Errors::SocketError: The processing instruction target matching "[xX][mM][lL]" is not allowed\nI get the following stacktrace when trying to use fog to list the directories of an aws s3 account.\nI am running this on jruby 1.6.1 on windows 7 64 bit.\n\n\nHere is the code I am running and the resulting stacktrace:\nhttps://gist.github.com/972522'
305,'','Fix server tests\nAdds some server tests as per discussion on #302\r\n\r\nAlso changes the "succeeds" test helper, which previously always passed (unless an error was raised).\r\n\r\nNow the succeeds helper only passes if the final value is truthy. Other helpers (like responds_to) seem to rely on this behavior (otherwise they aren\'t testing anything).'
304,'',"Single instance lookup uses the 'instance-id' filter name\n"
303,'','[compute|aws] Add get_password_data request. \nThis request only applies to MS Windows instances,\r\nso use an MS Win AMI in the instance tests.\r\n\r\nRelaxes the parser formats flexible to make tests\r\nless brittle to other instances.\r\n\r\n(This depends on pull request #302)'
302,'',"[compute|aws] Fix describe_instances filtering.\ndescribe_instances now correctly handles filters\r\nwith a single instance id. E.g.\r\n\r\n    AWS[:compute].describe_instances('instance-id' => 'i-12345678')"
301,'','ArgumentError thrown if ENV[\'HOME\'] is not an existing directory when calling Fog::credentials_path\nWhen ENV[\'HOME\'] is set to a non-existent directory, Fog::credentials_path throws an ArgumentError exception as File.expand_path expects to expand an absolute file path, but gets \'~/.fog\' instead. Checking if ENV[\'HOME\'] to be an existent directory solves the issue:\n\nmodule Fog\n ...\n  def self.credentials_path\n    @credential_path ||= begin\n      path = ENV["FOG_RC"] || (ENV[\'HOME\'] && File.directory?(ENV[\'HOME\']) && \'~/.fog\')\n      File.expand_path(path) if path\n    end\n  end\n\n\nMy apologies for not being able to write a test for this (as I\'m not sure how to mock the results of File.directory? using the shindo test library).'
300,'','[storage|google] update to use API v2\nsee http://googlecode.blogspot.com/2011/05/google-storage-for-developers-open-to.html for details'
299,'','[compute|aws] Add failing tests for keypair parsing.\nThe private key is being truncated by the parser.\r\n\r\nIn irb, notice we only get the first line of the private key:\r\n\r\n  Fog::Compute.new(:provider => \'AWS\').key_pairs.create(:name => \'fog-test\')\r\n   =>   <Fog::AWS::Compute::KeyPair\r\n      name="fog-test",\r\n      fingerprint="ba:4a:33:1d:dc:71:f1:ec:e3:12:c4:8c:ad:7a:da:a5:9b:aa:3d:a1",\r\n      private_key="-----BEGIN RSA PRIVATE KEY-----"\r\n    > \r\n\r\nThis is due to a bug in the current base parser. You may want to hold out on releasing today. I\'ll post more details momentarily.'
298,'',"should use autoload instead of require\nI had this case where I was doing Fog::Storage.new in a loop (kind of, just each object had his own storage object) and was calling get_object_url on their storage object.\r\n\r\nThe initialize method was taking ages to be run due to the calls 'require' present inside methods.\r\nif active_support 2.X was loaded, because it redefines the 'require' method and do so crazy ugly things, the time to do this loop was insanely slow.\r\n\r\nWith activerecord 3 it looks like the problem doesn't exist, Maybe the solution is to some autoload instead of 'require'\r\nI have made an ugly fix for me here, and added some benchs.\r\nFeel free to use it.\r\n\r\nhttps://github.com/vivienschilis/fog/tree/optimize_inits_with_active_support\r\n\r\nBest,\r\nVivien\r\n\r\n"
297,'',"Google Cloud Storage Support\nLooks like Google's in the cloud storage game now: http://code.google.com/apis/storage/\r\n\r\nAPI looks similar to the others: http://code.google.com/apis/storage/docs/developer-guide.html"
296,'','[aws|rds] Improve instance tests\n* Tests pass even if other RDS servers & snapshots are in the AWS account\r\n* Removed unnecessary Fog.wait_for blocks\r\n* DRYed up values as variables\r\n* Cleaned up whitespace'
295,'','[aws|iam] Improve Server certificates\n* Add support for list_server_certificates\r\n* Add some tests for uploading, listing, and deleting server certificates\r\n* In the UploadServerCertificate parser, parse UploadDate as a Time object (instead of string)'
294,'','[aws|rds] Remove redundant NotFound class\nThis class is already defined in core.'
293,'',"excon - segmentation fault when used with pg gem\nWhen I use fog along with the pg gem, ruby has a segmentation fault when it tries to connect to AWS.  I've created a sample rails project to demonstrate the issue.  I've tried this rails project on two machines and they both reproduce the issue. The project is basically an empty rails project that just makes a few fog calls (ie there are not postgresql calls). As long as the pg gem is in the Gemfile, excon will crash.    Weird thing is that the project running on Heroku (which also uses Postgresql) works fine.\r\n\r\nHere is the error http://pastie.org/1867304\r\nhere is a list of the gems in the gemset  http://pastie.org/1867308\r\nAnd the project can be found at https://github.com/athirn/test_fog\r\n\r\nNote, you will need to put your AWS credentials into config/fog\r\n\r\nAthir"
292,'','S3\'s copy_object doesn\'t like double forward slashes\nIf the source_object_name for S3\'s copy_object request has a leading forward slash, the x-amz-copy-source will have two slashes and fail with a 404.\n\nOne solution is to change\n```headers = { \'x-amz-copy-source\' => "/#{source_bucket_name}/#{source_object_name}" }.merge!(options)```\n\nto\n```headers = { \'x-amz-copy-source\' => "/#{source_bucket_name}/#{source_object_name.sub(/^\\//, \'\')}" }.merge!(options)```\n\nin\n```fog/storage/requests/aws/copy_object.rb```'
291,'','AWS write-only upload with IAM\nI am trying to upload a file with Fog into an AWS bucket. The intent is to implement a Mac style Drop Box where the script can drop files but cannot see what other files are present. \r\n\r\nI am using some sample code where bucket is my bucket name, folder is the remote folder and file the full name to the local file\r\n\r\n```\r\nconnection = Fog::Storage.new(:provider=>\'AWS\',:aws_secret_access_key=>AWS_SECRET,:aws_access_key_id=>AWS_KEY)\r\nconnection.directories.get(bucket)\r\ndirectory.files.create(:key=>folder + \'/\' + File.basename(file),:body=>File.open(file),:public=>false)\r\n```\r\n\r\nThe code is working when I use my full AWS credentials however it fails when I use an IAM account. The error (see below) is an access denied when doing a GET on path \'/\' of the bucket as part of the directories.get(bucket). I am moving this code from RightAws and that library is properly uploading with the IAM account (but does not have the other goodies that Fog has). \r\n\r\nIs there another API that I should use just for uploading? I would like the code to not try to list the bucket at all since I want to disable that capability in the IAM policy.\r\n\r\n```\r\n#<Excon::Response:0x000001019b6e08 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>xxxxx</RequestId><HostId>xx+xxx/xx</HostId></Error>", @headers={"x-amz-request-id"=>"xxx", "x-amz-id-2"=>"xx+xx/eZwhnd8s2", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Wed, 04 May 2011 17:09:40 GMT", "Server"=>"AmazonS3"}, @status=403>\r\n```\r\n\r\nRight now the policies are pretty lax on this one bucket, and it still fails. I would like to tighten them up to allow only uploads (s3:PutObject) from this one account.\r\n\r\n```\r\n{\r\n\t"Version": "2008-10-17",\r\n\t"Statement": [\r\n\t\t{\r\n\t\t\t"Effect": "Allow",\r\n\t\t\t"Principal": {\r\n\t\t\t\t"AWS": "arn:aws:iam::XXXXXX:userXXXX"\r\n\t\t\t},\r\n\t\t\t"Action": "s3:*",\r\n\t\t\t"Resource": "arn:aws:s3:::XXX/*"\r\n\t\t}\r\n\t]\r\n}\r\n```'
290,'','Add "how to create keys" to Getting Started wiki\nhttps://github.com/geemus/fog/wiki/getting-started-with-fog getting started guide starts with:\r\n\r\n<pre> server = AWS.servers.create(:image_id => "ami-22b0534b", :key_name => "geemus")</pre>\r\n\r\nWhat is key "geemus"? How do I create keys or set them up etc with fog?\r\n\r\nNic'
289,'','Image is broken on wiki/getting-started-with-fog\nOn https://github.com/geemus/fog/wiki/getting-started-with-fog there is a broken image.'
288,'','What does ":default provides VirtualBox" mean?\n\r\n<pre>$ fog\r\n  Welcome to fog interactive!\r\n  :default provides VirtualBox\r\n>> compute = Fog::Compute.new\r\nArgumentError: wrong number of arguments (0 for 1)\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/lib/fog/compute.rb:4:in `new\'\r\n\tfrom (irb):1:in `<top (required)>\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/bin/fog:39:in `block in <top (required)>\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/bin/fog:39:in `catch\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/bin/fog:39:in `<top (required)>\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/bin/fog:19:in `load\'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/bin/fog:19:in `<main>\'\r\n</pre>\r\n\r\nWhat is a :default? How do I spin up a virtualbox image?'
287,'',"first example on fog.io failed: undefined method `servers' for AWS:Class\n<pre>$ fog\r\n  Welcome to fog interactive!\r\n  :default provides VirtualBox\r\n>> server = AWS.servers.create\r\nNoMethodError: undefined method `servers' for AWS:Class\r\n\tfrom (irb):1:in `<top (required)>'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/bin/fog:39:in `block in <top (required)>'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/bin/fog:39:in `catch'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.2/bin/fog:39:in `<top (required)>'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/bin/fog:19:in `load'\r\n\tfrom /Users/drnic/.rvm/gems/ruby-1.9.2-p180/bin/fog:19:in `<main>'\r\n</pre>"
286,'',"Fix for issue #283: S3 get_object request doesn't really support the Range header\nOkay, this is the small fix for the Range header. I hope a new minor version will be out soon so I'll be able to get rid of the monkey patching I've done in my own code :)\r\n\r\nReally awesome project - thanks!"
285,'','[aws] Add Autoscaling API \nhttp://docs.amazonwebservices.com/AutoScaling/latest/APIReference/\r\n\r\nThis is more of a feature request than an issue.'
284,'',"Remove dependency on git in gemspec\nIt seems spork on MacOS X can't find git installed with homebrew by default.  I.e., it's not on the PATH as used by spork.  This means fog won't load in a project because it shells out to git to get its file listing.\r\n\r\nSpork-aside, it'd likely be a good deal faster to just list the files in the gemspec than it is to shell out to another executable."
283,'',"S3 get_object request doesn't really support the Range header\nAlthough I can set the Range header when calling get_object, the hard-coded :expects => 200, (get_object.rb, line 46 on version 0.7.2) makes excon raise an error.\r\n\r\nA quick fix should be to change that line to :expects => [ 200, 206 ],\r\n\r\nThanks,\r\nTal"
282,'','Fix xml value parsing\nxml character entities amongst other things cause multiple calls to\r\nFog::Core::Parsers::Base#characters so it needs to accumulate the\r\npassed in values.\r\n\r\nBug noticable in aws get bucket requests returning empty etags for\r\ncontained keys.'
281,'','[core] Compare models by their identity\nThis makes copies of the same model equal. E.g.\r\n\r\n    server = AWS[:compute].server.create\r\n    copy = AWS[:compute].servers.get(server.id)\r\n\r\n    server == copy # => true'
280,'',"[aws|elb] Create a model and collection for load_balancers\nI'm starting to like shindo. :-)"
279,'','[storage|aws] Fix docs to say files.each, not each_file.\nFixed the API, forgot to update the docs.\r\n\r\nThis updates the docs.'
278,'geemus','[storage|google&rackspace] should auto-paginate for each\nFor consistency and ease of use, these providers should be updated to match up with the aws changes introduced here:\r\nhttps://github.com/geemus/fog/pull/269\r\n\r\nYou should be able to take those changes and add them in more or less the same way, but with a little tweaking around how the actual pagination works.\r\n\r\nLet me know if there are any questions or how I can help, thanks!'
277,'','[aws|elb] Add support for creating and deleting listeners\nAdd ELB#create_load_balancer_listeners and ELB#delete_load_balancer_listeners'
276,'','[stormondemand] Implement Stormondemand API\nThis implements the basic API for cloud server provider Storm on Demand (http://stormondemand.com). \r\n\r\nThanks,\r\nIan'
275,'','[compute|aws] Fix & improve some tests.\nUse m1.small flavor with gentoo ami; smallest\r\nflavor that supports instance storage.\r\n\r\nExpect nullable strings for these attributes:\r\n* snapshot descriptions\r\n* tag descriptions\r\n* volume snapshotIds\r\n\r\nWhitespace cleanup.'
274,'',"Updated Image identifiers\nHi,\r\n\r\nWe've updated the images and thus identifiers used to reference the images in the tests and for the default image.\r\n\r\nAlso added a missing comma from a test stopping it running.\r\n\r\nCheers,\r\n\r\nPaul"
273,'','Multi zone mocks\nAdds per-region zoneinfo to AWS mock.\r\n\r\nAlso a tiny documentation fix.'
272,'','Fix typo in spec output\nJust a typo, nothing more.'
271,'',"Fix tests and have nicer mkdir errors\nFixes:\r\n- syntax error in bluebox tests\r\n- skipping an unmocked bit of rackspace during mock mode tests\r\n\r\nAdds:\r\n- a helpful error message with provider[:storage].directories.create('mydir')"
270,'',"Ability to instrument, log, and debug fog requests\nThis is a proposal for a rather significant change to fog, so I'm proposing it here before working on it.\r\n\r\nAdd the ability to instrument, log, and debug fog requests. Fog users could implement a subscriber pattern to access info about fog reqests (duration, parameters, etc). Subscribers could log request info to a file, put it an audit system, etc.\r\n\r\nBy default, nothing would subscribe to the notifications, so default behavior would not change. \r\n\r\nAs a proof-of-concept, I've hacked up a way to log and instrument fog requests in this gist: https://gist.github.com/920101\r\n\r\nThe proof-of-concept works by monkey-patching private 'request' methods.\r\n\r\nHere's how we can bake this functionality into Fog:\r\n\r\n* implement a Fog::Instrumentation::Notifier class that can send notifications to Subscribers.\r\n* wrap every Fog::provider::service::Real#request method with a call to the notifier (perhaps DRY up the requests too)\r\n* implement a Fog::Instrumentation::Subscriber module to handle notifications. By default, it does nothing with notifications.\r\n\r\nUsers who want to log/instrument requests can include Fog::Instrumentation::Subscriber in their class to access notifications.\r\n\r\nThis is closely modeled on the ActiveSupport::LogSubscriber (https://github.com/rails/rails/blob/master/activesupport/lib/active_support/log_subscriber.rb), but it does not depend on it.\r\n\r\nIt might be a few weeks before I can get to this.\r\n\r\nCheers,\r\nAaron\r\n"
269,'',"AWS::Storage::Directory#each_file\nThese commits add the `#each_file` method to iterate all files in an S3 bucket.\r\n\r\nI added a warning to `AWS::Storage::Files#each` referencing `#each_file`. The implementation's not the best thing in the world, but it gets the job done. Not sure how to improve it, though.\r\n\r\nI didn't see where the tests for this should go, so I didn't write any. It works when I run it by hand, FWIW. That's also why I didn't add support to other providers: no automated tests and no spare credentials laying around for manual tests."
268,'',"Fix aws attributes\nCommit 1364f1a0 introduces a regression where many parsed attributes contain a trailing linebreak and whitespace.\r\n\r\nThis commit removes the trailing whitespace, at least in AWS Computer server models.\r\n\r\nI'm not very familiar with the DNS/Route 53 API, so I may have undone what commit 1364f1a0 fixed.\r\n\r\nI added tests that some AWS EC2 attributes should not contain whitespace. It's not the best place to test this, but I didn't see any Fog::Parsers::Base unit tests."
267,'','[rackspace] Cloud Load Balancers\nRackspace announced Cloud Load Balancers (API docs: http://www.rackspace.com/cloud/cloud_hosting_products/loadbalancers/api/). Could fog support managing these?'
266,'',"occasional aws connection issues\nWe've got some automated scripts handling snapshots in AWS, and so far a couple times a day we'll get some random connection issues. Below are two stacktraces of each of the two distinct types of connection problems we've seen. I guess my main question is are these standard AWS issues we'll have to work around or are they solvable in fog?\r\n\r\nThanks,\r\nEric\r\n\r\n\r\nInternalError => Request could not be executed due to an internal service error\r\n[GEM_ROOT]/gems/excon-0.6.1/lib/excon/connection.rb:178:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/core/connection.rb:20:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/aws.rb:260:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/requests/aws/create_tags.rb:33:in `create_tags'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/models/aws/tag.rb:27:in `save'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/core/collection.rb:50:in `create'\r\napp/models/snapshot.rb:33:in `create'\r\napp/models/snapshot.rb:30:in `tap'\r\n\r\nInternalError => Request could not be executed due to an internal service error\r\n[GEM_ROOT]/gems/excon-0.6.1/lib/excon/connection.rb:178:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/core/connection.rb:20:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/aws.rb:260:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/requests/aws/describe_instances.rb:64:in `describe_instances'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/models/aws/servers.rb:64:in `all'\r\napp/models/server.rb:65:in `instance'\r\n\r\n\r\nConnection reset by peer\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:36:in `sysread'\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:36:in `fill_rbuff'\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:159:in `eof?'\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:134:in `readline'\r\n[GEM_ROOT]/gems/excon-0.6.1/lib/excon/response.rb:22:in `parse'\r\n[GEM_ROOT]/gems/excon-0.6.1/lib/excon/connection.rb:162:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/core/connection.rb:20:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/aws.rb:260:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/requests/aws/create_snapshot.rb:27:in `create_snapshot'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/models/aws/snapshot.rb:35:in `save'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/core/collection.rb:50:in `create'\r\napp/models/snapshot.rb:30:in `create'\r\napp/models/snapshot.rb:64:in `take_snapshot'\r\n\r\nConnection reset by peer\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:36:in `sysread'\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:36:in `fill_rbuff'\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:159:in `eof?'\r\n/opt/ruby-enterprise/lib/ruby/1.8/openssl/buffering.rb:134:in `readline'\r\n[GEM_ROOT]/gems/excon-0.6.1/lib/excon/response.rb:22:in `parse'\r\n[GEM_ROOT]/gems/excon-0.6.1/lib/excon/connection.rb:162:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/core/connection.rb:20:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/aws.rb:260:in `request'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/requests/aws/describe_snapshots.rb:46:in `describe_snapshots'\r\n[GEM_ROOT]/gems/fog-0.7.2/lib/fog/compute/models/aws/snapshots.rb:26:in `all'\r\napp/models/server.rb:90:in `snapshot_in_progress?'\r\napp/models/server.rb:96:in `service_check!'\r\n"
265,'','AWS Server tags don\'t get saved properly when new servers are created\nWhen creating a new server like so:\r\n\r\n    compute.servers.create({:tags => {"Name" => "AMQP Consumer"}, :flavor_id => "t1.micro", :image_id => "ami-99999"})\r\n\r\nThe response shows:\r\n\r\n    <Fog::AWS::Compute::Server\r\n        [...]\r\n        tags={:name=>"AMQP Consumer"},\r\n        [...]\r\n    >\r\n\r\nAnd so it appears it would have the specified keys, but upon checking the server in the console or via the command line it doesn\'t have the tags specified. \r\n'
264,'','Improving Fog::Model\nThis is a pair of changes to make Model#wait_for and Model#reload more useful.\r\n\r\nModel#wait_for had a subtle bug where it would never drop out if reloads were failing.\r\n\r\nModel#reload made no effort to contain network-related errors, which should (at least in certain contexts) be treated as "reload failure".  The context that called attention to this problem was Model#wait_for, which calls reload repeatedly expecting failures to be "false".  Other examples may exist, but if you\'d prefer this change be limited to just Model#wait_for, I\'d be happy to make that change as well.'
263,'','Problem when parsing  a Route 53 DKIM record\nWhen parsing a Route53 DNS record containing a  double quote character " such as\r\n"v=DKIM1; k=rsa; p=MIGfMA0GCSqG....x59/8qdGvAo+S5xwIDAQAB"\r\nthe parser just retains the last double quote.'
262,'','describe_availability_zones mock is us-east only\nthe describe_availability_zones mock for AWS should return something realistic dependent on the region given, instead of always returning us-east'
261,'','Add AWS::ELB#configure_health_check request (with tests!)\nAdds support for modifying health checks for AWS elastic load balancers.'
260,'','fix Destinations for send_raw_email\nDestination in send_raw_email was sent incorrectly. Generating\nDestinations=Destinations.member.1email@example.com\ninstead of\nDestinations.member.1=email@example.com\n\nAlso corrected doc by changing "Delete an existing verified email address" to "Send a raw email".'
259,'','Drop default_executable line from gemspec.\nThis line should be removed from the gemspec:\n * inferred when only one executable available\n * deprecated (with noisy warnings) in rubygems 1.7'
258,'',"[aws|rds] Fix exception for missing DB security groups\nRDS#describe_db_instances('no-such-group') raises\r\n  Fog::AWS::RDS::NotFound\r\ninstead of\r\n  Excon::Errors::NotFound"
257,'','Add link to multipart upload and threads article\nAdded a link to the post for multipart uploads + threads.\r\n\r\nGavin'
256,'','SimpleDB encode_batch_attributes\nHere is a correction for item and attribute counters in encode_batch_attributes.'
255,'','incorrect item and attribute counters in Fog::AWS::SimpleDB.encode_batch_attributes\nitem_index should be incremented after the attribute_key loop and attribute_index should be zeroed before the loop.'
254,'',"[aws|elb] Fix Policies in describe_load_balancers parser.\nParse PolicyName, CookieName, and\r\nCookieExpirationPeriod tags that may appear under\r\nthe Policies tag.\r\n\r\nAlso, lightly DRY'ed up the parser."
253,'',"Prevent running Voxel tests with no credentials\nVoxel tests were running even if no credentials in place. Added them to the list so they aren't run."
252,'',"Fix Blocks Load Balancer support, adding BLB tests.\nHey there,\r\n\r\nI've fixed up a few issues with the Fog::Bluebox::Compute::Server class, which wasn't expecting any input for our new BLB API (needed to add options[:lb_applications], options[:lb_services], and options[:lb_backends].)\r\n\r\nAlso added in some tests, though feedback is much appreciated.\r\n\r\nCheers,\r\n\r\n-- ian"
251,'',"Fog sets rubygems_version when it shouldn't\n"
250,'','Fog specifies its excon dependency incorrectly\nFog 0.6.0 depends on excon >= 0.5.5.\r\n\r\nexcon 0.6.1 is not API compatible with fog 0.6.0\r\n\r\nThe dependency on excon for fog 0.6.0 should have been ~> 0.5.5.\r\n\r\nThe dependency on excon for fog 0.7.2 should be ~> 0.6.1'
249,'',"[aws|elb] Add tests for create, describe, and delete.\nThis adds 3  tests for Fog::AWS::ELB (create, describe, delete). It's not very much, but it's a start.\r\n\r\nIt might be enough to close https://github.com/geemus/fog/issues#issue/142"
248,'','[slicehost] Excon errors\nTrying to use fog with slicehost results in an excon error. Using RVM 1.5.2 with ruby 1.9.2-p180 and fog 0.7.1:\r\n\r\n\r\n    ruby-1.9.2-p180 :001 > require \'fog\'\r\n     => true \r\n    ruby-1.9.2-p180 :002 > SLICEHOST_API_PASSWORD ||= ENV[\'SLICEHOST_API_PASSWORD\'] || \'my_api_password\'\r\n     => "my_api_password" \r\n    ruby-1.9.2-p180 :003 > compute = Fog::Compute.new(\r\n    ruby-1.9.2-p180 :004 >       :provider           => \'Slicehost\',\r\n    ruby-1.9.2-p180 :005 >       :slicehost_password => SLICEHOST_API_PASSWORD\r\n    ruby-1.9.2-p180 :006?>   )\r\n     => #<Fog::Slicehost::Compute::Real:0x000001020776c0 @slicehost_password="my_api_password", @host="api.slicehost.com", @port=443, @scheme="https", @connection=#<Fog::Connection:0x000001018183d0 @excon=#<Excon::Connection:0x00000101818380 @connection={:headers=>{}, :host=>"api.slicehost.com", :path=>"", :port=>"443", :query=>nil, :scheme=>"https"}, @socket_key="api.slicehost.com:443">, @persistent=nil>> \r\n    ruby-1.9.2-p180 :007 > compute.servers\r\n    Excon::Errors::SocketError: wrong number of arguments (3 for 1)\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/connection.rb:16:in `block in request\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/excon-0.6.0/lib/excon/response.rb:47:in `parse\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/excon-0.6.0/lib/excon/connection.rb:140:in `request\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/connection.rb:20:in `request\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/compute/slicehost.rb:92:in `request\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/compute/requests/slicehost/get_slices.rb:28:in `get_slices\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/compute/models/slicehost/servers.rb:13:in `all\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/collection.rb:123:in `lazy_load\'\r\n    \tfrom (eval):3:in `empty?\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/collection.rb:70:in `block in inspect\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/formatador-0.1.3/lib/formatador.rb:92:in `indent\'\r\n    \tfrom /Users/someuser/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/collection.rb:63:in `inspect\'\r\n    \tfrom /Users/someuser/.rvm/rubies/ruby-1.9.2-p180/bin/irb:16:in `<main>\'\r\n    \r\n'
247,'','AWS ELB broken in 0.7.1\nIt seems that the AWS load balancer code is broken in 0.7.1\r\n\r\n<pre>\r\n\r\nruby-1.9.2-p180 :014 > e = Fog::AWS::ELB.new(:aws_access_key_id=>AWS_KEY,:aws_secret_access_key=>AWS_SECRET)\r\n => #<Fog::AWS::ELB::Real:0x00000103065d48 @aws_access_key_id="AKIAJG6K56RGT34TNDQA", @aws_secret_access_key="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", @hmac=#<Fog::HMAC:0x00000103065ca8 @key="I9D52aiKMKQoeG09rri00eFClQiFW0Azced2RMg8", @digest=#<OpenSSL::Digest::Digest: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855>, @signer=#<Proc:0x00000103065bb8@/usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.1/lib/fog/core/hmac.rb:30 (lambda)>>, @host="elasticloadbalancing.us-east-1.amazonaws.com", @path="/", @port=443, @scheme="https", @connection=#<Fog::Connection:0x000001030659d8 @excon=#<Excon::Connection:0x00000103065988 @connection={:headers=>{}, :host=>"elasticloadbalancing.us-east-1.amazonaws.com", :path=>"/", :port=>"443", :query=>nil, :scheme=>"https"}, @socket_key="elasticloadbalancing.us-east-1.amazonaws.com:443">, @persistent=nil>> \r\nruby-1.9.2-p180 :015 > e.describe_load_balancers\r\nExcon::Errors::SocketError: wrong number of arguments (3 for 1)\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.1/lib/fog/core/connection.rb:16:in `block in request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.2-p180/gems/excon-0.6.0/lib/excon/response.rb:47:in `parse\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.2-p180/gems/excon-0.6.0/lib/excon/connection.rb:140:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.1/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.1/lib/fog/aws/elb.rb:95:in `request\'\r\n\tfrom /usr/local/rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.1/lib/fog/aws/requests/elb/describe_load_balancers.rb:45:in `describe_load_balancers\'\r\n\tfrom (irb):15\r\n\tfrom /usr/local/rvm/rubies/ruby-1.9.2-p180/bin/irb:16:in `<main>\'\r\n</pre>'
246,'',"Excon 0.6.0 breaks ELB\nrequire 'fog'\r\n\r\nELB = Fog::AWS::ELB.new\r\n\r\nruby-1.9.2-p136 :005 >   ELB.describe_load_balancers\r\nExcon::Errors::SocketError: wrong number of arguments (3 for 1)\r\n\tfrom /Users/tomh/.rvm/gems/ruby-1.9.2-p136@fogBroke/gems/fog-0.7.1/lib/fog/core/connection.rb:16:in `block in request'\r\n\tfrom /Users/tomh/.rvm/gems/ruby-1.9.2-p136@fogBroke/gems/excon-0.6.0/lib/excon/response.rb:47:in `parse'\r\n\tfrom /Users/tomh/.rvm/gems/ruby-1.9.2-p136@fogBroke/gems/excon-0.6.0/lib/excon/connection.rb:140:in `request'\r\n\tfrom /Users/tomh/.rvm/gems/ruby-1.9.2-p136@fogBroke/gems/fog-0.7.1/lib/fog/core/connection.rb:20:in `request'\r\n\tfrom /Users/tomh/.rvm/gems/ruby-1.9.2-p136@fogBroke/gems/fog-0.7.1/lib/fog/aws/elb.rb:95:in `request'\r\n\tfrom /Users/tomh/.rvm/gems/ruby-1.9.2-p136@fogBroke/gems/fog-0.7.1/lib/fog/aws/requests/elb/describe_load_balancers.rb:45:in `describe_load_balancers'\r\n\tfrom (irb):5\r\n\tfrom /Users/tomh/.rvm/rubies/ruby-1.9.2-p136/bin/irb:16:in `<main>'\r\n"
245,'',"create_access_key for username failing.. excon error?\n% rvm use 1.9.2@fog --create\r\nUsing /Users/codecafe/.rvm/gems/ruby-1.9.2-p180 with gemset fog\r\n\r\n% gem install fog\r\n\r\n% gem list\r\n\r\n*** LOCAL GEMS ***\r\n\r\nbuilder (3.0.0)\r\nexcon (0.6.0)\r\nfog (0.7.1)\r\nformatador (0.1.2)\r\njson (1.5.1)\r\nmime-types (1.16)\r\nnet-ssh (2.1.3)\r\nnokogiri (1.4.4)\r\nrake (0.8.7)\r\nruby-hmac (0.4.0)\r\n\r\n% irb\r\n\r\nrequire 'fog'\r\n\r\nnew_username = 'myusername'\r\n\r\nbucket_name = 'mybucket'\r\n\r\naws_credentials = { \r\n :aws_access_key_id => 'XXXCXCATATTETT',\r\n :aws_secret_access_key => 'loremipsumgratisforumquorum',\r\n}\r\n\r\niam = Fog::AWS::IAM.new(aws_credentials)\r\n\r\nuser_response = iam.create_user(new_username)\r\n\r\nkey_response  = iam.create_access_key('UserName' => new_username)\r\n\r\nExcon::Errors::SocketError: wrong number of arguments (3 for 1)\r\n        from /Users/codecafe/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/connection.rb:16:in `block in request'\r\n        from /Users/codecafe/.rvm/gems/ruby-1.9.2-p180@fog/gems/excon-0.6.0/lib/excon/response.rb:47:in `parse'\r\n        from /Users/codecafe/.rvm/gems/ruby-1.9.2-p180@fog/gems/excon-0.6.0/lib/excon/connection.rb:140:in `request'\r\n        from /Users/codecafe/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/core/connection.rb:20:in `request'\r\n        from /Users/codecafe/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/aws/iam.rb:106:in `request'\r\n        from /Users/codecafe/.rvm/gems/ruby-1.9.2-p180@fog/gems/fog-0.7.1/lib/fog/aws/requests/iam/create_access_key.rb:31:in `create_access_key'\r\n        from (irb):12\r\n        from /Users/codecafe/.rvm/rubies/ruby-1.9.2-p180/bin/irb:16:in `<main>'"
244,'',"Fixing Broken Single Quote Escaping\nThe escaping behavior is incorrect in that it only escapes the first apostrophe, which is only made necessary because commands are execute through `bash`.  Since `bash` is not guaranteed to be installed (sad, but true), and since this represents unexpected behavior, I've pared this down to the simplest thing that could possibly work."
243,'','updated base parser to not eagerly strip data\nI was only able to test this on EC2, let me know if there are any issues.'
242,'','Base Parser fix to presumptuous strip in #characters method\nfor consideration:\n\nremoved strip statement from value in def characters. was not necessary and causes problems with AWS security groups. generally, it seems more dangerous to act on strings than to allow the actual values to pass through and allow consumers to deal with them.  specifically, it made managing AWS security groups impossible because you can\'t depend on the name being returned in a set to match the name of an actual specific record\n\nin response to\n\nhttps://github.com/geemus/fog/issues/#issue/241\nfog / lib / fog / core / parser.rb\nin def characters(string):\n\nParser calling .strip causes issues with AWS Security Groups that have a leading or trailing space in the name.\n\nIf I create a SecurityGroup [Compute|AWS] with a space after or before the name, ie: "Test " it is created fine. When I query against SecurityGroups.all, it is returned as just "Test" with the space missing. If I go to do a lookup: security_groups.get("Test "), it is returned, but is listed as just "Test".\n\n'
241,'','[core] Parser calling .strip causes issues with AWS Security Groups that have a leading or trailing space in the name\nfog / lib / fog / core / parser.rb\r\nin def characters(string):\r\n\r\nParser calling .strip causes issues with AWS Security Groups that have a leading or trailing space in the name.\r\n\r\nIf I create a SecurityGroup [Compute|AWS] with a space after or before the name, ie: "Test " it is created fine.  When I query against SecurityGroups.all, it is returned as just "Test" with the space missing.  If I go to do a lookup: security_groups.get("Test "), it is returned, but is listed as just "Test".\r\n'
240,'','Add key_pairs write and writable? methods\nThese methods enable Fog users to check whether or not they can write out private key files. They can also write files out, with an optional path that defaults to a "safe" location in .ssh, prefixed with fog_. Includes some shindo test action.'
239,'',"Fog.credentials_path should deal with missing env vars better\nCurrently if FOG_RC and HOME are unset you an error is raised from expand_path because it's given a nil value.\r\n\r\nInstead the method should simply return nil when it can't find a path for the credentials. Fog.credentials handles nil values from credentials_path already."
238,'',"Rackspace Storage's head_object method uses the HEAD HTTP method, not GET\nRackspace Storage's head_object method uses the HEAD HTTP method, not GET"
237,'','Rackspace => Storage => head_object method should use HEAD instead of GET\nRight now the method uses GET instead of HEAD. A nasty side effect is that you pull the whole file into memory then.\r\n\r\nhttps://github.com/geemus/fog/blob/master/lib/fog/storage/requests/rackspace/head_object.rb#L15\r\n\r\nPatch is on the way.\r\n'
236,'','[compute] Provide a mechanism for retrieving RSA fingerprints\nDifferent providers have different out-of-band mechanisms for fetching RSA fingerprints.  A single method for fetching that information would be valuable.'
235,'',"expose default timeout value\nSo it can be accessed from other things that wish to preserve the default timeout under some conditions but not others. \r\n(right now it's just a hardcode default argument value ala timeout=600)"
234,'','Fix AWS instance mock dns filter name\nThe correct name of the dns filter is dns-name, not dns-token.  Appears to have been a typo in the mock.'
233,'',"AWS fog mocks don't detach IPs like real AWS\nIf I have an IP attached to a instance in AWS, and then make a fog call to attach a different IP to that instance, I find that AWS disconnects the existing attached IP.\r\n\r\nThe fog mocks do not behave this way (they allow you to have multiple IPs attached to an instance)"
232,'','AWS Bugfix\nServer#key_pair calls Connection#keypairs, which really should be Connection#key_pairs.'
231,'',"[storage|hdfs] add initial support for hadoop storage\nHi there\n\nAre there any plans to implement HDFS storage? It looks like this would fit nicely into fog's portfolio: http://hadoop.apache.org/hdfs/\n\nTx"
230,'',"Region parameter on cloud formation requests\nHey Wesley,\r\n\r\nAny special reason for the 'region' parameter not being passed to 'recognizes' in the cloudformation service? If not, here's a patch to fix it. Since the constructor was already expecting the parameter and I couldn't find tests around it, the change was minimal, probably the smallest pull request you'll ever get. :)\r\n\r\nThanks\r\n\r\nFabio\r\n\r\n"
229,'','a common :name attribute in servers\nI\'m wondering if it makes sense to have a :name attribute for an AWS server instance.\r\nIt\'s currently only possible to get it via the tags.\r\n\r\nAmazon itself uses the Tags["Name"] to display it in the AWS console, so I guess it\'s pretty standard, not?\r\n\r\nThis would allow me to unify the name lookup across providers.\r\n\r\nRationale: In my tool [mccloud](https://github.com/jedi4ever/mccloud) I use the a prefix for names to find instances belonging to specific projects. \r\n\r\na)I can\'t use tags as this is not unified.\r\nb) the servers.all does not allow a kind of filter\r\n\r\nThanks for taking this under consideration!'
228,'','[storage|rackspace] Cloud Files large file support\nRackpace announced this feature for multi-part large file support here: http://www.rackspace.com/cloud/blog/2011/03/25/rackspace-cloud-files-now-supporting-extremely-large-file-sizes/\r\n\r\nAdditional docs here: http://www.rackspace.com/cloud/blog/2011/03/25/rackspace-cloud-files-now-supporting-extremely-large-file-sizes/'
227,'','Add new AWS mocking features\n* mock delete_tags\r\n* implement tag filtering for instances, volumes, snapshots'
226,'','Fix rackspace escaping\nCGI.escape doesn\'t properly escape container or object names with spaces or other important characters in them when accessing the Rackspace Storage REST API.  Using URI.escape does.\r\n\r\nFrom master:\r\n\r\n    >> d = f.directories.get("Raw Video")\r\n    Excon::Errors::BadRequest: Expected(200) <=> Actual(400 Bad Request)\r\n\r\nFrom this branch:\r\n\r\n    >> d = f.directories.get("Raw Video") \r\n    =>   Fog::Rackspace::Storage::Directory\r\n        key"Raw Video",\r\n        bytes"12845395968",\r\n        count"20"\r\n'
225,'','Issue 224\nRemoved CGI escape call.  It seems unnecessary and is adding the escaped characters to the descriptions.'
224,'','[compute|aws] SecurityGroup.description is being CGI escaped\nIn create_security_group, description is being CGI escaped.  Is this intentional?  I do not see the purpose. My descriptions end+up+looking+like+this.'
223,'',"Rackspace SSL\nHere's a topic branch that adds the ability to get the public_url for Rackspace storage directories and files as an https URL, instead of an http."
222,'',"add service related tags to tests\nRight now most tests have provider related tags, but not service tags.\r\n\r\nTags generally appear as the 3rd argument in a Shindo.tests block (at the top of a tests file).  For instance if you look at AWS related tests they almost all have an aws tag, but not a service tag.  To complete this ticket you will need to go through, for instance, all tests in the storage directory and add a 'storage' tag.  Note that some helpers may also need to be updated to accomodate this change.\r\n\r\nBy making this addition it facilitates running focused tests without needing to worry where they reside.  For instance, to just run aws storage tests you would be able to do `bundle exec shindo +aws +storage`, which isn't really currently supported (you could run either requests or models by passing a specific directory, but not all of them).  You could also run all storage tests 'bundle exec shindo +storage` or skip all storage tests `bundle exec shindo -storage`.  All in all, adding this makes it easier and more accessible to test whatever a contributor might actually need to work on.\r\n\r\nAs always, let me know if this is not clear enough and I'll be happy to clarify."
221,'','Fog::AWS::Compute::Server#attributes omits some nil attributes (causes ArgumentError: negative argument in Formatador.display_table)\nI stumbled on this when attempting to run:\n\n    $ fog\n      Welcome to fog interactive!\n      :default provides AWS\n    >> AWS.servers.table [:id, :public_ip_address]\n      +------------+--+\n    ArgumentError: negative argument\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/formatador-0.1.1/lib/formatador/table.rb:41:in `*\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/formatador-0.1.1/lib/formatador/table.rb:41:in `block in display_table\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/formatador-0.1.1/lib/formatador/table.rb:40:in `each\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/formatador-0.1.1/lib/formatador/table.rb:40:in `display_table\'\n    \tfrom (eval):3:in `display_table\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.0/lib/fog/core/collection.rb:112:in `table\'\n    \tfrom (irb):1:in `<top (required)>\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.0/bin/fog:39:in `block in <top (required)>\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.0/bin/fog:39:in `catch\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/gems/fog-0.7.0/bin/fog:39:in `<top (required)>\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/bin/fog:19:in `load\'\n    \tfrom /Users/gabebug/.rvm/gems/ruby-1.9.2-p180/bin/fog:19:in `<main>\'\n      >> AWS.servers\n        <Fog::AWS::Compute::Servers\n          filters={}\n          [\n            <Fog::AWS::Compute::Server\n              id="i-xxxxxxxx",\n              public_ip_address=nil,\n              private_ip_address=nil,\n              state="stopped",\n              ... (etc)     \n            >\n          ]\n        >\n\nHowever, if I run AWS.servers.first.attributes (which is what #table references), public_ip_address and private_ip_address do not appear in the hash.'
220,'','Content length calculation, ETag header and LastModified header\nA few unrelated changes all for storage, mostly aws in this pull, sorry:\r\n\r\n* normalise ETag header: remove quotes\r\n* normalise LastModified headers to be consistent between save/create (perhaps the file model should use the :time attribute for this)\r\n* decouple body size calculation from File/String, this makes it possible to stream non-File/String objects if they implement the protocol for :size, :read (needs excon geemus/excon#32)'
219,'',"Rackspace servicenet\nThis code adds support for the Rackspace Servicenet to the Storage, CDN, and Compute classes.  The servicenet is an internal network that is not charged for bandwidth, which makes it a useful feature for those using Rackspace services from within the Rackspace hosting environment.\r\n\r\nI'm running into an issue with the tests - even though I'm trying to turn off SSL certificate verification in Excon if servicenet is enabled (as it changes the hostname of the endpoint), it doesn't seem to be working.  When I work with the code outside of the testing environment, though, things work fine.  I'm not familiar with Shindo (or Excon for that matter), so pointers there would be appreciated.\r\n\r\nAnyway, this should be a useful addition for people using Rackspace services."
218,'','Fix to SimpleDB to allow non-ascii characters\nWhen sending non-ascii characters encoded as UTF-8 to SimpleDB with fog, the response is a 403. This is mitigated by setting the appropriate Content-Type header.\r\n\r\nTo reproduce (this is on REE):\r\n\r\n        sdb = Fog::AWS::SimpleDB.new(:aws_access_key_id => key_id, :aws_secret_access_key => key, :host => "sdb.#{region}.amazonaws.com")\r\n        sdb.put_attributes(domain, "some-item", {:n => \'aÃ±a\'})\r\n\r\n(See also: https://forums.aws.amazon.com/thread.jspa?messageID=220215)'
217,'','support for manipulating iam login profiles\n'
216,'',"77 monitoring\nHi,\nI saw your tweet and I had some time :)\n\nHere is a possible patch for issue 77.\n\nThe method is not called monitoring= but monitor= as I had trouble having both behaviors (attribute vs. request) coexisting in the same method. Here is the comment I put in the code\n\n    I tried to call it monitoring= and be smart with attributes[]\n    but in #save a #merge_attribute is called after #run_instance\n    thus making an un-necessary request. Use this until finding a clever solution\n\nAll FOG_MOCK=true shindo tests pass but since I don't have an AWS account please test with the real implementations.\n\n--Gilles"
215,'',"Allow string keys in credentials file [issue 179]\nAllow string or symbols for keys in credentials file.\r\n\r\nI saw your twitter call to action - I've started with an easy one."
214,'','Add rds restore commands\nAdd two RDS requests for restoring a database\r\n'
213,'',"DNSimple api issues\nHi,\r\n\r\nI've fixed several DNSimple API issues that were causing various Fog::DNS features to simply not work. The commit log should be fairly explanatory.\r\n\r\nRe testing (slightly off topic): the tests were passing with bugs included. The tests aren't rigorous enough. I'd like to fix this but I can't make sense of the Shindo test framework - I'm an rspec guy. In Shindo, how do you assert a particular value ? or test for nil/not-nil?\r\n\r\nRegards,\r\nIjonas."
212,'',"Fix rds snapshots safer\nFixes snapshots.get() method in the RDS snapshot collection.\r\n\r\nThis patch doesn't change the API for RDS#describe_snapshots.\r\n\r\nChoose either this patch or https://github.com/geemus/fog/pull/211"
211,'',"Fix rds snapshots\nThe snapshots.get(id) method returns the first snapshot, not the snapshot you intend.\r\n\r\nThis patch fixes that by changing the RDS#describe_snapshots arguments to match what the snapshots collection is using.\r\n\r\nNote that this patch changes the API to RDS#describe_snapshots (for the better, IMHO).\r\n\r\nIn a moment, I'll submit another patch that fixes the bug without changing the API.\r\n\r\nChoose either this patch (to improve the API), or the other one (to preserve backwards compatibility)."
210,'','Fix rds db name\nThe RDS db_parser currently ignores the DBName attribute. This trivial patch fixes that.\r\n'
209,'','NoMemoryError: failed to allocate memory from C:/Ruby/lib/ruby/gems/1.8/gems/excon-0.5.6/lib/excon/response.rb:60\nHi,\r\n\r\nI get a "NoMemoryError: failed to allocate memory" error when i try to download a large file (>1GB) using the storage model like this:\r\n\r\ns3 = Fog::AWS::Storage.new\r\nFile.open(destination,\'wb\') { |f| f << s3.directories.get(bucket).files.get(file_basename).body }\r\n\r\nIs there a way to specified a chunk_size so the whole file doesn\'t live into memory? \r\n\r\nThanks,\r\n\r\nRodrigo Estebanez'
208,'','Add support for AWS RDS DB security groups\nTo compliment the recent support for Amazon Relational Database Service, this adds support for managing security groups within RDS'
207,'',"fog mocking reset_data is broken\nThe requirement of tearing down all mocked data between tests is quickly becoming complicated as stubbing is mixed in. eg. @snapshot.should_receive(:destroy).and_return({raise 'failure'}) to simulate failure then proceeds to block actual destruction of the mocked data, influencing tests later on.\n\nDoes such functionality already exist?  Scans of the code didn't turn anything up.\nA naive method clear_all_data { @data.clear } resulted in many NoMethodError you have a Nil ... exceptions."
206,'','[storage|aws] add functionality for managing bucket policies\nJust need to add stuff to add/get/remove bucket policy.  Should be similar to other storage requests for the most part (and perhaps similar to aws/iam for the actual policy contents).  There are three methods to add in total, and here are the relevant docs:\r\n\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/RESTBucketPUTpolicy.html\r\n\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/RESTBucketGETpolicy.html\r\n\r\nhttp://docs.amazonwebservices.com/AmazonS3/latest/API/RESTBucketDELETEpolicy.html'
205,'',"[ecloud|compute] add_disk for also submits cpu/memory\nWhen calling add_disk on a server in the ecloud provider the cpu and memory are also submitted in the request XML. This causes the Terremark API to think that the cpu and memory are being changed (it apparently doesn't check to see if the values actually changed -- just if they're present). This prevents adding new disks to running VMs."
204,'',"file_expand\nHi wes,\r\nI got this error:\r\nArgumentError - couldn't find HOME environment -- expanding `~/.fog\r\n\r\nI suppose it's because something as unset my HOME variable?\r\nI don't know why HOME was not set correctly at this time but It's too bad that fog was failing just because of that as I was specifying credentials in the call and not in the default config file.\r\n\r\nshouldn't you rescue Argument or verify the HOME variable exists before?"
203,'',"How do I get a list of all AWS flavors?\nIn fog/compute/models/aws/flavors.rb it says `AWS.flavors.all` returns a list of all AWS flavors (line 14 + 20), but this doesn't work. How do I get the list?"
202,'',"Collection.rb - slice needs special treatment\nslice was failing due to lazy loading. Other ops I thought would similarly fail such as -, +, rotate, etc did not. The only one I found that needed tweaking was slice.\r\n\r\nt1 = ec2.tags.all(:key => 'ec2-tag')\r\nirb(main):013:0> t2 = t1.slice(2,3)\r\nNoMethodError: undefined method `describe_tags' for nil:NilClass\r\n        from /opt/ruby-enterprise-1.8.7/lib/ruby/gems/1.8/gems/activesupport-3.0.3/lib/active_support/whiny_nil.rb:48:in `>\r\n        from /opt/code/fog/lib/fog/compute/models/aws/tags.rb:21:in `all'\r\n        from /opt/code/fog/lib/fog/core/collection.rb:137:in `lazy_load'\r\n        from (eval):3:in `empty?'\r\n        from /opt/code/fog/lib/fog/core/collection.rb:84:in `inspect'\r\n        from /opt/ruby-enterprise-1.8.7/lib/ruby/gems/1.8/gems/formatador-0.0.16/lib/formatador.rb:92:in `indent'\r\n        from /opt/code/fog/lib/fog/core/collection.rb:77:in `inspect'\r\n        from /opt/ruby-enterprise-1.8.7/lib/ruby/1.8/irb.rb:310:in `output_value'\r\n"
201,'',"[compute|aws] create_volume mocks should raise on non-existant snapshot\nWe sometimes get:\n Fog::Service::NotFound: The snapshot 'snap-xxxx' does not exist.\n\nThe fog mocks should raise this error if you attempt to call create_volume with a snapshot that doesn't exist (in the mocks)\n\ncurrently the create_volume call succeeds"
200,'','Brightbox updates and fixes\nSome errors had crept into the response formats due to changes in the beta. These have been fixed.\r\n\r\nAlso added a new request to support our new console and added a test for the request.\r\n\r\nServer#public_ip_address has also been set to a non-nil value.'
199,'',"Fog::Collection::Array functions and lazy loading\nI used Array.slice on a list of returned snapshots. Attempting to get the length of the array results in a stack trace.\r\n    snapshots = snapshots && snapshots.length > number_allowed ? snapshots.slice(0, snapshots.length - number_allowed) : nil\r\n\r\nThe trace (below) exists because the new array is not populated with the special sauce (connection object is nil) like reject & select are populated. See Fog::Collection. I added slice to the reject & select list and my code works fine.\r\n\r\nSo the question is why are only reject & select methods given the special sauce? Is there a reason the other methods that return an Array are not similarly modified?\r\n\r\n    undefined method `describe_snapshots' for nil:NilClass\r\n    /opt/ruby-enterprise-1.8.7/lib/ruby/gems/1.8/gems/activesupport-3.0.3/lib/active_support/whiny_nil.rb:48:in `method_missing'\r\n    /opt/code/fog/lib/fog/compute/models/aws/snapshots.rb:26:in `all'\r\n    /opt/code/fog/lib/fog/core/collection.rb:123:in `lazy_load'\r\n    (eval):3:in `length'\r\n    /opt/code/backupadmin/app/models/snapshot_removal_job.rb:24:in `remove_unneeded_snapshots'"
198,'','Aws tag destroy\nThe destroy method of aws.tag.rb doesn\'t appear to work. Changing the arg in the call to delete_tags from a String to a hash appears to resolve the issue.\r\n\r\ndef self.remove_tag(snapshot, tag_name)\r\n    tags = aws_connection.tags.all({:key => tag_name}) \r\n    tags.each {|t| t.destroy if t.resource_id == snapshot.id } if tags \r\nend\r\n\r\nirb(main):003:0> Snapshot.remove_tag(snap, \'example_tag\')\r\nNoMethodError: undefined method `keys\' for "":String\r\n\tfrom /opt/code/fog/lib/fog/compute/requests/aws/delete_tags.rb:28:in `delete_tags\'\r\n\tfrom /opt/code/fog/lib/fog/compute/models/aws/tag.rb:21:in `destroy\'\r\n\tfrom /opt/code/backupadmin/app/models/snapshot.rb:43:in `remove_tag\'\r\n\tfrom (eval):5:in `each\'\r\n\tfrom (eval):5:in `each\'\r\n\tfrom /opt/code/backupadmin/app/models/snapshot.rb:43:in `remove_tag\'\r\n\tfrom (irb):3\r\n'
197,'','get_object_url fails with cyrillic characters\nI use get_object_url with Cyrillic file name ("ÐÐ¾Ð¹ Ð´Ð¾ÐºÑÐ¼ÐµÐ½Ñ.docx") and when i try dowload file by this link i get the message "SignatureDoesNotMatch"\n \n      def url\n        connection.get_object_url("mybucket", "mypath", Time.now + 60*60)\n      end\n       def connection\n        Fog::Storage.new(\n            :provider              => \'AWS\',\n            :aws_secret_access_key =>"secret",\n            :aws_access_key_id     => "access_key_id"\n        )\n      end'
196,'','get_object_url for docx files\nWhen I try to use get_object_url for .docx files I get amazon s3 message "SignatureDoesNotMatch, The request signature we calculated does not match the signature you provided. Check your key and signing method."\r\nFor other types it works.\r\n      def url\r\n        connection.get_object_url("mybucket", "mypath", Time.now + 60*60)\r\n      end\r\n       def connection\r\n        Fog::Storage.new(\r\n            :provider              => \'AWS\',\r\n            :aws_secret_access_key =>"secret",\r\n            :aws_access_key_id     => "access_key_id"\r\n        )\r\n      end'
195,'',"[compute|aws] Fog mocks don't emulate volume (un)availability\nWhen talking to amazon, we sometimes get errors that say Fog::Service::Error: VolumeInUse => vol-xxxxx is unavailable\n\nwe get this when attempting to attach a volume to an instance immediately after provisioning the volume. (without any sort of wait for the volume state to change)\n\nBy setting Fog::Mock.delay we can see that the volume takes longer to change states from 'creating' to 'available'.\n\nWe would also like to see the Mocks raising an error (the same one amazon would send) when attempting to attach a volume that is still 'creating' and not yet 'available'\n"
194,'','Support HTTPS on Elastic Load Balancers\nIf using the HTTPS protocol, an IAM SSL Certificate ID is also required.'
193,'','Server certificate parser\nAdds a request parser for uploading server certificates.'
192,'','Upload / delete server certificates\nThis allows uploading server certificates (SSL certs) for use on AWS.  Particularly useful in conjunction with elastic load balancers.'
191,'',"[dns] Rename ip to value on Record\nTurns out ip was naive and inappropriate in some cases.  I think it would be better to deprecate this and use something a bit more general.  I think ip should perhaps just be 'value'. This should include deprecation of existing methods throughout."
190,'','Rds\nInitial support for rds'
189,'','[aws|iam] Added GetUserPolicy\n'
188,'','Fix for changing credentials\nCorrects fog issue 187'
187,'',"Ability to change credentials needed\nIf you change the variables in the credentials file to try and reload/change which credentials are used, the @credentials variable still always stays the same.  I'll send a pull request shortly with a very easy fix."
186,'',"Cloudformation implementation\nHey, I added some basic CloudFormation support. I don't have much experience writing tests so currently there's no tests for these. I've tested each request method and verified they work as expected, though did run into a strange issue. When running describe_stacks, the Amazon API documentation says StackName is not required, however, when making the request without StackName, it errors out saying it is required. Should this method be kept to the documentation or what the reality of the situation appears to be?"
185,'','[aws|compute] Delete tag with nil value should delete all tags\nFixes #184.'
184,'',"No tag value for a tag key has undesired behavior in AWS.\nAccording to the AWS API specification you should be able to send a request to delete a tag with a nil value.  When you do it should delete the tag regardless of the tag's value.  The code in  lib/fog/compute/requests/aws/delete_tags.rb will only delete tags when you give a specific value for the tag.  This is because it currently converts keys with a nil value into an empty string.\r\n\r\nPull request with a small patch to fix is incoming."
183,'',"undefined method 'fog_credentials=' on app start-up\nHi,\r\n\r\nUsing carrierwave + fog + s3 to manage images in a rails app.\r\n\r\nWhen I start my app I get  \r\nundefined method `fog_credentials=' for CarrierWave::Uploader::Base:Class (NoMethodError)\r\n\r\nat \r\n\r\nconfig/initializers/initializer.rb:3\r\n\r\nHere's the code:\r\n\r\nCarrierWave.configure do |config|\r\n  config.fog_credentials = {\r\n  :provider  => 'AWS', \r\n  :aws_access_key_id => 'my_key_Id',\r\n  :aws_secret_access_key => 'my_secret_code'\r\n  }\r\n  config.fog_directory = 'my_bucket_name'\r\nend\r\n\r\nstorage is set to fog in my uploader file.\r\n\r\nThoughts?  I initially was using just the s3 option for carrierwave, but got the 'broken pipe' errors.\r\n\r\nThanks,\r\n\r\nSteve"
182,'','DNSimple provider\nAll tests are green. Please accept this initial pass at a DNSimple provider.'
181,'',"[server|scp] add basic scp support\nHello, I took some time to add basic scp support. The error handling may not be compliant with the rest of fog, I wasn't sure how this part should be done. There's also missing progress display, again not sure how that should be handled."
180,'','[aws|iam] update group & update signing certificate support\nI have added update group and update signing certificate support to the AWS IAM service. There does seem to be a disconnect between the IAM documentation for update group requests and the expected response. It is indicated that the  group data should be returned as part of the response but it is not.'
179,'','[core] Credentials file should permit symbol and string keys\nThe credentials file (`~/.fog`) should permit symbol and string keys.\n\nYAML with string keys is shorter, simpler, and more readable than YAML with symbol keys.\n\nWhen Fog parses the file, it may internally convert all string keys in the credentials file to symbols for compatibility.\n\nCheers!\n'
178,'','Added update user to IAM\nAdded "update user" to the IAM lib.  Added a request and a parser.'
177,'','[aws|compute] fixed missing require line for basic parser \nAfter adding the new Nokogiri stuff, it appears everything in AWS that uses the basic parser fails to work. To keep everything pretty standard, added the necessary require lines to the requests.'
176,'','[aws|iam] missing update_user request/parser\nFog::AWS::IAM missing call for update user\n\nhttp://docs.amazonwebservices.com/IAM/latest/APIReference/index.html?API_UpdateUser.html\n\n'
175,'','Documentation for create_access_key response has a typo in a key\nhttp://rubydoc.info/gems/fog/0.5.3/Fog/AWS/IAM/Real#create_access_key-instance_method\r\n\r\nThe doc shows Username in the response Hash, but it should be UserName'
174,'',"Add Changelog\nIt'd be very helpful if the changelogs for each release that being sent to the mailing list could be consolidated into a single changelog file in the repo."
173,'','issue #85, [aws|compute] authorize/revoke security group requests name should be required param\nI added the deprecation pieces to the Real and Mock classes and changed up the models to reflect the changes. '
172,'','AWS Storage Hangs\nI\'m running \'0.5.3\'. The following snippet hangs forever:\r\n\r\n    connection = Fog::Storage.new(\r\n      aws_access_key_id: "****",\r\n      aws_secret_access_key: "****",\r\n      provider: "AWS"\r\n    )\r\n    directory = connection.directories.get("attached")\r\n    directory.files.create(:body => "sample", :key => "sample.txt")\r\n\r\nIf I change out the storage for \'Google\' (and credentials) it works fine. I am able to browse the directory, just not upload with the \'fog\' gem. No warning or errors, just infinite loop.'
171,'',"Unable to serialize AWS Compute/Storage\nI am trying to store my results in a Rails cache but it looks like the COMPUTE object doesn't have a serialization method that Marshal.dump() can work with.\r\n\r\n    >> servers.class\r\n    => Fog::AWS::Compute::Servers\r\n    >> Marshal.dump(servers)\r\n    ArgumentError: wrong number of arguments (1 for 0)\r\n    \t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/fog 0.5.2/lib/fog/core/attributes.rb:116:in `_dump'\r\n\t    from (irb):42:in `dump'\r\n\t    from (irb):42\r\n\t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/railties-3.0.3/lib/rails/commands/console.rb:44:in `start'\r\n\t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/railties-3.0.3/lib/rails/commands/console.rb:8:in `start'\r\n\t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/railties-3.0.3/lib/rails/commands.rb:23:in `<top (required)>'\r\n\t    from script/rails:6:in `require'\r\n\t    from script/rails:6:in `<main>'\r\n    >> \r\n\r\n\r\nSTORAGE gives me a different error:\r\n    >> storage.class\r\n    => Fog::AWS::Storage::Real\r\n    >> Marshal.dump(storage)\r\n    TypeError: no marshal_dump is defined for class OpenSSL::Digest::Digest\r\n\t    from (irb):47:in `dump'\r\n\t    from (irb):47\r\n\t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/railties-3.0.3/lib/rails/commands/console.rb:44:in `start'\r\n\t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/railties-3.0.3/lib/rails/commands/console.rb:8:in `start'\r\n\t    from /Users/rnhurt/.rvm/gems/ruby-1.9.2-p0@rain/gems/railties-3.0.3/lib/rails/commands.rb:23:in `<top (required)>'\r\n\t    from script/rails:6:in `require'\r\n\t    from script/rails:6:in `<main>'\r\n    >> "
170,'','Adds support for disabling/enabling monitors\n'
169,'',"[Local Storage] escaping of paths\nHello,\r\nimagine you have a dev environment in which you want to store all your files locally in (Rails) /public. We outsourced this logic by using Fog::Local::Storage. Now there is some old logic that will create files with names with lots of special chars in it. fog will escape this name by CGI.escape.\r\n\r\nThis will lead to a problem if I want to access this file with the escaped name via URL. The server won't find any matching file. \r\n\r\nI made a fork in which I changed the handling to only take care of forward- and back-slashes. This will not cause any difficulties in such cases.\r\n\r\nMaybe you are interested in this tiny change, I'm not sure if this breaks any of the philosophy or causes compatibility issues (Windows?), but it's just a suggestion (test behaviour did not change):\r\n\r\nhttps://github.com/MarcelHB/fog/commit/e2ce00fbce2566896a6b8c6eb6b88e2e0fb4c11c\r\n\r\nIf you have any comment or better idea, I'd like to hear of them. :-)\r\n\r\nThanks"
168,'','[aws|compute] instance placement ignored\nIt appears that no matter what is used as the placement value in a servers.create call, all of my instances are showing up in us-west-1b. I thought it might have been AWS forcing this but the issue does not exist when booting servers from their web console. I can even place a random string of characters in the placement value and it makes no difference, throws no error.\r\n\r\nSeen in version 0.5.1.'
167,'','Tickets/master/166\nJust a one line change to address Ticket #166.  Action is set to CreateTags in the delete_tags request method.'
166,'','AWS delete_tags uses wrong action?\nLine 29 of lib/fog/compute/requests/aws/delete_tags.rb is set to use the CreateTags action.  Changing it to DeleteTags as according to the API documentation enables the delete_tags request method to actually delete tags.'
165,'',"[voxel|compute] The start of a Voxel.net provider\nThis is a first pass at a Voxel (www.voxel.net) provider.  Currently it supports compute with images, servers and deletion of such.   I've created Mocks although they need work to be more dynamic, and it needs tests.\r\n\r\nI will provide more work on this going forward but I thought it might be a good time to get a pull request in for comment.    I'm a bit new to this process (not specifically a developer by trade) so please let me know where I can help things.\r\n\r\nI was having some trouble with the XML -> Hash parser currently available (seems it doesn't provide all attributes in it's ouput) so I have utilized xml-simple in the mean time.   I expect that the inclusion of this additional gem is the most glaring problem and intend to replace it.   Any suggestions in this area would be helpful.\r\n\r\nVoxel's API is documented @ http://api.voxel.net/docs/ and I am currently a staff member so I can provide test accounts with available capacity as needed.\r\n\r\nThanks!"
164,'',"Aws redirect doesn't call block\nI have forked the project and fixed the issue to avoid corrupted file on a redirect.\r\n\r\nI think this is the right way to do it and it's a very small change.\r\nUnfortunately I couldn't run the spec :(\r\n\r\nTell me what you think about it.\r\n\r\nCheers,\r\nVivien"
163,'','Redirection and blocks\nIf you have a piece of code like this\r\n\r\n    put_object(\'mybucket\', \'myfile\') do |chunk|\r\n        file.write(chunk)\r\n    end\r\n\r\nAnd if you get redirected then you ends with a file having the xml of the first response + the content of your key.\r\n\r\nMight be worthy to check the headers first before executing the block?\r\nOtherwise I have to do \r\n\r\n     if chunk != "<Error> ....\r\n\r\nWhich is not very safe has it\'s a chunk.\r\n\r\nThanks for help.\r\nVivien'
162,'','Issue161\nA fix for Issue161 that I raised.\r\n\r\nhttps://github.com/geemus/fog/issues/issue/161\r\n\r\nCheers, Gavin'
161,'','AWS S3 Multipart Uploads fail signature verification\nWhen using AWS multipart uploads we were getting failures that the signature amazon calculated did not match the signature provided. We traced this down to the order of the headers that were being sent with the request. The partNumber header was coming in the wrong place.'
160,'',"[storage|aws] File#get should not rescue NotFound for no such bucket\nHi,\n\nLook at this\nhttps://github.com/geemus/fog/blob/master/lib/fog/storage/models/aws/files.rb#L50-52\n\nI think get() should not rescue Excon::Errors::NotFound.\nThe rescue has to be done on a higher level. For AWS you can get a NotFound error code for different reasons. NoSuchKey or NoSuchBucket.\nBecause it's been rescued I can't have access to the exception and parse the response body.\n\nFor now I use put_object method to do it\n"
159,'','[aws|sqs] initial support\nJust the basics for SQS, but thought I would solicit feedback early in the process. Hope your food poisoning disappears quickly.'
158,'','Get tests to work under 1.9.2\n'
157,'',"[storage|aws] Query params signed URLs force HTTPS\nhttps:// is currently hardcoded for query param authenticated S3 URLs.  Is it possible to add an option (with the default going either way) for non-https URLs?\n\nWas looking into making this change myself, but I don't want to mess up the usage of authenticated URLs on other providers -- not sure if it would be acceptable to add another arg to get_object_url..."
156,'',"Adding Bluebox DNS api support\nI've added support for Bluebox's DNS API to fog - have a look.\r\n\r\nThanks!"
155,'',"[aws|s3] Private signature method\nIs there a reason that Fog::Storage::AWS::Real#signature is a private method?  It's perfectly reasonable to need a signature for other purposes than a query params authenticated URL and would be nice if this was public.  Calling it with send() now, but would be nice to know that it won't change/break in future releases.\r\n\r\nFor example, we use signatures for proxying/caching protected S3 files with Nginx (completely masks our storage backend)."
154,'',"Reduced redundancy\nJust a quick documentation addition for S3's RRS -- which is already supported by Fog."
153,'','Gogrid updates\nHi,\r\n\r\nI have added gogrid support to list the default and/or stored passwords on a gogrid account. I would like to add this into the main repository, so that I can publish my Chef Knife extensions to work with gogrid. If there is something that needs to be cleaned up or you have any questions please let me know.\r\n\r\nThanks,\r\n\r\nLum'
152,'','adding some more API support for IAM (ListGroupsForUser)\nHey, wanted to add another request method for IAM'
151,'',"adding some iam (aws) signing certificate support\nHey, I was using your gem and came across missing API features in the IAM area. I also want to add a few other pieces, but figured I would start here. Let me know if there's any issues with my coding style, I tried to follow what was already there."
150,'','Provider text in ArgumentError doesnt correspond with class [fixed]\n'
149,'','Bringing gogrid integration to a barely working state\nNow you can:\r\n\r\n * create a server\r\n * list servers\r\n * wait for servers to be ready\r\n * stop servers'
148,'','Fix custom caller_reference not working with AWS DNS to create zone\nSee files changed, pretty trivial change.\r\n\r\nzomg fix it.\r\n\r\n:)'
147,'',"feature request: add AWS SES support: http://aws.amazon.com/ses/\ntodo, add support for aws simple email service ('poligies if this is the wrong place to track these)"
146,'',"Fixing a typo in the require for go_grid support\nShould be require 'fog/compute/models/go_grid/image'"
145,'',"Initial work on ses\nStill need to implement SendEmail and SendRawEmail, I don't quite understand how to pass in the multilevel nested hashes. "
144,'','S3: SignatureDoesNotMatch on European buckets\nHi,\r\n\r\nI\'m running into an error with fog. As soon as I try to get a signed url to one of the objects in an european bucket, the url seems to be incorrectly signed. After some investigation I\'ve found out that the signature isn\'t the problem but the url. The urls I get are in the form of "https://s3-eu-west-1.amazonaws.com/{bucket_name}/{object}" with the signature etc attached. If I change the url to the virtual hosted-style "https://{bucket_name}.s3.amazonaws.com/{object}" the signature works fine.\r\n\r\nBest regards,\r\n\r\ncroaker'
143,'',"Use Net::SSH's KeyManager to detect ssh-agent\nThe presence of `ENV['SSH_AUTH_SOCK']` is necessary but not sufficient for `ssh-agent` support (e.g. no agent may be listening on the socket; the listening agent may be SSH2-compatible and hence [currently unsupported](https://github.com/net-ssh/net-ssh/blob/v2.0.0/lib/net/ssh/authentication/agent.rb#L83-84)) so it is better to delegate this decision to `Net::SSH`.\r\n\r\nThis is [davidx's work](https://github.com/davidx/fog/compare/af6ad7f...9aa94ce); I just rebased it."
142,'','[aws|elb] needs tests\nAt the time it was written the understanding was that they would be coming shortly after the implementation and I think we all forgot about it.  ALAS!  This should be remedied immediately if not sooner.'
141,'',"AWS Elastic Load Balancer\nI get the following when trying to create load balancers:\r\n\r\nNoMethodError: undefined method `indexed_param' for Fog::AWS::ELB:Class\r\n\tfrom /Users/jkmiller/.rvm/gems/ruby-1.9.2-p136/gems/fog-0.4.1/lib/fog/aws/requests/elb/create_load_balancer.rb:25:in `create_load_balancer'\r\n"
140,'',"ssh-agent authentication support for Fog::SSH\nAs per geemus/fog#139, `Fog::SSH` should support `ssh-agent` authentication.\r\n\r\n`Net::SSH` 2.x does this out of the box: [`Net::SSH#start` uses `Authentication::Session`](https://github.com/net-ssh/net-ssh/blob/v2.0.0/lib/net/ssh.rb#L183), which [uses `Authentication::KeyManager`](https://github.com/net-ssh/net-ssh/blob/v2.0.0/lib/net/ssh/authentication/session.rb#L55), which [transparently uses identities from `ssh-agent`](https://github.com/net-ssh/net-ssh/blob/v2.0.0/lib/net/ssh/authentication/key_manager.rb#L20-23).\r\n\r\nAll Fog has to do is make the authentication credentials optional when `ENV['SSH_AUTH_SOCK']` is set."
139,'',"Fog::SSH should support ssh-agent authentication\n`Fog::SSH` (and therefore `Fog::AWS::Compute::Server#ssh` etc) shouldn't have to require `:key_data`, `:keys` or `:password`, because `Net::SSH` will quite happily collect this data from `ssh-agent` if it's running."
138,'','Allow additional connection options\nAdds an additional optional param when creating a Fog::Connection object which can pass on other connection params to the underlying Excon object.'
137,'','[aws | compute] Describe images mock\nPatch adds (admittedly untested) mock for describe_images request.'
136,'',"New URLs\nHi Wesley,\r\n\r\nWe've updated our URL this weekend.  Attached is the commit containing the updates.\r\n\r\nThanks\r\n\r\n- Jesse"
135,'',"Making further progress on specs\nI made some progress towards getting the specs to run for me:\r\n\r\n* Mock some credentials with dummy values\r\n* Fix some broken paths.\r\n\r\nAfter this, I still get yet another error from a broken require:\r\n\r\n    $ rake\r\n    (in /home/phiggins/projects/phiggins-fog)\r\n    export FOG_MOCK=false && bundle exec shindont examples\r\n      Skipping tests for aws due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for bluebox due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for brightbox due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for gogrid due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for google due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for linode due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for local due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for newservers due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for rackspace due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for slicehost due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for terremark due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for aws due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for bluebox due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for brightbox due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for gogrid due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for google due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for linode due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for local due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for newservers due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for rackspace due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for slicehost due to lacking credentials (add some to '~/.fog' to run them)\r\n      Skipping tests for terremark due to lacking credentials (add some to '~/.fog' to run them)\r\n      \r\n      storage tests (storage)   \r\n      dns tests (dns) /home/phiggins/projects/phiggins-fog/lib/fog/core/service.rb:78:in `require': no such file to load -- fog/dns/models/zerigo/count_hosts (LoadError)\r\n            from /home/phiggins/projects/phiggins-fog/lib/fog/core/service.rb:78:in `block in setup_requirements'\r\n            from /home/phiggins/projects/phiggins-fog/lib/fog/core/service.rb:77:in `each'\r\n            from /home/phiggins/projects/phiggins-fog/lib/fog/core/service.rb:77:in `setup_requirements'\r\n            from /home/phiggins/projects/phiggins-fog/lib/fog/core/service.rb:47:in `new'\r\n            from /home/phiggins/projects/phiggins-fog/lib/fog/dns.rb:18:in `new'\r\n            from /home/phiggins/projects/phiggins-fog/examples/dns_tests.rb:18:in `block (3 levels) in <top (required)>'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:77:in `instance_eval'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:77:in `block in tests'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/formatador-0.0.16/lib/formatador.rb:92:in `indent'\r\n            from (eval):3:in `indent'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:77:in `tests'\r\n            from /home/phiggins/projects/phiggins-fog/examples/dns_tests.rb:15:in `block (2 levels) in <top (required)>'\r\n            from /home/phiggins/projects/phiggins-fog/examples/dns_tests.rb:10:in `each'\r\n            from /home/phiggins/projects/phiggins-fog/examples/dns_tests.rb:10:in `block in <top (required)>'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:77:in `instance_eval'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:77:in `block in tests'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/formatador-0.0.16/lib/formatador.rb:92:in `indent'\r\n            from (eval):3:in `indent'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:77:in `tests'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:37:in `initialize'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:13:in `new'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo.rb:13:in `tests'\r\n            from /home/phiggins/projects/phiggins-fog/examples/dns_tests.rb:7:in `<top (required)>'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo/bin.rb:53:in `load'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo/bin.rb:53:in `block (2 levels) in run_in_thread'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo/bin.rb:50:in `each'\r\n            from /home/phiggins/.rvm/gems/ruby-1.9.2-p136/gems/shindo-0.1.12/lib/shindo/bin.rb:50:in `block in run_in_thread'\r\n    rake aborted!\r\n    Command failed with status (1): [export FOG_MOCK=false && bundle exec shind...]\r\n    /home/phiggins/projects/phiggins-fog/Rakefile:49:in `block in <top (required)>'\r\n    (See full trace by running task with --trace)\r\n    \r\n\r\n\r\n"
134,'','add OpenStack support\nAdd support for OpenStack compute (Nova) and storage (Swift).\r\n\r\n* Nova has an EC2 compatible API\r\n* Swift has a Rack Files compatible API\r\n\r\nWe really need to just extend the existing Fog::AWS::Compute and Fog::Rackspace::Files Fog libraries and allow the ability to pass the server endpoint in.'
133,'','Fix paths\nFixed some paths that were keeping the test/spec rake task from running. Then while I was in there I fixed some more just for fun.'
132,'','[rackspace] update to latest api 2011/01/04\n'
131,'','add interogative for what is mocked\nnot sure exactly how this would work, but it would make testing easier (instead of having the if_mocked stuff strewn everywhere).  Basically you could check to see if a provider/service is mocked (at all) and potentially have more granular is_method_mocked(:whatever) or something to that effect.  Seems like it could consolidate a lot of stuff that lives in too many places currently.  Bug geemus if you wanna tackle and he can answers questions and do a better brain dump.'
130,'','Excon::Errors::SocketError: SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed\nHi Geemus,\n\nFog broke on windows after fog(0.3.30) and excon(0.2.8). it fails with an SSL error. I\'d be glad to troubleshooting but i\'m not sure how to do it.\n<pre><code>\nPS C:\\chef\\log> ruby -v\nruby 1.8.7 (2010-01-10 patchlevel 249) [i386-mingw32]\nPS C:\\chef\\var> gem install fog --no-ri --no-rdoc\nSuccessfully installed excon-0.3.6\nSuccessfully installed fog-0.3.34\n2 gems installed\n\nPS C:\\chef\\var> fog\n  Welcome to fog interactive!\n  :default provides AWS\n>> s3=Fog::AWS::Storage.new\n#<Fog::AWS::Storage::Real:0x33c0870 @connection=#<Fog::Connection:0x36a7568 @persistent=true, @excon=#<Excon::Connection\n:0x36a7508 @connection={:scheme=>"https", :headers=>{}, :host=>"s3.amazonaws.com", :query=>nil, :port=>443, :path=>"/"}, @socket_key="s3.amazonaws.com:443">>, @aws_secret_access_key="NON_SHOWED", @endpoint=nil,\n @port=443, @path="/", @scheme="https", @aws_access_key_id="NON_SHOWED", @host="s3.amazonaws.com", @hmac=#<Fog\n::HMAC:0x36a76e8 @digest=#<OpenSSL::Digest::Digest: da39a3ee5e6b4b0d3255bfef95601890afd80709>, @key="\nNON_SHOWED", @signer=#<Proc:0x02d38058@C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/lib/fog/core/hmac.rb:22>>>\n>> s3.directories.last.files\nExcon::Errors::SocketError: SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed\n        from C:/Ruby/lib/ruby/gems/1.8/gems/excon-0.3.6/lib/excon/connection.rb:171:in `connect\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/excon-0.3.6/lib/excon/connection.rb:171:in `connect\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/excon-0.3.6/lib/excon/connection.rb:188:in `socket\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/excon-0.3.6/lib/excon/connection.rb:101:in `request\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/lib/fog/core/connection.rb:20:in `request\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/lib/fog/aws/storage.rb:249:in `request\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/lib/fog/aws/requests/storage/get_service.rb:32:in `get_service\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/lib/fog/aws/models/storage/directories.rb:13:in `all\'\n        from C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/lib/fog/core/collection.rb:122:in `lazy_load\'\n        from (eval):3:in `last\'\n        from (irb):2\n        from C:/Ruby/lib/ruby/gems/1.8/gems/fog-0.3.34/bin/fog:33\n        from C:/Ruby/bin/fog:19:in `load\'\n        from C:/Ruby/bin/fog:19\n</code></pre>\nThanks,\n\nRodrigo Estebanez'
129,'',"[aws|storage] files model should provide easier pagination\nSomething like #next_page and #previous_page (I'm not that keen on this as the actual api, but you get the idea).  In some way/shape/form it should be able to check is_truncated to see if there are other pages and then set the marker to the last key from the current set or something.  You may want to discuss your solution with geemus to make sure you are on the same page before getting too far along on this."
128,'','Fog in script\nFog via scripts, Fog.providers doesn\'t work, hence no access to AWS class like there is in the console (just running plain "fog" on the CLI.'
127,'','Add support for idempotently creating instances\nSometimes calls to AWS fail. It would be really handy if fog could try 2 or 3 times to create an instance using the new idempotent RunInstances API.\r\n\r\nhttp://aws.typepad.com/aws/2010/09/new-amazon-ec2-feature-idempotent-instance-creation.html'
126,'','Added better security group documentation\nThis is purely a documentation patch that adds better docs for authorizing/revoking ports/groups for security groups for AWS.'
125,'','Bug with ruby 1.8.6\nRan into an interesting bug tonight with 1.8.6 attempting to do the following:\n\n         s3.directories.get(\'my-bucket\')\n\nwhere my_bucket looks like this:\n\n        Fog::AWS::Storage::Directory\n          key"my-bucket",\n          creation_dateThu Mar 11 16:55:42 UTC 2010\n\nHere\'s the stack trace:\n\n        NoMethodError: private method `gsub!\' called for Tue Apr 20 23:28:18 UTC 2010:Time\n\tfrom /home/jvincent/.rvm/rubies/ruby-1.8.6-p399/lib/ruby/1.8/date/format.rb:965:in `_parse\'\n\tfrom /home/jvincent/.rvm/rubies/ruby-1.8.6-p399/lib/ruby/1.8/time.rb:240:in `parse\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/attributes.rb:58:in `last_modified=\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/attributes.rb:136:in `send\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/attributes.rb:136:in `merge_attributes\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/attributes.rb:133:in `each\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/attributes.rb:133:in `merge_attributes\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/model.rb:10:in `initialize\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/collection.rb:97:in `new\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/collection.rb:97:in `new\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/aws/models/storage/files.rb:72:in `new\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/collection.rb:87:in `load\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/collection.rb:86:in `each\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/core/collection.rb:86:in `load\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/lib/fog/aws/models/storage/directories.rb:33:in `get\'\n\tfrom (irb):4\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/gems/fog-0.3.34/bin/fog:33\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/bin/fog:19:in `load\'\n\tfrom /home/jvincent/.rvm/gems/ruby-1.8.6-p399@fog/bin/fog:19\n\nI did some research and I think there was an issue with symbols and to_s needing to be called in 1.8.6 but I can\'t be sure. I\'m doing some more research now.'
124,'',"Load balancer support\nHi Wes,\r\n\r\nthis pull request is to add support for our load balancers api. It's been waiting on some server side work that got completed this week.  Paul is on holiday but said everything should be really to send to you - hope all is well with it.\r\n\r\nThanks!\r\n\r\nJohn."
123,'','[slicehost] should support update methods\ncurrently only supports create, destroy, get and list'
122,'','excon > 0.3.3 breaks some ec2 call signatures\nJust did an update to latest fog and my AWS credentials stopped working. Validated they were still good and remembered that there was a similar issue previously with named-parameters. Dropped back to 0.0.18 and things work again.'
121,'',"Errno::ENOENT: No such file or directory - /Users/kevin/.fog\nRunning under Mac OS X 10.6.5 I'm getting:\r\n\r\n    Fog::Storage.new(:provider => 'AWS') # Errno::ENOENT: No such file or directory - /Users/kevin/.fog\r\n    Fog::Storage.new(:provider => 'Google') # Errno::ENOENT: No such file or directory - /Users/kevin/.fog\r\n\r\nIt doesn't make a difference if the credentials are specified or not."
120,'','S3 Storage \':key\' Does Not Allow Leading \'/\'\nThe following will not work:\r\n\r\n     directory.files.create(:key => "/avatar.png", :body => File.open(\'/avatar.png\'))\r\n\r\nWhile this works just fine:\r\n\r\n    directory.files.create(:key => "avatar.png", :body => File.open(\'/avatar.png\'))'
119,'','IAM enhancements\nThis implements the IAM get_user call. Probably need to push this into a model at some point?'
118,'','Images parsing fix\nHey Wes,\r\n\r\nThis branch contains the fixes to let the decribe_images parser work with tags.  I also added in an attribute to the model for "name", since AWS supports the attribute.\r\n\r\nThanks!\r\nChris'
117,'','More modern gemspec (see issue #116)\nAs per mitchellh suggestion and to fix the problem of (a) not being able to build against current source (#116) and (b) no access to Route 53 service (#115) please find a pull request for a new gemspec file which includes all files automatically.'
116,'','Unable to build gem from source\n    ~> git clone https://github.com/geemus/fog.git\n    ~> cd fog\n    ~/fog> gem build fog.gemspec\n    ERROR:  While executing gem ... (Gem::InvalidSpecificationException)\n        ["spec/compact_progress_bar_formatter.rb", "spec/core/attributes_spec.rb", "spec/lorem.txt"] are not files\n\nIf I create these folders & files I can build the Gem but then I get:\n\n    ruby-1.9.2-p0 > require \'fog\'\n    LoadError: no such file to load -- fog/core/mock\n    \tfrom <internal:lib/rubygems/custom_require>:29:in `require\'\n    \tfrom <internal:lib/rubygems/custom_require>:29:in `require\'\n    \tfrom /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.32/lib/fog/core.rb:26:in `<top (required)>\'\n    \tfrom <internal:lib/rubygems/custom_require>:29:in `require\'\n    \tfrom <internal:lib/rubygems/custom_require>:29:in `require\'\n    \tfrom /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.32/lib/fog.rb:1:in `<top (required)>\'\n    \tfrom <internal:lib/rubygems/custom_require>:33:in `require\'\n    \tfrom <internal:lib/rubygems/custom_require>:33:in `rescue in require\'\n    \tfrom <internal:lib/rubygems/custom_require>:29:in `require\'\n    \tfrom (irb):1\n    \tfrom /Users/jdoe/.rvm/rubies/ruby-1.9.2-p0/bin/irb:17:in `<main>\'\n\nWhen I comment out line 26 in lib/fog/core.rb I get a second error, basically the same warning but for \'fog/core/wait_for\'\n\nSorry if I\'m filing bugs on an incomplete check-in, I got the impression from some of the AWS blogs and the examples that the gem usable for Route53.'
115,'','"Unsupported AWS service: dns" when attempting to use AWS Route53 functionality or examples\nWhen running the [example code](https://github.com/geemus/fog/blob/master/examples/dns_methods.rb) for a Route53 zone setup I\'m getting:\n\n    ArgumentError: Unsupported AWS service: dns\n\t  from /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.31/lib/fog/aws/bin.rb:19:in `class_for\'\n\t  from /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.31/lib/fog/aws/bin.rb:25:in `block in []\'\n\t  from /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.31/lib/fog/aws/bin.rb:45:in `yield\'\n\t  from /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.31/lib/fog/aws/bin.rb:45:in `default\'\n\t  from /Users/jdoe/.rvm/gems/ruby-1.9.2-p0/gems/fog-0.3.31/lib/fog/aws/bin.rb:45:in `[]\'\n\t  from (irb):3\n\t  from /Users/jdoe/.rvm/rubies/ruby-1.9.2-p0/bin/irb:17:in `<main>\'\n\nI\'ve checked my keys are up to date in `~/.fog` (and also in irb by including the fog libraries and looking at `Fog::credentials[:aws_access_key_id]`). I\'ve signed up for the Route53 service on Amazon and can interrogate/make changes via the [ruby_route_53](https://github.com/pcorliss/ruby_route_53) gem and the [DNS30](http://aws.typepad.com/aws/2010/12/dns30-a-visual-tool-for-amazon-route-53.html) web service.\n\nAny pointers to the dumb thing I\'ve forgotten to do?'
114,'',"AWS Route 53 suport & test scripts for all 4 DNS providers\n-at this point, all 4 DNS providers are fully supported (there are a few caveats like we don't support Zerigo templates)\r\n-using Fog credentials now rather than hard-coded credentials\r\n-there are tests for each provider. each has 10-15 cases each\r\n"
113,'','Named parameters gem adds "key_for" method on all classes\nThis breaks with dm-sweatshop. '
112,'','Zerigo dns\nfull support for Zerigo DNS service.    Includes support for all API methods except those for creating templates.  There is a complete sample on how to manage zones and records in examples/dns_methods.rb\r\n'
111,'','complete support for Linode DNS functions\nthis branch is based on 0.3.31 and includes full support for the Linode DNS functions.  There is also a very good example of how to use the functions in the example/dns_methods.rb file.  This file also has good examples on how to use the Slicehost DNS functions as well.\r\n\r\nnote, no mocks or tests.  Would like to add this but need to talk to geemus first.'
110,'','excon >= 0.3.0 breaks Fog::AWS::Storage (does not match the signature you provided)\n\r\nAfter upgrading fog to the latest version Fog::AWS::Storage broke. I spent quite a bit of time troubleshooting and i found that the real problem was with a newer version of excon. Using excon 0.2.8 works fine. Here is a way to reproduce the problem:\r\n\r\n<code>\r\ns3=Fog::AWS::Storage.new\r\ns3.directories.last.files\r\nExcon::Errors::Forbidden: Expected([307, 200]) <=> Actual(403 Forbidden)\r\n  request => {:path=>"/", :expects=>[307, 200], :method=>"GET", :query=>{}, :host=>"rave-conf-dev.s3.amazonaws.com", :scheme=>"https", :socket_key=>"s3.amazonaws.com:443", :idempotent=>true, :headers=>{"Authorization"=>"AWS AKIAJ4PJTRF5ZOLNQ3QA:fnSRxMZ4SV6/saLNZTbC+KbP1MI=", "Date"=>"Fri, 10 Dec 2010 19:55:09 +0000", "Content-Length"=>0, "Host"=>"s3.amazonaws.com"}, :port=>443}\r\n  response => #<Excon::Response:0x10259fd00 @headers={"x-amz-id-2"=>"1aBybDpe9jB6dqhtYLvfZPouAE67d6BepM/wr7HZvDbNFDxoyZhxqOsKnJwiBUup", "Transfer-Encoding"=>"chunked", "Date"=>"Fri, 10 Dec 2010 19:55:09 GMT", "Content-Type"=>"application/xml", "x-amz-request-id"=>"DAF85C3241E0B82E", "Server"=>"AmazonS3"}, @status=403, @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>SignatureDoesNotMatch</Code><Message>The request signature we calculated does not match the signature you provided. Check your key and signing method.</Message><StringToSignBytes>47 45 54 0a 0a 0a 46 72 69 2c 20 31 30 20 44 65 63 20 32 30 31 30 20 31 39 3a 35 35 3a 30 39 20 2b 30 30 30 30 0a 2f</StringToSignBytes><RequestId>DAF85C3241E0B82E</RequestId><HostId>1aBybDpe9jB6dqhtYLvfZPouAE67d6BepM/wr7HZvDbNFDxoyZhxqOsKnJwiBUup</HostId><SignatureProvided>fnSRxMZ4SV6/saLNZTbC+KbP1MI=</SignatureProvided><StringToSign>GET\\n\\n\\nFri, 10 Dec 2010 19:55:09 +0000\\n/</StringToSign><AWSAccessKeyId>AKIAJ4PJTRF5ZOLNQ3QA</AWSAccessKeyId></Error>">\r\n\tfrom /Library/Ruby/Gems/1.8/gems/excon-0.3.2/lib/excon/connection.rb:124:in `request\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/core/connection.rb:20:in `request\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/aws/storage.rb:247:in `request\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/aws/requests/storage/get_bucket.rb:55:in `get_bucket\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/aws/models/storage/directories.rb:24:in `get\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/aws/models/storage/files.rb:30:in `all\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/core/collection.rb:122:in `lazy_load\'\r\n\tfrom (eval):3:in `empty?\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/core/collection.rb:70:in `inspect\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/formatador-0.0.16/lib/formatador.rb:92:in `indent\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/lib/fog/core/collection.rb:63:in `inspect\'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:302:in `output_value\'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:151:in `eval_input\'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:263:in `signal_status\'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:147:in `eval_input\'\r\n\tfrom /System/Library/Frameworks/Ruby.framework/Versions/1.8/usr/lib/ruby/1.8/irb.rb:146:in `eval_input\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/bin/fog:46\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/bin/fog:46:in `catch\'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.30/bin/fog:46\r\n\tfrom /usr/bin/fog:19:in `load\'\r\n</code>\r\n'
109,'','added support for all Slicehost DNS methods\nall the DNS methods are supported\r\nmethods with optional parameters, allow these\r\nreasonable comments for all method headers\r\nno mocks or test cases - need to learn more about these'
108,'','Had a field day with credentials.rb\nAlso, I added a @todo, noting that ArgumentError should perhaps see less use. A more correct choice is often LoadError or RuntimeError.  In fact, just doing:\r\n\r\n        raise "There\'s an Error In This Message!"\r\n\r\nDefaults to RuntimeError\r\n'
107,'',"credentials.rb\nHi Wesley,\r\n\r\nWe've been working with chef / knife today and discovered it looks like credentials.rb is missing from the core library include.  Do let me know if that's intentional, but otherwise, it looks like this should be added back.\r\n\r\nThanks!\r\n\r\n- Jesse"
106,'','Brightbox request tests\nManaged to write up Shindo tests to cover the requests against the Brightbox API.'
105,'','Brightbox request tests\nManaged to write up Shindo tests to cover the requests against the Brightbox API.'
104,'','use latest named-parameters for bugfix\nThere was a bug in named-parameters. Fixed now.\r\nSee [comments](https://github.com/geemus/fog/pull/103#issuecomment-595925)\r\n'
103,'',"Reforked and chunked into manageable pieces...\nHere's the same pull request. I reforked to have a clean start and applied the same changes as before.\r\nSimilar changes are grouped under a single commit (or theme) to make it easier to visualize the changes."
102,'',"aws thing went away when using wait_for after creation\nEventual consistency means that this sometimes occurs, see aws/models/servers/bootstrap for an example of how wait_for could 'smooth' this to generally avoid the issue."
101,'','Problem with tags and snapshots\nSee this gist: https://gist.github.com/730720\r\n\r\nI might be creating tags improperly but the same thing happens when I create a random K/V tag on a snapshot in AWS management console.\r\n\r\nOnce I remove the tag, I can query that snapshot again.'
100,'',"Made it so that Real classes inherit the requires/recognizes requirements.\nThis makes it so that Services cannot be instantiated with incorrect parameters.\r\n\r\nAdditional changes include:\r\n- Checking service requirements no longer creates an instance of that service (faster).\r\n- Fog::Rackspace::authenticate relies on caller to pass correct options (it's implied since the services that use this method have their \r\n- Warning printed when requirements check receives an incorrect service key.\r\n"
99,'',"3 bug fixes\nHello, Wesley.\r\n\r\nHere are 3 small bug fixes:\r\n\r\n  another attribute that got missed the in the refactoring from ivars to getters.\r\n  a place where we're expecting an object, but selecting a one member array.\r\n  a bit where Fog::AWS::Compute rejects public and private key attributes.  \r\n\r\n(Maybe I'm doing something wrong on this last one, but the way I'm using it, this makes it impossible to ssh in to the box.)\r\n\r\nThanks!\r\nBrian"
98,'',"'shindo tests' fails to run (on ruby 1.9.2p0)\n$ ruby --version\r\nruby 1.9.2p0 (2010-08-18 revision 29036) [x86_64-darwin10.5.0]\r\n\r\n$  FOG_MOCK=true bundle exec shindo tests\r\n/Users/jgalang/Code/opensource/fog.master/tests/helper.rb:15:in `require': no such file to load -- tests/helpers/collection_tests (LoadError)\r\n        from /Users/jgalang/Code/opensource/fog.master/tests/helper.rb:15:in `<top (required)>'\r\n        from /Users/jgalang/.rvm/gems/ruby-1.9.2-p0/gems/shindo-0.1.10/lib/shindo/bin.rb:47:in `load'\r\n        from /Users/jgalang/.rvm/gems/ruby-1.9.2-p0/gems/shindo-0.1.10/lib/shindo/bin.rb:47:in `block (2 levels) in run_in_thread'\r\n        from /Users/jgalang/.rvm/gems/ruby-1.9.2-p0/gems/shindo-0.1.10/lib/shindo/bin.rb:45:in `each'\r\n        from /Users/jgalang/.rvm/gems/ruby-1.9.2-p0/gems/shindo-0.1.10/lib/shindo/bin.rb:45:in `block in run_in_thread'\r\n"
97,'',"Start of a Cloudkick provider\nWhat the subject says.\r\n\r\nI'll probably work on this tomorrow at SHDH a bit more."
96,'',"squashed commits (starting from 76624c4, ending with 1717638)\nBasically everything starting from the Nov 21 pull request, to Nov 29. I apologize for the large number of combined commits.\r\n\r\nAnyway, invoking `bin/fog` still shows:\r\n\r\n    $ ./bin/fog \r\n      Welcome to fog interactive!\r\n      :default credentials provide AWS, Bluebox, Brightbox, GoGrid, Google, Local, NewServers and Slicehost\r\n      You have access to the following Vcloud services: :ecloud.\r\n\r\nAnd the tests returns the same results as before (same amount of passed, failures, and pendings); so maybe everything's covered this time around.\r\n\r\n"
95,'',"Found a tiny bug in creating CloudFront distros\nHi Wesley,\r\n\r\nHere's a patch for a typo in put_distribution_config.rb.\r\n\r\nThanks,\r\nJames"
94,'','Nokogiri Gem Version\nIs there a reason for the specific Nokogiri version (1.4.3.1) in the .gemspec?\r\n\r\nWe\'re getting a conflict with Webrat and Capybara (they require 1.4.4).\r\n\r\nBundler could not find compatible versions for gem "nokogiri":\r\n  In Gemfile:\r\n    fog (= 0.3.25) depends on\r\n      nokogiri (~> 1.4.3.1)\r\n\r\n    capybara depends on\r\n      nokogiri (1.4.4)\r\n'
93,'','[aws | compute] more documentation updates\nWes,\r\n\r\nHere are more doc updates to AWS compute.\r\n\r\nthanks\r\nMike Riley'
92,'',"Rackspace resize\nHi,\r\n\r\nI have implemented resize / confirm / revert actions for rackspace. They are only tested with mocks right now as I think I'm hitting a quota right now. Will test live soon.\r\n\r\n--Gilles"
91,'','Fix for detaching EBS volumes.\nHello, Wesley.\r\n\r\nFog was throwing an error when I tried to detach EBS volumes, so I fixed it.\r\n\r\nThanks for writing Fog!\r\n\r\nBrian'
90,'','get undefined method address\nFirst create an IP address:\r\n\r\n>> AWS.addresses.create\r\n  <Fog::AWS::Compute::Address\r\n    public_ip="957.8.1.2",\r\n    server_id=nil\r\n  >\r\n\r\nthen try to destroy it:\r\n\r\n>> AWS[:compute].address.destroy("957.8.1.2")\r\nNoMethodError: undefined method `address\' for #<Fog::AWS::Compute::Mock:0x101d5f640>\r\n\tfrom (irb):5\r\n\tfrom /Library/Ruby/Gems/1.8/gems/fog-0.3.21/bin/fog:35\r\n\tfrom /usr/bin/fog:19:in `load\'\r\n\tfrom /usr/bin/fog:19\r\n\r\nDoesn\'t seem to work for some reason.'
89,'','commented out unnecessary code (forgot to comment it out before i did the previous pull request)\n'
88,'','Uncommented section to filter out unwanted keys from options arg...\n'
87,'',"updates\nWes,\r\n\r\nUpdated flavors, volumes and key_pairs.   Comments and examples added.  If there is anything you don't care for, let me know so I can adjust and then send a new pull request.\r\n\r\nMike Riley"
86,'',"remove reset_data and make Fog.mock! reset all mocked data\nreset_data doesn't seem to work properly in most cases anyway, so it is probably better to just have a central consolidated way to make this all happen.  Not exactly sure what the best implementation details will be though."
85,'','[aws|compute] authorize/revoke security group requests name should be required param\nIt currently parses it out of a options hash, but since it is actually required it ought to have it as a first param (and options hash as an optional second param).  This is more consistent with other methods throughout fog.  This should be done in a backwards compatible way with deprecation warnings for the time being.'
84,'','specs/tests for which you have no credentials should be loudly skipped\nThis makes it more accessible for new users, by simply having loud pending messages rather than outright failure.'
83,'','model create/destroy should unload parent collection\nThis will cause the parent collection to be re-lazy loaded if it is referenced again and avoids the problem of stale collection data (which is often confusing for users). Not sure how to best do this without a good deal of duplication or some alias method stuff (gross!).'
82,'','This adds the recognizes clause/declaration to appropriate classes.\nThis adds the recognizes clause/declaration to appropriate classes.\r\nAlso: encapsulated/delegated implementation of requires, recognizes to [NamedParameters](https://github.com/jurisgalang/named-parameters) gem.\r\n'
81,'',"Bundler take-two\nMain points of interest:\n\n* gem install and bundle install can be made to give the same result (albeit via a workaround)\n* fog-dev gem is a possibility using same approach as runtime gem install\n* Build and release tasks build on Bundler's - hope these help?\n* Specs and features: \n\n\n       $ cucumber /usr/src/fog/features/tasks/release.feature -r features\n       5 scenarios (5 passed)\n       40 steps (40 passed)\n\n       $ cucumber /usr/src/fog/features/bdd/bdd.feature -r features\n       1 scenario (1 passed)\n       7 steps (7 passed)\n\n      $ cucumber /usr/src/fog/features/tasks/build.feature -r features\n      9 scenarios (9 passed)\n      57 steps (57 passed)\n\n      $ cucumber /usr/src/fog/features/tasks/version_bump.feature -r features\n      4 scenarios (4 pending)\n      28 steps (8 skipped, 4 pending, 16 passed)\n\n      $ rspec /usr/src/fog/spec/lib/fog/core/version_helper_spec.rb\n      Finished in 0.08027 seconds\n      35 examples, 0 failures\n"
80,'',"Added ganeti support\nHi -\r\n\r\nI added initial Ganeti v2 support.  I implemented it similar to Linode (ie without Models).\r\nIf interested feel free to incorporate it.  Since there are no models, I do not have tests.\r\n\r\nHowever, I wouldn't mind testing what the URLs would look like in each compute request,\r\nsince the API really comes down to the types of URLs you're generating (in my case).\r\n\r\nAnyways, I have tested the cases I need manually, and all seems to work correctly.\r\n\r\nJohn"
79,'','adding AWS::Storage put_object_acl request (similar to put_bucket_acl)\nBasically a modified version of put_bucket_acl - to handle versions and add the object_name to the URL.\n\nI saw that you are doing arg-checks (bucket/object not-nil) for get*_acl requests but not for put ones - probably cause S3 will raise a similar exception - so following the same style. We can be a bit more dry about creating the "data" part of the put_*_acl requests - where is the right place to put this code (take the acl hash and create the ACL-elements that AWS expects)?\n\nAbout tests: none of the ACL requests have any tests. If we set up the @data[:acl] correctly in the put_*_acl do you remember if the rest of the code already respects @data[:acl]? Also a bit tricly will be the use the email addresses in put_*_acl - how AWS translates that to a canonical user. For mocks setting up fake data will be enough but for real tests we might have to work more.\n\n shindo:\n   problems with require (fixed - see if you want to accept that)\n   performance problems - *something* in the storage/buckets tests grabs all the resources and makes my macbook crawl and howl :( (didn\'t dig in)\n\nI suppose we should have (get-acl-after-put-acl, permission-denied-after-put-acl tests for both buckets and objects) - please let me know your thoughts.\n\nI have tested this code manually through the cli for now.\n'
78,'','tiny fix.\nAdded google_storage_* keys to generated sample .fog file content - will take care of 2 failing tests when running with FOG_MOCK=true.'
77,'',"[compute|aws] monitoring status doesn't update\nWhen trying to change the monitoring status of an instance.  It doesn't update after setting the new value:\n\n    AWS.servers[1].monitoring\n\nfalse\n\n    AWS.servers[1].monitoring = true\n\ntrue\n\n    AWS.servers[1].monitoring\n\nfalse\n\n"
76,'','Attribute memoization introduced in v0.3.21 changes behaviour of "squashed" attributes\nJust noticed an issue was introduced in commit e25afbd2847ee0fee5acba6925f42c37889e0fa2\r\n\r\nWe use the squash option on attributes to get a single value from an attribute that is a hash in the JSON response. Defined as (for example):\r\n\r\n    attribute :zone_id, :aliases => "zone", :squash => "id"\r\n\r\nFollowing the memoization change squashed attributes are no longer returning the expected value but the entire hash before the squash.\r\n\r\nThe change was introduced in v0.3.21.\r\n\r\nUsing Fog version 0.3.20 gives this:\r\n\r\n    @server.attributes[:zone_id].inspect # => "zon-13eu1"\r\n\r\nUsing Fog version 0.3.21 gives:\r\n\r\n    @server.attributes[:zone_id].inspect # => {"handle"=>"gb1-a", "resource_type"=>"zone", "url"=>"https://api.gb1.brightbox.com/1.0/zones/zon-13eu1", "id"=>"zon-13eu1"}\r\n\r\nVery simple script against Brightbox provider to demonstrate is https://gist.github.com/706863\r\n'
75,'',"Server SSL certificates are not verified\nFog doesn't verify server SSL certificates, it will happy accept invalid certificates with no complaint. This makes it trivially easy to mount a man-in-the-middle attack against it to steal authentication credentials.\r\n\r\nExcon is the part at fault really, in Excon::Connection.connect it explicitly uses OpenSSL::SSL::VERIFY_NONE.\r\n\r\nI'd argue that the default should be to verify certificates, rejecting invalid ones, and have an option to disable verification it if required.\r\n\r\n"
74,'','[aws|s3] put_object_acl request got overlooked\nshould be pretty similar in functionality/parsing to put_bucket_acl, just got overlooked somehow'
73,'','AWS::ELB Requests\nSome of the request classes were passing a 3rd argument (1) to the AWS.indexed_param method.'
72,'','Fix for issue #67: handle arrays in SimpleDB mock\n[aws|simpledb] put_attributes: fix to handle array values for attributes.\r\n Fixes Issue #67: https://github.com/geemus/fog/issues/#issue/67'
71,'','S3 Signed URL errors for files containing "+" character\nWhen working with Amazon S3 Storage, the signed url that is returned for objects with a "+" character in the key name is incorrect. Visiting the URL results in an InvalidSignature error.\r\n\r\nFilename that works:\r\n\r\n* foo-bar.ext\r\n\r\nFilename that fails:\r\n\r\n* foo+bar.ext\r\n\r\nI will put together a gist a little later which demonstrates in detail, but it should be pretty easy duplicate. I will update this issue with a comment when I have the gist available.\r\n\r\nCurrent environment is:\r\n\r\n* REE 1.8.7 2010.02\r\n* fog 0.3.17 \r\n\r\nThanks.'
70,'',"Fog install: bundler vs gem - which?\nI've integrated bundler a little more.  From that experience and reading around it seems bundler vs gem roles is in a state of flux, and I think you can't ensure they will always leave the installation in the same state.\n\nAt some point projects will have to choose how they say their gem's dependencies are managed, bundler vs gem. Seeing what bundler brings more than gem I'm inclined to think of `gem install fog` as literally that.  Install Fog's files - i.e. this gets you a subset of what a `git clone ...` brings down to your computer.  Either way you should have to run `bundle install`.\nSo I'd advocate that the fog.gemspec list no dependencies other than bundler, and user and dev instructions emphasize that `gem install fog` is considered a distribution channel for a minimal subset (the production set) of files in the git repository.\nWether you use `gem install fog` or `git clone ...` you have to run `bundle install` to install the library dependencies, according to what is already on your system.\n\nAdvantages:\n\n- `gem install fog` on a test/production machine means you don't mangle/touch the installed gems, and get just what are needed.\n- `gem install fog` is much faster with no external dependencies e.g. \n    \n$ time gem install fog-131.0.0.3.gem --no-ri --no-rdoc\n    Successfully installed fog-131.0.0.3\n    1 gem installed\n    real\t0m0.619s\n    user\t0m0.450s\n    sys\t0m0.170s\n- removes ambiguity about how to install Fog (`bundle install`)\n- `gem install fog` provides a succinct way to grab the released runtime files of fog and no other.\n- Bundler should make developing less painful\n- Bundler should make installation more robust\n- there are not two ways of installing Fog's dependencies.\n\nDisadvantages:\n\n- Very unconventional (currently) interpretation of `gem install fog`\n- Since `gem install -y` became the default people now expect `gem install fog` to install something else too, and Fog just won't.\n- It is not what all the other kids are doing.\n- Additional instructions needed until the idea sinks in.\n- Complaints, complaints, complaints\n\nThoughts?"
69,'','This pull request is a fix for https://github.com/geemus/fog/issues#issue/41 <eom/>\n'
68,'','aws server ssh/bootstrap frequently hangs when using micro instances\nCurrent implementation has a hacky 10 second sleep which seemed to work.  For some reason if you try to connect prior to some amount of delay net ssh will just hang.  Should instead try earlier, but with a timeout/retry loop until a connection can be established.  That way it can work faster in some cases and in other cases it will at least not fail (mostly the micro case where it seems 10 seconds is not long enough).'
67,'','simpledb put_attributes mock returns strings instead of arrays\nImported from ruby-fog google group:\n\nHi folks,\n\n(I am in a bit of a hurry this morning, will probably dig into the problem\nlater today) but saw this behavior with the SimpleDB mock and thought it\'s\ngood to bring it forward. If I put an array into the real SDB (AWS[:sdb]\nbelow) I get an array back, but the mock, while putting it in, is converting\nthe array into a string (sdb_mock):\nhttps://github.com/geemus/fog/blob/master/lib/fog/aws/requests/simpledb/put_attributes.rb#L57\n\n    $> fog\n    Welcome to fog interactive!\n    :default credentials provide AWS\n\n    >> AWS[:sdb].put_attributes("test", "first", { \'a\' => [\'A\', \'B\', \'C\'], \'b\' => 199 }, \'c\' => \'XXX\' )\n    #<Excon::Response:0xb7bfd0e4 @body={"RequestId"=>"0cb8fcd2-ba9c-f3e4-91df-7bf89322e62a", "BoxUsage"=>2.20035e-05}, @headers {"Transfer-Encoding"=>"chunked", "Date"=>"Tue, 09 Nov 2010 16:35:31 GMT", "Content-Type"=>"text/xml", "Server"=>"Amazon SimpleDB"}, @status=200>\n\n    >> AWS[:sdb].get_attributes("test", "first").body["Attributes"]\n    {"a"=>["A", "B", "C"], "b"=>["199"]}\n\n    >> Fog.mock!\n    true\n\n    >> sdb_mock = Fog::AWS::SimpleDB.new(:aws_access_key_id => \'\', :aws_secret_access_key => \'\')\n    #<Fog::AWS::SimpleDB::Mock:0xb7be1ce0 @aws_access_key_id="", @data={:domains=>{}}>\n\n    >> sdb_mock.create_domain("test")\n    #<Excon::Response:0xb7bdfbc0 @body={"RequestId"=>"13b00208-de41-2755-8e23-f8e01323a685", "BoxUsage"=>0.0062779331}, @headers={}, @status=200>\n\n    >> sdb_mock.put_attributes("test", "first", { \'a\' => [\'A\', \'B\', \'C\'], \'b\' => 199 }, \'c\' => \'XXX\' )\n    #<Excon::Response:0xb7bccdcc @body {"RequestId"=>"c13afee2-8f69-6cd6-971c-108b20023c03", "BoxUsage"=>0.0029045245}, @headers={}, @status=200>\n\n    >> sdb_mock.get_attributes("test", "first").body["Attributes"]\n    {"a"=>["ABC"], "b"=>["199"]}\n\n- Arnab '
66,'',"Feature request: Server#scp\nGotta say - Server#ssh is awesome.  The #bootstrap method is sweet.\r\n\r\nWould it be possible to Server#scp a local file onto the server?  Specifically I'm looking to make it easier to inject chef recipes into an EC2 instance running an opscode AMI (http://wiki.opscode.com/display/chef/Amazon+EC2+AMIs+with+Chef) but I think this would be generally useful."
65,'',"Patches and new cloud provider\nWe've added support for our new (in beta) Cloud system at Brightbox (Compute)\r\n\r\nThere's a few patches that are required for the JSON parsing to be done correctly based on our nested JSON objects which lead up to the last commit. I've added specs to support these changes in how attributes are declared.\r\n\r\nAny problems or clean ups, let me know."
64,'',"nicer accessors for headers on AWS|Storage File\nFor example, 'Cache-Control' and 'Expires'\nSee: http://docs.amazonwebservices.com/AmazonS3/latest/API/RESTObjectPUT.html"
63,'','documentation updates\nnothing too crazy, just some wording tweaks, and adding an example or two.'
62,'','vCloud mocking rework\nEd and I redid the vCloud & TM provider mocking to use mock objects instead of a giant Hash. This has made it much easier to address things in the mock data and mock more complex operations.'
61,'',"Fog Doesn't work with Rubinius\nI have just tried to run Fog with Rubinius (both 1.1 stable and rvm rbx-head) and there is a bug preventing Fog from working.\r\n\r\nI have documented the issue in [this Gist](https://gist.github.com/688ca4b2a4dd7537e901). I haven't dug in to the code yet, but I'd be happy to test further, or try to dig in to a fix when I have more time."
60,'',"consistent private/public ip accessors (thanks abecc)\nfor instance AWS servers have private_ip_address and ip_address\n\nbut Rackspace servers have addresses['public'] and addresses['private'] (which are arrays)\n\narray vs single value may need to be reconciled and naming should be unified\n\nprivate_ip_address and public_ip_address would probably be good as the accessors\n\nSo other stuff will need to be updated and/or deprecated as appropriate to allow for this\n\nYou may want to talk to geemus before tackling this, because it could be a bit hairy.  Otherwise I'll get to it eventually."
59,'',"Fog doesn't work under ruby 1.9.2\n    fc = Fog::AWS::Compute.new( $AWS_CREDENTIALS )\r\n    p fc.servers\r\n\r\nResults in:\r\n\r\n    gems/fog-0.3.14/lib/fog/aws/models/compute/servers.rb:27:in `all': undefined method `describe_instances' for nil:NilClass (NoMethodError)\r\n            from gems/fog-0.3.14/lib/fog/core/collection.rb:121:in `lazy_load'            from (eval):3:in `empty?'            from gems/fog-0.3.14/lib/fog/core/collection.rb:69:in `block in inspect'\r\n            from gems/formatador-0.0.15/lib/formatador.rb:92:in `indent'\r\n            from gems/fog-0.3.14/lib/fog/core/collection.rb:62:in `inspect'\r\n            from foggy.rb:10:in `p'\r\n            from foggy.rb:10:in `<main>'\r\n"
58,'','Already initialized constant errors\nWhen I use fog gem I get a ton of errors on my console, and my app runs really slowly.\n\nhttp://gist.github.com/659163'
57,'','slicehost deprecation warning incorrect\nFix in: http://github.com/joewilliams/fog/tree/slicehost_deprecation_warning'
56,'','AWS content_type\nThe following does not set the content type of an AWS object.\r\n\r\nfile = directory.files.create(:key => \'hello.html\',:content_type => \'text/plain\')\r\nfile.acl = \'public-read\'\r\nfile.content_type = \'text/plain\'\r\nfile.body = \'hello\'\r\nfile.save\r\n\r\ncontent_type is set as an attribute with an alias Content-Type but it doesnt make it to the put_object method. If I alter the save method in the file class\r\n\r\ndef save(options = {})\r\nrequires :body, :directory, :key\r\nif options != {}\r\nFormatador.display_line("[yellow][WARN] options param is deprecated, use acl= instead[/] [light_black](#{caller.first})[/]")\r\nend\r\nif @acl\r\noptions[\'x-amz-acl\'] ||= @acl\r\nend\r\nif self.content_type\r\noptions[\'Content-Type\'] = self.content_type\r\nend\r\ndata = connection.put_object(directory.key, @key, @body, options)\r\n@etag = data.headers[\'ETag\']\r\ntrue\r\nend\r\n\r\nthen it works. But I doubt this is the intended solution since it doesnt use the attribute aliases.\r\n\r\n'
55,'','AWS::Compute::Volume#force_detach method or similar needed\nWe have encountered alot of volumes which are in a broken state. \r\nHaving to drop down into the requests is overly complex. '
54,'','bin/fog doesn\'t work in windows 2008 - 64bits; however bin/fog code works fine in irb\n\r\n\r\nPS C:\\Users\\Administrator> fog\r\nC:/Ruby187/lib/ruby/site_ruby/1.8/rbreadline.rb:4404: uninitialized constant RbReadline::Encoding (NameError)\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require\'\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require\'\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/readline.rb:8\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require\'\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require\'\r\n        from C:/Ruby187/lib/ruby/1.8/irb/input-method.rb:85\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require\'\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require\'\r\n        from C:/Ruby187/lib/ruby/1.8/irb.rb:20\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require\'\r\n        from C:/Ruby187/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require\'\r\n        from C:/Ruby187/lib/ruby/gems/1.8/gems/fog-0.3.13/bin/fog:3\r\n        from C:/Ruby187/bin/fog:19:in `load\'\r\n        from C:/Ruby187/bin/fog:19\r\nPS C:\\Users\\Administrator>\r\n\r\n\r\n#pasting the code of bin/fog on an irb session works fine:\r\n\r\nPS C:\\Ruby187\\lib\\ruby\\gems\\1.8\\gems\\fog-0.3.13\\bin> irb\r\nirb(main):001:0> require File.expand_path(File.join(File.dirname(__FILE__), \'..\', \'lib\', \'fog\'))\r\n=> true\r\nirb(main):002:0> require \'irb\'\r\n=> false\r\nirb(main):003:0> require \'yaml\'\r\n=> true\r\nirb(main):004:0> require File.join(\'fog\', \'core\', \'credentials\')\r\n=> true\r\nirb(main):005:0> Fog.credential = ARGV.first ? ARGV.first.to_sym : nil\r\n=> nil\r\nirb(main):006:0> Fog.bin = true\r\n=> true\r\nirb(main):007:0> Fog.mock! if ENV[\'FOG_MOCK\']\r\n=> nil\r\nirb(main):008:0> unless Fog.credentials\r\nirb(main):009:1>   exit\r\nirb(main):010:1> end\r\n=> nil\r\nirb(main):011:0>\r\nirb(main):012:0* require \'fog/core/bin\'\r\n=> true\r\nirb(main):013:0>\r\nirb(main):014:0* providers = Fog.providers.map{|provider| provider.to_s}\r\n=> ["AWS"]\r\nirb(main):015:0> providers = if providers.length > 1\r\nirb(main):016:1>   providers[0...-1].join(\', \') << \' and \' << providers[-1]\r\nirb(main):017:1> else\r\nirb(main):018:1*   providers.first\r\nirb(main):019:1> end\r\n=> "AWS"\r\nirb(main):020:0>\r\nirb(main):021:0* if ARGV.length > 1\r\nirb(main):022:1>\r\nirb(main):023:1*   puts(instance_eval(ARGV[1..-1].join(\' \')).to_json)\r\nirb(main):024:1>\r\nirb(main):025:1* else\r\nirb(main):026:1*\r\nirb(main):027:1*   ARGV.clear # Avoid passing args to IRB\r\nirb(main):028:1>   IRB.setup(nil)\r\nirb(main):029:1>   @irb = IRB::Irb.new(nil)\r\nirb(main):030:1>   IRB.conf[:MAIN_CONTEXT] = @irb.context\r\nirb(main):031:1>   IRB.conf[:PROMPT][:FOG] = IRB.conf[:PROMPT][:SIMPLE].dup\r\nirb(main):032:1>   IRB.conf[:PROMPT][:FOG][:RETURN] = "%s\\n"\r\nirb(main):033:1>   @irb.context.prompt_mode = :FOG\r\nirb(main):034:1>   @irb.context.workspace = IRB::WorkSpace.new(binding)\r\nirb(main):035:1>\r\nirb(main):036:1*   Formatador.display_line(\'Welcome to fog interactive!\')\r\nirb(main):037:1>   Formatador.display_line(":#{Fog.credential.to_s} credentials provide #{providers}")\r\nirb(main):038:1>   providers = Fog.providers\r\nirb(main):039:1>   Fog.modules.each do |_module_|\r\nirb(main):040:2*     if _module_.respond_to?(:startup_notice)\r\nirb(main):041:3>       _module_.send(:startup_notice)\r\nirb(main):042:3>     end\r\nirb(main):043:2>   end\r\nirb(main):044:1>\r\nirb(main):045:1*   catch(:IRB_EXIT) { @irb.eval_input }\r\nirb(main):046:1>\r\nirb(main):047:1* end\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant UnrecognizedSwitch\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant NotImplementedError\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant CantReturnToNormalMode\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant IllegalParameter\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant IrbAlreadyDead\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant IrbSwitchedToCurrentThread\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant NoSuchJob\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant CantShiftToMultiIrbMode\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant CantChangeBinding\r\nC:/Ruby187/lib/ruby/1.8/e2mmap.rb:152: warning: already initialized constant UndefinedPromptMode\r\n  Welcome to fog interactive!\r\n  :default credentials provide AWS\r\n>>'
53,'','CloudFront invalidation\nWould it be possible to add CloudFront invalidation to Fog?\r\n\r\nIn reference to this announcement: \r\nhttp://aws.amazon.com/about-aws/whats-new/2010/08/31/cloudfront-adds-invalidation-feature/'
52,'',"AWS Tag Support for Addresses\nAWS supports tags on addresses and we're looking to use these to keep track of which services the IP has been white listed with so that appropriate IP addresses can be assigned to new instances automatically."
51,'',"Simultaneously and individually run specs\n* Rakefile tasks and helper functions to:\n\n      rake async:aws[state]                # Async run AWS Fog specs and tests live or mocked\n      rake aws[state]                      # Run AWS Fog specs and tests live or mocked\n      rake spec:all[state]                 # Run Fog's RSpec for all vendors with state (default :mocked)\n      rake spec:async:all[state]           # Async run Fog's RSpec for all vendors with state (default :mocked)\n      rake spec:async:cloud[vendor,state]  # Async run Fog's RSpec for vendor (default :aws) and state (default :mocked)\n      rake spec:cloud[vendor,state]        # Run Fog's RSpec for vendor (default :aws) and state (default :mocked)\n      rake spec:clouds:list                # List all cloud vendors and whether they have live and mock tests and spec's\n"
50,'',"Bundler \nExtend Bundler usage:\n\n* Direct and indirect gem dependencies and versions listed in Gemfile.\n\n* Bundler.require(...) in lib/fog.rb, benchs, Rakefile, spec\n\n* Remove Rakefile tasks that are now redundant\n\nMisc:\n\n* Add JetBrain's config's to .gitignore (since .gitignore is in the repo)\n\nTodo:\n\n* Write Bundler features + specs - apologies."
49,'','[aws|storage] SignatureDoesNotMatch Error when using copy_object\nThis was the request object (with replaced bucket and aws id): \r\n\r\n`{:path=>"/originals%2FIMG_4262.jpg", :body=>nil, :method=>"PUT", :headers=>{"x-amz-copy-source"=>"/bucket/originals/IMG_4262.jpg", "Authorization"=>"AWS 1CTJ5AW7ZBATAVJNMS82:YvC4QSNM9ByChRgXKHQScqC55wQ=", "Date"=>"Sun, 24 Oct 2010 15:53:34 +0000", "Content-Length"=>0, "Host"=>"bucket.s3-external-3.amazonaws.com"}, :expects=>[307, 200], :host=>"bucket.s3-external-3.amazonaws.com"}`\r\n\r\n'
48,'',"JSON warnings on load\nUsing fog in my Rails app, whenever the environment is loaded (for tests, or starting the server), I see the following warnings:\n\n    /Users/patnakajima/.rvm/gems/ree-1.8.7-2010.02/gems/json-1.4.6/lib/json/common.rb:65: warning: already initialized constant State\n    /Users/patnakajima/.rvm/gems/ree-1.8.7-2010.02/gems/json-1.4.6/lib/json/common.rb:66: warning: already initialized constant SAFE_STATE_PROTOTYPE\n    /Users/patnakajima/.rvm/gems/ree-1.8.7-2010.02/gems/json-1.4.6/lib/json/common.rb:67: warning: already initialized constant FAST_STATE_PROTOTYPE\n    /Users/patnakajima/.rvm/gems/ree-1.8.7-2010.02/gems/json-1.4.6/lib/json/common.rb:74: warning: already initialized constant PRETTY_STATE_PROTOTYPE\n    /Users/patnakajima/.rvm/gems/ree-1.8.7-2010.02/gems/json-1.4.6/lib/json/pure.rb:76: warning: already initialized constant JSON_LOADED\n\nI tried forking fog to remove the `require 'json'`, but the warnings were still there, and I don't see any other libraries that fog depends on requiring json either.\n\nThe app is using Rails 3.\n\nAny ideas?"
47,'',"AWS image regression in fog 0.3.8\nIn fog 0.3.7, calling @compute.images.get('someImageId') would yield the proper AMI. Each version from 0.3.8 to today's 0.3.11 are returning an unrelated kernel image."
46,'','modify security groups?\nHi,\r\n\r\nI see the ability to create and delete security groups but not modify, so if we could get that as well it would relieve some problems modifying security groups for customers :) and we could automate it :)\r\n\r\n'
45,'','[rackspace][storage] NoMethodError: undefined method `name=\'\nThis is the full error message:\r\n\r\nNoMethodError: undefined method `name=\' for #<Fog::Rackspace::Storage::File:0x00000100c855b8>\r\n\r\nI get this exception when I do try to get a container within rackspace and the container contains files:\r\n\r\nconnection.directories.get("test")\r\n\r\nThe problem seems to be that the json object returned from rackspace returns "name" as the identity key, not "key." The rackspace/storage/file.rb uses the "key" attribute as the identity, so when fog tries to bind the the name value it says that name is undefined.'
44,'','TM eCloud get_vapp and power_on mocking\n'
43,'','Mock AWS ids are not always the correct length\nHex vales used for mock AWS ids are expected to be exactly 8 characters.  This was exposed by the regex in the create_tags mock.'
42,'',"Create a mock for aws create_tags\nAdds a mock.  Admittedly not well tested but used in the specs for a project I'm working on."
41,'',"Would be nice if Fog::EC2::Compute.new raised an error for unknown options\nIf you create a new compute object like so:\r\n\r\n`Fog::EC2::Compute.new(:aws_access_key_id => 'squirrel', :aws_secret_access_key => 'secret', :aws_region => 'us-west-1')`\r\n\r\nthen what you actually get isn't using the us-west-1 region, but us-east-1 (the default). The correct key to use is `:region`, not `:aws_region`. It would be nice to get an error telling me that Fog doesn't know what `:aws_region` is."
40,'',"Describe instance doesn't list tags\nDue to a bug in the parser's item element context check, tags never get added to the instance.  This patch reorders the context check in the describe instance parser so that the most specific possible context is checked before less specific contexts."
39,'','cleaned up some warnings and fixed error building gem \nthe following warnings where fixed:\r\n\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/core/ssh.rb:59: warning: shadowing outer local variable - channel\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/core/ssh.rb:64: warning: shadowing outer local variable - channel\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/core/ssh.rb:68: warning: shadowing outer local variable - channel\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/core/ssh.rb:73: warning: shadowing outer local variable - channel\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/core/ssh.rb:77: warning: shadowing outer local variable - channel\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/local/storage.rb:56: warning: mismatched indentations at \'end\' with \'class\' at 3\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/terremark/ecloud.rb:30: warning: mismatched indentations at \'end\' with \'if\' at 26\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/terremark/ecloud.rb:63: warning: mismatched indentations at \'end\' with \'module\' at 3\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/terremark/vcloud.rb:30: warning: mismatched indentations at \'end\' with \'if\' at 26\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/terremark/vcloud.rb:94: warning: mismatched indentations at \'end\' with \'class\' at 33\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/terremark/vcloud.rb:109: warning: mismatched indentations at \'end\' with \'module\' at 3\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/vcloud/terremark/ecloud.rb:182: warning: shadowing outer local variable - service\r\n\r\nthe following warnings still exist (ran out of time tonight):\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/terremark/ecloud.rb:48: warning: mismatched indentations at \'end\' with \'class\' at 33\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/aws/compute.rb:77: warning: shadowing outer local variable - hash\r\n/Users/anuaimi/.rvm/gems/ruby-1.9.2-p0@rails3/bundler/gems/fog-3ec39c332fe4/lib/fog/aws/storage.rb:78: warning: shadowing outer local variable - hash\r\n\r\nthe following error building the gem is fixed (believe related to last commit where files were deleted):\r\nathir-nuaimis-macbook-pro:fog anuaimi$ gem build fog.gemspec \r\nERROR:  While executing gem ... (Gem::InvalidSpecificationException)\r\n    ["spec/aws/requests/storage/delete_bucket_spec.rb", "spec/aws/requests/storage/delete_object_spec.rb", "spec/aws/requests/storage/get_service_spec.rb", "spec/aws/requests/storage/put_bucket_spec.rb", "spec/aws/requests/storage/put_object_spec.rb"] are not files'
38,'','Initial mocking for instantiate_vapp_template\nAnd other supporting things along the way.\r\n\r\nPlus some fixing of specs. Some still broken.'
37,'',"fixed gemspec for lib/core/fog refactor\nIgnore the gogrid stuff since it's not tested. Cherry pick the gemspec commit. Low hanging fruit so I could keep working on the GoGrid stuff."
36,'','Initial AWS Tag support\nI\'ve implemented the initial plumbing for AWS Tag requests.  Right now all "describe" methods work.  You can pull query a list of all tags associated with your AWS account (along with filter support). You can also call the "tags" method on the Image, Server and Volume model and get a list of the tags associated with that instance.  I am continuing on with create_tags and delete_tags next.'
35,'','Remove lib/ from require paths in TM eCloud models\nBreaks use as an installed gem with it there.'
34,'','Benchmarks getting started/howto.\nWould be useful to have a how to for running the benchmarks.\r\n\r\nSo far I\'ve got in Gemfile:\r\n\r\n    group :benchmark do\r\n      gem \'right_aws\', \'2.0.0\'\r\n      gem \'right_http_connection\', \'1.2.4\'\r\n      gem \'xml-simple\', \'1.0.12\'\r\n      gem \'aws-s3\', \'0.6.2\', :require => \'aws/s3\'\r\n    end\r\n\r\nOn running I see:\r\n\r\n    $ ruby ./benchs/fog_vs.rb \r\n    /home/hedge/.rvm/gems/ruby-1.9.1-p378/gems/bundler-1.0.0.rc.6/lib/bundler/runtime.rb:132: warning: Insecure world writable dir /home/hedge in PATH, mode 042777\r\n      [WARN] Fog::AWS::S3#new is deprecated, use Fog::AWS::Storage#new instead (./benchs/fog_vs.rb:12:in `<main>\') \r\n    I, [2010-10-07T22:58:00.829828 #29792]  INFO -- : New RightAws::S3Interface using shared connections mode\r\n    Rehearsal ------------------------------------------------------------\r\n    fog.put_bucket           /home/hedge/.rvm/gems/ruby-1.9.1-p378/gems/excon-0.2.3/lib/excon/connection.rb:73:in `request\': Expected([307, 200]) <=> Actual(403 Forbidden) (Excon::Errors::Forbidden)\r\n      request => {:expects=>[307, 200], :body=>nil, :headers=>{"Date"=>"Thu, 07 Oct 2010 11:58:00 +0000", "Authorization"=>"AWS INTENTIONALLY_LEFT_BLANK:gF7+H6CW8zOOgXKjpr0wGGKB6eQ=", "Host"=>"fogbench0.s3.amazonaws.com", "Content-Length"=>0}, :idempotent=>true, :host=>"fogbench0.s3.amazonaws.com", :method=>"PUT", :path=>"/"}\r\n      response => #<Excon::Response:0x000000042619f0 @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>InvalidAccessKeyId</Code><Message>The AWS Access Key Id you provided does not exist in our records.</Message><RequestId>EDC8117E534ECA2E</RequestId><HostId>8OMcapZvWXzNjCCAqgC1zC24t2ZqamvZPWPVnrgwoRUsT+RCZEZD3Vf02k29Mu7i</HostId><AWSAccessKeyId>INTENTIONALLY_LEFT_BLANK</AWSAccessKeyId></Error>", @headers={"x-amz-request-id"=>"EDC8117E534ECA2E", "x-amz-id-2"=>"8OMcapZvWXzNjCCAqgC1zC24t2ZqamvZPWPVnrgwoRUsT+RCZEZD3Vf02k29Mu7i", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"chunked", "Date"=>"Thu, 07 Oct 2010 11:57:59 GMT", "Server"=>"AmazonS3"}, @status=403>\r\n\t    from /usr/src/fog/lib/fog/core/connection.rb:20:in `request\'\r\n\t    from /usr/src/fog/lib/fog/aws/storage.rb:181:in `request\'\r\n\t    from /usr/src/fog/lib/fog/aws/requests/storage/put_bucket.rb:34:in `put_bucket\'\r\n\t    from ./benchs/fog_vs.rb:32:in `block (3 levels) in <main>\'\r\n\t    from ./benchs/fog_vs.rb:31:in `times\'\r\n\t    from ./benchs/fog_vs.rb:31:in `block (2 levels) in <main>\'\r\n\t    from /home/hedge/.rvm/rubies/ruby-1.9.1-p378/lib/ruby/1.9.1/benchmark.rb:294:in `measure\'\r\n\t    from /home/hedge/.rvm/rubies/ruby-1.9.1-p378/lib/ruby/1.9.1/benchmark.rb:262:in `block in bmbm\'\r\n\t    from /home/hedge/.rvm/rubies/ruby-1.9.1-p378/lib/ruby/1.9.1/benchmark.rb:260:in `each\'\r\n\t    from /home/hedge/.rvm/rubies/ruby-1.9.1-p378/lib/ruby/1.9.1/benchmark.rb:260:in `bmbm\'\r\n\t    from ./benchs/fog_vs.rb:29:in `<main>\'\r\n\r\n'
33,'',"Dev doc's: specs tests always green?\nLittle detail for dev-getting started. \nAre the spec's and tests always green?\nOr is this expected:\n\n    cat >~/.fog <<EOT\n    :default:\n      :aws_access_key_id:     INTENTIONALLY_LEFT_BLANK\n      :aws_secret_access_key: INTENTIONALLY_LEFT_BLANK\n      :bluebox_api_key:       INTENTIONALLY_LEFT_BLANK\n      :bluebox_customer_id:   INTENTIONALLY_LEFT_BLANK\n      :local_root:            INTENTIONALLY_LEFT_BLANK\n      :new_servers_password:  INTENTIONALLY_LEFT_BLANK\n      :new_servers_username:  INTENTIONALLY_LEFT_BLANK\n      :public_key_path:       INTENTIONALLY_LEFT_BLANK\n      :private_key_path:      INTENTIONALLY_LEFT_BLANK\n      :rackspace_api_key:     INTENTIONALLY_LEFT_BLANK\n      :rackspace_username:    INTENTIONALLY_LEFT_BLANK\n      :slicehost_password:    INTENTIONALLY_LEFT_BLANK\n      :terremark_username:    INTENTIONALLY_LEFT_BLANK\n      :terremark_password:    INTENTIONALLY_LEFT_BLANK\n    EOT\n\nRunning default rake task:\n\n    rake \n    <snip>\n    955 examples, 215 failures, 2 pending\n\n"
32,'','Rackspace Cloudfiles: How can I create directory markers?\nHello,\n\nWhen using S3, I\'m doing something like this:\n\ndirectory = s3.directories.get("backups")\ndirectory.files.create(:key => "db/somefile.gz", :body => open("somefile.gz"))\n\nThis works, and I don\'t know if it\'s amazon\'s s3 api, but the "db" directory key is created too. So it looks like in the "backup" bucket, there\'s a "db" directory, and inside that directory is my "somefile.gz" file.\n\nI\'m trying to do the same thing with Rackspace Cloudfiles with the same code. It does work, but fog doesn\'t generate "directory markers," so you just end up with a key like "db/somefile.gz" and no "db" key. I figured I\'d create my own directory markers with the put_object method, but it seems the Utils#parse_data method sets the data header for me. I can\'t create an object with Content-Type "application/directory." Any help would be appreciated, thanks!'
31,'',"Jeweler issue #81\nJeweler has closed this and, despite on going reports, doesn't seem to want to fix this issue as at 1.5.0-pre3...\r\nWould you accept patches switching to bundler?\r\n"
30,'','Local "clouds"\nIs there any interest in having support for private clouds i.e. libvirt/xend/vmware? I might have some time free to take a gander at adding it.'
29,'',"Idempotent instances on AWS\nI added a field for ClientToken to the AWS servers. It'd be cool to make this a bit more built in but at least it should be useable at this point. There's something up with my home laptop and I can't run the specs or use the fog binary so I'll have to check it when I get to work."
28,'','Ruby 1.9.2 Encoding issue for S3 uploads\nI ran the following code in ruby 1.9.2 patch level 0 and it uploaded incorrectly to s3. If I manually set Content-MD5 in the headers, I get an MD5 mismatch from Amazon. \n\n<pre><code>\n@connection ||= Fog::AWS::Storage.new(\n  :aws_access_key_id => access_key,\n  :aws_secret_access_key => secret_access_key)\n\nblob = File.read(\'sample.jpg\')\n\n@connection.put_object \'test\', "path/sample_fog.jpg", blob,\n  \'Content-Type\' => \'binary/octet-stream\',\n  \'x-amz-acl\' => \'public-read\'</code><pre>'
27,'',"Implemented support for Amazon's 307 Temporary Redirect\nSometimes, I guess especially when using EU buckets, Amazon will issue a 307 Temporary Redirect asking you to repeat the request to another endpoint.\r\n\r\nWhen that happens, you're stuck unless the library supports those, because they simply refuse to accept it at the normal endpoint.\r\n\r\nSo I had to implement it.\r\n\r\nHope you'll find it useful.\r\n\r\n//Lars"
26,'','Make fog Ubuntu Enterprise Cloud/Eucalyptus friendly \nHi,\r\nAs UEC/EUcalyptus is AWS compliant in terms of api, please make it possible to define additional availability zones/regions with UEC settings.'
25,'','adds google storage service and spec\n'
24,'','URLs for AWS-S3 without https support\nSorry for bothering you again.\r\n\r\nWhen I call url() for a Fog::AWS::Storage::File, it returns a link that begins with "http://" - hardcoded - which is bad as I have to rely on a secure connection.\r\n\r\nOf course I\'m able to handle this inside my code. But I\'d like to know whether you intend to add some switch/option support here.'
23,'','Wrong AWS-S3 url for eu-Bucket\nHello again,\r\nI\'ve seen you added a S3 host for region "eu-west-1" in lib/fog/aws/storage.rb. Let\'s say I have a bucket called "mybucket" on host "s3-eu-west-1.amazonaws.com".\r\n\r\nThen I call url() for a Fog::AWS::Storage::File instance, I get the following URL:\r\n    http://mybucket.s3-eu-west-1.amazonaws.com/test_upload.txt?...\r\n\r\nThis won\'t work, as far as I know it must be:\r\n    http://mybucket.s3.amazonaws.com/test_upload.txt?...\r\nor\r\n    http://s3-eu-west-1.amazonaws.com/mybucket/test_upload.txt?...\r\n\r\nPlease repair this, thank you.'
22,'','ec2 micro instances\nUsing the knife gem (chef) I get the following error when trying to launch a t1.micro instance:\r\n\r\n\r\n    knife ec2 server create "role[app]" -i ami-fae20893 -f t1.micro -x ubuntu -Z us-east-1a -k ~/.chef/clientserver.pem \r\n    /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/excon-0.2.2/lib/excon/connection.rb:69:in `request\': UnsupportedOperation => AMIs with an instance-store root device are not supported for the instance type \'t1.micro\'. (Fog::AWS::EC2::Error)\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/fog-0.2.30/lib/fog/connection.rb:20:in `request\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/fog-0.2.30/lib/fog/aws/ec2.rb:194:in `request\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/fog-0.2.30/lib/fog/aws/requests/ec2/run_instances.rb:101:in `run_instances\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/fog-0.2.30/lib/fog/aws/models/ec2/server.rb:141:in `save\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/fog-0.2.30/lib/fog/collection.rb:47:in `create\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/chef-0.9.8/lib/chef/knife/ec2_server_create.rb:124:in `run\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/chef-0.9.8/lib/chef/knife.rb:127:in `run\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/chef-0.9.8/lib/chef/application/knife.rb:118:in `run\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/gems/chef-0.9.8/bin/knife:25:in `<top (required)>\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/bin/knife:19:in `load\'\r\n\t    from /home/matt/.rvm/gems/ruby-1.9.2-p0@rails3/bin/knife:19:in `<main>\'\r\n'
21,'',"Issues when initializing Fog::Local::Storage\nHi,\nas your documentation does not match the latest gem of version 0.2.30, I switched to 1e3a676. Now I'm in a Ruby 1.9.2 console, I do the following:\n    require 'fog'\n    Fog::Local::Storage.new({:local_root => '/Users/marcel/source/app'})\n\nFirst, lib/fog/local/models/storage/directories.rb attempts to require directory.rb from a wrong path. Ok, no big deal.\n\nNext try, I get this:\n    TypeError: can't convert Symbol into Integer\n    from [...]/ruby-1.9.2-p0/bundler/gems/fog-1e3a676/lib/fog/attributes.rb:21:in `[]'\n\nCan you tell me something about this?"
20,'','BlueBox Group support\nI\'ve recently created a box using the SSH key support, and they call this "ssh_public_key" in the documentation here: https://boxpanel.blueboxgrp.com/public/the_vault/index.php/Blocks_API#POST_.2Fapi.2Fblocks\r\n'
19,'','undefined method `blank?\' in ec2/server.rb\n    connection = Fog::AWS::EC2.new(:aws_access_key_id => "xxx", :aws_secret_access_key => "xxx", :region => "eu-west-1")\r\n    connection.servers\r\n\r\nGives me...\r\n\r\n    NoMethodError: undefined method `blank?\' for nil:NilClass\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/aws/models/ec2/server.rb:36:in `initialize\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:92:in `new\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:92:in `new\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:82:in `load\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:81:in `each\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:81:in `load\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/aws/models/ec2/servers.rb:33:in `all\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:117:in `lazy_load\'\r\n\tfrom (eval):3:in `empty?\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:65:in `inspect\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/formatador-0.0.15/lib/formatador.rb:92:in `indent\'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.24/lib/fog/collection.rb:58:in `inspect\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:310:in `output_value\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:159:in `eval_input\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:271:in `signal_status\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:155:in `eval_input\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:154:in `eval_input\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:71:in `start\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:70:in `catch\'\r\n\tfrom /Users/druiden/.rvm/rubies/ruby-1.8.7-p299/lib/ruby/1.8/irb.rb:70:in `start\'\r\n\r\nI guess blank? is commonly an ActiveSupport addition and it doesn\'t seem like you\'re using activesupport or defining your own blank anywhere.'
18,'','Fog mock for AWS EC2 Volume destroy does not fail when attached\nIt should raise an error. '
17,'',"European ami not found\nI wanted to boot an ec2 instance using an eu-west ubuntu ami from http://alestic.com/ but got:\r\n\r\n    /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/excon-0.2.0/lib/excon/connection.rb:69:in `request': The AMI ID 'ami-cf4d67bb' does not exist (Fog::AWS::EC2::NotFound)\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.22/lib/fog/connection.rb:20:in `request'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.22/lib/fog/aws/ec2.rb:193:in `request'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.22/lib/fog/aws/requests/ec2/run_instances.rb:101:in `run_instances'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.22/lib/fog/aws/models/ec2/server.rb:130:in `save'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/fog-0.2.22/lib/fog/collection.rb:47:in `create'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/chef-0.9.8/lib/chef/knife/ec2_server_create.rb:124:in `run'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/chef-0.9.8/lib/chef/knife.rb:127:in `run'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/chef-0.9.8/lib/chef/application/knife.rb:118:in `run'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/gems/chef-0.9.8/bin/knife:25\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/bin/knife:19:in `load'\r\n\tfrom /Users/druiden/.rvm/gems/ruby-1.8.7-p299/bin/knife:19\r\n"
16,'',"Fresh install of fog has problems with latest nokogiri (1.4.3)\nI get this with nokogiri 1.4.3 (latest)\r\n\r\n\r\n/usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require': no such file to load -- nokogiri/version_warning (LoadError)\r\n\tfrom /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'\r\n\tfrom /usr/lib/ruby/gems/1.8/gems/nokogiri-1.4.3/lib/nokogiri.rb:34\r\n\tfrom /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'\r\n\tfrom /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'\r\n\tfrom /usr/lib/ruby/gems/1.8/gems/fog-0.2.20/bin/../lib/fog.rb:10\r\n\tfrom /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'\r\n\tfrom /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'\r\n\tfrom /usr/lib/ruby/gems/1.8/gems/fog-0.2.20/bin/fog:2\r\n\tfrom /usr/bin/fog:19:in `load'\r\n\tfrom /usr/bin/fog:19\r\n\r\n\r\nUsing 1.4.2 it works fine.  1.4.3 was released  very recently."
15,'','Adding create_image for EC2\nSorry, dunno what the proper way to request a pull is, but I have a branch (user: ctennis, branch: create_image) that adds create_image as another EC2 method to create AMIs from running instances.'
14,'','JSON::ParserError: 705 creating new Rackspace container\nWhen I create a new container in Rackspace Cloud Files I get:\n\ndirectory = Rackspace.directories.create(:key => "fogRocks")\n\nJSON::ParserError: 705: unexpected token at \'202 Accepted\n\nThe request is accepted for processing.\n\n   \'\n\tfrom /var/lib/gems/1.8/gems/json-1.4.3/lib/json/common.rb:146:in `parse\'\n\tfrom /var/lib/gems/1.8/gems/json-1.4.3/lib/json/common.rb:146:in `parse\'\n\tfrom /var/lib/gems/1.8/gems/fog-0.2.9/lib/fog/rackspace/files.rb:126:in `storage_request\'\n\tfrom /var/lib/gems/1.8/gems/fog-0.2.9/lib/fog/rackspace/requests/files/put_container.rb:15:in `put_container\'\n\tfrom /var/lib/gems/1.8/gems/fog-0.2.9/lib/fog/rackspace/models/files/directory.rb:37:in `save\'\n\tfrom /var/lib/gems/1.8/gems/fog-0.2.9/lib/fog/collection.rb:47:in `create\'\n\tfrom (irb):3\n\tfrom /var/lib/gems/1.8/gems/fog-0.2.9/bin/fog:24\n\tfrom /var/lib/gems/1.8/bin/fog:19:in `load\'\n\tfrom /var/lib/gems/1.8/bin/fog:19\n\nI believe this is stating that the returned value from Rackspace isn\'t JSON data which Fog is expecting to get.  The container is successfully created, but because the method fails it doesn\'t create the directory object within ruby.  That means that directory can\'t be used for transferring files.'
13,'',"Cannot run specs: undefined method `credentials' for Fog:Module\n<pre>\r\n$ sudo gem install shindo\r\n$ rake spec\r\n\r\n..../fog/lib/fog/aws/bin.rb:4: undefined method `credentials' for Fog:Module (NoMethodError)\r\n</pre>"
12,'','Wrapper for newservers\nnewservers.com look shiny (ezra mentioned them on twitter); plans to add them to fog? (no expectation; just wondering :)'
11,'','Fog fails miserably on s3 truncated responses with message "s3 bucket name(IsTruncated) is not a valid dns name"\nAs you surely know, amazon s3 will mention in response \'<isTruncated>true</isTruncated>\' if number of returned keys was more then max_keys (default 1000).\r\n\r\nIt looks like fog is not ready for that response and not only it makes it to fail request, but it also messes up some internal data structures in the process, so than even \'untruncated\' responses are no more understood.\r\n\r\nHere is a debug session (with some sensitive data removed to protect innocent).\r\n\r\n    >> fog = Fog::AWS::S3.new( :aws_access_key_id => Conf.aws_access_key_id, :aws_secret_access_key => Conf.aws_secret_access_key)\r\n    => #<Fog::AWS::S3::Real:0x31d079c @connection=#<Fog::Connection:0x31c9e24 ...\r\n    >> bucket = fog.directories.find { |o| o.key == \'dev-tmp.xxx.com\' }\r\n    =>   Fog::AWS::S3::Directory\r\n        key"dev-tmp.xxx.com",\r\n        creation_dateWed Sep 02 18:23:34 UTC 2009\r\n\r\n    >> bucket.files.all(:prefix => \'images/tiles/cache/providers/s36squares\')\r\n    =>   Fog::AWS::S3::Files\r\n        delimiternil,\r\n        directory    Fog::AWS::S3::Directory\r\n          key"dev-tmp.xxx.com",\r\n        ...\r\n\r\n    >> bucket.files.all(:prefix => \'images/tiles/cache/providers/s36squares\', :max_keys => 2)\r\n      [WARN] fog: the specified s3 bucket name(IsTruncated) is not a valid dns name.  See: http://docs.amazonwebservices.com/AmazonS3/latest/dev/index.html?Introduction.html\r\n    => nil\r\n    >> bucket.files.all(:prefix => \'images/tiles/cache/providers/s36squares\')\r\n      [WARN] fog: the specified s3 bucket name(IsTruncated) is not a valid dns name.  See: http://docs.amazonwebservices.com/AmazonS3/latest/dev/index.html?Introduction.html\r\n    => nil'
10,'',"declared dependency on ruby-hmac gem is causing trouble\nI am running in environments that have openssl version of HMAC available and I would much rather keep using it instead of 100% ruby implementation of hmac (ruby-hmac gem) - it is much faster.\r\n\r\nSee here: http://deisui.org/~ueno/ruby/hmac.html \r\nCitation: 'NOTE: If your apps can assume Ruby/OpenSSL available, consider using OpenSSL::HMAC instead.\r\n\r\nTo make it much worse, my project simply does not start when I add fog to it (and that pulls ruby-hmac as dependency). It crashes on startup with message: 'uninitialized constant HMAC::Base'.\r\nThat is happening because of name conflict between native version of HMAC and ruby one.\r\n\r\nThe easiest solution for this problem seems to be excluding ruby-hmac from list of gem dependencies. Those that need it, can still install it, while those that do not, can live without it."
9,'','Fog should be written in Haskell\nTake advantage of lazy String parsing, not silly SAX parsing.'
8,'',"Prettier printing\nFog, the IRB shell for it in particular, needs some prettier printing options. Using pp on most objects doesn't help much, unfortunately. Ideally, we'd have some nice columnized output, but I'd settle for just being able to get one attribute per line from pp to start with."
7,'',"Empty instances appearing in responses\nWhen getting a list back via AWS.servers, I'm occasionally seeing double the number of instances being reported back. There's one set of 'normal' instances, and another set with a whole bunch of nil values. This was most recently seen when looking at an account that had reached its instance limit, but I'm not sure if that's really related or not."
6,'','newly created Rackspace::Servers::Server forgets its password after wait_for { ready? }\nJust noticed this:\r\n\r\n    irb(main):053:0> server = Rackspace.servers.create(:flavor_id => 1, :image_id => 11, :name => \'test-server\')\r\n    => #<Fog::Rackspace::Servers::Server id=146118 addresses={"public"=>["REDACTED"], "private"=>["REDACTED"]} password="REDACTED" flavor_id=1 host_id="REDACTED" image_id=11 metadata={} name="REDACTED" personality=nil progress=nil status="BUILD">\r\n    irb(main):054:0> server.wait_for { ready? }\r\n    => nil\r\n    irb(main):055:0> server.password\r\n    => nil\r\n\r\nIt\'s a little unexpected, but it makes sense why it\'s happening. After each tick, the server is reloaded, and the way rackspace works is to only ever give you the password, and the subsequent calls omit it.\r\n\r\nAlthough, this might suggest a bug (or intended behavior?) in merge_attributes.'
5,'',"Rackspace.authenticate mentions ec2 in error messages\n    /gentoo/usr/lib/ruby/gems/1.8/gems/fog-0.0.40/lib/fog/rackspace.rb:13:in `authenticate': rackspace_api_key is required to access ec2 (ArgumentError)\r\n            from /gentoo/usr/lib/ruby/gems/1.8/gems/fog-0.0.40/lib/fog/rackspace/servers.rb:53:in `initialize'\r\n\r\nA quick patch is at technicalpickles@9085e617b5a79d99b460c1b937db58ba1246c655"
4,'',"creating EC2 security groups seem to require description\nGot this while trying to create a security group:\r\n\r\n    irb(main):022:0> AWS.security_groups.create(:name => 'fog-test')\r\n    NoMethodError: private method `gsub' called for nil:NilClass\r\n            from /gentoo/usr/lib/ruby/1.8/cgi.rb:342:in `escape'\r\n            from /gentoo/usr/lib/ruby/gems/1.8/gems/fog-0.0.40/lib/fog/aws/requests/ec2/create_security_group.rb:22:in `create_security_group'\r\n            from /gentoo/usr/lib/ruby/gems/1.8/gems/fog-0.0.40/lib/fog/aws/models/ec2/security_group.rb:45:in `save'\r\n            from /gentoo/usr/lib/ruby/gems/1.8/gems/fog-0.0.40/lib/fog/collection.rb:62:in `create'\r\n            from (irb):22\r\n            from /gentoo/usr/lib/ruby/gems/1.8/gems/fog-0.0.40/bin/fog:127\r\n            from /gentoo/usr/bin/fog:19:in `load'\r\n            from /gentoo/usr/bin/fog:19\r\n\r\nThis suggests that Fog::AWS::EC2::SecurityGroup authorize_group_and_owner needs `requires :description`."
3,'','Fog::AWS::EC2::Server seems to forget its group_id after it\'s ready\nI noticed that after an EC2 Server is created, it still knows its :group_id. However, after it is ready (ie server.wait_for { ready ? }), it becomes nil. It also is nil when I look at AWS.servers.\r\n\r\n    irb(main):028:0> server = AWS.servers.create(:image_id => \'ami-5059be39\', :group_id => \'sumo\', :key_name => \'sumo\')\r\n    => #<Fog::AWS::EC2::Server id="i-de4d48b6" ami_launch_index=0 availability_zone="us-east-1c" dns_name="" group_id="sumo" image_id="ami-5059be39" state="pending" flavor_id="m1.small" kernel_id="aki-714daa18" key_name="sumo" created_at=Thu Jan 21 17:52:59 UTC 2010 monitoring=false product_codes=[] private_dns_name="" ramdisk_id="ari-6a5bbc03" reason="" user_data=nil>\r\n    irb(main):029:0> server.wait_for { ready? }\r\n    => nil\r\n    irb(main):030:0> server.group_id\r\n    => nil\r\n    irb(main):031:0> AWS.servers.last\r\n    => #<Fog::AWS::EC2::Server id="i-de4d48b6" ami_launch_index=0 availability_zone="us-east-1c" dns_name="ec2-75-101-193-220.compute-1.amazonaws.com" group_id=nil image_id="ami-5059be39" state="running" flavor_id="m1.small" kernel_id="aki-714daa18" key_name="sumo" created_at=Thu Jan 21 17:52:59 UTC 2010 monitoring=false product_codes=[] private_dns_name="ip-10-243-123-19.ec2.internal" ramdisk_id="ari-6a5bbc03" reason="" user_data=nil>\r\n\r\n\r\n'
2,'',"AWS.servers.create does not seem to respect :group_id\nI'm using this as an example:\r\n\r\n    server = AWS.servers.create(:image_id => 'ami-5059be39', :group_id => 'sumo')\r\n    server.wait_for { ready? }\r\n\r\nI checked AWS console, but it seems that it uses the default security group."
1,'',"rdocinfo yard not rendering\nSubject: Re: fog [zapnap/rdocinfo GH-28]\r\n\r\nIt appears that fog's .document file is incorrect. It lists various patterns that are not actually present in the source repo -- such as files in the features directory, a license etc -- so yardoc is failing to generate. Fix (or remove) this and resubmit, and it should render fine.\r\n\r\nView this Discussion online: http://github.com/zapnap/rdocinfo/issues/28/find?comment=81720"
3289,'','Change architecture attribute in AWS::Compute::Server model\nchange `:architecture` from attr_accessor to attribute in `lib/fog/aws/models/compute/server.rb`'
3288,'',"Fog 1.25.0 gets Excon warning\nOur Amazon EC3 uploading seems to have broken as of the 1.25.0 release. Ruby 2.1.4 and Rails 4.1.8. The only message that comes up is this stack trace and warning from Excon.\r\n\r\nVersion-locking to 1.24.0 fixed the issue.\r\n\r\n```\r\n[excon][WARNING] Excon requests with a :request_block can not be :idempotent.\r\n/app/vendor/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/middlewares/idempotent.rb:7:in `error_call'\r\n/app/vendor/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n/app/vendor/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n/app/vendor/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/connection.rb:255:in `rescue in request'\r\n/app/vendor/bundle/ruby/2.1.0/gems/excon-0.41.0/lib/excon/connection.rb:203:in `request'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-core-1.25.0/lib/fog/core/connection.rb:63:in `request'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-xml-0.1.1/lib/fog/xml/connection.rb:9:in `request'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/storage.rb:521:in `_request'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/storage.rb:516:in `request'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/requests/storage/put_object.rb:31:in `put_object'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-1.25.0/lib/fog/aws/models/storage/file.rb:208:in `save'\r\n/app/vendor/bundle/ruby/2.1.0/gems/fog-core-1.25.0/lib/fog/core/collection.rb:50:in `create'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/storage/fog.rb:261:in `store'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/storage/fog.rb:80:in `store!'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/uploader/store.rb:59:in `block in store!'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/uploader/callbacks.rb:17:in `with_callbacks'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/uploader/store.rb:58:in `store!'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/mount.rb:375:in `store!'\r\n/app/vendor/bundle/ruby/2.1.0/gems/carrierwave-0.10.0/lib/carrierwave/mount.rb:207:in `store_file!'\r\n```\r\n\r\nLet me know if you need further details!"
3287,'',"Enabling logging on AWS:Storage throws error\nWhen using fog / lib / fog / aws / requests / storage / put_bucket_logging.rb for enabling logging on an s3 bucket, an error is thrown. The put_bucket_logging method references an undeclared variable called 'acl' in line 40:\r\n\r\n@storage.put_bucket_logging( bucket_name, logging_status )\r\n\r\n````\r\nin fog-1.25.0/lib/fog/aws/requests/storage/put_bucket_logging.rb:40\r\nundefined local variable or method `acl' for #<Fog::Storage::AWS::Real:0x007fac3ab05278>\r\n`````\r\n\r\n"
3285,'',"Libvirt VM creation: disk of file type regardless volume/pool type\nDue to libvirt /models /compute/templates/server.xml.erb, when creating a VM the disk attached is always of file type : \r\n```erb\r\n<% volumes.each do |vol| -%>\r\n    <disk type='file' device='disk'>\r\n      <driver name='qemu' type='<%= vol.format_type %>'/>\r\n      <source file='<%= vol.path %>'/>\r\n      <%# we need to ensure a unique target dev -%>\r\n      <target dev='vd<%= ('a'..'z').to_a[volumes.index(vol)] %>' bus='virtio'/>\r\n    </disk>\r\n<% end -%>\r\n```\r\n\r\nWhen the volume type is not file such as scsi or rbd, in my case, I get 'vol.path' file not found error from libvirt.\r\n\r\nTo get around it, replacing the code snippet to this (should be more generic?):\r\n```erb\r\n <% volumes.each do |vol| -%>\r\n    <disk type='volume' device='disk'>\r\n      <driver name='qemu' type='<%= vol.format_type %>'/>\r\n      <source  pool='<%= vol.pool_name' volume='<%= vol.name %>'/>\r\n      <%# we need to ensure a unique target dev -%>\r\n      <target dev='vd<%= ('a'..'z').to_a[volumes.index(vol)] %>' bus='virtio'/>\r\n    </disk>\r\n<% end -%>\r\n```\r\n\r\nAs far as I have tested, this works for file, block and network volumes.\r\n\r\nIt does not work in my scenario because libvirt does not support attaching disk from rbd pool yet.\r\n\r\nSo I had to add a condition to determine if the pool type is rbd and then provide specific disk configuration for attaching rbd volume. The problem with this is that I had to use to the name of the pool to tell if it's rbd type, which is not very clean. I also had to load specific rbd configuration from a rbd conf file that I added.\r\n\r\nIs there anyway that in 'server.xml.erb' template I can get something like <%= vol.pool_type %> ?\r\n\r\nWhat is the proper way to pass rbd specific configuration ?\r\n\r\nThanks in advance for any help with these questions and I would be happy to contribute to adapt the libvirt module so as to make it functional to every kind of volume."
3280,'',"ready? not working for Cloudstack\nif you create a server or volume, you should be able to call ready? to see if the new object is ready to be used.  Right now the ready method just checks a member variable which means that it stays as 'false' even after the vm/volume are ready to use.  Instead the method should get the job Id and then use connection.jobs.get(job_id) to get the current status of the job from Cloudstack."
3278,'','Add support for "Assume role with saml" in AWS\nSupport for AssumeRoleWithSAML:\r\nhttp://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithSAML.html\r\n\r\nThis one is a bit tricky as everything tends to be signed in fog, this STS command needs to work without being signed.\r\n\r\nTo do that the usual `:aws_access_key_id` and `:aws_secret_access_key` need to be optional.'
3260,'','Accessing tags on Fog::Compute::RackspaceV2::Server\nIs there a way to read the tags attached to a Fog::Compute::RackspaceV2::Server ?\r\n\r\nAs far as I can tell there is no way\r\n\r\nIt would also be good to assign tags too.'
3250,'','cloud_init support in ovirt\nthis pr brings cloud_init support for ovirt provider by means of providing a user_data hash upon starting of the vm.\r\nthe rbovirt related part is under review at https://github.com/abenari/rbovirt/pull/48'
3247,'','Disk Profile support (oVirt)\nAdded support to pull a list of all disk profiles from oVirt, and modified the volumes model, to allow disk profiles as an option. This branch requies the changes I made in the rbovirt branch of the same branch name.'
3238,'','Aliyun support\nIs there a plan for Aliyun in China? Aliyun provides cloud compute and storage resources like AWS does. I can help on that.'
3224,'',"AWS Cloudfront Requests/Models do not support MinimumProtocolVersion attribute - SSLv3 vs TLSv1\nListed on http://docs.aws.amazon.com/AmazonCloudFront/latest/APIReference/CreateDistribution.html and http://docs.aws.amazon.com/AmazonCloudFront/latest/APIReference/PutConfig.html\r\n\r\nRelates to http://en.wikipedia.org/wiki/POODLE - CloudFront defaults to SSLv3 being enabled for Dedicated IP on existing buckets.\r\n\r\nAWS Email sent to customers this week:\r\n\r\n--------------------------\r\n\r\nDear Amazon CloudFront Customer,\r\n\r\nWe'd like to provide you an update regarding our plans for continued support of SSLv3 in Amazon CloudFront due to the recently announced POODLE issue with SSL CVE-2014-3566: http://aws.amazon.com/security/security-bulletins/CVE-2014-3566-advisory/\r\n\r\nIf you are using the Dedicated IP Custom SSL Certificates to serve SSL traffic, you may configure whether your distribution accepts SSLv3 connections. We have added an option to select this in both the console and the API. For existing distributions that use Dedicated IP Custom SSL, the default value for this new setting will be to allow SSLv3, so you will need to update your distributions if you want to disallow SSLv3. We do recommend that customers disable SSLv3 if their use case allows it.\r\n\r\nAdditionally, starting on November 3rd, 2014, we will begin disabling SSLv3 for ALL customers who use SSL with the default CloudFront domain name (*.cloudfront.net). If you believe that this policy will negatively affect your website or application, please contact us as soon as possible so that we can discuss your options: https://aws.amazon.com/forms/poodle_sslv3\r\n\r\nIf you're using Custom SSL Certificates and Server Name Indication (SNI), you donât need to take any action because, as SNI-Only Custom SSL distributions already did not allow SSLv3 connections.\r\n\r\nThank you,\r\nThe Amazon CloudFront team\r\n\r\nAmazon Web Services, Inc. is a subsidiary of Amazon.com, Inc. Amazon.com is a registered trademark of Amazon.com, Inc. This message was produced and distributed by Amazon Web Services Inc., 410 Terry Ave. North, Seattle, WA 98109-5210"
3221,'','libvirt lxc support\nHello, I\'ve had a quick look at getting lxc support in the libvirt driver. I\'m no programmer, and have no experience with ruby. With the following changes I was able to create a lxc container using the libvirt driver. \r\n\r\nI would like to see lxc support in some fashion in the libvirt driver, hope this can help that happen.\r\n\r\n```diff\r\n# diff libvirt/models/compute/templates/server.xml.erb.lxc  libvirt/models/compute/templates/server.xml.erb\r\n9d8\r\n<     <init>\'<%= os_init %>\'</init>\r\n11a11,15\r\n>   <features>\r\n>     <acpi/>\r\n>     <apic/>\r\n>     <pae/>\r\n>   </features>\r\n13,15d16\r\n<   <on_poweroff>destroy</on_poweroff>\r\n<   <on_reboot>restart</on_reboot>\r\n<   <on_crash>destroy</on_crash>\r\n39a41,43\r\n>     <serial type=\'pty\'>\r\n>       <target port=\'0\'/>\r\n>     </serial>\r\n41c45\r\n<       <target type=\'lxc\' port=\'0\'/>\r\n---\r\n>       <target port=\'0\'/>\r\n42a47,52\r\n>     <input type=\'tablet\' bus=\'usb\'/>\r\n>     <input type=\'mouse\' bus=\'ps2\'/>\r\n>     <graphics type=\'<%= display[:type] %>\' port=\'<%= display[:port] %>\' autoport=\'yes\' <% if display[:listen] and !(display[:listen].empty?)  %> listen=\'<%= display[:listen] %>\'<% end %> <% if display[:password] and !(display[:password].empty?) %>passwd=\'<%=display[:password] %>\'<% end %> />\r\n>     <video>\r\n>       <model type=\'cirrus\' vram=\'9216\' heads=\'1\'/>\r\n>     </video>\r\n```\r\n\r\n```diff\r\n#diff libvirt/models/compute/server.rb libvirt/models/compute/server.rb.lxc \r\n15a16\r\n>         attribute :os_init\r\n361c362,363\r\n<             :os_type                => "hvm",\r\n---\r\n>             :os_type                => "exe",\r\n>             :os_init                => "/bin/init",\r\n363c365\r\n<             :domain_type            => "kvm",\r\n---\r\n>             :domain_type            => "lxc",\r\n```'
3217,'','Added XenServer server support for suspend and resume.\n'
3216,'','Added public_ip_address field to XenServer::Server class\nThe field ssh_ip_address in Fog::Compute::Server residing in fog-core expects it to be available.'
3214,'',"AWS China region\nI don't think I see `cn-north-1` references in fog yet.\r\n\r\nIt was announced Dec 2013 http://aws.amazon.com/blogs/aws/coming-soon-new-china-beijing-region/\r\n\r\nServices:\r\n\r\n```\r\nAmazon Elastic Compute Cloud (Amazon EC2)\r\nAmazon Elastic Block Store (Amazon EBS)\r\nAmazon Simple Storage Service (Amazon S3)\r\nAmazon Relational Database Service (Amazon RDS)\r\nAmazon DynamoDB\r\nAmazon Elastic MapReduce (Amazon EMR)\r\nAmazon Virtual Private Cloud (Amazon VPC)\r\nAmazon CloudWatch\r\nAWS CloudFormation\r\nAmazon Simple Queue Service (Amazon SQS)\r\nAmazon Simple Notification Service (Amazon SNS)\r\nAuto Scaling\r\nElastic Load Balancing\r\nAmazon Glacier\r\nAmazon Simple Workflow (SWF)\r\nAWS Identity and Access Management (IAM)\r\nAmazon ElastiCache\r\nAWS Storage Gateway\r\nAWS Management Console\r\nAWS Premium Support\r\n```"
3200,'','Fog::AWS::Compute::Real#describe_instances does not conform to the published query standards\nWhile working with an internal project aimed at providing an API compatible with with Amazon\'s, it was found that the  [Fog::AWS::Compute::Real#describe_instances](https://github.com/fog/fog/blob/master/lib/fog/aws/requests/compute/describe_instances.rb#L65-L67) method does not follow the published [query standards](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/Query-Requests.html#query-parameters) for Amazon Elastic Compute Cloud API.\r\n\r\nFrom the API Reference:\r\n\r\n```text\r\nSome operations take lists of parameters. These lists are specified using the param.n notation, \r\nwhere n is an integer starting from 1.\r\n```\r\n\r\nFrom the method mentioned above:\r\n\r\n```ruby\r\ninstance_ids.each_with_index do |id, index|\r\n  params.merge!("InstanceId.#{index}" => id)\r\nend\r\n```\r\n\r\nThis leaves the body of the request with an invalid query parameter `InstanceId.0`\r\n\r\nI can submit a pull-request if you feel this is something you you want to correct. Technically, I have zero issues using fog to talk directly to Amazon\'s API.'
3194,'',"Lazy Fog::Storage::OpenStack connection?\nI'm hitting a performance issue with Fog::Storage::Openstask which authenticates to the remote server as soon as it's initialized. The `auth_token` is indeed required when interacting with the storage, yet I often just need to generate signed URL to dowload private files, but these do require the `management_url` which is received along with the `auth_token` (to extract the scheme, host and port).\r\n\r\nI was wondering if it would be safe to provide these values or the `management_url` directly? That would enable us to have a lazy connection, which would only authenticate before making the first request. Or maybe there are reasons to not do that in the Swift protocol?"
3191,'','Adds openstack_region parameter to OpenStack Identity Service\nFixes #3184 \r\n'
3190,'','Homogenize error handling\nError handling differs a lot between providers in Fog. This is especially annoying when you develop with Fog and have to handle different providers, from the client side, it makes us impossible to rescue exceptions without having to look at each case. Part of what makes Fog a great library is that **centralized** \'API\' for all cloud resources. When everything works well, usually values returned are ```Excon``` responses and one can more or less trust that (I haven\'t tested all corner cases).\r\n\r\nI propose we take seriously error handling and homogenize error handling as much as possible. This requires Fog to provide an interface ```Fog::Errors``` with a few typical errors ```NotFound```, ```Unauthorized```, and make all providers return errors of the type ```Fog::Errors::ProviderName::ParticularError```, i.e: ```Fog::Errors::Openstack::Compute::NotEnoughResources```. Common errors should be raised through ```Fog::Errors``` should provide something already like I mentioned. (that\'s already in fog-core)\r\n\r\nFor instance:\r\n* Opennebula\r\n  * Fog::Errors::Error\r\n  * Fog::Compute::OpenNebula\r\n* Xen server\r\n  * Fog::Error\r\n  * Fog::XenServer\r\n* Linode\r\n  * Fog::Errors::Error , mostly\r\n  * string (```raise "whatever error"```)\r\n  * Exception\r\n* HP\r\n  * Fog::Errors::Error\r\n  * Fog::HP::(LB/DNS/BlockStorage/Network/HPV2)\r\n* Cloudstack\r\n  * Fog::Compute::Cloudstack\r\n* Google compute engine\r\n  * Raises strings...\r\n* Rackspace\r\n  * Fog::Rackspace\r\n  * Fog::Compute::Rackspace\r\n* Openstack\r\n  * Fog::(Compute | Network)::Openstack\r\n\r\nand the list could go on and on. I think the only provider that is doing consistent error handling generalized for Fog is DigitalOcean and almost Linode. Openstack and AWS handle errors well but if you are developing for both platforms you cannot generally rescue errors for both. There are some providers like Docker (I\'m working on fixing it, that\'s how I found this) that don\'t even pass errors up the stack.\r\n  \r\nWould this be a welcome change? I\'m willing to work on this to some extent, that is, rescuing errors in this fashion where they are already rescued, I cannot take a look at all APIs to see which ones are actually hiding errors.'
3186,'',"adding support for network interfaces and public IP association (non-default VPCs) for EC2 spot instances\nAs per subject. There were no tests around this stuff right now, and no mocks. I don't feel super confident implementing them myself without some coaching though... let me know if this is an issue."
3184,'','Fog::Identity.new(provider: Openstack... fails. Need guidance for Testcase.\nHello\r\nWhen I tried to connect with Fog::Identity.new(provider: \'Openstack\' ... to our Keystone Instance which has different regions it failed. When adding the attribute :openstack_region I got the Warning "[fog][WARNING] Unrecognized arguments: openstack_region" so I added the followin lines of code to ./lib/fog/openstack/identity.rb and now it works.\r\n\r\n```ruby\r\nLine 7:      recognizes :openstack_auth_token, :openstack_management_url, :persistent,\r\n                 :openstack_service_type, :openstack_service_name, :openstack_tenant,\r\n                 :openstack_api_key, :openstack_username, :openstack_current_user_id,\r\n                 :current_user, :current_tenant,\r\n                 :openstack_region,\r\n                 :openstack_endpoint_type\r\n...\r\nLine 178   @openstack_region   = options[:openstack_region]\r\n...\r\nLine 265  :openstack_region => @openstack_region,\r\n\r\n```\r\n\r\n I read your guidelines for contributing and that I\'d have to write a testcase. Thing is I have no clue where I should put the testcase for that missing attribute. If you could guide me where to put the testcase I will send a pullrequest.\r\n\r\nThank you \r\n- Renato'
3183,'',"Accessors to get credentials from AWS::Storage\nI'm not sure this is the best way, but in my code I have an instance of `Fog::AWS::Storage::Real` and I need to somehow extract AWS credentials from this object."
3179,'',"[vcloud_director] Independent disk attachment prevents local disk attachment\nLeaving this issue as a note to myself to investigate further, but I have noticed that after attaching an independent disk via the post_upload_disk (sic) call, it is no longer possible to add local disks via the Model vm.disks operations.\r\n\r\nThis *might* be a limitation of vCloud Director, but I suspect it's down to assumptions made in the VM model.\r\n\r\n"
3165,'',"Why are the credential keys not generalized?\nWe're currently implementing `fog` in one of our applications and were surprised to find that all of the credential keys for each service are specific to that service.\r\n\r\nI would have thought that I'd be able to set something like:\r\n\r\n```\r\nSTORAGE_PROVIDER=AWS\r\nSTORAGE_USERNAME=foo\r\nSTORAGE_PASSWORD=bar\r\n```\r\n\r\nAnd in my code do something like:\r\n\r\n```ruby\r\n    @connection ||= Fog::Storage.new(\r\n      provider: ENV['STORAGE_PROVIDER'],\r\n      username: ENV['STORAGE_USERNAME'],\r\n      password: ENV['STORAGE_PASSWORD'])\r\n```\r\n\r\nConsidering the point of fog is that you can abstract away your cloud providers, then theoretically changing it shouldn't require a code change.\r\n\r\nPlease let me know if I'm misunderstanding.\r\n\r\nThanks for all the hard work on this!"
3156,'',"Sakuracloud changes have broken require / incorrect dependencies\nAs of e8a9ecaf7d6616b8031b68657a5c911c5c7fcc30...\r\n\r\n```\r\n$ bundle exec fog\r\n/Users/paul/code/fog/lib/fog/bin.rb:84:in `require': cannot load such file -- fog/bin/sakuracloud (LoadError)\r\n\tfrom /Users/paul/code/fog/lib/fog/bin.rb:84:in `<top (required)>'\r\n\tfrom /Users/paul/code/fog/bin/fog:37:in `require'\r\n\tfrom /Users/paul/code/fog/bin/fog:37:in `<top (required)>'\r\n\tfrom /Users/paul/.gem/ruby/2.1.2/bin/fog:23:in `load'\r\n\tfrom /Users/paul/.gem/ruby/2.1.2/bin/fog:23:in `<main>'\r\n```"
3150,'','fix mock to reality\nhvm based images can not have a digit at end of device name. AWS throws\r\nan error. mock needs to reflect reality.\r\n\r\nPR is WIP:\r\n\r\n- [ ] need to figure out how to determine if a instance is hvm?\r\n- [ ] need to integrate test (at least manually) to verify mock behavior etc.'
3140,'','Add support for cname buckets\nAs per http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html#VirtualHostingCustomURLs'
3139,'nirvdrum',"[vsphere] new default dest_folder in vm_clone\nfixes fog/fog#3134\r\n\r\nWe want to allow someone to not set the dest_folder option because they\r\nmight not have a desired folder structure and not care. In case they\r\nfollow common examples and use a folder called 'templates/' for templates\r\nwe don't want to create the new vm in that folder. It is better to\r\ndefault to the root folder.\r\n\r\nConflicts:\r\n\tlib/fog/vsphere/requests/compute/vm_clone.rb"
3137,'',"Fog::Local::File not safe for concurrent use\nHi, we've run in to issues using Fog as a local blobstore from multiple concurrent clients. Specifically the [`.save` method](https://github.com/fog/fog/blob/master/lib/fog/local/models/storage/file.rb#L99) creates parent directories (**ab/cd**/abcd-efgh-ijkl) only if they don't exist before the file is saved. This is fine, but if another file with the same first four characters in its key is being deleted at the same time those directories can [get deleted](https://github.com/fog/fog/blob/master/lib/fog/local/models/storage/file.rb#L64) before the actual  save happens. When this occurs we get an `ENOENT - No such file or directory` error (and it does seem to occur reasonably frequently under real load).\r\n\r\nI'm not sure whether Local::File is supposed to be thread-safe or to work for concurrent access from more than one process, or whether we should expect to have to work around these issues at a higher level. Please let us know if you think you would accept a PR to fix the code here to be resilient to concurrent deletes and saves. Thanks! "
3136,'','added requests files for linode image and linode disk api calls\n'
3131,'',"[Linode] add Images support\nLinode has support for snapshotting and deploying from custom Images now: https://www.linode.com/api/image\r\n\r\nI would like to [contribute support](https://github.com/displague/fog/compare/fog:master...more_linode_support) for this but I am struggling with how to deal with the fact that linode.images is already present in fog -- with the current implementation dealing with Linode's [deployable](https://www.linode.com/api/linode/linode.disk.createfromdistribution) [distribution images](https://www.linode.com/api/utility/avail.distributions).\r\n\r\nWe obviously don't want to rewrite history and change the existing fog calls.  Do the new images need a new namespace?  Can they share the old namespace and use parameters to distinguish which type of images should be used?\r\n\r\n"
3123,'','[openstack] deprecate namespaced params\nThis normalizes all of the class options for the openstack provider by removing the prepended "openstack_" string to all config parameters.\r\n\r\nWhen developing tooling for a multi-cloud environment (e.g. openstack and aws), the goal should be to abstract away differences between cloud providers. This is not possible when each fog provider has chosen to add provider-specific nomenclature to their configuration parameters.\r\n\r\nWhen I specify "region", it should be implied that it means "region" in whatever provider I\'ve instantiated. I shouldn\'t have to add complexity to my code to say "In the AWS case, the param is called "region", but in the OpenStack case, it\'s called "openstack_region".\r\n\r\nThis pull request is aimed at fixing this issue.'
3122,'','[openstack] support filtering in list servers mock\nMake the mocking for openstack closer to reality'
3121,'nirvdrum','[vsphere] find network by name and dvswitch\ngiven a name and a switch name\r\nor just a name and whether a dvs is desired\r\nor just a name\r\n\r\nWhen you just want the first (or only) distributed virtual switch on a given cluster, you for example call `get_raw_network(name, datacenter_name, true)` This enables a network admin to choose where a new machine will be placed on the network by moving a network to a distributed virtual switch or non distributed virtual switch.'
3117,'nirvdrum',"[vsphere] get resource pool without name\nThis appears to be the best way to allow cloning into a chosen cluster which is not using any resource pools. Luckily the cluster is able to return a default resource pool. I have this working with vsphere 5.1 and rbvmomi 1.6.0.\r\nThe option to the vm_clone method would look like this `'resource_pool' => ['cluster5', nil]`"
3115,'','Bring AWS CloudFront API Models/Requests up to date\nHeaps of missing functionality, specifically around the use of Price Classes, Custom/Dedicated SSL certificates, etc.\r\n\r\nCurrent API version is 3~ years behind, has some authentication breakage when you try and just change the version to 2014-05-31:\r\n\r\n```\r\n response => #<Excon::Response:0x007f991daab9b0 @data={:body=>"<?xml version=\\"1.0\\"?>\\n<ErrorResponse xmlns=\\"http://cloudfront.amazonaws.com/doc/2014-01-31/\\"><Error><Type>Sender</Type><Code>IncompleteSignature</Code><Message>Authorization header requires \'Credential\' parameter. Authorization header requires \'Signature\' parameter. Authorization header requires \'SignedHeaders\' parameter.\r\n```'
3114,'',"Exception raised in Google#get_target_pool_health when instance is terminated\nGoogle instances can be terminated, yet still in a Target Pool.  A `Fog::Errors::Error` exception is raised as 'resource is not ready', which prevents you from getting health for all other instances in that Target Pool.\r\n\r\nHere's how I'm calling Target Pool `#get_health`\r\n```\r\n  if (t = load_balancers.target_pools.get(n)) && t.get_health.any?\r\n          Hash[*t.get_health.map{|i, h|\r\n                 i = i.split_link if split\r\n                 [i, {:state => h.first['healthState'], :ip_address => h.first['ipAddress'] }]\r\n               }.flatten]\r\n  end\r\n```\r\n\r\nAnd the backtrace\r\n```\r\n#<Fog::Errors::Error: The resource 'projects/<PROJECT>/zones/us-central1-b/instances/<INSTANCE>' is not ready>\r\n/Users/dacamp/.rvm/gems/ruby-2.0.0-p481/gems/fog-1.23.0/lib/fog/google/compute.rb:179:in `build_excon_response'\r\n/Users/dacamp/.rvm/gems/ruby-2.0.0-p481/gems/fog-1.23.0/lib/fog/google/compute.rb:959:in `build_response'\r\n/Users/dacamp/.rvm/gems/ruby-2.0.0-p481/gems/fog-1.23.0/lib/fog/google/requests/compute/get_target_pool_health.rb:21:in `block in get_target_pool_health'\r\n/Users/dacamp/.rvm/gems/ruby-2.0.0-p481/gems/fog-1.23.0/lib/fog/google/requests/compute/get_target_pool_health.rb:19:in `map'\r\n/Users/dacamp/.rvm/gems/ruby-2.0.0-p481/gems/fog-1.23.0/lib/fog/google/requests/compute/get_target_pool_health.rb:19:in `get_target_pool_health'\r\n/Users/dacamp/.rvm/gems/ruby-2.0.0-p481/gems/fog-1.23.0/lib/fog/google/models/compute/target_pool.rb:79:in `get_health'\r\n```"
3099,'','Update Nokogiri version from 1.5.11 to 1.6\nAre there any plans to upgrade Nokogiri to version 1.6?\r\n\r\nI have forked fog and upgraded nokogiri to 1.6 and all seems to be working. Should I put this in as PR or are there other considerations I haven\'t thought about?\r\n\r\nFrom the Nokogiri change logs (1.6.0.rc1):\r\n\r\n"Ruby 1.9.2 and higher now required"\r\n"Support for Ruby 1.8.7 and prior has been dropped"\r\n\r\nIs this a problem?'
3098,'',"Fixed incorrect docs for using tags for autoscaling groups\nTags previously recommended using an array but each_with_index didn't\r\nwork properly. Previously it would jumble all your hash into a value if\r\nyou used this inline documentation."
3087,'','Rackspace get_object_https_url should never return servicenet URL\nThe code in lib/fog/rackspace/requests/storage/get_object_https_url.rb generates an expiring "TempUrl". The entire point of this is to grant temporary public access to private files. If, however, the server using Fog is located at Rackspace and configured with ```:rackspace_servicenet => true``` (to use the faster internal network) then get_object_https_url returns a servicenet URL, e.g. "https://snet-storage101.ord1.clouddrive.com/v1/MossoCloudFS_[etc]".\r\n\r\nSince a Rackspace domain name starting with "snet-" cannot ever be used external to Rackspace, this defeats the purpose of get_object_https_url. I would argue that get_object_https_url should ignore the ```:rackspace_servicenet => true``` configuration option and return an externally-accessible URL.'
3086,'','[AWS] Add support for Amazon Kinesis\n[Amazon Kinesis](http://aws.amazon.com/kinesis/) '
3084,'','Domain support in Identity v3\nWith the Identity v2.0 API marked as deprecated in Icehouse (alltho reverted after release), cloud providers are starting to require using the v3 API to authenticate.\r\n\r\nThis is needed to support domains, to achieve full multi-tenancy in public clouds.\r\n\r\nThe v2.0 API seems to be scheduled for removal in the Kilo release next year.\r\n\r\nPlease look into supporting v3 and domains.\r\n\r\nDocumentation for the v3 API:\r\n* http://api.openstack.org/api-ref-identity-v3.html\r\n\r\nAviator support for v3 API:\r\n* https://github.com/aviator/aviator/blob/master/lib/aviator/openstack/identity/requests/v3/public/create_token.rb'
3083,'',"Image create example for Google is broken\nI'm using https://github.com/fog/fog/blob/master/lib/fog/google/examples/image_create.rb as a template. Specifically, at least two different issues:\r\n\r\nFirst, `connection.image.create` should be `connection.images.create` -- trivial fix\r\n\r\nSecond, `connection.images.create` fails with:\r\n\r\n```\r\n/home/diwaker/.rvm/gems/ruby-2.0.0-p195@mgt_console/gems/fog-1.23.0/lib/fog/google/compute.rb:179:in `build_excon_response': Invalid value for field 'image.hasRawDisk': 'false'.  (Fog::Errors::Error)\r\n        from /home/diwaker/.rvm/gems/ruby-2.0.0-p195@mgt_console/gems/fog-1.23.0/lib/fog/google/compute.rb:959:in `build_response'\r\n        from /home/diwaker/.rvm/gems/ruby-2.0.0-p195@mgt_console/gems/fog-1.23.0/lib/fog/google/requests/compute/get_global_operation.rb:21:in `get_global_operation'\r\n        from /home/diwaker/.rvm/gems/ruby-2.0.0-p195@mgt_console/gems/fog-1.23.0/lib/fog/google/models/compute/operations.rb:27:in `get'\r\n        from /home/diwaker/.rvm/gems/ruby-2.0.0-p195@mgt_console/gems/fog-1.23.0/lib/fog/google/models/compute/image.rb:79:in `save'\r\n        from /home/diwaker/.rvm/gems/ruby-2.0.0-p195@mgt_console/gems/fog-core-1.23.0/lib/fog/core/collection.rb:51:in `create'\r\n```"
3082,'','Easier retry/idempotent logic\nJust throwing an idea out there...\r\n\r\n> To retry or not to retry; that is the 4th [hard question of CS](http://martinfowler.com/bliki/TwoHardThings.html)\r\n\r\nOr is it? Excon supports an :idempotent flag and I\'ve thought about going through the rackspace and/or openstack providers and marking things as idempotent. But, it\'s tedious to mark each service when there\'s a pretty clear pattern at [restcookbook.com](http://restcookbook.com/HTTP%20Methods/idempotency/):\r\n\r\n<table style="margin: 3em">\r\n    <tbody><tr><th>HTTP Method</th><th>Idempotent</th><th>Safe</th></tr>\r\n    <tr><td>OPTIONS    </td><td>yes       </td><td>yes</td></tr>\r\n    <tr><td>GET        </td><td>yes       </td><td>yes</td></tr>\r\n    <tr><td>HEAD       </td><td>yes       </td><td>yes</td></tr>\r\n    <tr><td>PUT        </td><td>yes       </td><td>no </td></tr>\r\n    <tr><td>POST       </td><td>no        </td><td>no </td></tr>\r\n    <tr><td>DELETE     </td><td>yes       </td><td>no </td></tr>\r\n    <tr><td>PATCH      </td><td>no        </td><td>no </td></tr>\r\n</tbody></table>\r\n\r\nI\'d be interested in an easier way to just set all "safe" and/or "idempotent" methods in the table above to retry. It could be as simple as setting the default value of the :idempotent flag based on the HTTP method, though I think having "safe_retry", "idempotent_retry" and "unsafe_retry" callbacks on a connection might be even better.\r\n\r\nAnyone else think that would be useful or is it just me?'
3075,'',"SSL Error on S3 connection\nI'm getting an error with S3 at the moment. If I set up a connection (using my key + secret, eu-west-1) such that `connection` is an instance of Fog::Storage::AWS::Real, then do \r\n\r\n`puts connection.directories.to_a`, I get an array of directory objects, as expected.\r\n\r\nHowever, if I try:\r\n\r\n`p connection.directories.to_a` or `puts connection.directories`\r\n\r\nI get the error details in the below trace, after a long delay.\r\n\r\nAny idea why this is happening?\r\n```\r\n/home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/ssl_socket.rb:105:in `connect_nonblock': SSL_connect SYSCALL returned=5 errno=0 state=SSLv2/v3 read server hello A (OpenSSL::SSL::SSLError) (Excon::Errors::SocketError)\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/ssl_socket.rb:105:in `block in initialize'\r\n\tfrom /usr/lib/ruby/2.1.0/timeout.rb:91:in `block in timeout'\r\n\tfrom /usr/lib/ruby/2.1.0/timeout.rb:35:in `block in catch'\r\n\tfrom /usr/lib/ruby/2.1.0/timeout.rb:35:in `catch'\r\n\tfrom /usr/lib/ruby/2.1.0/timeout.rb:35:in `catch'\r\n\tfrom /usr/lib/ruby/2.1.0/timeout.rb:106:in `timeout'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/ssl_socket.rb:101:in `initialize'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:414:in `new'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:414:in `socket'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:126:in `request_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/mock.rb:44:in `request_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/instrumentor.rb:22:in `request_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:15:in `request_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:15:in `request_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:15:in `request_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:269:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/idempotent.rb:12:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:292:in `rescue in request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:229:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/idempotent.rb:12:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:292:in `rescue in request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:229:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/idempotent.rb:12:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/middlewares/base.rb:10:in `error_call'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:292:in `rescue in request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/excon-0.38.0/lib/excon/connection.rb:229:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-1.23.0/lib/fog/xml/sax_parser_connection.rb:35:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-1.23.0/lib/fog/xml/connection.rb:17:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-1.23.0/lib/fog/aws/storage.rb:535:in `request'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-1.23.0/lib/fog/aws/requests/storage/get_service.rb:21:in `get_service'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-1.23.0/lib/fog/aws/models/storage/directories.rb:11:in `all'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-core-1.23.0/lib/fog/core/collection.rb:139:in `lazy_load'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-core-1.23.0/lib/fog/core/collection.rb:15:in `empty?'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-core-1.23.0/lib/fog/core/collection.rb:84:in `block in inspect'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/formatador-0.2.5/lib/formatador.rb:92:in `indent'\r\n\tfrom /home/iain/.gem/ruby/2.1.0/gems/fog-core-1.23.0/lib/fog/core/collection.rb:77:in `inspect'\r\n```"
3073,'','@server.scp() hangs sporadically\nI have a script to bootstrap an instance and then scp a bunch of files to the new instance to set up our environment.  The bootstrap part works ok, but about 3 times out of 5, my scp()s hang:\r\n\r\n```ruby\r\n@server = @connection.servers.bootstrap(\r\n:image_id => \'...\',\r\n:flavor_id => \'m3.large\',\r\n:private_key_path => \'...\',\r\n:username => \'ubuntu\' \r\n)\r\n@server.scp( "/usr/local/bin/bootstrap-testrunner", "/tmp" )\r\n```\r\n\r\nThat scp() hangs, and when I abort, I get:\r\n\r\n```\r\n^C^C/usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/ruby_compat.rb:30:in `select\': Interrupt\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/ruby_compat.rb:30:in `io_select\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/connection/session.rb:209:in `process\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/connection/session.rb:169:in `block in loop\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/connection/session.rb:169:in `loop\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/connection/session.rb:169:in `loop\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-ssh-2.9.1/lib/net/ssh/connection/session.rb:118:in `close\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-scp-1.2.1/lib/net/scp.rb:210:in `ensure in start\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/net-scp-1.2.1/lib/net/scp.rb:210:in `start\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/fog-core-1.23.0/lib/fog/core/scp.rb:71:in `upload\'\r\n\tfrom /usr/local/lib/ruby/gems/1.9.1/gems/fog-core-1.23.0/lib/fog/compute/models/server.rb:75:in `scp\'\r\n\tfrom /usr/local/bin/boot-testrunner:69:in `copy_bootstrap_files\'\r\n\tfrom /usr/local/bin/boot-testrunner:110:in `<main>\'\r\n```\r\n\r\nIf I do the scp on the command line from the "host" to the new instance, it works fine.\r\n\r\n<pre>\r\nroot@test:~# ruby -v\r\nruby 1.9.3p448 (2013-06-27 revision 41675) [x86_64-linux]\r\nroot@test:~# gem list\r\n\r\n*** LOCAL GEMS ***\r\n\r\nbigdecimal (1.1.0)\r\nbuilder (3.2.2)\r\nbundler (1.6.5)\r\nexcon (0.38.0)\r\nfog (1.23.0)\r\nfog-brightbox (0.1.1)\r\nfog-core (1.23.0)\r\nfog-json (1.0.0)\r\nfog-softlayer (0.3.11)\r\nformatador (0.2.5)\r\ninflecto (0.0.2)\r\nio-console (0.3)\r\nipaddress (0.8.0)\r\njson (1.5.5)\r\nmime-types (2.3)\r\nmini_portile (0.6.0)\r\nminitest (2.5.1)\r\nmulti_json (1.10.1)\r\nnet-scp (1.2.1)\r\nnet-ssh (2.9.1)\r\nnokogiri (1.6.3.1)\r\nrake (0.9.2.2)\r\nrdoc (3.9.5)\r\n</pre>'
3071,'','[openstack] add block_device_mapping_v2\nfix block_device_mapping_v2\r\n\r\nhttp://docs.openstack.org/api/openstack-compute/2/content/POST_block_device_mapping_v2_createServer__v2__tenant_id__servers_ext-os-block-device-mapping-v2-boot.html'
3068,'',"Atmos chunked transfers don't work\nAtmos files.get and file.save do not work. \r\nI think this is because of chunking. I can fix the files.get by enabling a block to be passed to get_namespace but uploading requires a bit more thought I think.\r\nIs anyone interested in helping to fix this? I can provide a test account on Atmos and some basic coding assistance.\r\n\r\n"
3061,'','[openstack] evacuate server implementation\nEvacuate server to make them available again on different host. \r\n\r\nSupports onSharedStorage, adminPassword options. '
3054,'','[AWS|Compute] Add security group egress rules\nAdd the ability to authorize and revoke egress rules in addition to ingress rules on AWS VPC.'
3038,'','Feature/improved network flavor models\nHi, \r\n\r\nwe improved the OpenNebula network and flavor models. \r\n\r\n- added get_by_name for the network model\r\n- identify the network within a flavor by id or name (OpenNebula allows name or id as identifying attribute)\r\n- added mocks and tests\r\n\r\nKind regards,\r\nb0e'
3029,'','[google|compute] Incorrect arguments for some operations.get calls causes exceptions\nThe recent update to google/models/compute/target_pool.save and google/models/compute/forwarding_rule.save pass operations.get incorrect arguments which in turn throws an error when wait_for is called on a nil object. My colleague or I will be submitting a pull request soon to fix this'
3021,'','AWS Launch Configuration missing Ebs.Volume_Type\nHi,\r\n\r\nThe AWS Autoscaling Launch Configuration object is missing the volume type attribute for creating and describing.  It should be part of the block_device_mappings.'
3019,'','virtualization-type is missing from Fog::Compute::AWS::Image model response.\nThere looks to be a mapping in lib/fog/aws/requests/compute/describe_images.rb for:\r\n\r\n\'virtualization-type\' => \'virtualizationType\'\r\n\r\nBut it doesn\'t look to be part of the model result?\r\n\r\nhttp://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeImages.html\r\n\r\n      <virtualizationType>paravirtual</virtualizationType>\r\n\r\nRunning fog 1.22.1 / fog-core 1.22.0\r\n\r\nExample:\r\n\r\n```\r\n   <Fog::Compute::AWS::Image\r\n    id="ami-fd2954cd",\r\n    architecture="x86_64",\r\n    block_device_mapping=[{"deviceName"=>"sdb", "virtualName"=>"ephemeral0"}, {"deviceName"=>"sdc", "virtualName"=>"ephemeral1"}],\r\n    description=nil,\r\n    location="s3_bucket_name/image.manifest.xml",\r\n    owner_id="xxxxxxx",\r\n    owner_alias=nil,\r\n    state="available",\r\n    type="machine",\r\n    is_public=false,\r\n    kernel_id="aki-xxxxxxxx",\r\n    platform=nil,\r\n    product_codes=[],\r\n    ramdisk_id=nil,\r\n    root_device_type="instance-store",\r\n    root_device_name="/dev/sda1",\r\n    tags={"Name"=>"ami_name"},\r\n    name="AMI Name"\r\n  >]\r\n```'
3016,'','[openstack|volume] update volume to pass availability zone on volume create\nThis PR is an attempt to fix issue https://github.com/fog/fog/issues/3011.\r\n\r\nCreate volume requests should now pass `availability_zone` as well as `source_volid`.'
3015,'',"[cloudstack] Add support for project apis.\nCurrently fog doesn't support the different project apis listed here:\r\nhttps://cloudstack.apache.org/docs/api/apidocs-4.3/TOC_Root_Admin.html\r\n\r\n"
3014,'','add endpoints and services support to openstack identity service\nI have added requests and models for service and endpoint using OpenStack Identity API'
3011,'',"availability zone is ignored when creating volume\nIt seems that Fog ignores the value of the availability_zone parameter when creating OpenStack volumes. In https://github.com/fog/fog/blob/master/lib/fog/openstack/models/compute/volume.rb line 28 I would expect this argument to be passed to the create_volume call, but it's not. \r\n\r\nIf this is by design, for example because there are problems with the OpenStack API when using this feature, it should be documented; but I would currently consider this a bug."
2998,'',"[hp] reauthenticate\nThe current hp (storage) provider doesn't support token expiration.\r\n\r\n\r\nWe have a token expiration time of around ~50 minutes when using our Swift service.\r\nAfterwards the fog gem will throw an exception.\r\n\r\nhttp://docs.openstack.org/api/quick-start/content/\r\n```\r\n2. Send API requests and include the token in the X-Auth-Token header. Continue to send API requests with that token until the job completes or a 401 Unauthorized error occurs.\r\n3. If the 401 Unauthorized error occurs, request another token.\r\n```\r\n\r\nThis PR fixes the hp (storage) provider.\r\n\r\nWhen creating the request it's important the original `params` won't be modified so that the `retry` will work."
2993,'',"including source_volid data in request for cloning\nIt would be useful to automate cloning of volumes. It's simply allowing another data point through the request. 'source_volid' is supported in Rackspace API. http://docs.rackspace.com/cbs/api/v1.0/cbs-devguide/content/POST_createVolume_v1__tenant_id__volumes_volumes.html"
2992,'','[vcloud_director] VM Network adapters\n- adding attribute on VM(s) to hold nics\r\n- DRYing up vms and vm parsers'
2991,'',"[vcloud_director] Fix VM Customization 400 \nThe AdminPassword XML element isn't present unless AdminPasswordEnabled but the API on the other end expects it to be set."
2986,'mwhagedorn','tests/hp/block_storage_tests.rb fails without network connection\nThere are 5 failing tests such as:\r\n\r\n```\r\n  \r\n  Fog::HP::BlockStorage (hp, blockstorage)\r\n    Test good credentials + returns {:auth_token=>"auth_token", :endpoint_url=>"http://127.0.0.1/bpath/", :service_catalog=>{:"Block Storage"=>{:zone=>"http://127.0.0.1/bpath/"}}, :expires=>"2014-06-10T16:42:17+02:00"}\r\n    Test expired credentials\r\n      - raises Excon::Errors::Unauthorized\r\n      getaddrinfo: Name or service not known (SocketError) (Excon::Errors::SocketError)\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/socket.rb:181:in `getaddrinfo\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/socket.rb:181:in `connect\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/ssl_socket.rb:131:in `connect\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/socket.rb:28:in `initialize\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/ssl_socket.rb:9:in `initialize\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/connection.rb:414:in `new\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/connection.rb:414:in `socket\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/connection.rb:126:in `request_call\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/middlewares/mock.rb:42:in `request_call\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/middlewares/instrumentor.rb:22:in `request_call\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/middlewares/base.rb:15:in `request_call\'\r\n        /usr/share/gems/gems/excon-0.33.0/lib/excon/connection.rb:269:in `request\'\r\n        /usr/share/gems/gems/fog-core-1.22.0/lib/fog/core/connection.rb:56:in `request\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/lib/fog/xml.rb:24:in `request\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/lib/fog/hp/core.rb:198:in `authenticate_v2\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/lib/fog/hp/block_storage.rb:121:in `initialize\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/tests/hp/block_storage_tests.rb:26:in `new\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/tests/hp/block_storage_tests.rb:26:in `block (3 levels) in <top (required)>\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:132:in `instance_eval\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:132:in `assert\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:108:in `raises\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/tests/hp/block_storage_tests.rb:26:in `block (2 levels) in <top (required)>\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:79:in `instance_eval\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:79:in `tests\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/tests/hp/block_storage_tests.rb:24:in `block in <top (required)>\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:79:in `instance_eval\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:79:in `tests\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:38:in `initialize\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:13:in `new\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo.rb:13:in `tests\'\r\n        /builddir/build/BUILD/rubygem-fog-1.22.0/usr/share/gems/gems/fog-1.22.0/tests/hp/block_storage_tests.rb:3:in `<top (required)>\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo/bin.rb:61:in `load\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo/bin.rb:61:in `block (2 levels) in run_in_thread\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo/bin.rb:58:in `each\'\r\n        /usr/share/gems/gems/shindo-0.3.8/lib/shindo/bin.rb:58:in `block in run_in_thread\'\r\n```\r\n\r\nThey fails when the host cannot be resolved, e.g. when /etc/resolv.conf is not available. This is default configuration for Fedora build infrastructure.\r\n\r\nAlthouhg not a show stopper, I would appreciate if this could be fixed.'
2985,'',"RiakCS ACL \n### Disclaimer\r\n\r\nThis is my first public contribute to the community and I'm not native english, so, please, help me if I'm doing something wrong. Thanks. ;-)\r\n\r\n### Problem\r\n\r\nI have a problem with `put_bucket_acl` and I can't figure if it's a bug or it's related to my config.\r\n\r\nAfter PUT, grantee ID and DisplayName are set to nil but Permission is correctly updated. Removing the new lines and with spaces from body solved the problem.\r\n\r\n[Here](https://github.com/panteo/fog/commit/663f922a65814f37ef9e495aa9aae6bba10f9bf9) it is my patch.\r\n\r\n### About my config (One RiakCS server)\r\n\r\nOS: Ubuntu 14.04 LTS x86_64\r\nKernel: 3.13.0-27-generic\r\nRiakCS: 1.4.5-1\r\nRiak: 1.4.9-1\r\nNginx: 1.4.6-1ubuntu3\r\nProtocol: HTTPS with valid wildcard certificate"
2981,'',"[google|compute] Remove hard-coded /projects/google/\n@icco - We're going to be getting rid of /projects/google which fog primarily uses for looking up images.  It only houses deprecated images now, so I'll send along a PR to pull that out of the image search."
2974,'','vSphere - fog lacks ability to fetch volume by ID\nAs per @nirvdrum Fog currently lacks the ability to fetch a volume by ID, so we need to fetch all volumes for all servers to find the volume we want.  This is terribly inefficient and fog should be updated.'
2971,'','Implement orchestration models\nAdds orchestration models for AWS and RS. Still a WIP. Looking for feedback. Related to/dependent on: https://github.com/fog/fog-core/pull/45'
2969,'','[vcloud_director] Add post_compose_vapp and post_recompose_vapp\n@mikepea, and the last one to compose vApps.'
2961,'','Support Rackspace next link in user list\nThis is a fix for issue https://github.com/fog/fog/issues/2960 allowing for more than 20 cloud database instance users to be returned by the API'
2960,'',"Rackspace Databases User List Incomplete\nWhether it was a change to Rackspace's API or the Cloud Databases integration was never tested against an instance with more than 20 users, when retrieving a list of all the users in a database instance, Fog only returns the first 20 users."
2958,'',"[centurylink] Initial take at the centurylink cloud API\nI've been working on some initial implementation to the CenturyLink Cloud API.  They are still developing and implementing their v2 API, I implemented a few of the available requests but none of the models.  I did implement a bit of the v1 API, at least as much as I needed for my project.\r\nI'm not too familiar with the testing requirements of a new provider, I could use some discussion and guidance on what should be added at this point."
2954,'',"[vsphere] modify vm_clone request to perform a windows sysprep on the image\nI need to modify the Vsphere vm_clone request so that when a windows VM is cloned, it is sysprep'd, and joined to an AD domain.  \r\n\r\nIn summary, this will involve replacing the current RbVmomi::VIM::CustomizationLinuxPrep object that is passed to the Vsphere API with an RbVmomi::VIM::CustomizationSysprep (parameter based), or RbVmomi::VIM::CustomizationSysprepText (to use an unattend.xml rendered from ERB).\r\n\r\nWould the maintainers prefer that this work be done in the current vm_clone request (making decisions on the OS type), or would it be better to create something like a vm_win_clone request?\r\n\r\nAny other requirements?\r\n"
2950,'','[vsphere] datacenter, cluster, resource_pool, mac_addresses details missing\nWhen I issue a list_virtual_machines, the datacenter, cluster, resource_pool, mac_addresses fields seem to not come across properly:\r\n\r\n```\r\n {"id"=>"5029f2a5-6162-025b-7da4-a8790961f0ed",\r\n  "name"=>"cloned-ubuntu",\r\n  "uuid"=>"4229703c-388e-f28d-4a49-5b263cd3b633",\r\n  "template"=>false,\r\n  "parent"=>Folder("group-v69"),\r\n  "hostname"=>nil,\r\n  "operatingsystem"=>nil,\r\n  "ipaddress"=>nil,\r\n  "power_state"=>"poweredOff",\r\n  "connection_state"=>"connected",\r\n  "hypervisor"=>\r\n   #<Proc:0x000000038a2390@/usr/lib64/ruby/gems/1.9.1/gems/fog-1.22.0/lib/fog/vsphere/compute.rb:150>,\r\n  "tools_state"=>"toolsNotInstalled",\r\n  "tools_version"=>"guestToolsNotInstalled",\r\n  "memory_mb"=>1024,\r\n  "cpus"=>1,\r\n  "corespersocket"=>1,\r\n  "overall_status"=>"green",\r\n  "guest_id"=>"ubuntu64Guest",\r\n  "mo_ref"=>"vm-79",\r\n  "datacenter"=>\r\n   #<Proc:0x000000038a2480@/usr/lib64/ruby/gems/1.9.1/gems/fog-1.22.0/lib/fog/vsphere/compute.rb:148>,\r\n  "cluster"=>\r\n   #<Proc:0x000000038a2408@/usr/lib64/ruby/gems/1.9.1/gems/fog-1.22.0/lib/fog/vsphere/compute.rb:149>,\r\n  "resource_pool"=>\r\n   #<Proc:0x000000038a2340@/usr/lib64/ruby/gems/1.9.1/gems/fog-1.22.0/lib/fog/vsphere/compute.rb:151>,\r\n  "mac_addresses"=>\r\n   #<Proc:0x000000038a22c8@/usr/lib64/ruby/gems/1.9.1/gems/fog-1.22.0/lib/fog/vsphere/compute.rb:155>,\r\n  "path"=>"/Datacenters/testdc/vm/New VMs",\r\n  "relative_path"=>"testdc/New VMs"}]\r\n111'
2945,'',"Improving Google authentication mechanisms\ngoogle/storage uses a legacy Amazon-compatible authentication system that still works, but has some limitations and requires some hackery to get working in a non-trivial case. It looks for the parameters :google_storage_access_key_id and :google_storage_secret_access_key\r\n\r\ngoogle/compute embraces the newer service account model, and accepts :google_project, google_client_email, :google_key_location, :google_key_string and :google_client\r\n\r\nInstances provisioned on Google Compute Engine can be authorized at launch time with service_account_scopes, which preauthorize the instance on various Google OAuth scopes, e.g.: https://www.googleapis.com/auth/devstorage.full_control -- once this is done, a GET query to the Google metadata server from that instance will return a valid token for the service for that instance scoped to its own project -- no other service accounts required.\r\n\r\nI would propose:\r\n\r\n1) expanding google/storage's vocabulary to accept the same service account parameters as google/compute\r\n\r\n2) expanding the vocabulary of google/compute to allow service_account_scopes to be set at instance launch time\r\n\r\n3) adding a parameter to both google/compute and google/storage to attempt using an OAuth token from the metadata service if fog is running on a preauthorized instance\r\n\r\nThis would allow a fog user to provision a Compute Engine node using fog and a provisioning service account, preauthorize that node to connect to Cloud Storage (and/or other Google OAuth scopes), and then have that node be able to run and interact with Cloud Storage, Datastore, etc. without needing to be issued its own unique service account.\r\n\r\nI can work on this and it doesn't look too terribly difficult, but I haven't contributed to fog before and this is really my first time looking at its internals. Before I waste too much effort, does this all sound worthwhile, and is there anyone actively maintaining the google stuff that I can coordinate with?"
2938,'',"vSphere 5.5U1 - SystemStackError: stack level too deep\nI'm trying to test fog with vSphere 5.5U1 and have started with this gist example: https://gist.github.com/jedi4ever/1216529\r\n\r\nruby 1.9.3p448 (2013-06-27) [x86_64-linux]\r\nfog (1.22.0)\r\nnokogiri (1.6.2.1)\r\nrbvmomi (1.6.0) <- Had to downgrade in order to get past RuntimeError: unknown VMODL type AnyType error\r\n\r\nHowever when trying to do a server list I get the error:\r\n\r\n```\r\n>> f.servers\r\nSystemStackError: stack level too deep\r\n        from /home/vagrant/.gem/ruby/1.9.1/gems/fog-core-1.22.0/lib/fog/core/attributes.rb:14\r\n```"
2937,'','listing files in a directory with a delimiter and iterating through it seems to not work\nI am seeing something which is a little strange. I have a bucket on S3, I want to get all the files in that bucket but want to filter out a sub-folder I have there. So I am doing this:\r\n\r\n`directory = S3.directories.get(fog_bucket, prefix: "gold", delimiter: "ignoreme")`\r\n\r\nnow when I do:\r\n\r\n`directory.files.count  `\r\n\r\nI get the right number(10), everything under ignoreme is not part of the count, but when I do this.\r\n\r\n```ruby\r\ndirectory.files.each do |file|\r\n  p file.key\r\nend\r\n```\r\n\r\nIt prints out the files under ignoreme, and the loop is run 14 times, am I missing anything here?'
2932,'','AWS security group tests have become unstable\nI\'ve been so busy travelling to the fog summit I missed that `tests/aws/requests/compute/security_group_tests.rb` has been failing randomly on different Travis settings for a while.\r\n\r\nhttps://travis-ci.org/fog/fog/jobs/25614603#L1105 is one of many failures.\r\n\r\nIt seems unstable enough that every build is failing and what I have noticed (but didn\'t look at further) is lots of people going "Hey it\'s not my changes!" about something so this hasn\'t been looked at.\r\n\r\nNeeds fixing or I\'ll disable the test.'
2928,'','aws/models/storage/files breaks in JRuby with "service and directory are required for this operation"\nI am the author of [Sluice](https://github.com/snowplow/sluice/blob/0.2.0/lib/sluice/storage/s3/s3.rb) which uses fog to perform lots of file operations on S3.\r\n\r\nIt works fine in Ruby, but in JRuby file ops involving Arrays of `Fog::Storage::AWS::File`s are erroring out with "error: org.jruby.embed.EvalFailedException: (ArgumentError) service and directory are required for this operation".\r\n\r\nHere are full steps to reproduce:\r\n\r\n```ruby\r\nvagrant@precise64:/tmp$ mkdir sluice-test\r\nvagrant@precise64:/tmp$ cd sluice-test/\r\nvagrant@precise64:/tmp/sluice-test$ rvm use jruby\r\nUsing /home/vagrant/.rvm/gems/jruby-1.7.11\r\nvagrant@precise64:/tmp/sluice-test$ jruby -S gem install sluice\r\nSuccessfully installed sluice-0.2.0\r\n1 gem installed\r\n\r\nvagrant@precise64:/tmp/sluice-test$ irb\r\njruby-1.7.11 :001 > require \'sluice\'\r\n => true\r\n\r\njruby-1.7.11 :002 > s3 = Sluice::Storage::S3::new_fog_s3_from(\r\njruby-1.7.11 :003 >       "eu-west-1",\r\njruby-1.7.11 :004 >       "xxx",\r\njruby-1.7.11 :005 >       "yyy")\r\n => #<Fog::Storage::AWS::Real:2150 @aws_credentials_expire_at=nil @connection=#\r\n<Fog::XML::Connection:0x29aa48fe @excon=#<Excon::Connection:10d0 @socket_key="https://s3-eu-west-1.amazonaws.com:443" @data={:chunk_size=>1048576, :ciphers=>"HIGH:!SSLv2:!aNULL:!eNULL:!3DES", :connect_timeout=>60, :debug_request=>false, :debug_response=>true, :headers=>{"User-Agent"=>"fog/1.22.0"}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::ResponseParser, Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>false, :nonblock=>true, :omit_default_port=>false, :persistent=>false, :read_timeout=>60, :retry_limit=>4, :ssl_verify_peer=>true, :tcp_nodelay=>false, :uri_parser=>URI, :write_timeout=>60, :host=>"s3-eu-west-1.amazonaws.com", :path=>"", :port=>443, :query=>nil, :scheme=>"https", :user=>nil, :password=>nil}>> @host="s3-eu-west-1.amazonaws.com" @aws_access_key_id="xxx" @persistent=false @port=443 @use_iam_profile=nil @region="eu-west-1" @path_style=false @endpoint=nil @scheme="https" @connection_options={:debug_response=>true, :headers=>{"User-Agent"=>"fog/1.22.0"}, :persistent=>false} @aws_session_token=nil>\r\n\r\nruby-1.7.11 :006 > in_l = Sluice::Storage::S3::Location.new("s3n://test-bucket/from/")\r\n => #<Sluice::Storage::S3::Location:0xed92dbb @dir="from", @bucket="test-bucket", @s3_location="s3n://test-bucket/from/">\r\n\r\njruby-1.7.11 :007 > out_l = Sluice::Storage::S3::Location.new("s3n://test-bucket/to/")\r\n => #<Sluice::Storage::S3::Location:0x295687d9 @dir="to", @bucket="test-bucket", @s3_location="s3n://test-bucket/to/">\r\n\r\njruby-1.7.11 :008 > files_moved = Sluice::Storage::S3::move_files(s3, in_l, out_l, \'.+\', false, false)\r\n  moving files from s3n://test-bucket/from/ to s3n://test-bucket/to/\r\nArgumentError: service and directory are required for this operation\r\nArgumentError: service and directory are required for this operation\r\n       requires at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-core-1.22.0/lib/fog/core/attributes.rb:188\r\n            all at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-1.22.0/lib/fog/aws/models/storage/files.rb:23\r\n      lazy_load at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-core-1.22.0/lib/fog/core/collection.rb:139\r\n           size at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-core-1.22.0/lib/fog/core/collection.rb:22\r\n  process_files at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/sluice-0.2.0/lib/sluice/storage/s3/s3.rb:466\r\n    synchronize at org/jruby/ext/thread/Mutex.java:149\r\n  process_files at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/sluice-0.2.0/lib/sluice/storage/s3/s3.rb:437\r\n           loop at org/jruby/RubyKernel.java:1521\r\n  process_files at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/sluice-0.2.0/lib/sluice/storage/s3/s3.rb:428\r\nArgumentError: service and directory are required for this operation\r\n       requires at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-core-1.22.0/lib/fog/core/attributes.rb:188\r\n            all at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-1.22.0/lib/fog/aws/models/storage/files.rb:23\r\n      lazy_load at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-core-1.22.0/lib/fog/core/collection.rb:139\r\n           size at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/fog-core-1.22.0/lib/fog/core/collection.rb:22\r\n  process_files at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/sluice-0.2.0/lib/sluice/storage/s3/s3.rb:466\r\n    synchronize at org/jruby/ext/thread/Mutex.java:149\r\n  process_files at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/sluice-0.2.0/lib/sluice/storage/s3/s3.rb:437\r\n           loop at org/jruby/RubyKernel.java:1521\r\n  process_files at /home/vagrant/.rvm/gems/jruby-1.7.11/gems/sluice-0.2.0/lib/sluice/storage/s3/s3.rb:428\r\n```\r\n\r\nThe exact same code works fine in Ruby.\r\n\r\nAny idea why JRuby would be struggling with Arrays of Fog Files in a way that vanilla Ruby does not?'
2927,'',"[vcloud_director] `ensure_list!` required in get_vapp, get_network_connection_system_section_vapp\nThe [:NetworkConnectionSection][:NetworkConnections] section of get_vapp.rb returns a Hash for single NIC VMs, and an Array for >1 NIC.\r\n\r\nSimilarly, the [:NetworkConnections] section of get_network_connection_system_section_vapp.rb does the same (it is in effect the same data).\r\n\r\nNormally in this instance we use `ensure_list!` to normalise this to an array before returning to the user.\r\n\r\nI'm logging this as a issue before taking a deeper look into it, in case it affects the model in an adverse way. Otherwise we should correct it as normal.\r\n"
2923,'','Add mock version of post_object_hidden_fields\nHi,\r\n\r\nthe `post_object_hidden_fields` method can be included in `Mock` class as is.\r\n\r\n'
2914,'',"Ftp storage ?\nHello!\r\n\r\nI am working on a Rails project which uses [asset_sync](https://github.com/rumblelabs/asset_sync) gem using fog to upload my app precompiled assets to Amazon S3. Now I need to upload my assets to a custom FTP server. I didn't find an existing fog storage to do that. Is there actually a way?\r\n\r\nI found this related [thread](https://groups.google.com/forum/#!msg/ruby-fog/PvMDEeooCKY/arbkkaD9dH8J). The author of the post highlights the fact that FTP storage is not technically a cloud storage, which seems true to me. Is it the reason why there is no such storage?"
2912,'','added post_create_snapshot to VcloudDirector::Real\nAdded post_create_snapshot to VcloudDirector::Real'
2910,'',"Ec2: If DescribeInstances fails (e.g. because of permissions) on server create, fog hangs\nserver.create just hangs until a timeout occurs.  In debug mode you can see excon retrying and receiving 403's repeatedly."
2906,'','[aws] key_pairs is case sensitive in get() but not at AWS\nI ran into an issue when requesting a key_pair from AWS Compute then trying to create that key which I thought did not exist.  It appears that the key_pairs.get("Keyname") is case sensitive, while AWS is not actually case sensitive.\r\n```\r\nfog.key_pairs.get("Keyname") # => <Fog::Compute::AWS::KeyPair ... >\r\nfog.key_pairs.get("keyname") # => nil\r\n```\r\nbut\r\n```\r\nfog.import_key_pair("keyname", keydata) # => Duplicate => The keypair \'Keyname\' already exists.\r\n```\r\nI saw there was already an issue open that might be related, but I don\'t know if it would fix this issue: https://github.com/geemus/excon/pull/376'
2897,'','linode compute labels\nSharing is caring, in terms of documentation.\r\n\r\nThis is not a fog issue per se, but may affect fog users and that can add a fair bit of pita to heavy users of abstraction.\r\n\r\nSome of Linode\'s API Label strings have undocumented limits that are a little out the norm.\r\n\r\nThe label objects have number of char limits on some strings 32, 1 - 48 arbitrary values that someone may have thought were enough.\r\n\r\nIn terms on the linode.update label context and things coming off the "name" object this is pretty important as in terms of abstraction and automation hostnames can be variable driven and longer than 32 chars and by RFC 1034 they can be 63 chars.  With abstraction generally having a object name to hostname assumption|relationship, this can be problematic.\r\n\r\nDiscovered and report under libcloud but we use fog as well and I know that our abstraction assumptions as users of abstraction will have the same effect with fog users.\r\n\r\nhttps://issues.apache.org/jira/browse/LIBCLOUD-547\r\n\r\nhttps://issues.apache.org/jira/browse/LIBCLOUD-548'
2896,'',"Allow for IAM Role to be specified when creating a new instance\nIt would be great to allow for the IAM Role to be specified when creating a new ec2 instance since it can't be specified after. "
2888,'','Discussion for create new instance in different zone using fog\nI have read and i tried to create new instance on another zone, but getting issues to create in another zone. when i read one blog, which shows that, for create instance in another regions, that depends on the ssh key. so how will be the procedure to create new instance in another region via fog? '
2883,'','Fog.mock! Rackspace public_url always return nil\n```ruby\r\nFog.mock!\r\nconnection = Fog::Storage.new({\r\n  :provider                 => \'Rackspace\',\r\n  :rackspace_username       => \'aaa\',\r\n  :rackspace_api_key        => \'bbb\'\r\n})\r\n\r\nconnection.directories.new(key: "whatever").save\r\n => true\r\nconnection.directories.get("whatever").public_url\r\n => nil\r\n```\r\n\r\nCannot test that if `public_url` always return nil. '
2877,'icco',"Move Google to a separate Gem\nI imagine this process will be talked about a little at the summit, but I'd love to do this this summer.\r\n\r\nI'd be curious about your thoughts on doing this @geemus.\r\n\r\nQuestions that have popped in my head:\r\n\r\n * Should the gem be owned by the fog organization or Google Cloud? \r\n * Testing policies?\r\n * Licensing?\r\n * Switch to semantic versioning?\r\n\r\netc."
2875,'',"Is anyone going to add support for AWS ElasticTranscoder\nOr maybe it's done already somewhere. Thanks for the great work on this Gem!"
2874,'','Openstack testing errors\nError output is below. Someone who has worked on the Fog Openstack code should have a look.\r\n\r\n     Fog::Compute[:openstack] | security_group (openstack) ++++++++      \r\n          tests/openstack/models/compute/security_group_tests.rb\r\n            success\r\n            Fog::Compute[:openstack] | security_group (openstack)\r\n       - returns true\r\n        expected => true\r\n        returned => false\r\n\r\n      tests/openstack/models/compute/security_group_tests.rb\r\n      - succeeds\r\n        expected => true\r\n         returned => false\r\n\r\n       tests/openstack/models/compute/security_group_tests.rb\r\n      - succeeds\r\n         expected => true\r\n        returned => false'
2859,'','[libvirt] add missing vol-delete feature\nThe following `irb` session shows the missing feature:\r\n```ruby\r\n\r\n1.9.2-p320 :019 > client.volumes\r\n =>   <Fog::Compute::Libvirt::Volumes\r\n    [\r\n      <Fog::Compute::Libvirt::Volume\r\n        id="/var/lib/libvirt/images/mytest.img",\r\n        pool_name="default",\r\n        key="/var/lib/libvirt/images/mytest.img",\r\n        name="mytest.img",\r\n        path="/var/lib/libvirt/images/mytest.img",\r\n        capacity=0,\r\n        allocation=0,\r\n        format_type="qcow2"\r\n      >,\r\n      <Fog::Compute::Libvirt::Volume\r\n        id="/var/lib/libvirt/images/test-vol-foo.qcow2",\r\n        pool_name="default",\r\n        key="/var/lib/libvirt/images/test-vol-foo.qcow2",\r\n        name="test-vol-foo.qcow2",\r\n        path="/var/lib/libvirt/images/test-vol-foo.qcow2",\r\n        capacity=5,\r\n        allocation=0,\r\n        format_type="qcow2"\r\n      >,\r\n      <Fog::Compute::Libvirt::Volume\r\n        id="/var/lib/libvirt/images/fog-test.qcow2",\r\n        pool_name="default",\r\n        key="/var/lib/libvirt/images/fog-test.qcow2",\r\n        name="fog-test.qcow2",\r\n        path="/var/lib/libvirt/images/fog-test.qcow2",\r\n        capacity=10,\r\n        allocation=0,\r\n        format_type="qcow2"\r\n      >\r\n    ]\r\n  >\r\n1.9.2-p320 :024 > client.volumes.delete :name => "fog-test.qcow2"\r\n => nil \r\n1.9.2-p320 :028 > client.volumes\r\n =>   <Fog::Compute::Libvirt::Volumes\r\n    [\r\n      <Fog::Compute::Libvirt::Volume\r\n        id="/var/lib/libvirt/images/mytest.img",\r\n        pool_name="default",\r\n        key="/var/lib/libvirt/images/mytest.img",\r\n        name="mytest.img",\r\n        path="/var/lib/libvirt/images/mytest.img",\r\n        capacity=0,\r\n        allocation=0,\r\n        format_type="qcow2"\r\n      >,\r\n      <Fog::Compute::Libvirt::Volume\r\n        id="/var/lib/libvirt/images/test-vol-foo.qcow2",\r\n        pool_name="default",\r\n        key="/var/lib/libvirt/images/test-vol-foo.qcow2",\r\n        name="test-vol-foo.qcow2",\r\n        path="/var/lib/libvirt/images/test-vol-foo.qcow2",\r\n        capacity=5,\r\n        allocation=0,\r\n        format_type="qcow2"\r\n      >,\r\n      <Fog::Compute::Libvirt::Volume\r\n        id="/var/lib/libvirt/images/fog-test.qcow2",\r\n        pool_name="default",\r\n        key="/var/lib/libvirt/images/fog-test.qcow2",\r\n        name="fog-test.qcow2",\r\n        path="/var/lib/libvirt/images/fog-test.qcow2",\r\n        capacity=10,\r\n        allocation=0,\r\n        format_type="qcow2"\r\n      >\r\n    ]\r\n  > \r\n```\r\n\r\nRunning `virsh` directly on the same setup, works fine:\r\n```\r\n$ virsh\r\nWelcome to virsh, the virtualization interactive terminal.\r\n\r\nType:  \'help\' for help with commands\r\n       \'quit\' to quit\r\nvirsh # vol-list  default\r\nName                 Path\r\n-----------------------------------------\r\nfog-test.qcow2       /var/lib/libvirt/images/fog-test.qcow2\r\nmytest.img           /var/lib/libvirt/images/mytest.img\r\ntest-vol-foo.qcow2   /var/lib/libvirt/images/test-vol-foo.qcow2\r\n\r\nvirsh # vol-delete --pool default "fog-test.qcow2"\r\nVol fog-test.qcow2 deleted\r\n                                                                                                                                                               \r\nvirsh # vol-list  default\r\nName                 Path\r\n-----------------------------------------\r\nmytest.img           /var/lib/libvirt/images/mytest.img                            \r\ntest-vol-foo.qcow2   /var/lib/libvirt/images/test-vol-foo.qcow2\r\n```'
2851,'','RackSpace v2 endpoint prroblem\nOn April 9th Rackspace rolled out a change to their end points.\r\n\r\nWe began getting this error running the latest (V 21) of fog:\r\n\r\nFog::Storage::Rackspace::NotFound - [HTTP 404 | tx06c7a8ec698945baaa1e0-0053461014dfw1] resource not found in dfw region:\r\n\r\nRackspace claims this was because we were using the V1 endpoint.\r\n\r\nIt appears that Fog was using the V2 endpoint.\r\n\r\nMeanwhile Rackspace rolled back their change so the problem is gone and is not reproducible.'
2850,'',"diffilculty to get the specified AMI via fog from amazon\nI have been trying to get the specified OS's AMI from amazon via fog,otherwise that list all the images(images.all), which i can't populate in a single step, that taking too time. i have used the describe_image method from  Fog::Compute::AWS::Real, but how to pass the OS name(ubuntu, windows...) to get the corresponding images from amazon via fog"
2833,'','Post multiple message to a Rackspace Cloud Queue with one API call\nThe Rackspace/Marconi API allows up to 10 messages to be posted to a queue with one API call.  Having the ability to do this from Fog would be great, especially since each API call costs money.\r\n\r\nFor reference see:\r\n\r\nhttps://wiki.openstack.org/wiki/Marconi/specs/api/v1#Post_Message.28s.29\r\nhttp://docs.rackspace.com/queues/api/v1.0/cq-gettingstarted/content/insert_messages.html\r\n\r\nBasically, I think the difference is that you post something like this:\r\n\r\n    [{"body": ..., "ttl": 60}, {"body": ..., "ttl": 60}, ...]\r\n\r\nInstead of this:\r\n\r\n    {"body": ..., "ttl": 60}\r\n'
2822,'','Adding support for Cloudstack extractTemplate API\n'
2798,'','Vsphere create blank VM - create_vm.rb issues\nI\'m prototyping the creation of a blank VM, using fog and vmware and I\'m hitting quite a few issues with the fog library.\r\n\r\n**Specs:**\r\nruby-1.9.3-p392\r\nfog (1.16.0)\r\nrbvmomi (1.6.0)\r\nVMware vsphere 4.1\r\n\r\n**Background on the infrastructure:**\r\n- I have a quite outdated vmware 4.1 infrastructure to deal with\r\n- I\'ve found that the latest fog brings as a dependency rbvmomi -v=1.8.1 which doesn\'t work with vsphere 4.1\r\n- I haven\'t tried latest fog with rbvmomi -v=1.6.0, this might work fine ( unknown as of now )\r\n\r\nScript that I\'m using is in this gist: https://gist.github.com/stefancocora/9803779\r\n\r\nI\'m putting together a **Hash** of attributes and then calling $connection.create_vm(attributes)\r\n\r\n@geemus has been very helpful in giving advice on using fog or what to do when fog doesn\'t do what I need. You can see the discussion in the comments on the already mentioned gist.\r\n\r\n**Issues list**\r\nThe issues I\'ve seen with fog are as follows - starting with the last and working back into history:\r\n- Revision 7 - **fog can\'t find the datastore path**\r\n```bash\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:27:in `rescue in create_vm\': failed to create vm: Could not descend into datastores. Please check your path. datastores/GRW_VMCP_MGMT_DATA_003 (ArgumentError)\r\nfrom /home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:9:in `create_vm\'\r\nfrom ./vsphere-grw_mgm-create_vm-prototype.rb:63:in `<main>\'\r\n```\r\n- Revision 6 - in my Hash I was passing interfaces as a Array of Hashes but fog expects it as an $connection.interfaces.new(...) object in create_vm.rb\r\n```ruby\r\n:interfaces =>\r\n[{"mac" => "00:50:56:aa:aa:aa",\r\n"network" => "GRW-CP-MGMT-INFRA-923",\r\n"name" => "Network adapter 1",\r\n"status" => "ok",\r\n"summary" => "VM Network",\r\n}]\r\n```\r\nError:\r\n```bash\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:26:in `rescue in create_vm\': failed to create vm: undefined method `type\' for #<Fog::Compute::Vsphere::Network:0x00000003203700> /home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:70:in `create_interface\' (NoMethodError)\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:42:in `block in device_change\'\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:42:in `map\'\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:42:in `device_change\'\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:14:in `create_vm\'\r\n./vsphere-grw_mgm-create_vm-prototype.rb:63:in `<main>\'\r\nfrom /home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:8:in `create_vm\'\r\nfrom ./vsphere-grw_mgm-create_vm-prototype.rb:63:in `<main>\'\r\n```\r\n- Revision 5 - I was passing the **volumes** as an Array of Hashes but fog, inside create_vm.rb expects is to be an $connection.volumes.new instance in create_vm.rb\r\n```ruby\r\n:volumes =>\r\n[{\r\n"id" => "5303693f-eae09bc7-2dc5-0017a4772800",\r\n"datastore" => $grwmgm_datastore,\r\n"mode" => "persistent",\r\n"size" => 8388608,\r\n"thin" => true,\r\n"name" => "fogtest01",\r\n"size_gb" => 8\r\n}],\r\n```\r\nError:\r\n```bash\r\n/home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:27:in `rescue in create_vm\': failed to create vm: undefined method `datastore\' for #<Hash:0x000000034fc920> (NoMethodError)\r\nfrom /home/stefan/.rvm/gems/ruby-1.9.3-p392@fog/gems/fog-1.16.0/lib/fog/vsphere/requests/compute/create_vm.rb:9:in `create_vm\'\r\nfrom ./vsphere-grw_mgm-create_vm-prototype.rb:65:in `<main>\'\r\n```\r\n'
2785,'','Fog::Compute::AWS::Flavor#cores vs vCPU vs ECU\nI\'m working on a project, where I start instances and based on the number of available cores, I do start more or less processes (say 1 process per CPU core).\r\n\r\nWhen I ask `Fog::Compute::AWS::Flavors.new.get("c3.large").cores` I get 7 (as defined in https://github.com/fog/fog/blob/master/lib/fog/aws/models/compute/flavors.rb). But 7 is the amount of ECU (EC2 Compute Unit), not the number of cores in the system.\r\n\r\nI was wondering if this is intentional (and if I need to create my own lookup), or a mistake.'
2783,'tokengeek',"Add support for global 'compatible' and 'proprietary' options to service\nQuick idea to discuss.\n\nSo along with 'provider' could we not add 'mode' or 'proprietary' as options to base service? \n\nThis dictates if models are created by including a module set by the providers and makes requests public.\n\nFor fog 1.x proprietary is true and exposes requests and uncommon methods that have been added.\n\nFog 2.0/3.0 we change it so it is false. So only the agreed public api to a service and its models are visible.\n\nRather than a boolean we could allow 'mode' and you can declare if you want warnings, proprietary mode or compatible mode.\n\nWe can use this to allow libraries and users to clean up their use of an abstraction layer so they can actually abstract things.\n\nThis is actually a core change but will eventually need work on most providers.\n"
2761,'','VM rename isn\'t persistant (vCloud Director)\nRe-opened as the suggested fix (calling \'save\' method) doesn\'t work.\r\n\r\nRenaming a VM doesn\'t appear to work/persist in vCloud Director:\r\n\r\nirb(main):085:0* vm\r\n=> id="vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\nvapp_id="vapp-56ab1743-d41e-42c3-8bad-8d1a958dc119",\r\nvapp_name="testbox",\r\nname="centos65x64",\r\ntype="application/vnd.vmware.vcloud.vm+xml",\r\nhref="https://myvdc.example.com/api/vApp/vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\nstatus="off",\r\noperating_system="Red Hat Enterprise Linux 6 (64-bit)",\r\nip_address="",\r\ncpu=2,\r\nmemory=2048,\r\nhard_disks=[{"Hard disk 1"=>10240}]\r\n>\r\n\r\nEditing it just as you would for cpu or memory changes it but it doesn\'t remain changed after a reload.\r\n\r\nirb(main):105:0* vm.name = "node1"\r\n=> "node1"\r\n\r\nirb(main):085:0* vm\r\n=> id="vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\nvapp_id="vapp-56ab1743-d41e-42c3-8bad-8d1a958dc119",\r\nvapp_name="testbox",\r\nname="node1",\r\ntype="application/vnd.vmware.vcloud.vm+xml",\r\nhref="https://myvdc.example.com/api/vApp/vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\nstatus="off",\r\noperating_system="Red Hat Enterprise Linux 6 (64-bit)",\r\nip_address="",\r\ncpu=2,\r\nmemory=2048,\r\nhard_disks=[{"Hard disk 1"=>10240}]\r\n>\r\n\r\nirb(main):085:0* vm.reload\r\n=> id="vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\nvapp_id="vapp-56ab1743-d41e-42c3-8bad-8d1a958dc119",\r\nvapp_name="testbox",\r\nname="centos65x64",\r\ntype="application/vnd.vmware.vcloud.vm+xml",\r\nhref="https://myvdc.example.com/api/vApp/vm-fkgdcca5-725a-4e87-bff3-46ef41480b53",\r\nstatus="off",\r\noperating_system="Red Hat Enterprise Linux 6 (64-bit)",\r\nip_address="",\r\ncpu=2,\r\nmemory=2048,\r\nhard_disks=[{"Hard disk 1"=>10240}]\r\n>\r\n\r\nCalling the suggested vm.save method doesn\'t work as the method doesn\'t seem to exist like it does for the network object.\r\n\r\nirb(main):033:0> vm.save\r\nNoMethodError: undefined method save\' for #<Fog::Compute::VcloudDirector::Vm:0x000000019e48b8>\r\nfrom (irb):33\r\nfrom /home/mnewman/.rbenv/versions/1.9.3-p448/bin/irb:12:in\'\r\n'
2759,'','\'account\' attribute not being passed to deploy_virtual_machine method in "fog/cloudstack/requests/compute/deploy_virtual_machine.rb"\nWhile trying to provision a VM on cloudstack using a non-admin user, I encountered the error below, which was vague. From further investigation, I noticed that \'account\' option was not being passed to the **deploy_virtual_machine** method.\r\n```\r\nFog::Compute::Cloudstack::BadRequest: only shared network or isolated network with the same account_id can be added to vm\r\n        from /home/ubuntu/.rvm/gems/ruby-1.9.3-p484/gems/fog-1.18.0/lib/fog/cloudstack/compute.rb:250:in `rescue in issue_request\'\r\n        from /home/ubuntu/.rvm/gems/ruby-1.9.3-p484/gems/fog-1.18.0/lib/fog/cloudstack/compute.rb:232:in `issue_request\'\r\n        from /home/ubuntu/.rvm/gems/ruby-1.9.3-p484/gems/fog-1.18.0/lib/fog/cloudstack/compute.rb:196:in `request\'\r\n        from /home/ubuntu/.rvm/gems/ruby-1.9.3-p484/gems/fog-1.18.0/lib/fog/cloudstack/requests/compute/deploy_virtual_machine.rb:26:in `deploy_virtual_machine\'\r\n        from /home/ubuntu/.rvm/gems/ruby-1.9.3-p484/gems/fog-1.18.0/lib/fog/cloudstack/models/compute/server.rb:105:in `save\'\r\n        from /home/ubuntu/.rvm/gems/ruby-1.9.3-p484/gems/fog-1.18.0/lib/fog/core/collection.rb:52:in `create\'\r\n        from (irb):211\r\n        from /home/ubuntu/.rvm/rubies/ruby-1.9.3-p484/bin/irb:12:in `<main>\'\r\n```\r\n\r\n*deploy_virtual_machine* method is called in *save* method in **fog-1.18.0/lib/fog/cloudstack/models/compute/server.rb**. It turns out that options put together in *save* method was lacking  **\'account\' => account_name** in options hash.\r\n\r\nSo the solution was simply to add "**\'account\' => account_name**" in options hash\r\n```ruby\r\n        def save\r\n          requires :image_id, :flavor_id, :zone_id\r\n\r\n          options = {\r\n            \'templateid\'        => image_id,\r\n            \'serviceofferingid\' => flavor_id,\r\n            \'zoneid\'            => zone_id,\r\n            \'networkids\'        => network_ids,\r\n            \'diskofferingid\'    => disk_offering_id,\r\n            \'name\'              => name,\r\n            \'displayname\'       => display_name,\r\n            \'group\'             => group,\r\n            \'domainid\'          => domain_id,\r\n            \'hostid\'            => host_id,\r\n            \'ipaddress\'         => ip_address,\r\n            \'iptonetworklist\'   => ip_to_network_list,\r\n            \'projectid\'         => project_id,\r\n            \'keypair\'           => key_name,\r\n            \'userdata\'           => user_data,\r\n            \'account\'           => account_name,      # <<=== this line\r\n          }\r\n    ...\r\n    ...\r\n```\r\nAny chance this fix can be merged into fog code please?\r\n\r\n*Further evidence of observation above:*\r\n**BEFORE** account attribute was added to options hash in deploy_virtual_machine, here was the contents of options hash\r\n```\r\n{"templateid"=>"c7104633-0368-4db5-83f1-e926346cb5c9",\r\n "serviceofferingid"=>"744dfb58-2a06-442f-9563-5839c4504db8",\r\n "zoneid"=>"6f4b8e91-ff61-4f05-b78d-713e8da4ca2c",\r\n "diskofferingid"=>"ecc8d125-f5df-46f0-8672-e342dac0be0a",\r\n "name"=>"rsyslog-1",\r\n "displayname"=>"rsyslog:1",\r\n "group"=>nil,\r\n "domainid"=>"3817857a-88f7-11e3-b12f-005056b95a38",\r\n "hostid"=>nil,\r\n "ipaddress"=>"10.30.200.202",\r\n "iptonetworklist"=>nil,\r\n "projectid"=>nil,\r\n "keypair"=>"chef",\r\n "userdata"=> REMOVED,\r\n "command"=>"deployVirtualMachine",\r\n "securitygroupids"=>\r\n  "863a1305-507e-4c47-acdb-59564e7c76e0,7fba911d-a4ac-4993-9a62-b4c06ec6c3b0",\r\n "networkids"=>"fb78ad9c-41ce-48ed-a7eb-3985d43b156f"}\r\n```\r\n**AFTER** account attribute was added to options hash in deploy_virtual_machine, here was the contents of options hash\r\n```\r\n{"templateid"=>"c7104633-0368-4db5-83f1-e926346cb5c9",\r\n "serviceofferingid"=>"744dfb58-2a06-442f-9563-5839c4504db8",\r\n "zoneid"=>"6f4b8e91-ff61-4f05-b78d-713e8da4ca2c",\r\n "diskofferingid"=>"ecc8d125-f5df-46f0-8672-e342dac0be0a",\r\n "name"=>"rsyslog-1",\r\n "displayname"=>"rsyslog:1",\r\n "group"=>nil,\r\n "domainid"=>"3817857a-88f7-11e3-b12f-005056b95a38",\r\n "hostid"=>nil,\r\n "ipaddress"=>"10.30.200.202",\r\n "iptonetworklist"=>nil,\r\n "projectid"=>nil,\r\n "keypair"=>"chef",\r\n "userdata"=> REMOVED,\r\n "command"=>"deployVirtualMachine",\r\n "securitygroupids"=>\r\n  "863a1305-507e-4c47-acdb-59564e7c76e0,7fba911d-a4ac-4993-9a62-b4c06ec6c3b0",\r\n "networkids"=>"fb78ad9c-41ce-48ed-a7eb-3985d43b156f",\r\n :account=>"stage"}\r\n```'
2750,'',"If you are trying to :delete VM which ISO image defined key is nil.\nFog doesn't create correct volume for iso images, and therefore delete on iso image volume is problematic."
2740,'',"iam.put_role_policy JSON Encoding\nSorry if I'm doing this all wrong, but I noticed that fog JSON encodes the policy document, which causes things to fail.\r\n\r\nOnce you comment out the JSON encoding portion and leave it as is, then the call goes through.\r\n\r\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/requests/iam/put_role_policy.rb"
2718,'',"Work towards service based gems\nThis is an old idea I've probably mentioned it before but worth highlighting for discussion.\r\n\r\nSince fog was originally an abstraction layer, we should investigate ways to create service based gems instead of provider centric ones.\r\n\r\nThis benefits tools that do one thing such as vagrant plugins (compute) or carrierwave uploading (storage) by requiring an abstraction layer over multiple providers who offer that one service.\r\n\r\nThe interface code should be part of `fog-core` but a `fog-compute` gem bundles providers who offer compute services.\r\n\r\nThis does introduce old dependency problems since AWS does everything any service gem pulls in XML stuff which becomes an annoying glitch if you want to use a standard interface over another DNS provider.\r\n\r\nWe could look at smarter loading of gems. I had a buggy as hell prototype that looked for `fog-*` gems installed on the system containing a registration class, tested some stuff (if their own dependencies were met) and required them.\r\n\r\nThe registration code allowed you to query a service for providers that were available and you had credentials for. I stopped because testing with Shindo syntax was too slow.\r\n\r\nAnyway before we run off and create 40 provider based gems that **enforce** lock in due to incompatible interfaces we should probably go back to the original benefit of `fog` as abstracting half a dozen cloud services.\r\n\r\n/cc @geemus but all are invited to comment."
2701,'','403 aws access denied\nHey, I\'ve been trying to upload images to aws with carrierwave, currently I\'m getting this error\r\n\r\n```\r\nExcon::Errors::Forbidden: Expected(200) <=> Actual(403 Forbidden)\r\n  response => #<Excon::Response:0xd91cd0c @data={:body=>"<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>34A7FEEC4AA9B144</RequestId><HostId>+pwgviyQ1kSSmtYrsoxu5i4oyqqwO2HSAbAeCCLqKa4IxWgWpPiPDMT3n+jOkmO9</HostId></Error>", :headers=>{"x-amz-request-id"=>"34A7FEEC4AA9B144", "x-amz-id-2"=>"+pwgviyQ1kSSmtYrsoxu5i4oyqqwO2HSAbAeCCLqKa4IxWgWpPiPDMT3n+jOkmO9", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"", "Date"=>"Thu, 20 Feb 2014 00:55:57 GMT", "Connection"=>"close", "Server"=>"AmazonS3"}, :status=>403, :remote_ip=>"207.171.163.152"}, @body="<?xml version=\\"1.0\\" encoding=\\"UTF-8\\"?>\\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>34A7FEEC4AA9B144</RequestId><HostId>+pwgviyQ1kSSmtYrsoxu5i4oyqqwO2HSAbAeCCLqKa4IxWgWpPiPDMT3n+jOkmO9</HostId></Error>", @headers={"x-amz-request-id"=>"34A7FEEC4AA9B144", "x-amz-id-2"=>"+pwgviyQ1kSSmtYrsoxu5i4oyqqwO2HSAbAeCCLqKa4IxWgWpPiPDMT3n+jOkmO9", "Content-Type"=>"application/xml", "Transfer-Encoding"=>"", "Date"=>"Thu, 20 Feb 2014 00:55:57 GMT", "Connection"=>"close", "Server"=>"AmazonS3"}, @status=403, @remote_ip="207.171.163.152">\r\nfrom /home/a/.rvm/gems/ruby-2.0.0-p353@i/gems/excon-0.31.0/lib/excon/middlewares/expects.rb:6:in `response_call\'\r\n```\r\n\r\nI tried updating gems and I\'m in the latest version, I also check other posts about that error but nothing seems to work, do I missing something?'
2695,'','[ Vagrant/Cloudstack ]: "list_virtual_machines" to include the "projectid" property.\nGuys, Hi. Thanks for all your efforts! I am using Vagrant and its "vagrant-cloudstack" plug-in. My "cloudstack" environment requires the "projectid" parameter passed to find my virtual machine and allow the "vagrant up" process to complete. It has to be part of the "list_virtual_machines" function. So far, I have patched the "list_virtual_machines.rb" file as a work-around. I\'ve also escalated that to the "vagrant-cloudstack" developer(s). \r\n... \r\nhttps://github.com/klarna/vagrant-cloudstack/issues/10\r\n...\r\nCould you please comment on the feasibility of a fix going in that direction?\r\n\r\nThanks in advance. Regards, Andrei\r\n'
2686,'','Mocking fog S3 file copy not including options hash\nI\'m noticing that when I try to fake a file copy to set a content-type in the options hash, the file doesn\'t get updated with the content-type option I\'m trying to set:\r\n\r\n```\r\nFog.mock!\r\nfile = fog_dir.files.create(:key => "image.png", :public => true)\r\n\r\noptions = {\r\n  \'Content-Type\' => "image/png",\r\n  \'x-amz-metadata-directive\' => \'REPLACE\'\r\n}\r\nfile.copy file.directory.key, file.key, options\r\n\r\n# Failing\r\nfog_dir.files.head(file_name).content_type.should eql "image/png"\r\n```\r\n\r\nAlso see my stackoverflow question http://stackoverflow.com/questions/21835327/faking-fog-s3-file-copy'
2682,'',"[OpenStack] Create an OpenStack provider that can be easily reused by other OpenStack-based providers\nIf you're a Fog developer working on a Fog provider for an OpenStack cloud, you're either going to:\r\n\r\n* Reinvent the wheel\r\n* Copy-paste much of the Fog OpenStack implementation\r\n\r\nBoth of these solutions are undesirable.\r\n\r\nInstead, Fog's OpenStack provider should be easily reusable within other Fog providers. Currently, this does not seem to be possible as the code within Fog OpenStack seems to be tightly coupled.  For instance, the <code>initialize</code> method in <code>Fog::OpenStack::Compute</code> sets multiple instance variables, an acceptable behavior in an initializer, but also authenticates against that cloud's Keystone auth and eagerly creates a connection to the service's endpoint.\r\n\r\nAn ideal Fog OpenStack provider would loosely couple its behaviors. Setting instance variables should be isolated from authentication and creating the service connection.\r\n\r\nDecoupling these behaviors in the existing Fog OpenStack provider would result in an API-breaking change. This is undesirable.\r\n\r\nInstead, we propose a ground up rewrite of the Fog OpenStack provider, designed from the ground up to be resuable by other Fog providers.  This will allow us, the OpenStack Fog developers, to better leverage one another's work.  \r\n\r\nA rewrite, instead of a refactoring, somewhat eases the migration path for current Fog OpenStack users. It seems better to create a whole new Fog API for OpenStack, and allow developers to transition to it, than to piecemeal break the existing API over several releases.\r\n\r\nWe (Rackspace) and HP have only a few days ago gotten together behind this effort.  Out of a desire to be good Ruby citizens, and in the interest of transparency, I am opening this issue as a forum to include other contributors to the current Fog OpenStack provider in the discussion.\r\n\r\n![Peace and long life](http://www.todayifoundout.com/wp-content/uploads/2010/06/Spock_vulcan-salute.png)"
2656,'',"Support AWS Support API\nAmazon provides an API for managing support tickets. It'd be awesome for Fog to provide these APIs. http://docs.aws.amazon.com/awssupport/latest/APIReference/Welcome.html\r\n\r\nI volunteer to write the support for the AWS Support API. I'm submitting the ticket as a placeholder in case anybody else is working on this as well - or in case the Fog maintainers object before I put too much time into it."
2654,'','Allow filter options to be passed to Storage::AWS::File#each\nThis is a very small pull request that allows for specifying the same options you can pass to `File#all` to `File#each` as well. \r\n\r\nI personally needed it to be able to paginate through more than 1,000 objects on S3 with a prefix option set. \r\n\r\nIf you think you may be interested in accepting this I can look into adding test coverage for it.'
2650,'',"Increase Dyn DNS timeout to 60, with a retry backoff.\nWe've had a rash of Dyn DNS API calls time out recently. In a support ticket with them, they suggested a longer retry period, with less frequent requests after 10 seconds.\r\n\r\nThis new code runs but has NOT been tested because at the moment their jobs are running fast enough to return status 200, not 307. If the direction of this change is acceptable, I'll do more to ensure it is tested thoroughly."
2644,'','Update release process to use Github Release Notes\nGithub has recently announced first class support for [Releases](https://github.com/blog/1547-release-your-software). It would be nice to update the release process to use this mechanism so users are able to consume this information in a more automated fashion.\r\n'
2629,'','Fog.mock! proposal to allow experimenting with Excon Stubs\nProposal to start moving towards Excon stubs without breaking Fog mocks.\r\n\r\nWhen you call `Fog.mock!` it should:\r\n\r\n1. Close all excon connections and make sure future connections are opened with `:mock => true` so no real requests are sent inadvertently.\r\n2. When a request is received it should first attempt to run the `Real` code path (which should now be using a mocked connection).  If there is a stub registered it will use it.\r\n3. If the  `Real` path raises `Excon::Errors::StubNotFound` then it should fall back to the `Mock` class.  If no `Mock` exists then it should raise `Fog::Errors::MockNotImplemented`.\r\n\r\nThat should let people start experimenting with Excon stubs (using VCR, WebMock or another other compatible tool) without breaking any current mocks.  It would even allow you to selectively override existing mocks in projects using Fog, to simulate error conditions or alternate data.'
2626,'tokengeek',"Replace/phase out current data validator with JSON schema\nThis was just raised on #1266 \r\n\r\nThe current code for testing if the data from an API response is limited and a bit buggy (https://github.com/fog/fog/blob/master/lib/fog/schema/data_validator.rb)\r\n\r\nI already had a major clean up on it whilst keeping backward compatibility but there's still a few corner cases I find and it's missing functionality.\r\n\r\nAt Brightbox we've been testing our JSON output using https://github.com/hoxworth/json-schema with much better results.\r\n\r\nDespite the name it is not JSON specific and it can verify one hash structure against the schema in another. It just uses JSON schema's terms/names/keys/structure not *only JSON*.\r\n\r\nUnlike a real XML validator it's fairly lightweight so could be included and used by either JSON or XML apis to ensure the `data` hash after parsing matches a schema.\r\n\r\nSo I propose that we add a new version of the helper that can be used to replace our undocumented schemas over a transitional period.\r\n\r\nThis will add new helpers to https://github.com/fog/fog/blob/master/tests/helpers/formats_helper.rb and require updates to the schemas.\r\n\r\nI expect including schema files (rather than schemas as Ruby hashes) would be acceptable but making external calls to gain a schema would not be."
2617,'',"[vcloud_director] EdgeGatewayServiceConfiguration poorly handles missing inputs\nThere are several cases in EdgeGatewayServiceConfiguration where a missing parameter will cause a NilClass no such method error (on 'each' and '[]').\r\n\r\nI've hit this in the VirtualServer Persistence section, but a quick review highlights that there are several places where it can occur.\r\n\r\n"
2601,'','Add configuration for path_style to RiakCS Provisioning client. \nDefaults to false if no user input is given (following the style for the s3client default settings).'
2595,'','[Rackspace] Add cloud database backup support\nSee http://docs.rackspace.com/cdb/api/v1.0/cdb-devguide/content/backups.html'
2588,'','[vcloud_director] Added âcreateâ method to catalogs.\n'
2577,'','[Rackspace] All API calls supporting pagination should support pagination in fog\n'
2567,'',"[ec2] server.wait_for { ready? } is swallowing errors\nIf the user doesn't have IAM permissions for DescribeInstances, the wait_for will not show the underlying error and will just spin forever."
2566,'','How to use ssh_add_key for Google server?\nHello, \r\n\r\nSo I\'m trying to use server.add_ssh_key...but it doesn\'t seem to update the server itself (on Google cloud).  It just seems to update my local copy (that I got with service.servers.get(name).  \r\n\r\nWhat is the preferred/accepted method of making the update happen on the actual instance on Google compute?\r\n\r\nI tried server.save after, but I\'m running into an error: "*** ArgumentError Exception: Parameter \'zone\' has an invalid value: https://www.googleapis.com/compute/v1beta16/projects/momentumsi1/zones/us-central1-a. Must match: /^[a-z](?:[-a-z0-9]{0,61}[a-z0-9])?$/." \r\n\r\nThat may be a whole other issue, but it might just be me using .save in a way it\'s not intended (saving a local "copy" to the cloud might work differently or something).  If it is actually an issue (maybe the API changed or something), I can log a different issue.'
2559,'','[OpenStack] Instance addresses are assumed to always be named \'public\' or \'private\'\nI have a cloud where the default names of \'public\' and \'private\' are not used for the collection of addresses returned upon a new server\'s creation.  Newer OpenStack deployments offer metadata along with the addresses to give a hint as to whether they are public or private, but given that with Neutron you can have arbitrary numbers of networks and IP addresses, simply assuming \'public\' and \'private\' here is insufficient.\r\n\r\nMost OpenStack deployments have an extension enabled that gives you metadata called OS-EXT-IPS which gives you a hint as to whether the IP address is public or private.  There is a \'type\' field which can contain the following values: "fixed", "floating", where fixed is assumed private and floating is assumed public.\r\n\r\nFor more detail:\r\nhttps://github.com/openstack/nova/blob/master/doc/api_samples/OS-EXT-IPS/servers-detail-resp.json'
2558,'','[OpenStack] Storage.head_containers errors on a fresh devstack\nApparently, head_containers expects a 204. On a fresh devstack, head_containers gets a 200 and errors.\r\n\r\nPer the [API documentation](http://docs.openstack.org/api/openstack-object-storage/1.0/content/retrieve-account-metadata.html)\r\n\r\n```\r\nThe HTTP return code will be 2xx (between 200 and 299, inclusive) if the request succeeds.\r\n```'
2548,'','Fog::Monitoring does not support Rackspace\nFog::Monitoring appears to exist to support a single provider (stormondemand). However, Rackspace also provides monitoring.\r\n\r\nCurrently, any user who tries to create a Fog::Monitoring instance with a provider of "Rackspace" gets the error\r\n\r\n```\r\nrackspace has no monitoring service\r\n```\r\n\r\nI\'d like to correct this as it could cause confusion to our users.\r\n\r\n@geemus: @krames explained to me that, preferably, fog waits until there are at least 3 providers supporting a feature before creating a new toplevel entity. But as the Fog::Monitoring class already exists, are you ok with us plugging Rackspace into it?'
2541,'','[cloudstack] Add models and requests to support CloudStack advanced network API\nAdd models and requests to support CloudStack advanced network API, which should be used in Cloud Foundry BOSH-CloudStack-CPI project. Most of these features belong to ClousStack API 4.0.x\r\n\r\nThese features include firewall management, associating IP address to vm, enabling static nat, and vlan ip range management etc.\r\n\r\nFiles affected:\r\n\r\nlib/fog/cloudstack/models/compute/firewall.rb\r\nlib/fog/cloudstack/models/compute/firewalls.rb\r\nlib/fog/cloudstack/models/compute/ipaddress.rb\r\nlib/fog/cloudstack/models/compute/ipaddresses.rb\r\nlib/fog/cloudstack/models/compute/key_pair.rb\r\nlib/fog/cloudstack/models/compute/key_pairs.rb\r\nlib/fog/cloudstack/models/compute/nat.rb\r\nlib/fog/cloudstack/models/compute/nats.rb\r\nlib/fog/cloudstack/models/compute/network.rb\r\nlib/fog/cloudstack/models/compute/networks.rb\r\nlib/fog/cloudstack/models/compute/ostype.rb\r\nlib/fog/cloudstack/models/compute/ostypes.rb\r\nlib/fog/cloudstack/models/compute/vlan.rb\r\nlib/fog/cloudstack/models/compute/vlans.rb\r\nlib/fog/cloudstack/requests/compute/associate_ip_address.rb\r\nlib/fog/cloudstack/requests/compute/copy_template.rb\r\nlib/fog/cloudstack/requests/compute/create_firewall_rule.rb\r\nlib/fog/cloudstack/requests/compute/create_tags.rb\r\nlib/fog/cloudstack/requests/compute/create_template.rb\r\nlib/fog/cloudstack/requests/compute/create_vlan_ip_range.rb\r\nlib/fog/cloudstack/requests/compute/delete_tags.rb\r\nlib/fog/cloudstack/requests/compute/delete_vlan_ip_range.rb\r\nlib/fog/cloudstack/requests/compute/disable_static_nat.rb\r\nlib/fog/cloudstack/requests/compute/disassociate_ip_address.rb\r\nlib/fog/cloudstack/requests/compute/enable_static_nat.rb\r\nlib/fog/cloudstack/requests/compute/list_tags.rb\r\nlib/fog/cloudstack/requests/compute/list_vlan_ip_ranges.rb\r\ntests/cloudstack/requests/assosiate_ip_address_tests.rb\r\ntests/cloudstack/requests/create_vlan_range_tests.rb\r\ntests/cloudstack/requests/delete_vlan_range_tests.rb\r\ntests/cloudstack/requests/disable_static_nat_tests.rb\r\ntests/cloudstack/requests/disassosiate_ip_address_tests.rb\r\ntests/cloudstack/requests/enable_static_nat_tests.rb\r\ntests/cloudstack/requests/list_vlan_range_tests.rb'
2540,'','[vcloud_director] making xml generators reusable\npulled out the xml generators from request classes. This would be helpful as virtualHardwareSection is repeated in multiple api requests.\r\n'
2528,'',"[digitalocean|compute] Set reasonable defaults for bootstrap\nI don't know about other compute providers, but EC2 and GCE both have `servers.bootstrap` set up so you can run it without any paramaters. It'd be nice if we set DigitalOcean up to do the same."
2502,'','AWS API failures caused by inability to parse responses with redundant element names\nIt appears as though the SAX parser is ignoring responses that contain repeated element names. Here is a sample response from AWS API (obtained via EC2 command line tools):\r\n\r\nhttps://gist.github.com/BrindleFly/c2fc52847d5773d3267e\r\n\r\nNote the use of <item> element for three purposes: 1) to denote separate reservation items, 2) to denote tag items for a reservation, and 3) for offering types with a specific reservation.\r\n\r\nTo reproduce you need to have an account tagging Amazon reservations and just do:\r\n\r\n```ruby\r\ncompute.describe_reserved_instances.body["reservedInstancesSet"].map {|res|\r\n  puts res.inspect\r\n  puts "-------------"\r\n}\r\n```\r\nYou get the following for output (note the separation of the items):\r\n\r\n```ruby\r\n{"reservedInstancesId"=>"xxxxxxx", "instanceType"=>"t1.micro", "availabilityZone"=>"us-east-1b", "start"=>2013-08-06 18:57:04 UTC, "duration"=>31536000, "fixedPrice"=>62.0, "usagePrice"=>0.0, "instanceCount"=>1, "productDescription"=>"Windows (Amazon VPC)", "state"=>"active"}\r\n-------------\r\n{"offeringType"=>"Heavy Utilization", "amount"=>0.006}\r\n-------------\r\n{}\r\n-------------\r\n```\r\n\r\nThis seems like a pretty serious issue that could impact all AWS API requests.\r\n'
2501,'icco','[google|compute] v1 update and enhancement (fixing tests, Networks setup, Server metadata update, Disk attachment, etc.)\nSince changes needed to move Fog to GCE v1 was made by @carlossg in #2494 I decided to share my work on this field. I plan to add support for Networks setup, Server metadata update and Disks attachment. \r\nCurrently **work is in progress** and I just want to hear feedback from @icco about following things:\r\n- since GCE returns on every operation and as I understand we have synchronous API here, I think we need to add  [wait](https://github.com/allomov/fog/blob/b73e99b1cd09da041a9f3493e3ad588886dc011b/lib/fog/google/models/compute/operation.rb#L45-L55) method to Operation and [use it to determine when operation ends](https://github.com/allomov/fog/blob/b73e99b1cd09da041a9f3493e3ad588886dc011b/lib/fog/google/models/compute/image.rb#L56-L57), `backoff_if_unfound` method can raise exception after 1 sec while inserting take more time;\r\n- you can use `Fog.wait_for` [method](https://github.com/allomov/fog/blob/b73e99b1cd09da041a9f3493e3ad588886dc011b/lib/fog/core/wait_for.rb) within `Compute#backoff_if_unfound` [method](https://github.com/fog/fog/blob/master/lib/fog/google/compute.rb#L104-L122) to DRY this method;\r\n- since we fill only `source` field of `raw_data` attribute for `Image` instance we can escape using additional hash and assign only source URL to `raw_data` attribute, it will reduce repetition (it is the worse idea I have because it will make new version incompatible with previous). Also this field can be refactored to accept `Fog::Storage::Google::File` object.\r\n\r\nThank you for your attention . :sparkling_heart:'
2469,'',"Rackspace Monitoring not handling pagination\nThe [all and overview calls][1] in Rackspace Monitoring don't actually handle pagination which means once you get over 100 entities the behavior changes in a non-obvious way. Since marker is never returned anywhere you can't even manually paginate.\r\n\r\nAttn: @krames \r\n\r\n[1]: https://github.com/fog/fog/blob/master/lib/fog/rackspace/models/monitoring/entities.rb#L16"
2458,'','[vcloud_director] Manage multiple VM connections\nVMs can have multiple connections, but vm.network retrieved only the first one.\r\n\r\nDetails about a real response and a correct output are documented in `lib/fog/vcloud_director/parsers/compute/vm_network.rb`\r\n\r\nThis patch adds options to add, remove and edit VM networks.'
2366,'','[Compute][VcloudDirector] Add Create OrgVdcNetwork / Add Edgegateway model integration / update readme\ncommit 81e460f403f501c44545a7c4abe1561076ac4680\r\nAuthor: tlawrence <tim.lawrence1984@gmail.com>\r\nDate:   Tue Nov 5 16:43:22 2013 +0000\r\n\r\n    Update README.md\r\n\r\n    Added gateway model and orgvdc net creation examples\r\n\r\ncommit 3a4e02e961bc41f8042174bb5345a3f728fcf3d1\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Tue Nov 5 16:08:11 2013 +0000\r\n\r\n    Added Org Vdc Net Creation\r\n    Added EdgeGateway Model Functionality (vdc.edgegateways.all etc)\r\n\r\ncommit f800e1e482e2a3f140a55c30206bbc0e38b29843\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Mon Nov 4 12:03:36 2013 +0000\r\n\r\n    delete old request file\r\n\r\ncommit 80b21e43be630f6af8f6595085893dce08336817\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Mon Nov 4 12:02:31 2013 +0000\r\n\r\n    Changed OrgNet to OrgVDCNet. create now works. Need to handle Gateway\r\n    section for NatRouted\r\n\r\ncommit 31a33a23bd1d43f4fc9a3dce12269fabb5635d36\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Mon Nov 4 11:17:53 2013 +0000\r\n\r\n    Added Mock class. Needs correct XML response\r\n\r\ncommit 50eb8741e2e4f5559fa87a92d9614602faa1a4db\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Sun Nov 3 21:07:09 2013 +0000\r\n\r\n    Partial Net Create Code. Not Working, XML Issues\r\n\r\ncommit 5b82fb3b0626f78dc49cdcf5d9a7ef61c596e359\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Fri Nov 1 13:19:32 2013 +0000\r\n\r\n    Update: Forgot to add the request to compute.rb\r\n\r\ncommit eb7b2c23a6efa8752468551d9943520dab8b33b9\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Fri Nov 1 12:10:54 2013 +0000\r\n\r\n    Added delete_network request and associated model\r\n\r\ncommit 4ac541a7c3ed7ac5258824d8f89b9259c6d1d22b\r\nAuthor: Tim <tim.lawrence1984@gmail.com>\r\nDate:   Fri Nov 1 12:07:01 2013 +0000\r\n\r\n    Added Delete Network Functionality'
2364,'',"AWS route table implementation incomplete\nIt's not possible to associate Route Tables with Subnets using the model interface for AWS.  Creating a Route Table using the model also quietly drops the specified tags and does nothing with them.  This would be a pull request rather than an issue, but I don't have time to fix this in the immediate future, so I'll leave this here and come back to it if noone else has had a chance to fix it in the meantime."
2352,'','[vcloud_director] Delete networks\nAdding delete_network request & associated "destroy" model implementation'
2310,'',"OpenStack boot from snapshot support is partially broken\nThe OpenStack create_server request currently supports passing in block_device_mapping options, but it is only handling a subset of the possible options (specifically volume_size, volume_id, delete_on_termination, and device_name).  The OpenStack API also supports passing in snapshot_id instead of volume_id.  When this is done, the API will first create a volume from the snapshot and then map the new volume as the boot device.  This means that create_server is supporting boot from volume but not boot from snapshot.\r\n\r\nThere is also a specific boot_from_snapshot request in the code currently, but it's not fully functional (it's missing basic parameters like nics) and it's completely redundant since 100% of the functionality can be done in create_server just by handling the snapshot_id option.\r\n\r\nFor completeness, the logic in create_server should be:\r\n\r\nif snapshot_id and not volume_id then pass snapshot_id, else pass volume_id\r\n\r\nThis will align with the OpenStack API and allow the boot_from_snapshot request to be deleted.\r\n\r\nAPI reference:  https://bugs.launchpad.net/nova/+bug/1029211"
2287,'','AWS CloudFormation ListStacks options\nHello,\r\n\r\nI\'ve been using the API for CloudFormation, and I noticed that in list_stacks,  to give the StackStatusFilter option, instead of specifying an array of members for the option such as \r\n```{"StackStatusFilter"=>["CREATE_IN_PROGRESS", "CREATE_COMPLETE"...]}```\r\nI have to do something like \r\n```\r\n{"StackStatusFilter.member.1"=>"CREATE_FAILED", "StackStatusFilter.member.2"=>"CREATE_IN_PROGRESS"}\r\n```\r\n\r\nIs this intentional?  I know AWS APIs require StackStatusFilter.member.N, but in other API calls with Fog, instead of specifying .member for each option, I can just pass in an array (create_stack has examples of this in their options, with Parameters/Capabilities)'
2175,'',"[cloudstack] group security rules not handling icmpcode / type\nHello\r\n\r\nCloudstack treates icmpcode / icmptype differently to startport and endport   (unlike AWS).   As a result, the current module doesn't support managing the icmp protocol.\r\n\r\nThis applies to the model and mocks. \r\n\r\nThanks"
2168,'','[vcloud_director] Parsing issues\n`vcloud_director` uses `Fog::ToHashDocument` to parse response requests. There are minor issues with this, such as attribute values always being String regardless of declared type in the schema, and less-minor issues with variable-length sequences, manifesting as parsed responses containing `:Key => Hash` or `:Key => [Hash, Hash]` depending on the sequence length. cf. #2134, #2155, #2166. There will be many more such occurrences.\r\n\r\nWhether `Fog::ToHashDocument` is behaving as intended or not, it\'s used by other providers so it\'s probably unwise to consider whether it should be \'fixed\'.\r\n\r\nIt seems undesirable to continue with piecemeal fixes. An obvious solution is to hook into `end_document` and force all sequences to Arrays, but today I came across what looks like a major issue:\r\n\r\nIn:\r\n```xml\r\n<Capabilities>\r\n  <SupportedHardwareVersions>\r\n    <SupportedHardwareVersion>vmx-04</SupportedHardwareVersion>\r\n    <SupportedHardwareVersion>vmx-07</SupportedHardwareVersion>\r\n    <SupportedHardwareVersion>vmx-08</SupportedHardwareVersion>\r\n  </SupportedHardwareVersions>\r\n</Capabilities>\r\n```\r\nOut:\r\n```ruby\r\n:Capabilities=>{\r\n  :SupportedHardwareVersions=>{\r\n    :SupportedHardwareVersion=>"vmx-08"\r\n  }\r\n}\r\n```\r\n\r\nIn view of the above, I\'m going to propose that `vcloud_director` needs bespoke response parsers, but I\'m open to other suggestions before embarking on it.'
2160,'',"Openstack methods assume the extension for floating IP's is loaded\nserver.public_ip_address and server.private_ip_address fail when executed against an Openstack implementation without the floating-ip extension loaded. I'm not sure how common this is, but Rackspace does it. While fog has a separate Rackspace provider, other small openstack implementations may follow their lead on config options.\r\n\r\nStacktraces:\r\n\r\n    irb(main):006:0> server.public_ip_address\r\n    Fog::Compute::OpenStack::NotFound: Fog::Compute::OpenStack::NotFound\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/expects.rb:10:in `response_call'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/response_parser.rb:8:in `response_call'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:349:in `response'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:247:in `request'\r\n    from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/core/connection.rb:57:in `request'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/core/deprecated/connection.rb:20:in `request'\r\n       from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/compute.rb:339:in `request'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/requests/compute/list_all_addresses.rb:10:in `list_all_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:95:in `all_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:110:in `floating_ip_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:116:in `floating_ip_address'\r\n        from (irb):6\r\n        from /usr/local/bin/irb:12:in `<main>'\r\n\r\n    irb(main):007:0> server.private_ip_address\r\n    Fog::Compute::OpenStack::NotFound: Fog::Compute::OpenStack::NotFound\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/expects.rb:10:in `response_call'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/middlewares/response_parser.rb:8:in `response_call'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:349:in `response'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/excon-0.25.3/lib/excon/connection.rb:247:in `request'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/core/connection.rb:57:in `request'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/core/deprecated/connection.rb:20:in `request'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/compute.rb:339:in `request'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/requests/compute/list_all_addresses.rb:10:in `list_all_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:95:in `all_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:110:in `floating_ip_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:122:in `private_ip_addresses'\r\n        from /usr/local/Cellar/ruby/1.9.3-p392/lib/ruby/gems/1.9.1/gems/fog-1.15.0/lib/fog/openstack/models/compute/server.rb:126:in `private_ip_address'\r\n        from (irb):7\r\n        from /usr/local/bin/irb:12:in `<main>'\r\n\r\nThis was discovered while testing kitchen-openstack: https://github.com/RoboticCheese/kitchen-openstack/issues/16"
2076,'',"No paging support for Rackspace Cloud Databases's Databases\n`Fog::Rackspace::Databases::Databases` does not support paging through the list of databases."
2019,'',"auto_scaling_group.instances does not return only instances for that group\nhere's a gist that shows the problem:\r\nhttps://gist.github.com/akatz/798561a1f893b8a6750f\r\n\r\nbut essentially calling instances on an autoscaling group returns all auto scaling instances. I def don't expect that.\r\n\r\nRelevant line here:\r\nhttps://github.com/fog/fog/blob/master/lib/fog/aws/models/auto_scaling/group.rb#L77-L79"
1990,'',"Add support for gluster volumes in libvirt\nI added support for gluster disk on Libvirt.\r\nGluster disk doesn't have file attribute but does have name.\r\nIn glusterfs name are like 'gluster_volume_name/file'\r\nSee example:\r\n    <disk type='network' device='disk'>\r\n      <driver name='qemu' type='raw' cache='none'/>\r\n      <source protocol='gluster' name='gv0/testglustervm.example.com-disk1'>\r\n        <host name='127.0.0.1'/>\r\n      </source>\r\n      <target dev='vda' bus='virtio'/>\r\n      <alias name='virtio-disk0'/>\r\n    </disk>\r\n\r\n\r\nSee http://libvirt.org/formatdomain.html#elementsDisks"
1978,'',"[Vsphere] added list/get compute resources functions\nThis patch is to add list/get compute resources of vsphere functions to fog. \r\n\r\nUsage:\r\nto list all compute resources: compute.list_compute_resources\r\nto just list effective compute resources(poweron + connected + not in maintenance state) : compute.list_compute_resources({:effective => true})\r\nto get compute resources by name: compute.get_compute_resource('xxx.xxx.xxx.xxx')\r\n\r\nNotice:\r\nVsphere abstracts clusters and hosts that don't belong to any cluster evenly as compute resource, so the return result may refer to either cluster or single host. If you want to get only hosts or clusters, you can use attribute 'isSingleHost' to determine the type. "
1965,'','Getting problem while uploading specific .html to S3 using "gem fog"\nI wrote one code to upload my file to S3 and it is working fine with RUBY but if I try to run same file with JRUBY it is giving error as\r\n```\r\n$ jruby fog_up.rb\r\nLoadError: no such file to load -- jruby_pageant\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/agent/java_pageant.rb:1\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/agent.rb:1\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/agent.rb:20\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/key_manager.rb:1\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/key_manager.rb:4\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/session.rb:1\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh/\r\nauthentication/session.rb:4\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh.\r\nrb:1\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/net-ssh-2.6.6/lib/net/ssh.\r\nrb:11\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/fog-1.12.1/lib/fog/joyent/\r\ncompute.rb:1\r\n  require at org/jruby/RubyKernel.java:1027\r\n  require at c:/jruby-1.7.3/lib/ruby/shared/rubygems/custom_require.rb:55\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/fog-1.12.1/lib/fog/joyent/\r\ncompute.rb:4\r\n  require at org/jruby/RubyKernel.java:1027\r\n   (root) at c:/jruby-1.7.3/lib/ruby/gems/shared/gems/fog-1.12.1/lib/fog/core/pr\r\novider.rb:1\r\n   (root) at fog_up.rb:2\r\n```\r\n\r\nHere is my code\r\n\r\n```ruby\r\nrequire \'rubygems\'\r\nrequire \'fog\'\r\n\r\ndata = File.open("file_name.html")\r\nbucket = \'BUCKET_NAME\'\r\npath = \'FOLDER_PATH\'\r\nconnection = Fog::Storage.new(\r\n  :provider => \'AWS\',\r\n  :aws_access_key_id => \'ACCESS_KEY\',\r\n  :aws_secret_access_key => \'SECRET_KEY\'\r\n)\r\n\r\ndirectory = connection.directories.get(bucket, prefix: path)\r\n\r\n# Upload to S3\r\nfile = directory.files.create(\r\n  :key    => \'file_name.html\',\r\n  :body   => data,\r\n  :public => true\r\n)\r\n```'
1915,'','Issue #1909 Allocate IP Address fails on Eucalyptus\n'
1839,'','Mocking in AWS generates invalid IP\nWhen Mocking AWS server the IP address generated using random_numbers are larger than a byte (e.g. octet ends up being 999, or anything < 254). '
1825,'','Setting region of AWS::Compute after initialization\nIt would be nice to be able to change the aws region AFTER the connection object is created, however this does not seem to be possible.  The host and excon connection still point to ec2.us-east-1.amazonaws.com even though the region has been set to \'us-west-1\'. \r\n\r\n1.9.2p290 :024 > ec2_connection = Fog::Compute::AWS.new(:aws_access_key_id => \'AKIAI....\', :aws_secret_access_key => \'wrun.............\')\r\n => #<Fog::Compute::AWS::Real:70116107567500 @use_iam_profile=nil @aws_access_key_id="AKIAIK.........." @aws_credentials_expire_at=nil @connection_options={} @region="us-east-1" @instrumentor=nil @instrumentor_name="fog.aws.compute" @version="2012-12-01" @endpoint=nil @host="ec2.us-east-1.amazonaws.com" @path="/" @persistent=false @port=443 @scheme="https" @connection=#<Fog::Connection:0x007f8a5b5d17f8 @excon=#<Excon::Connection:7f8a5b5d12d0 @data={:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"User-Agent"=>"fog/1.9.0"}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/atistler/.rvm/gems/ruby-1.9.2-p290@cloudstack/gems/excon-0.21.0/data/cacert.pem", :ssl_verify_peer=>false, :uri_parser=>URI, :write_timeout=>60, :host=>"ec2.us-east-1.amazonaws.com", :path=>"/", :port=>"443", :query=>nil, :scheme=>"https", :user=>nil, :password=>nil} @socket_key="https://ec2.us-east-1.amazonaws.com:443">, @persistent=false>>\r\n1.9.2p290 :025 > ec2_connection.region = \'us-west-1\'\r\n => "us-west-1"\r\n1.9.2p290 :026 > ec2_connection\r\n => #<Fog::Compute::AWS::Real:70116107567500 @use_iam_profile=nil @aws_access_key_id="AKIAIKTPL6FEOAZCNTYQ" @aws_credentials_expire_at=nil @connection_options={} @region="us-west-1" @instrumentor=nil @instrumentor_name="fog.aws.compute" @version="2012-12-01" @endpoint=nil @host="ec2.us-east-1.amazonaws.com" @path="/" @persistent=false @port=443 @scheme="https" @connection=#<Fog::Connection:0x007f8a5b5d17f8 @excon=#<Excon::Connection:7f8a5b5d12d0 @data={:chunk_size=>1048576, :connect_timeout=>60, :headers=>{"User-Agent"=>"fog/1.9.0"}, :idempotent=>false, :instrumentor_name=>"excon", :middlewares=>[Excon::Middleware::Expects, Excon::Middleware::Idempotent, Excon::Middleware::Instrumentor, Excon::Middleware::Mock], :mock=>false, :nonblock=>true, :read_timeout=>60, :retry_limit=>4, :ssl_ca_file=>"/Users/atistler/.rvm/gems/ruby-1.9.2-p290@cloudstack/gems/excon-0.21.0/data/cacert.pem", :ssl_verify_peer=>false, :uri_parser=>URI, :write_timeout=>60, :host=>"ec2.us-east-1.amazonaws.com", :path=>"/", :port=>"443", :query=>nil, :scheme=>"https", :user=>nil, :password=>nil} @socket_key="https://ec2.us-east-1.amazonaws.com:443">, @persistent=false>>'
1806,'','[aws|compute] VPC support related to addresses (elastic IPs)\ni found a few bugs when writing tests against mocks related to allocating, associating, and disassociating elastic IPs in VPC.'
1794,''," Created API request generator. Added support for all cloudstack API com...\nI had submitted the pull request #1762\r\nFollowing the suggestions from dm1try I create a API request generator.\r\nI also added support for all other missing cloudstack API calls.\r\n\r\nA have a couple of questions:\r\n1 - In the compute file for cloudstack I see that all the api request files are required.\r\nWouldn't be better to require just one file where all the api request files are required, this way decoupling the compute file from the api requests?\r\n\r\n2 - Another question is regarding the Mock class.\r\nI would like to automate the creation of the Mock class as well as the Real class.\r\nAnd also create tests for all the API requests. so we can have a solid and robust away to update future api changes.\r\n\r\nIf you guys like the ideas and want to go ahead  with #1 and #2 I can create the issues so we can keep track of them\r\n\r\nI really need to have this pull requests committed since we are planning to put our scripts in production and they depend on this commit, so if there are any changes still pending please let me know and I'll fix them asap.\r\n\r\nThanks \r\n\r\n*what time do you guys usually go to irc?\r\n"
1791,'','Adding Dropbox, Box, ...\nIs it possible to add dropbox.com & box.com storage?'
1773,'','Fix circular requires in fog\nWhen run with -w fog prints out 1763 lines of warnings, most of which\r\nare:\r\n\r\n    warning: loading in progress, circular require considered harmful - [file]\r\n\r\nfollowed by a backtrace showing the circular require path.\r\n\r\nEach of these circular requires are pulling in the fog provider\r\nnamespace, but due to the explicit namespacing in fog this is not\r\nnecessary.\r\n\r\nThe require may be necessary to have the service properly registered\r\nwith the provider.  Without this require this patch may break a user who\r\nrequires "fog/openstack/compute", but I am unsure if this is a supported\r\nuse of fog, please advise.'
1762,'','Added some more cloudstack api support.\nJust added some extra calls that I needed to use in a project.'
1746,'','add missing attributes to aws describe_reserved_instances parser\nIn particular it looks like tagSet, instanceTenancy, currencyCode, recurringCharges:amount and recurringCharges:frequency. See: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-ItemType-DescribeReservedInstancesResponseSetItemType.html\r\n\r\nAlso, since tagSet has <item> tags it is throwing off the parser when tags are present to make it appear as though there are one or more (empty) instances in the return value.'
1741,'nirvdrum','[vsphere|compute] add template model details\nCurrently\r\n    templates = @fog.list_templates(options)\r\nwill only return the `id` field.\r\n\r\n@jeffmccune  this PR pads out the model with a bunch of other fields.\r\n'
1737,'','delete_on_termination=true attribute on new volume is not set on create \nI am using a config hash to create a new EBS volume and attach it to an existing server like so:\r\n```\r\n      new_ebs_config = {\r\n                        \'availability_zone\'     => \'us-east-1d,\r\n                        \'size\'                  => 20,\r\n                        \'device\'                => "/dev/sdj",\r\n                        \'delete_on_termination\' => true,\r\n                        \'type\' => \'standard\'\r\n                        \'server\' => instance_id\r\n      }\r\n      new_volume = @ec2.volumes.create(new_ebs_config)\r\n```\r\n\r\nThe `delete_on_termination` attribute is not being set on this new volume after it has been attached to the server. I have been using \r\n```\r\n          @ec2.modify_instance_attribute(\r\n            @instance_id, {\r\n              \'BlockDeviceMapping.1.DeviceName\'              => config[\'device\'],\r\n              \'BlockDeviceMapping.1.Ebs.DeleteOnTermination\' => config[\'delete_on_termination\'].to_s\r\n            }\r\n          )\r\n```\r\n\r\nIt would be nice to have it set after `attach` is called if `server` is part of the passed in config. '
1622,'',"[openstack|identity] get_user_by_name request does not work as expected\nIt looks like Identity.get_user_by_name returns the full list of users currently and tests fail against a real installation.\r\n\r\nI believe @drbrain noted this first (see b430ec6a20eb1216130df5024e32d18c4a60c3d6), so the question is, should we tweak the request to return the user requested or should we remove it?\r\n\r\n@dprince?\r\n\r\nI'd like to open a pull request if there's consensus around this feature."
1521,'',"AWS AutoScaling group min_size & max_size getting set to 0\nWhen creating an auto scaling group, the `min_size` and `max_size` parameters are getting overridden to 0. I've tried looking through the code, but the way the mappings/aliases/etc is very strange to me, so I'm not sure where the error is occurring.\r\n\r\nThe way I'm trying to create the group is:\r\n\r\n    as = Fog::AWS::AutoScaling.new(...)\r\n    group = as.groups.create(..., :min_size => 1, :max_size => 2, ...)\r\n\r\nI've put in code in the `Fog::AWS::AutoScaling::Group#save` method and at that point, both `max_size` and `min_size` are `0`.\r\n\r\n(This is with the 1.9.0 gem)"
1503,'','AWS auto scaling: availability zones are not a required parameter\nCurrently AWS::AutoScaling::Group has `availability_zones` as a required parameter. Per the [AWS API documentation](http://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_CreateAutoScalingGroup.html), availability zones are not a required parameter when creating an auto scaling group. If you provide VPCZoneIdentifier (subnet IDs), the zone(s) is optional.'
1487,'','[azure] support within fog\nfog::azure would make life much nicer for folks interacting with Azure'
1480,'','[vsphere] searching for VM improved to search whole cluster instead of current folder.\nSorry for the duplicate, the other one closed when I was trying to rebase an update to the pull request.\r\n\r\nThe current search options will either only find based on UUID or by VM name. The issue with the VM name is it will only check the top level folder instead of the whole datacenter which means if you use folders for organization the VM will never be found unless at top level. I also moved some functionality to a new function so other functions can take advantage of it without having to duplicate code. Like if I want to just verify that a VM exists and a method can be created to call and verify that a VM was returned as oppose to going through the hash build.\r\n\r\nThe only caveat is the get_virtual_machine will take a while depending on how many VMs are returned because the attribute of the name appears to not be included as part of the view created and accessing that property looks like it makes another call which slows down the entire process.\r\n\r\nraw_list_all_virtual_machines method was created and list_all_virtual_machines calls it so methods like the get_vm_by_name do not have to wait for the hash build from list_all_virtual_machines because the hash build is very slow depending on the VMs returned. An example would be, in my environment we have 600 VMs and just searching for a name takes about ~30 seconds, to build the hash takes about ~4 minutes.\r\n'
1430,'',"add user data information in cloudstack\nadd  params 'user_data' when create virtualmachine interface"
1418,'','"Connection" should be fully wrapped with mocks\nWhilst working on #1392 and general other changes I got the feeling that we are missing a layer or two of abstraction.\r\n\r\nWe have `Fog::Connection` which is a wrapper to Excon. However we get back an `Excon::Response` object which is technically an implementation detail (which HTTP library we are using).\r\n\r\nI think we should be returning a fog specific response. This would also allow us to move the response body parsing to this response object as well.\r\n\r\nIf you look within a `Fog::Service` however, it\'s collections have `requests` and mocked requests. Where this is standing out is for the local virtualisation systems like VirtualBox and Vsphere.\r\n\r\nThe connection within those services is not a HTTP connection to a remote service. Often a \'connection\' through a native Ruby library to the hypervisor.\r\n\r\nThe other abstraction problem is fog\'s mocking is implemented at the Service level. So the factory will give you one of two different classes `Real` or `Mock`. So we are duplicating code or relying on `Shared` modules or worse having two different implementations.\r\n\r\nSo rather than just isolating the live connection to an API we actually have two blocks of code that rely on a HTTP interface.\r\n\r\nSo we are leaking Excon out and we are setting ourselves up so that the request/response model through it\'s interface is the definitive way.\r\n\r\nMy idea for improving this so far:\r\n\r\n* Create errors and a response object as the response for a "request"\r\n* Providers update request to return response object\r\n* Response object returns parsed data not "body" for parsing\r\n* Abstract response frees providers to create their own Connection subclasses, different input standard output (even if still provider specific data).\r\n* Providers raise suitable general errors for any HTTP or code/socket problems with messages\r\n* Move mocking from the Service level down to the Connection level\r\n\r\nNot exactly trivial changes. Several possible strategies to phase in however.'
1317,'','Supported AWS regions in #supported_regions helper\nThe supported_regions helper is a wrapper around an instance variable\nso that in future, fog users can self-modify the list as data\nto support newly available services in regions, or newly available\nregions; without waiting for fog version releases.'
1309,'','support cloudstack dissociateIpAddress\n'
1287,'','Support multiple vendors in an implementation of common Cloud APIs.\nCurrently the Rackspace and HP implementations are very inconsistent and use different names for the same attribute (ie for hp the name of a volume is name while in rackspace it is display_name).  \n\nA suggestions has been made for openstack|rackspace|hp to Make OpenStack implementations reuse base API code - https://github.com/fog/fog/issues/1144\n\nBut i think a better approach would be to add an vendor connection parameter to the openstack implementation in fog. Then the openstack implementation can check if vendor is HP or RACKSPACE and do slightly different things (ie metadata is different).\n This would provide a more consistent implementation of openstack instead of the separate rackspace and hp implementations although they could still co-exist with the openstack implementation that supported multiple vendors. \n\n Similarly the AWS implementation need to be enhanced to support eucalyptus and CloudStack as vendors in addition to Amazon. \n\n Anyway I hope this provokes discussion because as the cloud matures certain APIs will become dominant  (I reckon AWS, OpenStack, Azure and Google Compute Engine but who knows). We need a way to support multiple vendors of a common API where there are just a small number of differences. '
1252,'','Clearer service definitions and specs\nIn discussing a rough roadmap (#1250) for Fog everyone is keen for us to work on getting clearer definitions of the Fog services that providers should be implementing.\r\n\r\nEven some of the services are muddled. Load balancers is available on several providers but you can\'t just use `LoadBalancer[:provider]` to gain access to the service as you can with `Compute` services.\r\n\r\nSo this issue is to discuss what we can do to get back on track.\r\n\r\nServices that look "official" are:\r\n\r\n* CDN\r\n* Compute\r\n* DNS\r\n* Storage\r\n\r\nAd-hoc services include:\r\n\r\n* Load balancers (defined by Rackspace, `ELB` branded version for AWS and part of Compute\'s models in Brightbox)\r\n\r\n@nirvdrum wanted to audit some of the higher level stuff. Others are welcome to chime in as well.\r\n\r\n@ahmeij mentioned us looking at moving provider specific parts to being non standard extensions (clearly marked as such). Also the possible need for an additional level besides models and requests to wrap provider specific models in these standardised versions.\r\n\r\nThe other part of this is that the interface we define needs to be specified by tests that providers can include and run to ensure they meet the requirements. The tests that currently do this need work.\r\n\r\nI think we can discuss general ideas here and then break each service down as further issues to decide exactly what a standard Fog service should be capable of.'
1210,'','[openstack] :openstack_auth_url should not require trailing /tokens\n[Rubiojr\'s gist](https://gist.github.com/2627365) is the first Google hit for "ruby fog openstack". Notice how the parameters for `Fog::Compute.new` there are mostly direct equivalents of the `OS_*` environment variables of the [Unified CLI](http://wiki.openstack.org/UnifiedCLI/Authentication), except for `OS_AUTH_URL_FOG`. That is because the common `OS_AUTH_URL` is the "identity API endpoint" which, as quoted by the /tokens API output itself, is of the form `scheme://host:5000/2.0`. OS_AUTH_URL_FOG currently needs to be `${OS_AUTH_URL}/tokens`.\r\n\r\nI think `:openstack_auth_url` should be compatible with the unified CLI and not require the trailing /tokens. \r\n\r\nA related issue is that the code distinguishing v1 authentication from v2 requires a trailing / after the 2.0.'
1187,'',"reading s3 upload progress\nI'm using fog via carrierwave to allow users of my app to push videos to s3.  The arrangement right now is a proxying one where they first push the file to my server, then I do some processing and push the output to s3 via fog.  The actual upload happens via creating a Fog::Storage::AWS::File instance.  It works great, but as the uploads can take several minutes I would like to be able to let the client poll me for upload progress so I can inform the user approximately when he'll be able to view his video.  I can't figure out via documentation or looking at the source for the Fog::Storage::AWS::File model how to do this (query upload progress).  Would appreciate guidance.  To be clear, I've figured out how to report progress of the uploads to my server, but I need to know how to poll for (or otherwise be given) the progress of the upload (via fog) from my server to s3."
1120,'','Enhancement to vSphere Cloud Provider\nThis pull request include latest code of vSphere compute/storage/HA services.'
1118,'','Provide easy access to AWS request ids\nWhen debugging issues with Amazon they often want the request ids they provide in responses. It would be nice if fog made these easy to get. There are at least a few complications here:\n\n* the various services provide the request id in different ways: differing headers, within XML responses, etc.\n* hard to get access to the original response on an HTTP status error, such as when `Error.slurp` is used\n* even with access the original response on an HTTP status error, the body is not parsed making it difficult to grab a request id within an XML response\n\nFor reference, here\'s what I\'m using to reliably extract the request id on positive responses from things like `aws_compute.describe_instances` for at least the AWS Compute, ELB and IAM services:\n\n```ruby\ndef extract_request_id(response)\n  if header_and_value = response.headers.detect {|k, v| k =~ /\\Ax-amzn?-request-?id\\z/i }\n    header_and_value.last\n  elsif id = response.body["requestId"]\n    id\n  elsif response.body["ResponseMetadata"] && id = response.body["ResponseMetadata"]["RequestId"]\n    id\n  end\nend\n```\n\nThis would be a lot easier if all AWS services provided the request id in the response headers, ideally using the same header key.'
362,'dylanegan',"Mock only accepts string options\nHi,\r\n\r\nIt's possible I have this wrong, but it looks like the Fog::AWS::Storage::Real class can accept symbols for the options hash, but the Mock class can only accept strings.\r\n\r\nSo whereas this seems to work fine when interacting directly with S3:\r\n\r\n<pre>\r\nresponse = @directory.connection.get_bucket(@directory.key, :prefix => prefix, :max_keys => MAX_KEYS, :marker => marker)\r\n</pre>\r\n\r\nIt must be called like so in order for the Mock implementation to be satisfied:\r\n\r\n<pre>\r\nresponse = @directory.connection.get_bucket(@directory.key, 'prefix' => prefix, 'max-keys' => MAX_KEYS, 'marker' => marker)\r\n</pre>\r\n\r\nSince all the options have defaults or get ignored otherwise, this could trip someone up rather easily."
